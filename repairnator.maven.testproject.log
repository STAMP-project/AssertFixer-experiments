[INFO] Scanning for projects...
[INFO] Inspecting build with total of 4 modules...
[INFO] Installing Nexus Staging features:
[INFO]   ... total of 4 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] kafka-junit
[INFO] kafka-junit-core
[INFO] kafka-junit4
[INFO] kafka-junit5
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building kafka-junit 3.0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:checkstyle (checkstyle-validate) @ kafka-junit ---
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:check (checkstyle-validate) @ kafka-junit ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- license-maven-plugin:3.0:check (default) @ kafka-junit ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building kafka-junit-core 3.0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:checkstyle (checkstyle-validate) @ kafka-junit-core ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:check (checkstyle-validate) @ kafka-junit-core ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ kafka-junit-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ kafka-junit-core ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- license-maven-plugin:3.0:check (default) @ kafka-junit-core ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ kafka-junit-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ kafka-junit-core ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.22.0:test (default-test) @ kafka-junit-core ---
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.pom (2 KB at 5.4 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon/1.0-beta-6/wagon-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon/1.0-beta-6/wagon-1.0-beta-6.pom (13 KB at 302.4 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.pom (4 KB at 90.6 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-providers/1.0-beta-6/wagon-providers-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-providers/1.0-beta-6/wagon-providers-1.0-beta-6.pom (3 KB at 60.6 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.pom (3 KB at 60.5 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.pom (390 B at 11.2 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.pom (704 B at 20.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.pom (8 KB at 210.6 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.pom (4 KB at 109.9 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.pom (4 KB at 100.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.pom (4 KB at 95.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-parent/1.5.0/jackrabbit-parent-1.5.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-parent/1.5.0/jackrabbit-parent-1.5.0.pom (25 KB at 589.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.pom (3 KB at 85.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-api/1.5.3/slf4j-api-1.5.3.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-api/1.5.3/slf4j-api-1.5.3.pom (3 KB at 88.3 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-parent/1.5.3/slf4j-parent-1.5.3.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-parent/1.5.3/slf4j-parent-1.5.3.pom (8 KB at 222.3 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.0/commons-httpclient-3.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.0/commons-httpclient-3.0.pom (8 KB at 224.0 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.pom (2 KB at 40.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.pom (2 KB at 54.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting/2.2.1/maven-reporting-2.2.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting/2.2.1/maven-reporting-2.2.1.pom (2 KB at 45.5 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.pom (2 KB at 46.6 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia/1.1/doxia-1.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia/1.1/doxia-1.1.pom (15 KB at 411.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.jar (11 KB at 142.6 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.jar (110 KB at 1456.6 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.jar (25 KB at 274.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.jar (39 KB at 400.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.jar (52 KB at 535.5 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.jar (30 KB at 699.5 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.jar (18 KB at 482.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.jar (6 KB at 158.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.jar (10 KB at 281.1 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar (298 KB at 2836.7 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.jar (12 KB at 325.6 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.jar (199 KB at 2275.9 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.jar (296 KB at 2792.3 KB/sec)
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running com.salesforce.kafka.test.ZookeeperTestServerTest
log4j: reset attribute= "false".
log4j: Threshold ="null".
log4j: Level value for root is  [INFO].
log4j: root level set to INFO
log4j: Class name: [org.apache.log4j.ConsoleAppender]
log4j: Parsing layout of class: "org.apache.log4j.PatternLayout"
log4j: Setting property [conversionPattern] to [%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n].
log4j: Adding appender named [console] to category [root].
2018-09-26 05:36:13 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:13 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:13 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:zookeeper.version=3.4.12--1, built on 03/27/2018 04:49 GMT
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:host.name=cyclone1
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:java.version=1.8.0_121
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:java.vendor=Oracle Corporation
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:java.class.path=/root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core/target/test-classes:/root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core/target/classes:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/junit/jupiter/junit-jupiter-api/5.2.0/junit-jupiter-api-5.2.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apiguardian/apiguardian-api/1.0.0/apiguardian-api-1.0.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/opentest4j/opentest4j/1.1.0/opentest4j-1.1.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/junit/platform/junit-platform-commons/1.2.0/junit-platform-commons-1.2.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/mockito/mockito-core/2.18.3/mockito-core-2.18.3.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/net/bytebuddy/byte-buddy/1.8.5/byte-buddy-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/net/bytebuddy/byte-buddy-agent/1.8.5/byte-buddy-agent-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/zookeeper/zookeeper/3.4.12/zookeeper-3.4.12.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/jline/jline/0.9.94/jline-0.9.94.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/kafka/kafka-streams/1.0.2/kafka-streams-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/kafka/connect-json/1.0.2/connect-json-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/kafka/connect-api/1.0.2/connect-api-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/rocksdb/rocksdbjni/5.7.3/rocksdbjni-5.7.3.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/kafka/kafka_2.11/1.0.2/kafka_2.11-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/kafka/kafka-clients/1.0.2/kafka-clients-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/lz4/lz4-java/1.4/lz4-java-1.4.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/slf4j/slf4j-simple/1.7.25/slf4j-simple-1.7.25.jar:
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:java.io.tmpdir=/tmp
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:java.compiler=<NA>
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:os.name=Linux
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:os.arch=amd64
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:os.version=3.10.0-862.3.2.el7.x86_64
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:user.name=root
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:user.home=/root
2018-09-26 05:36:13 INFO  ZooKeeperServer:100 - Server environment:user.dir=/root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core
2018-09-26 05:36:13 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:13 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:13 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:13 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:13 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38732
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:zookeeper.version=3.4.12--1, built on 03/27/2018 04:49 GMT
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:host.name=cyclone1
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:java.version=1.8.0_121
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:java.vendor=Oracle Corporation
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:java.class.path=/root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core/target/test-classes:/root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core/target/classes:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/junit/jupiter/junit-jupiter-api/5.2.0/junit-jupiter-api-5.2.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apiguardian/apiguardian-api/1.0.0/apiguardian-api-1.0.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/opentest4j/opentest4j/1.1.0/opentest4j-1.1.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/junit/platform/junit-platform-commons/1.2.0/junit-platform-commons-1.2.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/mockito/mockito-core/2.18.3/mockito-core-2.18.3.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/net/bytebuddy/byte-buddy/1.8.5/byte-buddy-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/net/bytebuddy/byte-buddy-agent/1.8.5/byte-buddy-agent-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/zookeeper/zookeeper/3.4.12/zookeeper-3.4.12.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/jline/jline/0.9.94/jline-0.9.94.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/kafka/kafka-streams/1.0.2/kafka-streams-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/kafka/connect-json/1.0.2/connect-json-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/kafka/connect-api/1.0.2/connect-api-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/rocksdb/rocksdbjni/5.7.3/rocksdbjni-5.7.3.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/kafka/kafka_2.11/1.0.2/kafka_2.11-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/kafka/kafka-clients/1.0.2/kafka-clients-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/lz4/lz4-java/1.4/lz4-java-1.4.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/salesforce/kafka-junit/433262372/.m2/org/slf4j/slf4j-simple/1.7.25/slf4j-simple-1.7.25.jar:
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:java.io.tmpdir=/tmp
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:java.compiler=<NA>
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:os.name=Linux
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:os.arch=amd64
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:os.version=3.10.0-862.3.2.el7.x86_64
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:user.name=root
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:user.home=/root
2018-09-26 05:36:14 INFO  ZooKeeper:100 - Client environment:user.dir=/root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core
2018-09-26 05:36:14 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:38732 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$175/1426329391@275710fc
2018-09-26 05:36:14 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38732. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:14 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38732, initiating session
2018-09-26 05:36:14 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:42836
2018-09-26 05:36:14 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:42836
2018-09-26 05:36:14 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:36:14 INFO  ZooKeeperServer:693 - Established session 0x1017076081c0000 with negotiated timeout 6000 for client /127.0.0.1:42836
2018-09-26 05:36:14 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38732, sessionid = 0x1017076081c0000, negotiated timeout = 6000
2018-09-26 05:36:14 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1017076081c0000
2018-09-26 05:36:15 INFO  ZooKeeper:687 - Session: 0x1017076081c0000 closed
2018-09-26 05:36:15 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:15 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:42836 which had sessionid 0x1017076081c0000
2018-09-26 05:36:15 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1017076081c0000
2018-09-26 05:36:15 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:15 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:15 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:15 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:15 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:15 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:15 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:15 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:15 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:15 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:15 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:15 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:15 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:15 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38732
2018-09-26 05:36:16 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:38732 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$175/1426329391@5af97850
2018-09-26 05:36:16 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38732. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:16 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38732, initiating session
2018-09-26 05:36:16 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:42838
2018-09-26 05:36:16 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:42838
2018-09-26 05:36:16 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-09-26 05:36:16 INFO  ZooKeeperServer:693 - Established session 0x10170760cef0000 with negotiated timeout 6000 for client /127.0.0.1:42838
2018-09-26 05:36:16 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38732, sessionid = 0x10170760cef0000, negotiated timeout = 6000
2018-09-26 05:36:16 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10170760cef0000
2018-09-26 05:36:16 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:42838 which had sessionid 0x10170760cef0000
2018-09-26 05:36:16 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10170760cef0000
2018-09-26 05:36:16 INFO  ZooKeeper:687 - Session: 0x10170760cef0000 closed
2018-09-26 05:36:16 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:16 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:16 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:16 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:16 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:16 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:16 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:16 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:16 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:16 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:16 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:16 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:16 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:16 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:16 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:16 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:37175
2018-09-26 05:36:17 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:37175 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$175/1426329391@5ef60048
2018-09-26 05:36:17 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:37175. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:17 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:37175, initiating session
2018-09-26 05:36:17 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:35268
2018-09-26 05:36:17 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:35268
2018-09-26 05:36:17 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:36:17 INFO  ZooKeeperServer:693 - Established session 0x1017076115f0000 with negotiated timeout 6000 for client /127.0.0.1:35268
2018-09-26 05:36:17 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:37175, sessionid = 0x1017076115f0000, negotiated timeout = 6000
2018-09-26 05:36:17 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1017076115f0000
2018-09-26 05:36:17 INFO  ZooKeeper:687 - Session: 0x1017076115f0000 closed
2018-09-26 05:36:17 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:35268 which had sessionid 0x1017076115f0000
2018-09-26 05:36:17 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1017076115f0000
2018-09-26 05:36:17 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:17 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:17 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:17 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:17 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:17 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:17 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:17 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:17 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:17 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:17 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:17 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:19 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:19 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:19 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:19 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:19 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:19 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:19 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:37175
2018-09-26 05:36:20 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:37175 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$175/1426329391@1d548a08
2018-09-26 05:36:20 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:37175. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:20 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:37175, initiating session
2018-09-26 05:36:20 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:35270
2018-09-26 05:36:20 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:35270
2018-09-26 05:36:20 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-09-26 05:36:20 INFO  ZooKeeperServer:693 - Established session 0x10170761d9c0000 with negotiated timeout 6000 for client /127.0.0.1:35270
2018-09-26 05:36:20 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:37175, sessionid = 0x10170761d9c0000, negotiated timeout = 6000
2018-09-26 05:36:20 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10170761d9c0000
2018-09-26 05:36:20 INFO  ZooKeeper:687 - Session: 0x10170761d9c0000 closed
2018-09-26 05:36:20 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:20 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10170761d9c0000
2018-09-26 05:36:20 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:35270 which had sessionid 0x10170761d9c0000
2018-09-26 05:36:20 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:20 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:20 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:20 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:20 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:20 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:20 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:20 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:20 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:20 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:20 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:20 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:20 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:20 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:20 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46148
2018-09-26 05:36:20 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:21 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46148 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$175/1426329391@16aa0a0a
2018-09-26 05:36:21 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46148. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:21 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46148, initiating session
2018-09-26 05:36:21 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55448
2018-09-26 05:36:21 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:55448
2018-09-26 05:36:21 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:36:21 INFO  ZooKeeperServer:693 - Established session 0x101707621f40000 with negotiated timeout 6000 for client /127.0.0.1:55448
2018-09-26 05:36:21 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46148, sessionid = 0x101707621f40000, negotiated timeout = 6000
2018-09-26 05:36:21 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x101707621f40000
2018-09-26 05:36:21 INFO  ZooKeeper:687 - Session: 0x101707621f40000 closed
2018-09-26 05:36:21 INFO  ClientCnxn:521 - EventThread shut down for session: 0x101707621f40000
2018-09-26 05:36:21 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55448 which had sessionid 0x101707621f40000
2018-09-26 05:36:21 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:21 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:21 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:21 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:21 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:21 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:21 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:21 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:21 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:21 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:21 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:21 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:21 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:21 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46148
2018-09-26 05:36:22 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46148 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$175/1426329391@780cb77
2018-09-26 05:36:22 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46148. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:22 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46148, initiating session
2018-09-26 05:36:22 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55450
2018-09-26 05:36:22 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:55450
2018-09-26 05:36:22 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-09-26 05:36:22 INFO  ZooKeeperServer:693 - Established session 0x1017076265e0000 with negotiated timeout 6000 for client /127.0.0.1:55450
2018-09-26 05:36:22 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46148, sessionid = 0x1017076265e0000, negotiated timeout = 6000
2018-09-26 05:36:22 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1017076265e0000
2018-09-26 05:36:22 INFO  ZooKeeper:687 - Session: 0x1017076265e0000 closed
2018-09-26 05:36:22 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:22 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1017076265e0000
2018-09-26 05:36:22 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55450 which had sessionid 0x1017076265e0000
2018-09-26 05:36:22 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:22 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:22 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:22 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:22 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:22 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:22 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:22 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:22 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:22 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:22 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:22 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:22 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:22 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:22 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46719
2018-09-26 05:36:23 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46719 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$175/1426329391@691a7f8f
2018-09-26 05:36:23 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46719. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:23 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46719, initiating session
2018-09-26 05:36:23 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:56202
2018-09-26 05:36:23 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:56202
2018-09-26 05:36:23 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:36:23 INFO  ZooKeeperServer:693 - Established session 0x10170762ae70000 with negotiated timeout 6000 for client /127.0.0.1:56202
2018-09-26 05:36:23 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46719, sessionid = 0x10170762ae70000, negotiated timeout = 6000
2018-09-26 05:36:23 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10170762ae70000
2018-09-26 05:36:23 INFO  ZooKeeper:687 - Session: 0x10170762ae70000 closed
2018-09-26 05:36:23 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:23 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10170762ae70000
2018-09-26 05:36:23 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:56202 which had sessionid 0x10170762ae70000
2018-09-26 05:36:23 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:23 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:23 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:23 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:23 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:23 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:23 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:23 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:23 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:23 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:23 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:23 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:23 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:23 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:23 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:45085
2018-09-26 05:36:23 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:23 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:23 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:24 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:45085 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$175/1426329391@50a7bc6e
2018-09-26 05:36:24 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:45085. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:24 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:45085, initiating session
2018-09-26 05:36:24 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:52814
2018-09-26 05:36:24 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:52814
2018-09-26 05:36:24 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:36:24 INFO  ZooKeeperServer:693 - Established session 0x10170762f540000 with negotiated timeout 6000 for client /127.0.0.1:52814
2018-09-26 05:36:24 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:45085, sessionid = 0x10170762f540000, negotiated timeout = 6000
2018-09-26 05:36:24 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10170762f540000
2018-09-26 05:36:24 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:52814 which had sessionid 0x10170762f540000
2018-09-26 05:36:24 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10170762f540000
2018-09-26 05:36:24 INFO  ZooKeeper:687 - Session: 0x10170762f540000 closed
2018-09-26 05:36:24 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:24 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:24 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:24 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:24 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:24 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:24 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:24 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:24 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:24 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:24 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:24 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:24 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:24 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:45085
2018-09-26 05:36:25 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:45085 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$175/1426329391@161b062a
2018-09-26 05:36:25 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:45085. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:25 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:45085, initiating session
2018-09-26 05:36:25 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:52816
2018-09-26 05:36:25 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:52816
2018-09-26 05:36:25 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-09-26 05:36:26 INFO  ZooKeeperServer:693 - Established session 0x101707633c70000 with negotiated timeout 6000 for client /127.0.0.1:52816
2018-09-26 05:36:26 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:45085, sessionid = 0x101707633c70000, negotiated timeout = 6000
2018-09-26 05:36:26 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x101707633c70000
2018-09-26 05:36:26 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:52816 which had sessionid 0x101707633c70000
2018-09-26 05:36:26 INFO  ZooKeeper:687 - Session: 0x101707633c70000 closed
2018-09-26 05:36:26 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:26 INFO  ClientCnxn:521 - EventThread shut down for session: 0x101707633c70000
2018-09-26 05:36:26 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:26 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:26 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:26 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:26 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:26 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:26 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:26 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:26 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:26 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:26 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:26 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:26 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:26 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:26 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:37917
2018-09-26 05:36:26 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:26 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:27 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:37917 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$175/1426329391@4034c28c
2018-09-26 05:36:27 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:37917. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:27 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:37917, initiating session
2018-09-26 05:36:27 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43608
2018-09-26 05:36:27 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:43608
2018-09-26 05:36:27 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:36:27 INFO  ZooKeeperServer:693 - Established session 0x101707638370000 with negotiated timeout 6000 for client /127.0.0.1:43608
2018-09-26 05:36:27 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:37917, sessionid = 0x101707638370000, negotiated timeout = 6000
2018-09-26 05:36:27 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x101707638370000
2018-09-26 05:36:27 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43608 which had sessionid 0x101707638370000
2018-09-26 05:36:27 INFO  ZooKeeper:687 - Session: 0x101707638370000 closed
2018-09-26 05:36:27 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:27 INFO  ClientCnxn:521 - EventThread shut down for session: 0x101707638370000
2018-09-26 05:36:27 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:27 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:27 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:27 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:27 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:27 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:27 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:27 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.76 s - in com.salesforce.kafka.test.ZookeeperTestServerTest
[INFO] testGetConnectStringBeforeStartingService  Time elapsed: 0.123 s
[INFO] testStart  Time elapsed: 2.561 s
[INFO] testStopAndStartPreservesData  Time elapsed: 4.243 s
[INFO] testRestartPreservesData  Time elapsed: 2.29 s
[INFO] testRestartCold  Time elapsed: 1.132 s
[INFO] testRestart  Time elapsed: 2.273 s
[INFO] testGetConnectString  Time elapsed: 1.123 s
[INFO] Running com.salesforce.kafka.test.KafkaTestServerTest
2018-09-26 05:36:27 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:27 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:27 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:27 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:27 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:27 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:27 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34203
2018-09-26 05:36:28 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:33740
	advertised.port = 33740
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 22
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:33740
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537932988220-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 33740
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:34203
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:36:28 INFO  KafkaServer:72 - starting
2018-09-26 05:36:28 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:34203
2018-09-26 05:36:28 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:34203 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@359df09a
2018-09-26 05:36:28 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:36:28 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34203. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:28 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:36:28 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34203, initiating session
2018-09-26 05:36:28 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:50774
2018-09-26 05:36:28 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:50774
2018-09-26 05:36:28 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:36:28 INFO  ZooKeeperServer:693 - Established session 0x10170763ca00000 with negotiated timeout 30000 for client /127.0.0.1:50774
2018-09-26 05:36:28 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34203, sessionid = 0x10170763ca00000, negotiated timeout = 30000
2018-09-26 05:36:28 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:36:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170763ca00000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 05:36:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170763ca00000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 05:36:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170763ca00000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 05:36:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170763ca00000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 05:36:29 INFO  KafkaServer:72 - Cluster ID = KClNEkrcQlS-Vn2ssMhBsw
2018-09-26 05:36:29 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537932988220-0/meta.properties
2018-09-26 05:36:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:36:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:36:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:36:29 INFO  LogManager:72 - Loading logs.
2018-09-26 05:36:29 INFO  LogManager:72 - Logs loading complete in 6 ms.
2018-09-26 05:36:29 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:36:29 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:36:29 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:36:29 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:36:29 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:30 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:33740.
2018-09-26 05:36:30 INFO  SocketServer:72 - [SocketServer brokerId=22] Started 1 acceptor threads
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Starting
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Starting
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Starting
2018-09-26 05:36:30 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:36:30 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Starting
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Starting
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Starting
2018-09-26 05:36:30 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:36:30 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] 22 successfully elected as the controller
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Starting become controller state transition
2018-09-26 05:36:30 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Starting up.
2018-09-26 05:36:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170763ca00000 type:setData cxid:0x2a zxid:0x17 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 05:36:30 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Startup complete.
2018-09-26 05:36:30 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=22] Removed 0 expired offsets in 3 milliseconds.
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Incremented epoch to 1
2018-09-26 05:36:30 INFO  ProducerIdManager:72 - [ProducerId Manager 22]: Acquired new producerId block (brokerId:22,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 05:36:30 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Starting up.
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Partitions being reassigned: Map()
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Partitions already reassigned: Set()
2018-09-26 05:36:30 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Starting
2018-09-26 05:36:30 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Startup complete.
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Resuming reassignment of partitions: Map()
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Currently active brokers in the cluster: Set()
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Currently shutting brokers in the cluster: Set()
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Current list of topics in the cluster: Set()
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] List of topics to be deleted: 
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] List of topics ineligible for deletion: 
2018-09-26 05:36:30 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=22] Started replica state machine with initial state -> Map()
2018-09-26 05:36:30 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=22] Started partition state machine with initial state -> Map()
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Ready to serve as the new controller with epoch 1
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Partitions undergoing preferred replica election: 
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Partitions that completed preferred replica election: 
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Resuming preferred replica election for partitions: 
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Starting preferred replica leader election for partitions 
2018-09-26 05:36:30 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=22] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:36:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170763ca00000 type:delete cxid:0x4a zxid:0x1a txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:36:30 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/22 (is it secure? false)
2018-09-26 05:36:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170763ca00000 type:create cxid:0x4b zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:36:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170763ca00000 type:create cxid:0x4c zxid:0x1c txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Starting the controller scheduler
2018-09-26 05:36:30 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:36:30 INFO  ZkUtils:72 - Registered broker 22 at path /brokers/ids/22 with addresses: EndPoint(127.0.0.1,33740,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:36:30 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537932988220-0/meta.properties
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Newly added brokers: 22, deleted brokers: , all live brokers: 22
2018-09-26 05:36:30 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Starting
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] New broker startup callback for 22
2018-09-26 05:36:30 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Controller 22 connected to 127.0.0.1:33740 (id: 22 rack: null) for sending state change requests
2018-09-26 05:36:30 INFO  SocketServer:72 - [SocketServer brokerId=22] Started processors for 1 acceptors
2018-09-26 05:36:30 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:30 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:30 INFO  KafkaServer:72 - [KafkaServer id=22] started
2018-09-26 05:36:30 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:33740]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:36:30 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:30 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:30 INFO  KafkaServer:72 - [KafkaServer id=22] shutting down
2018-09-26 05:36:30 INFO  KafkaServer:72 - [KafkaServer id=22] Starting controlled shutdown
2018-09-26 05:36:30 INFO  KafkaController:72 - [Controller id=22] Shutting down broker 22
2018-09-26 05:36:30 INFO  KafkaServer:72 - [KafkaServer id=22] Controlled shutdown succeeded
2018-09-26 05:36:30 INFO  SocketServer:72 - [SocketServer brokerId=22] Stopping socket server request processors
2018-09-26 05:36:30 INFO  SocketServer:72 - [SocketServer brokerId=22] Stopped socket server request processors
2018-09-26 05:36:30 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 22], shutting down
2018-09-26 05:36:30 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 22], shut down completely
2018-09-26 05:36:30 INFO  KafkaApis:72 - [KafkaApi-22] Shutdown complete.
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Shutting down
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Stopped
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Shutdown completed
2018-09-26 05:36:30 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Shutting down.
2018-09-26 05:36:30 INFO  ProducerIdManager:72 - [ProducerId Manager 22]: Shutdown complete: last producerId assigned 0
2018-09-26 05:36:30 INFO  TransactionStateManager:72 - [Transaction State Manager 22]: Shutdown complete
2018-09-26 05:36:30 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Shutting down
2018-09-26 05:36:30 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Stopped
2018-09-26 05:36:30 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Shutdown completed
2018-09-26 05:36:30 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Shutdown complete.
2018-09-26 05:36:30 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Shutting down.
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Shutting down
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Stopped
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Shutdown completed
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Shutting down
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Shutdown completed
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Stopped
2018-09-26 05:36:30 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Shutdown complete.
2018-09-26 05:36:30 INFO  ReplicaManager:72 - [ReplicaManager broker=22] Shutting down
2018-09-26 05:36:30 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:36:30 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:36:30 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:36:30 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 22] shutting down
2018-09-26 05:36:30 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 22] shutdown completed
2018-09-26 05:36:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Shutting down
2018-09-26 05:36:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Stopped
2018-09-26 05:36:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Shutdown completed
2018-09-26 05:36:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Shutting down
2018-09-26 05:36:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Stopped
2018-09-26 05:36:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Shutdown completed
2018-09-26 05:36:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Shutting down
2018-09-26 05:36:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Stopped
2018-09-26 05:36:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Shutdown completed
2018-09-26 05:36:31 INFO  ReplicaManager:72 - [ReplicaManager broker=22] Shut down completely
2018-09-26 05:36:31 INFO  LogManager:72 - Shutting down.
2018-09-26 05:36:31 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:36:31 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:36:31 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:36:31 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:36:31 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:36:31 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:36:31 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:36:31 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:36:31 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=22] Stopped partition state machine
2018-09-26 05:36:31 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=22] Stopped replica state machine
2018-09-26 05:36:31 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Shutting down
2018-09-26 05:36:31 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Stopped
2018-09-26 05:36:31 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Shutdown completed
2018-09-26 05:36:31 INFO  KafkaController:72 - [Controller id=22] Resigned
2018-09-26 05:36:31 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:36:31 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10170763ca00000
2018-09-26 05:36:31 INFO  ZooKeeper:687 - Session: 0x10170763ca00000 closed
2018-09-26 05:36:31 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:50774 which had sessionid 0x10170763ca00000
2018-09-26 05:36:31 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10170763ca00000
2018-09-26 05:36:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:36:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:36:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:36:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:36:32 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:36:32 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:36:32 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:36:32 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:36:32 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:36:32 INFO  SocketServer:72 - [SocketServer brokerId=22] Shutting down socket server
2018-09-26 05:36:32 INFO  SocketServer:72 - [SocketServer brokerId=22] Shutdown completed
2018-09-26 05:36:32 INFO  KafkaServer:72 - [KafkaServer id=22] shut down completed
2018-09-26 05:36:32 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:32 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:32 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:32 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:32 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:32 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:32 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:32 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:32 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:32 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:32 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:32 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:32 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:32 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:32 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:32 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:44942
2018-09-26 05:36:32 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:33 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:40418
	advertised.port = 40418
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:40418
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537932993796-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 40418
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:44942
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:36:33 INFO  KafkaServer:72 - starting
2018-09-26 05:36:33 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:44942
2018-09-26 05:36:33 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:44942 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@66ea1466
2018-09-26 05:36:33 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:36:33 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:36:33 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:44942. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:33 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:44942, initiating session
2018-09-26 05:36:33 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:52228
2018-09-26 05:36:33 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:52228
2018-09-26 05:36:33 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:36:33 INFO  ZooKeeperServer:693 - Established session 0x101707652690000 with negotiated timeout 30000 for client /127.0.0.1:52228
2018-09-26 05:36:33 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:44942, sessionid = 0x101707652690000, negotiated timeout = 30000
2018-09-26 05:36:33 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:36:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 05:36:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 05:36:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 05:36:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 05:36:34 INFO  KafkaServer:72 - Cluster ID = -BUdQgZpSUGuV94uVG5npg
2018-09-26 05:36:34 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537932993796-0/meta.properties
2018-09-26 05:36:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:36:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:36:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:36:34 INFO  LogManager:72 - Loading logs.
2018-09-26 05:36:34 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 05:36:34 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:36:34 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:36:34 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:36:34 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:36:34 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:40418.
2018-09-26 05:36:34 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 05:36:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 05:36:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 05:36:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 05:36:34 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:36:34 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:36:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 05:36:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 05:36:34 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:36:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 05:36:34 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 05:36:34 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 05:36:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:36:34 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 05:36:34 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 05:36:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 05:36:34 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 05:36:34 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 05:36:34 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 05:36:34 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 05:36:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x45 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:36:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x46 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:36:34 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:36:34 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,40418,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:36:34 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537932993796-0/meta.properties
2018-09-26 05:36:34 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 05:36:34 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 05:36:34 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 05:36:34 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:40418 (id: 1 rack: null) for sending state change requests
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 05:36:34 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 05:36:34 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:36:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:36:34 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 05:36:35 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:35 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:35 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 05:36:35 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:40418]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:36:35 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:35 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:35 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 05:36:35 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-09-26 05:36:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:setData cxid:0x54 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/transactional-topic1537932992790 Error:KeeperErrorCode = NoNode for /config/topics/transactional-topic1537932992790
2018-09-26 05:36:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x55 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:36:35 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-09-26 05:36:35 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(transactional-topic1537932992790)], deleted topics: [Set()], new partition replica assignment [Map(transactional-topic1537932992790-0 -> Vector(1))]
2018-09-26 05:36:35 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for transactional-topic1537932992790-0
2018-09-26 05:36:35 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for transactional-topic1537932992790-0
2018-09-26 05:36:35 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions transactional-topic1537932992790-0
2018-09-26 05:36:35 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=transactional-topic1537932992790,Partition=0,Replica=1]
2018-09-26 05:36:35 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions transactional-topic1537932992790-0
2018-09-26 05:36:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x5d zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/transactional-topic1537932992790/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/transactional-topic1537932992790/partitions/0
2018-09-26 05:36:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x5e zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/transactional-topic1537932992790/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/transactional-topic1537932992790/partitions
2018-09-26 05:36:35 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=transactional-topic1537932992790,Partition=0,Replica=1]
2018-09-26 05:36:35 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions transactional-topic1537932992790-0
2018-09-26 05:36:35 INFO  Log:72 - [Log partition=transactional-topic1537932992790-0, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:35 INFO  Log:72 - [Log partition=transactional-topic1537932992790-0, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms
2018-09-26 05:36:35 INFO  LogManager:72 - Created log for partition [transactional-topic1537932992790,0] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:35 INFO  Partition:72 - [Partition transactional-topic1537932992790-0 broker=1] No checkpointed highwatermark is found for partition transactional-topic1537932992790-0
2018-09-26 05:36:35 INFO  Replica:72 - Replica loaded for partition transactional-topic1537932992790-0 with initial high watermark 0
2018-09-26 05:36:35 INFO  Partition:72 - [Partition transactional-topic1537932992790-0 broker=1] transactional-topic1537932992790-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:35 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:40418]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-26 05:36:35 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:35 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:35 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:40418]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = MyRandomString1537932995643
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-26 05:36:35 INFO  KafkaProducer:336 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1537932995643] Instantiated a transactional producer.
2018-09-26 05:36:35 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1537932995643] Overriding the default acks to all since idempotence is enabled.
2018-09-26 05:36:35 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:35 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:35 INFO  TransactionManager:346 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1537932995643] ProducerId set to -1 with epoch -1
2018-09-26 05:36:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:setData cxid:0x67 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/__transaction_state Error:KeeperErrorCode = NoNode for /config/topics/__transaction_state
2018-09-26 05:36:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x68 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:36:35 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"2":[1],"1":[1],"3":[1],"0":[1]}}
2018-09-26 05:36:35 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __transaction_state with 4 partitions and replication factor 1 is successful
2018-09-26 05:36:35 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__transaction_state)], deleted topics: [Set()], new partition replica assignment [Map(__transaction_state-1 -> Vector(1), __transaction_state-0 -> Vector(1), __transaction_state-2 -> Vector(1), __transaction_state-3 -> Vector(1))]
2018-09-26 05:36:35 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-09-26 05:36:35 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-09-26 05:36:35 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-09-26 05:36:35 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__transaction_state,Partition=1,Replica=1],[Topic=__transaction_state,Partition=0,Replica=1],[Topic=__transaction_state,Partition=2,Replica=1],[Topic=__transaction_state,Partition=3,Replica=1]
2018-09-26 05:36:35 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-09-26 05:36:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x73 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/1
2018-09-26 05:36:36 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x74 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions
2018-09-26 05:36:36 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x7b zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/0
2018-09-26 05:36:36 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x80 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/2
2018-09-26 05:36:36 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x84 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/3
2018-09-26 05:36:36 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__transaction_state,Partition=1,Replica=1],[Topic=__transaction_state,Partition=0,Replica=1],[Topic=__transaction_state,Partition=2,Replica=1],[Topic=__transaction_state,Partition=3,Replica=1]
2018-09-26 05:36:36 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __transaction_state-3,__transaction_state-0,__transaction_state-1,__transaction_state-2
2018-09-26 05:36:36 INFO  Log:72 - [Log partition=__transaction_state-3, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:36 INFO  Log:72 - [Log partition=__transaction_state-3, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 05:36:36 INFO  LogManager:72 - Created log for partition [__transaction_state,3] in /tmp/1537932993796-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:36 INFO  Partition:72 - [Partition __transaction_state-3 broker=1] No checkpointed highwatermark is found for partition __transaction_state-3
2018-09-26 05:36:36 INFO  Replica:72 - Replica loaded for partition __transaction_state-3 with initial high watermark 0
2018-09-26 05:36:36 INFO  Partition:72 - [Partition __transaction_state-3 broker=1] __transaction_state-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:36 INFO  Log:72 - [Log partition=__transaction_state-0, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:36 INFO  Log:72 - [Log partition=__transaction_state-0, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:36 INFO  LogManager:72 - Created log for partition [__transaction_state,0] in /tmp/1537932993796-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:36 INFO  Partition:72 - [Partition __transaction_state-0 broker=1] No checkpointed highwatermark is found for partition __transaction_state-0
2018-09-26 05:36:36 INFO  Replica:72 - Replica loaded for partition __transaction_state-0 with initial high watermark 0
2018-09-26 05:36:36 INFO  Partition:72 - [Partition __transaction_state-0 broker=1] __transaction_state-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:36 INFO  Log:72 - [Log partition=__transaction_state-1, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:36 INFO  Log:72 - [Log partition=__transaction_state-1, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:36 INFO  LogManager:72 - Created log for partition [__transaction_state,1] in /tmp/1537932993796-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:36 INFO  Partition:72 - [Partition __transaction_state-1 broker=1] No checkpointed highwatermark is found for partition __transaction_state-1
2018-09-26 05:36:36 INFO  Replica:72 - Replica loaded for partition __transaction_state-1 with initial high watermark 0
2018-09-26 05:36:36 INFO  Partition:72 - [Partition __transaction_state-1 broker=1] __transaction_state-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:36 INFO  Log:72 - [Log partition=__transaction_state-2, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:36 INFO  Log:72 - [Log partition=__transaction_state-2, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:36 INFO  LogManager:72 - Created log for partition [__transaction_state,2] in /tmp/1537932993796-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:36 INFO  Partition:72 - [Partition __transaction_state-2 broker=1] No checkpointed highwatermark is found for partition __transaction_state-2
2018-09-26 05:36:36 INFO  Replica:72 - Replica loaded for partition __transaction_state-2 with initial high watermark 0
2018-09-26 05:36:36 INFO  Partition:72 - [Partition __transaction_state-2 broker=1] __transaction_state-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:36 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-2
2018-09-26 05:36:36 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-1
2018-09-26 05:36:36 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-0
2018-09-26 05:36:36 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-3
2018-09-26 05:36:36 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __transaction_state-0. Cache now contains 0 entries.
2018-09-26 05:36:36 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Initialized transactionalId MyRandomString1537932995643 with producerId 0 and producer epoch 0 on partition __transaction_state-0
2018-09-26 05:36:36 INFO  TransactionManager:346 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1537932995643] ProducerId set to 0 with epoch 0
2018-09-26 05:36:36 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: transactional-topic1537932992790-0. Cache now contains 0 entries.
2018-09-26 05:36:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:setData cxid:0x96 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 05:36:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x97 zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:36:37 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-09-26 05:36:37 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 05:36:37 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 05:36:37 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:36:37 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:36:37 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:36:37 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:36:37 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:36:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0xd3 zxid:0x3d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 05:36:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0xd4 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 05:36:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0xdd zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 05:36:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0xe3 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 05:36:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0xe9 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 05:36:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0xef zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 05:36:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0xf5 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 05:36:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0xfb zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 05:36:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x101 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 05:36:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x107 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 05:36:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x10d zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 05:36:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x113 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 05:36:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x119 zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 05:36:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x11f zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 05:36:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x126 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 05:36:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x12c zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 05:36:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x132 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 05:36:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x138 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 05:36:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x13e zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 05:36:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x144 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 05:36:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x14a zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 05:36:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x150 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 05:36:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x156 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 05:36:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x15c zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 05:36:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x162 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 05:36:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x168 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 05:36:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x16e zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 05:36:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x174 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 05:36:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x17a zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 05:36:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x180 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 05:36:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x186 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 05:36:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x18c zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 05:36:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x192 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 05:36:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x198 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 05:36:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x19e zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 05:36:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1a4 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 05:36:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1aa zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 05:36:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1b0 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 05:36:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1b6 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 05:36:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1bc zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 05:36:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1c2 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 05:36:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1c8 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 05:36:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1ce zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 05:36:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1d4 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 05:36:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1da zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 05:36:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1e0 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 05:36:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1e6 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 05:36:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1ec zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 05:36:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1f2 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 05:36:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1f8 zxid:0xcf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 05:36:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707652690000 type:create cxid:0x1fe zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 05:36:43 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:36:43 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 05:36:43 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 05:36:43 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:43 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:43 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537932993796-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:44 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537932993796-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:44 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537932993796-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 05:36:44 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 05:36:44 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 05:36:44 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 05:36:44 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Discovered group coordinator 127.0.0.1:40418 (id: 2147483646 rack: null)
2018-09-26 05:36:44 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Revoking previously assigned partitions []
2018-09-26 05:36:44 INFO  AbstractCoordinator:336 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] (Re-)joining group
2018-09-26 05:36:44 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 0 (__consumer_offsets-31)
2018-09-26 05:36:47 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Stabilized group test-consumer-group generation 1 (__consumer_offsets-31)
2018-09-26 05:36:47 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Assignment received from leader for group test-consumer-group for generation 1
2018-09-26 05:36:47 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-31. Cache now contains 0 entries.
2018-09-26 05:36:47 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Successfully joined group with generation 1
2018-09-26 05:36:47 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Setting newly assigned partitions [transactional-topic1537932992790-0]
2018-09-26 05:36:47 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1537932995643] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 05:36:47 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 1 (__consumer_offsets-31)
2018-09-26 05:36:47 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Group test-consumer-group with generation 2 is now empty (__consumer_offsets-31)
2018-09-26 05:36:47 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 05:36:47 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 05:36:47 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:36:47 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 05:36:47 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 05:36:47 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 05:36:47 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 05:36:47 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 05:36:47 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 05:36:47 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 05:36:47 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1
2018-09-26 05:36:47 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 05:36:47 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 05:36:47 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 05:36:47 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 05:36:47 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 05:36:47 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 05:36:47 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 05:36:47 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 05:36:47 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:36:47 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:36:47 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:36:47 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 05:36:47 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 05:36:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 05:36:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 05:36:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 05:36:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 05:36:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 05:36:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 05:36:48 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 05:36:48 INFO  LogManager:72 - Shutting down.
2018-09-26 05:36:48 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:36:48 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:36:48 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:36:48 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:36:48 INFO  ProducerStateManager:72 - [ProducerStateManager partition=transactional-topic1537932992790-0] Writing producer snapshot at offset 2
2018-09-26 05:36:48 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__transaction_state-0] Writing producer snapshot at offset 4
2018-09-26 05:36:48 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2
2018-09-26 05:36:48 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:36:48 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:36:48 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:36:48 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:36:48 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 05:36:48 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 05:36:48 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 05:36:48 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 05:36:48 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 05:36:48 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 05:36:48 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:36:48 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x101707652690000
2018-09-26 05:36:48 INFO  ZooKeeper:687 - Session: 0x101707652690000 closed
2018-09-26 05:36:48 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:52228 which had sessionid 0x101707652690000
2018-09-26 05:36:48 INFO  ClientCnxn:521 - EventThread shut down for session: 0x101707652690000
2018-09-26 05:36:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:36:49 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:36:49 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:36:49 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:36:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:36:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:36:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:36:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:36:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:36:51 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 05:36:51 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 05:36:51 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 05:36:51 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:51 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:51 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:51 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:51 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:51 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:51 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:51 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:51 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:51 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:51 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:51 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:51 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:51 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:51 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:51 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:45449
2018-09-26 05:36:52 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:35227
	advertised.port = 35227
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:35227
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933012639-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 35227
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:45449
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:36:52 INFO  KafkaServer:72 - starting
2018-09-26 05:36:52 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:45449
2018-09-26 05:36:52 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:45449 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@7db0565c
2018-09-26 05:36:52 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:36:52 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:36:52 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:45449. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:52 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:48834
2018-09-26 05:36:52 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:45449, initiating session
2018-09-26 05:36:52 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:48834
2018-09-26 05:36:52 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:36:52 INFO  ZooKeeperServer:693 - Established session 0x10170769c030000 with negotiated timeout 30000 for client /127.0.0.1:48834
2018-09-26 05:36:52 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:45449, sessionid = 0x10170769c030000, negotiated timeout = 30000
2018-09-26 05:36:52 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:36:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170769c030000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 05:36:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170769c030000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 05:36:53 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170769c030000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 05:36:53 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170769c030000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 05:36:53 INFO  KafkaServer:72 - Cluster ID = T_F_9_Y-TNSZfuZJgQccqg
2018-09-26 05:36:53 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933012639-0/meta.properties
2018-09-26 05:36:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:36:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:36:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:36:53 INFO  LogManager:72 - Loading logs.
2018-09-26 05:36:53 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 05:36:53 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:36:53 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:36:53 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:36:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:36:53 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:35227.
2018-09-26 05:36:53 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 05:36:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 05:36:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 05:36:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 05:36:53 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:36:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:36:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 05:36:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 05:36:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 05:36:53 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:36:53 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 05:36:53 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 05:36:53 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:36:53 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 05:36:53 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 05:36:53 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170769c030000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 05:36:53 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 05:36:53 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 05:36:53 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 05:36:53 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 05:36:53 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170769c030000 type:create cxid:0x46 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:36:53 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170769c030000 type:create cxid:0x48 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:36:53 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 05:36:53 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,35227,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set()
2018-09-26 05:36:53 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933012639-0/meta.properties
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 05:36:53 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 05:36:53 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 05:36:53 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:36:53 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170769c030000 type:delete cxid:0x4f zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:36:53 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 05:36:53 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:53 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:53 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 05:36:53 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 05:36:53 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 1, deleted brokers: , all live brokers: 1
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 1
2018-09-26 05:36:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 05:36:53 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:36:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:35227 (id: 1 rack: null) for sending state change requests
2018-09-26 05:36:53 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 05:36:53 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 05:36:53 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 05:36:53 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 05:36:53 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 05:36:53 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 05:36:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 05:36:53 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 05:36:54 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 05:36:54 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 05:36:54 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 05:36:54 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 05:36:54 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 05:36:54 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 05:36:54 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 05:36:54 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 05:36:54 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 05:36:54 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 05:36:54 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:36:54 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:36:54 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:36:54 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 05:36:54 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 05:36:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 05:36:54 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 05:36:54 INFO  LogManager:72 - Shutting down.
2018-09-26 05:36:54 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:36:54 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:36:54 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:36:54 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:36:54 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:36:54 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:36:54 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:36:54 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:36:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 05:36:54 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 05:36:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 05:36:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 05:36:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 05:36:54 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 05:36:54 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:36:54 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10170769c030000
2018-09-26 05:36:54 INFO  ZooKeeper:687 - Session: 0x10170769c030000 closed
2018-09-26 05:36:54 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:48834 which had sessionid 0x10170769c030000
2018-09-26 05:36:54 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10170769c030000
2018-09-26 05:36:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:36:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:36:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:36:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:36:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:36:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:36:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:36:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:36:56 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 05:36:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:36:56 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 05:36:56 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 05:36:56 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:36:56 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:36:56 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:36:56 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:36:56 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:36:56 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:36:56 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:36:56 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:36:56 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:36:56 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:36:56 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:36:56 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:36:56 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:36:56 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:36:56 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:36:56 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:37711
2018-09-26 05:36:56 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:36:57 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:45193
	advertised.port = 45193
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:45193
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933017562-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 45193
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:37711
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:36:57 INFO  KafkaServer:72 - starting
2018-09-26 05:36:57 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:37711
2018-09-26 05:36:57 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:37711 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@5851bd4f
2018-09-26 05:36:57 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:36:57 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:36:57 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:37711. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:36:57 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:37711, initiating session
2018-09-26 05:36:57 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:58588
2018-09-26 05:36:57 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:58588
2018-09-26 05:36:57 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:36:57 INFO  ZooKeeperServer:693 - Established session 0x1017076af3f0000 with negotiated timeout 30000 for client /127.0.0.1:58588
2018-09-26 05:36:57 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:37711, sessionid = 0x1017076af3f0000, negotiated timeout = 30000
2018-09-26 05:36:57 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:36:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 05:36:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 05:36:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 05:36:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 05:36:58 INFO  KafkaServer:72 - Cluster ID = 365jeug7TKmZQALF0tjTyA
2018-09-26 05:36:58 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933017562-0/meta.properties
2018-09-26 05:36:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:36:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:36:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:36:58 INFO  LogManager:72 - Loading logs.
2018-09-26 05:36:58 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 05:36:58 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:36:58 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:36:58 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:36:58 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:36:58 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:45193.
2018-09-26 05:36:58 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 05:36:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 05:36:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 05:36:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 05:36:58 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:36:58 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:36:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 05:36:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 05:36:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 05:36:58 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:36:58 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 05:36:58 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 05:36:58 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:36:58 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 05:36:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 05:36:58 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 05:36:58 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 05:36:58 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 05:36:58 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 05:36:58 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 05:36:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:36:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:36:58 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:36:58 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,45193,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:36:58 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933017562-0/meta.properties
2018-09-26 05:36:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 05:36:58 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 05:36:58 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 05:36:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:45193 (id: 1 rack: null) for sending state change requests
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 05:36:58 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:36:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:36:58 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 05:36:58 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:58 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:58 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 05:36:58 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45193]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:36:58 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:58 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 05:36:58 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-09-26 05:36:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:setData cxid:0x54 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/subscribe-topic1537933016557 Error:KeeperErrorCode = NoNode for /config/topics/subscribe-topic1537933016557
2018-09-26 05:36:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x55 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:36:58 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-09-26 05:36:59 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(subscribe-topic1537933016557)], deleted topics: [Set()], new partition replica assignment [Map(subscribe-topic1537933016557-0 -> Vector(1))]
2018-09-26 05:36:59 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for subscribe-topic1537933016557-0
2018-09-26 05:36:59 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for subscribe-topic1537933016557-0
2018-09-26 05:36:59 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions subscribe-topic1537933016557-0
2018-09-26 05:36:59 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=subscribe-topic1537933016557,Partition=0,Replica=1]
2018-09-26 05:36:59 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions subscribe-topic1537933016557-0
2018-09-26 05:36:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x5d zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/subscribe-topic1537933016557/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/subscribe-topic1537933016557/partitions/0
2018-09-26 05:36:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x5e zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/subscribe-topic1537933016557/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/subscribe-topic1537933016557/partitions
2018-09-26 05:36:59 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=subscribe-topic1537933016557,Partition=0,Replica=1]
2018-09-26 05:36:59 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions subscribe-topic1537933016557-0
2018-09-26 05:36:59 INFO  Log:72 - [Log partition=subscribe-topic1537933016557-0, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:36:59 INFO  Log:72 - [Log partition=subscribe-topic1537933016557-0, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:36:59 INFO  LogManager:72 - Created log for partition [subscribe-topic1537933016557,0] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:36:59 INFO  Partition:72 - [Partition subscribe-topic1537933016557-0 broker=1] No checkpointed highwatermark is found for partition subscribe-topic1537933016557-0
2018-09-26 05:36:59 INFO  Replica:72 - Replica loaded for partition subscribe-topic1537933016557-0 with initial high watermark 0
2018-09-26 05:36:59 INFO  Partition:72 - [Partition subscribe-topic1537933016557-0 broker=1] subscribe-topic1537933016557-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:36:59 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:45193]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-26 05:36:59 WARN  ProducerConfig:246 - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2018-09-26 05:36:59 WARN  ProducerConfig:246 - The configuration 'group.id' was supplied but isn't a known config.
2018-09-26 05:36:59 WARN  ProducerConfig:246 - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2018-09-26 05:36:59 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:59 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:59 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: subscribe-topic1537933016557-0. Cache now contains 0 entries.
2018-09-26 05:36:59 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 05:36:59 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:45193]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-26 05:36:59 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:36:59 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:36:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:setData cxid:0x67 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 05:36:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x68 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:36:59 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-09-26 05:36:59 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 05:36:59 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 05:36:59 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:36:59 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:36:59 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:36:59 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:36:59 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:36:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xa4 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 05:36:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xa5 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 05:36:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xac zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 05:36:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xb2 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 05:36:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xb8 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 05:37:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xbe zxid:0x39 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 05:37:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xc4 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 05:37:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xca zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 05:37:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xd0 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 05:37:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xd6 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 05:37:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xdc zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 05:37:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xe2 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 05:37:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xe8 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 05:37:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xee zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 05:37:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xf4 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 05:37:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0xfa zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 05:37:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x100 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 05:37:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x106 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 05:37:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x10c zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 05:37:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x112 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 05:37:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x118 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 05:37:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x11e zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 05:37:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x124 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 05:37:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x12c zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 05:37:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x132 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 05:37:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x138 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 05:37:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x13e zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 05:37:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x144 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 05:37:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x14a zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 05:37:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x150 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 05:37:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x156 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 05:37:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x15c zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 05:37:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x162 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 05:37:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x168 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 05:37:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x16e zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 05:37:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x174 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 05:37:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x17a zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 05:37:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x180 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 05:37:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x186 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 05:37:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x18c zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 05:37:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x192 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 05:37:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x198 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 05:37:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x19f zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 05:37:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x1a5 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 05:37:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x1ab zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 05:37:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x1b1 zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 05:37:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x1b7 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 05:37:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x1bf zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 05:37:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x1c5 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 05:37:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x1cc zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 05:37:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076af3f0000 type:create cxid:0x1d1 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 05:37:05 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:37:05 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933017562-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:05 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933017562-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:05 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537933017562-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 05:37:05 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 05:37:05 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 1 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 05:37:05 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 05:37:05 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Discovered group coordinator 127.0.0.1:45193 (id: 2147483646 rack: null)
2018-09-26 05:37:05 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Revoking previously assigned partitions []
2018-09-26 05:37:05 INFO  AbstractCoordinator:336 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] (Re-)joining group
2018-09-26 05:37:05 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 0 (__consumer_offsets-31)
2018-09-26 05:37:08 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Stabilized group test-consumer-group generation 1 (__consumer_offsets-31)
2018-09-26 05:37:08 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Assignment received from leader for group test-consumer-group for generation 1
2018-09-26 05:37:08 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-31. Cache now contains 0 entries.
2018-09-26 05:37:08 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Successfully joined group with generation 1
2018-09-26 05:37:08 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Setting newly assigned partitions [subscribe-topic1537933016557-0]
2018-09-26 05:37:08 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 1 (__consumer_offsets-31)
2018-09-26 05:37:08 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Group test-consumer-group with generation 2 is now empty (__consumer_offsets-31)
2018-09-26 05:37:09 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 05:37:09 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 05:37:09 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:37:09 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 05:37:09 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 05:37:09 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 05:37:09 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 05:37:09 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 05:37:09 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 05:37:09 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 05:37:09 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 05:37:09 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 05:37:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 05:37:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 05:37:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 05:37:09 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 05:37:09 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 05:37:09 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 05:37:09 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 05:37:09 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:37:09 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:37:09 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:37:09 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 05:37:09 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 05:37:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 05:37:09 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 05:37:09 INFO  LogManager:72 - Shutting down.
2018-09-26 05:37:09 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:37:09 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:37:09 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:37:09 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:37:10 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2
2018-09-26 05:37:10 INFO  ProducerStateManager:72 - [ProducerStateManager partition=subscribe-topic1537933016557-0] Writing producer snapshot at offset 1
2018-09-26 05:37:11 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:37:11 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:37:11 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:37:11 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:37:11 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 05:37:11 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 05:37:11 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 05:37:11 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 05:37:11 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 05:37:11 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 05:37:11 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:37:11 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1017076af3f0000
2018-09-26 05:37:11 INFO  ZooKeeper:687 - Session: 0x1017076af3f0000 closed
2018-09-26 05:37:11 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:58588 which had sessionid 0x1017076af3f0000
2018-09-26 05:37:11 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1017076af3f0000
2018-09-26 05:37:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:37:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:37:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:37:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:37:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:37:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:37:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:37:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:37:12 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 05:37:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:37:12 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 05:37:12 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 05:37:12 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:37:12 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:37:12 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:37:12 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:37:12 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:37:12 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:37:12 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:37:12 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:37:12 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:37:12 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:37:12 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:37:12 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:37:12 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:37:12 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:37:12 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:37:12 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40519
2018-09-26 05:37:13 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:44252
	advertised.port = 44252
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:44252
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933033419-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 44252
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:40519
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:37:13 INFO  KafkaServer:72 - starting
2018-09-26 05:37:13 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:40519
2018-09-26 05:37:13 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40519 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@24b52d3e
2018-09-26 05:37:13 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:37:13 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:37:13 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40519. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:37:13 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40519, initiating session
2018-09-26 05:37:13 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:57462
2018-09-26 05:37:13 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:57462
2018-09-26 05:37:13 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:37:13 INFO  ZooKeeperServer:693 - Established session 0x1017076ed300000 with negotiated timeout 30000 for client /127.0.0.1:57462
2018-09-26 05:37:13 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40519, sessionid = 0x1017076ed300000, negotiated timeout = 30000
2018-09-26 05:37:13 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:37:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 05:37:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 05:37:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 05:37:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 05:37:14 INFO  KafkaServer:72 - Cluster ID = 8lfeITZJR_e9A3AhFbvU0Q
2018-09-26 05:37:14 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933033419-0/meta.properties
2018-09-26 05:37:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:37:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:37:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:37:14 INFO  LogManager:72 - Loading logs.
2018-09-26 05:37:14 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 05:37:14 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:37:14 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:37:14 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:37:14 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:37:14 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:44252.
2018-09-26 05:37:14 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 05:37:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 05:37:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 05:37:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 05:37:14 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:37:14 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:37:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 05:37:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 05:37:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 05:37:14 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:37:14 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 05:37:14 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 05:37:14 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:37:14 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 05:37:14 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 05:37:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 05:37:14 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 05:37:14 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 05:37:14 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 05:37:14 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 05:37:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:37:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:37:14 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:37:14 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,44252,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:37:14 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933033419-0/meta.properties
2018-09-26 05:37:14 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 05:37:14 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 05:37:14 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 05:37:14 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:44252 (id: 1 rack: null) for sending state change requests
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 05:37:14 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:37:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:37:14 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 05:37:14 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:14 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:14 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 05:37:14 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44252]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:37:14 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:14 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-09-26 05:37:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:setData cxid:0x54 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/testRestartingBroker-1537933032415 Error:KeeperErrorCode = NoNode for /config/topics/testRestartingBroker-1537933032415
2018-09-26 05:37:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x55 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:37:14 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(testRestartingBroker-1537933032415)], deleted topics: [Set()], new partition replica assignment [Map(testRestartingBroker-1537933032415-0 -> Vector(1))]
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for testRestartingBroker-1537933032415-0
2018-09-26 05:37:14 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for testRestartingBroker-1537933032415-0
2018-09-26 05:37:14 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions testRestartingBroker-1537933032415-0
2018-09-26 05:37:14 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=testRestartingBroker-1537933032415,Partition=0,Replica=1]
2018-09-26 05:37:14 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions testRestartingBroker-1537933032415-0
2018-09-26 05:37:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x5d zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/testRestartingBroker-1537933032415/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/testRestartingBroker-1537933032415/partitions/0
2018-09-26 05:37:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x5e zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/testRestartingBroker-1537933032415/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/testRestartingBroker-1537933032415/partitions
2018-09-26 05:37:14 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:37:15 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=testRestartingBroker-1537933032415,Partition=0,Replica=1]
2018-09-26 05:37:15 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions testRestartingBroker-1537933032415-0
2018-09-26 05:37:15 INFO  Log:72 - [Log partition=testRestartingBroker-1537933032415-0, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:15 INFO  Log:72 - [Log partition=testRestartingBroker-1537933032415-0, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:15 INFO  LogManager:72 - Created log for partition [testRestartingBroker-1537933032415,0] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:15 INFO  Partition:72 - [Partition testRestartingBroker-1537933032415-0 broker=1] No checkpointed highwatermark is found for partition testRestartingBroker-1537933032415-0
2018-09-26 05:37:15 INFO  Replica:72 - Replica loaded for partition testRestartingBroker-1537933032415-0 with initial high watermark 0
2018-09-26 05:37:15 INFO  Partition:72 - [Partition testRestartingBroker-1537933032415-0 broker=1] testRestartingBroker-1537933032415-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:15 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:44252]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 05:37:15 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:15 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:15 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: testRestartingBroker-1537933032415-0. Cache now contains 0 entries.
2018-09-26 05:37:15 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 05:37:15 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44252]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:37:15 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:15 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:15 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:44252]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 05:37:15 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:15 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:setData cxid:0x67 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 05:37:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x68 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:37:19 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-09-26 05:37:19 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 05:37:19 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 05:37:19 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:37:19 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:37:19 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:37:19 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:37:19 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:37:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xa4 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 05:37:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xa5 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 05:37:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xae zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 05:37:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xb4 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 05:37:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xba zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 05:37:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xc0 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 05:37:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xc6 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 05:37:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xcc zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 05:37:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xd2 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 05:37:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xd8 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 05:37:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xde zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 05:37:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xe4 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 05:37:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xea zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 05:37:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xf0 zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 05:37:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xf6 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 05:37:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0xfc zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 05:37:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x102 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 05:37:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x109 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 05:37:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x10f zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 05:37:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x115 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 05:37:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x11b zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 05:37:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x121 zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 05:37:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x127 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 05:37:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x12d zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 05:37:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x133 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 05:37:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x139 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 05:37:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x13f zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 05:37:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x147 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 05:37:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x14d zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 05:37:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x153 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 05:37:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x159 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 05:37:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x15f zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 05:37:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x165 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 05:37:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x16b zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 05:37:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x171 zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 05:37:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x177 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 05:37:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x17d zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 05:37:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x183 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 05:37:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x189 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 05:37:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x18f zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 05:37:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x195 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 05:37:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x19b zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 05:37:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x1a1 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 05:37:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x1a8 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 05:37:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x1ae zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 05:37:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x1b4 zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 05:37:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x1bc zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 05:37:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x1c2 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 05:37:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x1c8 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 05:37:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x1ce zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 05:37:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017076ed300000 type:create cxid:0x1d4 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 05:37:25 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:37:25 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:25 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537933033419-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 05:37:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 05:37:25 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 05:37:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 05:37:25 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:44252 (id: 2147483646 rack: null)
2018-09-26 05:37:25 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-09-26 05:37:25 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 05:37:25 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 05:37:25 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:37:25 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 05:37:25 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 05:37:25 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 05:37:25 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 05:37:25 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 05:37:25 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 05:37:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 05:37:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 05:37:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 05:37:25 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 05:37:25 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 05:37:25 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 05:37:25 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 05:37:25 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 05:37:25 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 05:37:25 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 05:37:25 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 05:37:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 05:37:26 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 05:37:26 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 05:37:26 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:37:26 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:37:26 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:37:26 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 05:37:26 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 05:37:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 05:37:26 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 05:37:26 INFO  LogManager:72 - Shutting down.
2018-09-26 05:37:26 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:37:26 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:37:26 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:37:26 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:37:27 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 1
2018-09-26 05:37:28 INFO  ProducerStateManager:72 - [ProducerStateManager partition=testRestartingBroker-1537933032415-0] Writing producer snapshot at offset 2
2018-09-26 05:37:28 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:37:28 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:37:28 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:37:28 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:37:28 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 05:37:28 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 05:37:28 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 05:37:28 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 05:37:28 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 05:37:28 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 05:37:28 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:37:28 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1017076ed300000
2018-09-26 05:37:28 INFO  ZooKeeper:687 - Session: 0x1017076ed300000 closed
2018-09-26 05:37:28 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:57462 which had sessionid 0x1017076ed300000
2018-09-26 05:37:28 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1017076ed300000
2018-09-26 05:37:28 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:37:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:37:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:37:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:37:30 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:37:30 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:37:30 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:37:30 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:37:30 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:37:30 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 05:37:30 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 05:37:30 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 05:37:30 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:37:30 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:37:30 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:37:30 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:37:30 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:37:30 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:37:30 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:37:30 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:37:30 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:37:30 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:37:30 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:37:30 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:37:30 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:37:30 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:37:30 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40519
2018-09-26 05:37:31 INFO  KafkaServer:72 - [KafkaServer id=1] starting
2018-09-26 05:37:31 INFO  KafkaServer:72 - [KafkaServer id=1] Connecting to zookeeper on 127.0.0.1:40519
2018-09-26 05:37:31 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40519 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@5215cd9a
2018-09-26 05:37:31 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:37:31 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:37:31 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40519. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:37:31 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:57490
2018-09-26 05:37:31 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40519, initiating session
2018-09-26 05:37:31 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:57490
2018-09-26 05:37:31 INFO  FileTxnLog:213 - Creating new log file: log.c4
2018-09-26 05:37:31 INFO  ZooKeeperServer:693 - Established session 0x101707732dd0000 with negotiated timeout 30000 for client /127.0.0.1:57490
2018-09-26 05:37:31 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40519, sessionid = 0x101707732dd0000, negotiated timeout = 30000
2018-09-26 05:37:31 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:37:31 INFO  KafkaServer:72 - [KafkaServer id=1] Cluster ID = 8lfeITZJR_e9A3AhFbvU0Q
2018-09-26 05:37:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:37:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:37:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:37:31 INFO  LogManager:72 - Loading logs.
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=testRestartingBroker-1537933032415-0, dir=/tmp/1537933033419-0] Loading producer state from offset 2 with message format version 2
2018-09-26 05:37:31 INFO  ProducerStateManager:72 - [ProducerStateManager partition=testRestartingBroker-1537933032415-0] Loading producer state from snapshot file '/tmp/1537933033419-0/testRestartingBroker-1537933032415-0/00000000000000000002.snapshot'
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=testRestartingBroker-1537933032415-0, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 15 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933033419-0] Loading producer state from offset 1 with message format version 2
2018-09-26 05:37:31 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/1537933033419-0/__consumer_offsets-0/00000000000000000001.snapshot'
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933033419-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:31 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933033419-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:31 INFO  LogManager:72 - Logs loading complete in 130 ms.
2018-09-26 05:37:31 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:37:31 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:37:31 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:37:31 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:37:31 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:44252.
2018-09-26 05:37:31 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 05:37:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 05:37:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 05:37:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 05:37:31 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:37:31 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:37:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 05:37:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 05:37:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 05:37:31 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:37:31 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 05:37:31 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 05:37:31 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:37:31 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Initialized controller epoch to 1 and zk version 0
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 2
2018-09-26 05:37:31 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 05:37:31 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 05:37:31 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 05:37:31 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 05:37:31 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 05:37:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707732dd0000 type:create cxid:0x43 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:37:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707732dd0000 type:create cxid:0x44 zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:37:31 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:37:31 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,44252,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:37:31 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 05:37:31 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:31 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:31 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 05:37:31 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44252]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:37:31 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:31 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set()
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set(testRestartingBroker-1537933032415, __consumer_offsets)
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: __consumer_offsets,testRestartingBroker-1537933032415
2018-09-26 05:37:31 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map([Topic=__consumer_offsets,Partition=48,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=11,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=10,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=21,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=6,Replica=1] -> ReplicaDeletionIneligible, [Topic=testRestartingBroker-1537933032415,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=13,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=34,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=26,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=44,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=46,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=12,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=33,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=47,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=37,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=23,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=42,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=32,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=2,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=43,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=4,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=40,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=28,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=15,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=22,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=3,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=7,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=38,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=16,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=8,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=17,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=36,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=49,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=29,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=45,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=5,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=41,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=27,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=24,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=30,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=31,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=35,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=19,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=20,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=9,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=14,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=25,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=18,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=39,Replica=1] -> ReplicaDeletionIneligible)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-19 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-19 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-30 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-30 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-47 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-47 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-29 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-29 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-41 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-41 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-39 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-39 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-10 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-10 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-17 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-17 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-14 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-14 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-40 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-40 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-18 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-18 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-26 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-26 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-0 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-24 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-24 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-33 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-33 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-20 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-20 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-21 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-21 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-3 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-3 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-22 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-22 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-5 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-5 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition testRestartingBroker-1537933032415-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition testRestartingBroker-1537933032415-0 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-12 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-12 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-8 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-8 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-23 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-23 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-15 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-15 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-48 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-48 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-11 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-11 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-13 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-13 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-49 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-49 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-6 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-6 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-28 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-28 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-4 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-4 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-37 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-37 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-31 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-31 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-44 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-44 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-42 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-42 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-34 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-34 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-46 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-46 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-25 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-25 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-45 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-45 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-27 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-27 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-32 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-32 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-43 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-43 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-36 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-36 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-35 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-35 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-7 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-7 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-9 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-9 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-38 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-38 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-1 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-1 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-2 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-2 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-16 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-16 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:37:31 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map(__consumer_offsets-19 -> OfflinePartition, __consumer_offsets-30 -> OfflinePartition, __consumer_offsets-47 -> OfflinePartition, __consumer_offsets-29 -> OfflinePartition, __consumer_offsets-41 -> OfflinePartition, __consumer_offsets-39 -> OfflinePartition, __consumer_offsets-10 -> OfflinePartition, __consumer_offsets-17 -> OfflinePartition, __consumer_offsets-14 -> OfflinePartition, __consumer_offsets-40 -> OfflinePartition, __consumer_offsets-18 -> OfflinePartition, __consumer_offsets-26 -> OfflinePartition, __consumer_offsets-0 -> OfflinePartition, __consumer_offsets-24 -> OfflinePartition, __consumer_offsets-33 -> OfflinePartition, __consumer_offsets-20 -> OfflinePartition, __consumer_offsets-21 -> OfflinePartition, __consumer_offsets-3 -> OfflinePartition, __consumer_offsets-22 -> OfflinePartition, __consumer_offsets-5 -> OfflinePartition, testRestartingBroker-1537933032415-0 -> OfflinePartition, __consumer_offsets-12 -> OfflinePartition, __consumer_offsets-8 -> OfflinePartition, __consumer_offsets-23 -> OfflinePartition, __consumer_offsets-15 -> OfflinePartition, __consumer_offsets-48 -> OfflinePartition, __consumer_offsets-11 -> OfflinePartition, __consumer_offsets-13 -> OfflinePartition, __consumer_offsets-49 -> OfflinePartition, __consumer_offsets-6 -> OfflinePartition, __consumer_offsets-28 -> OfflinePartition, __consumer_offsets-4 -> OfflinePartition, __consumer_offsets-37 -> OfflinePartition, __consumer_offsets-31 -> OfflinePartition, __consumer_offsets-44 -> OfflinePartition, __consumer_offsets-42 -> OfflinePartition, __consumer_offsets-34 -> OfflinePartition, __consumer_offsets-46 -> OfflinePartition, __consumer_offsets-25 -> OfflinePartition, __consumer_offsets-45 -> OfflinePartition, __consumer_offsets-27 -> OfflinePartition, __consumer_offsets-32 -> OfflinePartition, __consumer_offsets-43 -> OfflinePartition, __consumer_offsets-36 -> OfflinePartition, __consumer_offsets-35 -> OfflinePartition, __consumer_offsets-7 -> OfflinePartition, __consumer_offsets-9 -> OfflinePartition, __consumer_offsets-38 -> OfflinePartition, __consumer_offsets-1 -> OfflinePartition, __consumer_offsets-2 -> OfflinePartition, __consumer_offsets-16 -> OfflinePartition)
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 2
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 05:37:31 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:37:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707732dd0000 type:delete cxid:0xdb zxid:0xcb txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 1, deleted brokers: , all live brokers: 1
2018-09-26 05:37:31 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 1
2018-09-26 05:37:31 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 05:37:31 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:44252 (id: 1 rack: null) for sending state change requests
2018-09-26 05:37:31 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=testRestartingBroker-1537933032415,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:37:31 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-19
2018-09-26 05:37:31 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,testRestartingBroker-1537933032415-0,__consumer_offsets-40
2018-09-26 05:37:31 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 1
2018-09-26 05:37:31 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1
2018-09-26 05:37:31 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-30
2018-09-26 05:37:31 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 05:37:31 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:31 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:44252]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 05:37:31 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:31 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-47
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-29
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-41
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-39
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-10
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-17
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-14
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-40
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-18
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-26
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-24
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-33
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-20
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-21
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-3
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-22
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-5
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition testRestartingBroker-1537933032415-0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-12
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-8
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-23
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-15
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-48
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:32 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:37:32 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-11
2018-09-26 05:37:32 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 05:37:32 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-13
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-49
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-6
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-28
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-4
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-37
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-31
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-44
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-42
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-34
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-46
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition testRestartingBroker-1537933032415-0 with initial high watermark 2
2018-09-26 05:37:33 INFO  Partition:72 - [Partition testRestartingBroker-1537933032415-0 broker=1] testRestartingBroker-1537933032415-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-25
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-45
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-27
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-32
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-43
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-36
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-35
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-7
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-9
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-38
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-1
2018-09-26 05:37:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 05:37:33 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-2
2018-09-26 05:37:33 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Loading group metadata for  with generation 0
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 29 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 05:37:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 05:37:33 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-16
2018-09-26 05:37:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,testRestartingBroker-1537933032415-0,__consumer_offsets-40
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-0 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-29 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-48 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-10 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-45 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-26 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-7 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-42 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-4 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-23 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-1 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-20 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-39 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-17 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-36 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-14 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-33 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-49 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-11 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-30 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-46 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-27 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-8 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-24 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-43 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-5 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-21 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-2 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-40 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-37 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-18 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-34 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-15 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-12 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-31 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-9 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-47 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-19 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition testRestartingBroker-1537933032415-0 broker=1] testRestartingBroker-1537933032415-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition testRestartingBroker-1537933032415-0 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-28 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-38 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-35 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-44 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-6 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-25 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-16 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-22 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-41 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-32 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-3 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:34 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 05:37:34 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-13 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 05:37:37 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:44252 (id: 2147483646 rack: null)
2018-09-26 05:37:37 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:1, offset:1}, Current: {epoch:0, offset0} for Partition: __consumer_offsets-0. Cache now contains 1 entries.
2018-09-26 05:37:37 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 05:37:37 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 05:37:37 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:37:37 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 05:37:37 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 05:37:37 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 05:37:37 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 05:37:37 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 05:37:37 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 05:37:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 05:37:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 05:37:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 05:37:37 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 05:37:37 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1000
2018-09-26 05:37:37 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 05:37:37 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 05:37:37 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 05:37:37 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 05:37:37 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 05:37:37 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 05:37:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 05:37:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 05:37:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 05:37:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 05:37:38 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 05:37:38 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 05:37:38 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:37:38 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:37:38 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:37:38 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 05:37:38 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 05:37:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 05:37:38 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 05:37:38 INFO  LogManager:72 - Shutting down.
2018-09-26 05:37:38 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:37:38 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:37:38 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:37:38 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:37:38 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2
2018-09-26 05:37:38 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:37:38 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:37:38 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:37:38 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:37:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 05:37:38 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 05:37:38 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 05:37:38 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 05:37:38 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 05:37:38 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 05:37:38 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:37:38 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x101707732dd0000
2018-09-26 05:37:38 INFO  ZooKeeper:687 - Session: 0x101707732dd0000 closed
2018-09-26 05:37:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:37:38 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:57490 which had sessionid 0x101707732dd0000
2018-09-26 05:37:38 INFO  ClientCnxn:521 - EventThread shut down for session: 0x101707732dd0000
2018-09-26 05:37:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:37:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:37:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:37:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:37:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:37:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:37:41 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:37:41 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:37:41 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 05:37:41 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 05:37:41 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 05:37:41 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:37:41 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:37:41 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:37:41 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:37:41 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:37:41 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:37:41 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:37:41 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:37:41 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[ERROR] Tests run: 6, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 74.096 s <<< FAILURE! - in com.salesforce.kafka.test.KafkaTestServerTest
[ERROR] testOverrideBrokerProperties  Time elapsed: 5.539 s
[ERROR] testGetKafkaBrokersBeforeBrokerIsStarted  Time elapsed: 0.001 s
[ERROR] testExactlyOnceTransaction  Time elapsed: 18.844 s  <<< FAILURE!
org.opentest4j.AssertionFailedError: Should not be empty! ==> expected: <false> but was: <true>
	at com.salesforce.kafka.test.KafkaTestServerTest.testExactlyOnceTransaction(KafkaTestServerTest.java:104)

[ERROR] testGetKafkaBrokers  Time elapsed: 4.922 s
[ERROR] testProducerAndConsumerSubscribe  Time elapsed: 15.857 s
[ERROR] testRestartingBroker  Time elapsed: 28.929 s
[INFO] Running com.salesforce.kafka.test.kafka_1_0_x.StreamsBuilderSmokeTest
2018-09-26 05:37:41 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:37:41 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:37:41 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:37:41 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:37:41 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:37:41 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:37:41 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:44125
2018-09-26 05:37:41 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:37:42 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:41381
	advertised.port = 41381
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:41381
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933062350-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 41381
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:44125
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:37:42 INFO  KafkaServer:72 - starting
2018-09-26 05:37:42 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:44125
2018-09-26 05:37:42 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:44125 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@669d2b1b
2018-09-26 05:37:42 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:37:42 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:37:42 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:44125. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:37:42 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:44125, initiating session
2018-09-26 05:37:42 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:47940
2018-09-26 05:37:42 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:47940
2018-09-26 05:37:42 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:37:42 INFO  ZooKeeperServer:693 - Established session 0x10170775e330000 with negotiated timeout 30000 for client /127.0.0.1:47940
2018-09-26 05:37:42 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:44125, sessionid = 0x10170775e330000, negotiated timeout = 30000
2018-09-26 05:37:42 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:37:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 05:37:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 05:37:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 05:37:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 05:37:43 INFO  KafkaServer:72 - Cluster ID = AWFtDcXvQQq6rdGupocU_w
2018-09-26 05:37:43 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933062350-0/meta.properties
2018-09-26 05:37:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:37:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:37:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:37:43 INFO  LogManager:72 - Loading logs.
2018-09-26 05:37:43 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 05:37:43 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:37:43 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:37:43 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:37:43 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:37:43 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:41381.
2018-09-26 05:37:43 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 05:37:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 05:37:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 05:37:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 05:37:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:37:43 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:37:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 05:37:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 05:37:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 05:37:43 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:37:43 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 05:37:43 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 05:37:43 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:37:43 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 05:37:43 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 05:37:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 05:37:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 05:37:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 05:37:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 05:37:43 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 05:37:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:37:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x43 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:37:43 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:37:43 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,41381,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:37:43 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933062350-0/meta.properties
2018-09-26 05:37:43 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 05:37:43 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 05:37:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 05:37:43 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:41381 (id: 1 rack: null) for sending state change requests
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 05:37:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:37:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:delete cxid:0x4e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:37:43 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 05:37:43 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:43 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:43 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 05:37:43 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:41381]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:37:43 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:43 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 05:37:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:setData cxid:0x50 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/stream-input-topic1537933061346 Error:KeeperErrorCode = NoNode for /config/topics/stream-input-topic1537933061346
2018-09-26 05:37:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x51 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:37:43 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(stream-input-topic1537933061346)], deleted topics: [Set()], new partition replica assignment [Map(stream-input-topic1537933061346-0 -> Vector(1))]
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for stream-input-topic1537933061346-0
2018-09-26 05:37:43 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for stream-input-topic1537933061346-0
2018-09-26 05:37:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions stream-input-topic1537933061346-0
2018-09-26 05:37:43 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=stream-input-topic1537933061346,Partition=0,Replica=1]
2018-09-26 05:37:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions stream-input-topic1537933061346-0
2018-09-26 05:37:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x59 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-input-topic1537933061346/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/stream-input-topic1537933061346/partitions/0
2018-09-26 05:37:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x5a zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-input-topic1537933061346/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/stream-input-topic1537933061346/partitions
2018-09-26 05:37:44 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=stream-input-topic1537933061346,Partition=0,Replica=1]
2018-09-26 05:37:44 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions stream-input-topic1537933061346-0
2018-09-26 05:37:44 INFO  Log:72 - [Log partition=stream-input-topic1537933061346-0, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:44 INFO  Log:72 - [Log partition=stream-input-topic1537933061346-0, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:44 INFO  LogManager:72 - Created log for partition [stream-input-topic1537933061346,0] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:44 INFO  Partition:72 - [Partition stream-input-topic1537933061346-0 broker=1] No checkpointed highwatermark is found for partition stream-input-topic1537933061346-0
2018-09-26 05:37:44 INFO  Replica:72 - Replica loaded for partition stream-input-topic1537933061346-0 with initial high watermark 0
2018-09-26 05:37:44 INFO  Partition:72 - [Partition stream-input-topic1537933061346-0 broker=1] stream-input-topic1537933061346-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:44 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:41381]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:37:44 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:44 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:setData cxid:0x60 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/stream-output-topic1537933061346 Error:KeeperErrorCode = NoNode for /config/topics/stream-output-topic1537933061346
2018-09-26 05:37:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x61 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:37:44 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-09-26 05:37:44 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(stream-output-topic1537933061346)], deleted topics: [Set()], new partition replica assignment [Map(stream-output-topic1537933061346-0 -> Vector(1))]
2018-09-26 05:37:44 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for stream-output-topic1537933061346-0
2018-09-26 05:37:44 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for stream-output-topic1537933061346-0
2018-09-26 05:37:44 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions stream-output-topic1537933061346-0
2018-09-26 05:37:44 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=stream-output-topic1537933061346,Partition=0,Replica=1]
2018-09-26 05:37:44 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions stream-output-topic1537933061346-0
2018-09-26 05:37:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x69 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-output-topic1537933061346/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/stream-output-topic1537933061346/partitions/0
2018-09-26 05:37:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x6a zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-output-topic1537933061346/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/stream-output-topic1537933061346/partitions
2018-09-26 05:37:44 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=stream-output-topic1537933061346,Partition=0,Replica=1]
2018-09-26 05:37:44 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions stream-output-topic1537933061346-0
2018-09-26 05:37:44 INFO  Log:72 - [Log partition=stream-output-topic1537933061346-0, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:44 INFO  Log:72 - [Log partition=stream-output-topic1537933061346-0, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:44 INFO  LogManager:72 - Created log for partition [stream-output-topic1537933061346,0] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:44 INFO  Partition:72 - [Partition stream-output-topic1537933061346-0 broker=1] No checkpointed highwatermark is found for partition stream-output-topic1537933061346-0
2018-09-26 05:37:44 INFO  Replica:72 - Replica loaded for partition stream-output-topic1537933061346-0 with initial high watermark 0
2018-09-26 05:37:44 INFO  Partition:72 - [Partition stream-output-topic1537933061346-0 broker=1] stream-output-topic1537933061346-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:44 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:41381]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 05:37:44 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:44 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:44 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: stream-input-topic1537933061346-0. Cache now contains 0 entries.
2018-09-26 05:37:45 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 05:37:45 INFO  StreamsConfig:238 - StreamsConfig values: 
	application.id = testStreamProcessor
	application.server = 
	bootstrap.servers = [127.0.0.1:41381]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	upgrade.from = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-09-26 05:37:45 INFO  StreamThread:336 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] Creating restore consumer client
2018-09-26 05:37:45 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:41381]
	check.crcs = true
	client.id = testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 05:37:45 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:45 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:45 INFO  StreamThread:336 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] Creating shared producer client
2018-09-26 05:37:45 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:41381]
	buffer.memory = 33554432
	client.id = testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 05:37:45 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:45 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:45 INFO  StreamThread:336 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] Creating consumer client
2018-09-26 05:37:45 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:41381]
	check.crcs = true
	client.id = testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testStreamProcessor
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 05:37:45 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:45 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:45 INFO  StreamThread:336 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] Starting
2018-09-26 05:37:45 INFO  StreamThread:346 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] State transition from CREATED to RUNNING
2018-09-26 05:37:45 INFO  KafkaStreams:336 - stream-client [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7]Started Streams client
2018-09-26 05:37:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:setData cxid:0x73 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 05:37:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x74 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:37:45 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-09-26 05:37:45 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 05:37:45 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 05:37:45 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:37:45 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:37:45 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:37:45 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:37:45 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:37:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xb0 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 05:37:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xb1 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 05:37:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xba zxid:0x39 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 05:37:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xc0 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 05:37:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xc6 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 05:37:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xcc zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 05:37:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xd2 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 05:37:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xd8 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 05:37:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xde zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 05:37:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xe4 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 05:37:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xea zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 05:37:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xf0 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 05:37:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xf6 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 05:37:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0xfc zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 05:37:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x102 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 05:37:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x108 zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 05:37:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x10e zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 05:37:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x114 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 05:37:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x11a zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 05:37:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x120 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 05:37:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x126 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 05:37:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x12c zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 05:37:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x132 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 05:37:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x138 zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 05:37:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x13e zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 05:37:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x144 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 05:37:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x14a zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 05:37:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x150 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 05:37:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x156 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 05:37:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x15c zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 05:37:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x162 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 05:37:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x168 zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 05:37:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x16e zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 05:37:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x174 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 05:37:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x17a zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 05:37:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x180 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 05:37:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x186 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 05:37:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x18c zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 05:37:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x192 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 05:37:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x198 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 05:37:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x19e zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 05:37:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1a4 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 05:37:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1aa zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 05:37:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1b0 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 05:37:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1b6 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 05:37:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1bc zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 05:37:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1c2 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 05:37:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1c8 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 05:37:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1ce zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 05:37:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1d4 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 05:37:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170775e330000 type:create cxid:0x1da zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 05:37:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:37:52 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933062350-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:37:52 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933062350-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:37:52 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537933062350-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 05:37:52 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 05:37:52 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 05:37:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 05:37:52 INFO  AbstractCoordinator:341 - [Consumer clientId=testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1-consumer, groupId=testStreamProcessor] Discovered group coordinator 127.0.0.1:41381 (id: 2147483646 rack: null)
2018-09-26 05:37:52 INFO  ConsumerCoordinator:341 - [Consumer clientId=testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1-consumer, groupId=testStreamProcessor] Revoking previously assigned partitions []
2018-09-26 05:37:52 INFO  StreamThread:346 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-09-26 05:37:52 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7]State transition from RUNNING to REBALANCING
2018-09-26 05:37:52 INFO  StreamThread:351 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-09-26 05:37:52 INFO  AbstractCoordinator:336 - [Consumer clientId=testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1-consumer, groupId=testStreamProcessor] (Re-)joining group
2018-09-26 05:37:52 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group testStreamProcessor with old generation 0 (__consumer_offsets-8)
2018-09-26 05:37:55 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Stabilized group testStreamProcessor generation 1 (__consumer_offsets-8)
2018-09-26 05:37:55 INFO  StreamPartitionAssignor:341 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1-consumer] Assigned tasks to clients as {a063df6a-f793-4d41-a8ca-5cf7137c23b7=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-09-26 05:37:55 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Assignment received from leader for group testStreamProcessor for generation 1
2018-09-26 05:37:55 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-8. Cache now contains 0 entries.
2018-09-26 05:37:55 INFO  AbstractCoordinator:341 - [Consumer clientId=testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1-consumer, groupId=testStreamProcessor] Successfully joined group with generation 1
2018-09-26 05:37:55 INFO  ConsumerCoordinator:341 - [Consumer clientId=testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1-consumer, groupId=testStreamProcessor] Setting newly assigned partitions [stream-input-topic1537933061346-0]
2018-09-26 05:37:55 INFO  StreamThread:346 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-09-26 05:37:55 INFO  StreamThread:351 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] partition assignment took 19 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-09-26 05:37:55 INFO  StreamThread:346 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-09-26 05:37:55 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7]State transition from REBALANCING to RUNNING
2018-09-26 05:37:55 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: stream-output-topic1537933061346-0. Cache now contains 0 entries.
2018-09-26 05:37:56 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7]State transition from RUNNING to PENDING_SHUTDOWN
2018-09-26 05:37:56 INFO  StreamThread:336 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] Informed to shut down
2018-09-26 05:37:56 INFO  StreamThread:346 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-09-26 05:37:56 INFO  StreamThread:336 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] Shutting down
2018-09-26 05:37:56 INFO  KafkaProducer:341 - [Producer clientId=testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 05:37:56 INFO  StreamThread:346 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-09-26 05:37:56 INFO  StreamThread:336 - stream-thread [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7-StreamThread-1] Shutdown complete
2018-09-26 05:37:56 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7]State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-09-26 05:37:56 INFO  KafkaStreams:336 - stream-client [testStreamProcessor-a063df6a-f793-4d41-a8ca-5cf7137c23b7]Streams client stopped completely
2018-09-26 05:37:56 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:41381]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:37:56 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:56 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:37:56 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:41381]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-26 05:37:56 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:37:56 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:00 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:41381 (id: 2147483646 rack: null)
2018-09-26 05:38:00 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-09-26 05:38:01 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 05:38:01 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 05:38:01 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:38:01 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 05:38:01 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 05:38:01 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 05:38:01 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 05:38:01 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 05:38:01 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 05:38:01 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 05:38:01 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 05:38:01 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 05:38:01 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 05:38:01 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 05:38:01 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 05:38:01 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 05:38:01 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 05:38:01 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 05:38:01 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 05:38:01 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:38:01 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:38:01 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:38:01 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 05:38:01 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 05:38:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 05:38:01 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 05:38:01 INFO  LogManager:72 - Shutting down.
2018-09-26 05:38:01 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:38:01 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:38:01 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:38:01 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:38:01 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 2
2018-09-26 05:38:02 INFO  ProducerStateManager:72 - [ProducerStateManager partition=stream-output-topic1537933061346-0] Writing producer snapshot at offset 25
2018-09-26 05:38:02 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 1
2018-09-26 05:38:03 INFO  ProducerStateManager:72 - [ProducerStateManager partition=stream-input-topic1537933061346-0] Writing producer snapshot at offset 25
2018-09-26 05:38:03 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:38:03 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:38:03 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:38:03 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:38:03 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 05:38:03 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 05:38:03 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 05:38:03 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 05:38:03 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 05:38:03 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 05:38:03 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:38:03 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10170775e330000
2018-09-26 05:38:03 INFO  ZooKeeper:687 - Session: 0x10170775e330000 closed
2018-09-26 05:38:03 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:47940 which had sessionid 0x10170775e330000
2018-09-26 05:38:03 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:38:03 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10170775e330000
2018-09-26 05:38:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:38:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:38:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:38:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:38:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:38:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:38:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:38:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:38:05 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 05:38:05 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 05:38:05 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 05:38:05 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:38:05 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:38:05 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:38:05 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:38:05 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:38:05 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:38:05 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:38:05 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:38:05 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.892 s - in com.salesforce.kafka.test.kafka_1_0_x.StreamsBuilderSmokeTest
[INFO] testStreamConsumer  Time elapsed: 23.892 s
[INFO] Running com.salesforce.kafka.test.KafkaBrokersTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.389 s - in com.salesforce.kafka.test.KafkaBrokersTest
[INFO] testSize  Time elapsed: 0.383 s
[INFO] testGetBrokerById  Time elapsed: 0.003 s
[INFO] testAsList  Time elapsed: 0.002 s
[INFO] Running com.salesforce.kafka.test.KafkaTestClusterTest
2018-09-26 05:38:05 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:38:05 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:38:05 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:38:05 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:38:05 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:38:05 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:38:05 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34673
2018-09-26 05:38:05 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:38:06 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:38:06 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:38:06 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:38:06 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:38:06 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:38:06 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:38:06 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:38:06 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:38:06 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:38:06 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:38:06 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:38:06 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:38:06 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:38:06 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:38:06 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34673
2018-09-26 05:38:07 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:46796
	advertised.port = 46796
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:46796
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933087683-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 46796
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:34673
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:38:07 INFO  KafkaServer:72 - starting
2018-09-26 05:38:07 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:34673
2018-09-26 05:38:07 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:34673 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@4016ccc1
2018-09-26 05:38:07 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:38:07 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:38:07 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34673. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:38:07 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34673, initiating session
2018-09-26 05:38:07 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55466
2018-09-26 05:38:07 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:55466
2018-09-26 05:38:07 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:38:07 INFO  ZooKeeperServer:693 - Established session 0x1017077c1280000 with negotiated timeout 30000 for client /127.0.0.1:55466
2018-09-26 05:38:07 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34673, sessionid = 0x1017077c1280000, negotiated timeout = 30000
2018-09-26 05:38:07 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:38:07 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 05:38:07 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 05:38:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 05:38:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 05:38:08 INFO  KafkaServer:72 - Cluster ID = ICWF4hGrTiiHW6HepadwVg
2018-09-26 05:38:08 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933087683-0/meta.properties
2018-09-26 05:38:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:38:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:38:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:38:08 INFO  LogManager:72 - Loading logs.
2018-09-26 05:38:08 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 05:38:08 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:38:08 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:38:08 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:38:08 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:38:08 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:46796.
2018-09-26 05:38:08 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 05:38:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 05:38:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 05:38:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 05:38:08 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:38:08 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:38:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 05:38:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 05:38:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 05:38:08 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 05:38:08 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:38:08 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 05:38:08 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:38:08 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 05:38:08 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 05:38:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 05:38:08 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 05:38:08 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 05:38:08 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 05:38:08 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 05:38:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:create cxid:0x45 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:38:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:create cxid:0x46 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:38:08 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:38:08 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,46796,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:38:08 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933087683-0/meta.properties
2018-09-26 05:38:08 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 05:38:08 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 05:38:08 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 05:38:08 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:46796 (id: 1 rack: null) for sending state change requests
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 05:38:08 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 05:38:08 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:38:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:38:08 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 05:38:08 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:08 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:08 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 05:38:08 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:38:08 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55466 which had sessionid 0x1017077c1280000
2018-09-26 05:38:08 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:38:08 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:38:08 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:38:08 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:38:08 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:38:08 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1017077c1280000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 05:38:08 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:38:08 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:38:08 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:38:08 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:38:08 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:38:08 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:38:08 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:38:08 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:38:08 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34673
2018-09-26 05:38:08 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:38:08 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:38:09 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 05:38:09 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:38:09 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:42378
	advertised.port = 42378
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:42378
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933089945-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 42378
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:34673
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:38:09 INFO  KafkaServer:72 - starting
2018-09-26 05:38:09 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:34673
2018-09-26 05:38:09 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:34673 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@21c7208d
2018-09-26 05:38:09 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:38:09 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:38:09 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34673. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:38:09 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34673, initiating session
2018-09-26 05:38:09 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55470
2018-09-26 05:38:09 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:55470
2018-09-26 05:38:09 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-09-26 05:38:09 INFO  ZooKeeperServer:693 - Established session 0x1017077c9fd0000 with negotiated timeout 30000 for client /127.0.0.1:55470
2018-09-26 05:38:09 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34673, sessionid = 0x1017077c9fd0000, negotiated timeout = 30000
2018-09-26 05:38:09 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:38:09 INFO  KafkaServer:72 - Cluster ID = ICWF4hGrTiiHW6HepadwVg
2018-09-26 05:38:09 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933089945-0/meta.properties
2018-09-26 05:38:09 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:38:09 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:38:09 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:38:09 INFO  LogManager:72 - Loading logs.
2018-09-26 05:38:09 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 05:38:10 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:38:10 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:38:10 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:38:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:38:10 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:42378.
2018-09-26 05:38:10 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 05:38:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 05:38:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 05:38:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 05:38:10 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:38:10 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:38:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 05:38:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 05:38:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 05:38:10 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 05:38:10 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 05:38:10 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:38:10 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 05:38:10 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 05:38:10 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 05:38:10 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 05:38:10 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 05:38:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c9fd0000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:38:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c9fd0000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:38:10 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:38:10 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,42378,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:38:10 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933089945-0/meta.properties
2018-09-26 05:38:10 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 05:38:10 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:10 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:10 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 05:38:10 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46796, 127.0.0.1:42378]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:38:10 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:10 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:10 INFO  KafkaTestCluster:260 - Found 1 of 1 brokers ready, continuing to wait for cluster to start.
2018-09-26 05:38:10 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46796, 127.0.0.1:42378]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:38:10 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:10 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:10 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34673. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:38:10 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55484
2018-09-26 05:38:10 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34673, initiating session
2018-09-26 05:38:10 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1017077c1280000 at /127.0.0.1:55484
2018-09-26 05:38:10 INFO  ZooKeeperServer:693 - Established session 0x1017077c1280000 with negotiated timeout 30000 for client /127.0.0.1:55484
2018-09-26 05:38:10 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34673, sessionid = 0x1017077c1280000, negotiated timeout = 30000
2018-09-26 05:38:10 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:38:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:delete cxid:0x52 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:38:10 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46796, 127.0.0.1:42378]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:38:10 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:10 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:10 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 05:38:10 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 05:38:10 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 05:38:10 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 05:38:10 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:42378 (id: 2 rack: null) for sending state change requests
2018-09-26 05:38:10 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1,2
2018-09-26 05:38:10 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-09-26 05:38:10 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46796, 127.0.0.1:42378]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:38:10 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:10 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:setData cxid:0x5c zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/topics/RestartClusterTest-1537933085672 Error:KeeperErrorCode = NoNode for /config/topics/RestartClusterTest-1537933085672
2018-09-26 05:38:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:create cxid:0x5d zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:38:11 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"1":[2,1],"0":[1,2]}}
2018-09-26 05:38:11 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(RestartClusterTest-1537933085672)], deleted topics: [Set()], new partition replica assignment [Map(RestartClusterTest-1537933085672-1 -> Vector(2, 1), RestartClusterTest-1537933085672-0 -> Vector(1, 2))]
2018-09-26 05:38:11 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for RestartClusterTest-1537933085672-1,RestartClusterTest-1537933085672-0
2018-09-26 05:38:11 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for RestartClusterTest-1537933085672-1,RestartClusterTest-1537933085672-0
2018-09-26 05:38:11 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions RestartClusterTest-1537933085672-1,RestartClusterTest-1537933085672-0
2018-09-26 05:38:11 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=RestartClusterTest-1537933085672,Partition=1,Replica=2],[Topic=RestartClusterTest-1537933085672,Partition=1,Replica=1],[Topic=RestartClusterTest-1537933085672,Partition=0,Replica=1],[Topic=RestartClusterTest-1537933085672,Partition=0,Replica=2]
2018-09-26 05:38:11 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-1,RestartClusterTest-1537933085672-0
2018-09-26 05:38:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:create cxid:0x68 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1537933085672/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/RestartClusterTest-1537933085672/partitions/1
2018-09-26 05:38:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:create cxid:0x69 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1537933085672/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/RestartClusterTest-1537933085672/partitions
2018-09-26 05:38:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c1280000 type:create cxid:0x6d zxid:0x2d txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1537933085672/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/RestartClusterTest-1537933085672/partitions/0
2018-09-26 05:38:11 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1537933085672,Partition=1,Replica=2],[Topic=RestartClusterTest-1537933085672,Partition=1,Replica=1],[Topic=RestartClusterTest-1537933085672,Partition=0,Replica=1],[Topic=RestartClusterTest-1537933085672,Partition=0,Replica=2]
2018-09-26 05:38:11 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:11 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:11 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-0, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:11 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-1, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:11 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-0, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:11 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-1, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:11 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1537933085672,0] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:11 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-0 broker=1] No checkpointed highwatermark is found for partition RestartClusterTest-1537933085672-0
2018-09-26 05:38:11 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-0 with initial high watermark 0
2018-09-26 05:38:11 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1537933085672,1] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:11 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-1 broker=2] No checkpointed highwatermark is found for partition RestartClusterTest-1537933085672-1
2018-09-26 05:38:11 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-1 with initial high watermark 0
2018-09-26 05:38:11 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-0 with initial high watermark 0
2018-09-26 05:38:11 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-1 with initial high watermark 0
2018-09-26 05:38:11 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-1 broker=2] RestartClusterTest-1537933085672-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:11 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-0 broker=1] RestartClusterTest-1537933085672-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:11 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-0 with initial high watermark 0
2018-09-26 05:38:11 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-1 with initial high watermark 0
2018-09-26 05:38:11 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-0, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:11 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-1, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:11 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-0, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:11 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-1, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:11 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1537933085672,0] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:11 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-0 broker=2] No checkpointed highwatermark is found for partition RestartClusterTest-1537933085672-0
2018-09-26 05:38:11 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-0 with initial high watermark 0
2018-09-26 05:38:11 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1537933085672,1] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:11 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-1 broker=1] No checkpointed highwatermark is found for partition RestartClusterTest-1537933085672-1
2018-09-26 05:38:11 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-1 with initial high watermark 0
2018-09-26 05:38:11 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:11 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:11 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-09-26 05:38:11 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting
2018-09-26 05:38:11 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([RestartClusterTest-1537933085672-1, initOffset 0 to broker BrokerEndPoint(2,127.0.0.1,42378)] )
2018-09-26 05:38:11 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([RestartClusterTest-1537933085672-0, initOffset 0 to broker BrokerEndPoint(1,127.0.0.1,46796)] )
2018-09-26 05:38:11 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:46796, 127.0.0.1:42378]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 05:38:11 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:11 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:11 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1537933085672-0. Cache now contains 0 entries.
2018-09-26 05:38:12 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in RestartClusterTest-1537933085672-1. High watermark 0 will be used for truncation.
2018-09-26 05:38:12 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in RestartClusterTest-1537933085672-0. High watermark 0 will be used for truncation.
2018-09-26 05:38:12 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-1, dir=/tmp/1537933087683-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-09-26 05:38:12 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-0, dir=/tmp/1537933089945-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-09-26 05:38:12 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1537933085672-0. Cache now contains 0 entries.
2018-09-26 05:38:12 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 05:38:12 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:46796, 127.0.0.1:42378]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 05:38:12 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:12 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:12 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1537933085672-1. Cache now contains 0 entries.
2018-09-26 05:38:12 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1537933085672-1. Cache now contains 0 entries.
2018-09-26 05:38:13 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 05:38:13 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 05:38:13 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 05:38:13 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:38:13 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=RestartClusterTest-1537933085672,Partition=1,Replica=1]
2018-09-26 05:38:13 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:13 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-09-26 05:38:13 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition RestartClusterTest-1537933085672-1 is {"leader":2,"leader_epoch":1,"isr":[2]}
2018-09-26 05:38:13 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:13 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:13 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-1 broker=2] RestartClusterTest-1537933085672-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-09-26 05:38:13 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 1 for partition RestartClusterTest-1537933085672-1 (last update controller epoch 1) since it is already the leader for the partition.
2018-09-26 05:38:13 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 05:38:13 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:13 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-0 broker=2] RestartClusterTest-1537933085672-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-09-26 05:38:13 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down
2018-09-26 05:38:13 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 05:38:13 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped
2018-09-26 05:38:13 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed
2018-09-26 05:38:13 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1 epoch 1 fails to send request (type=StopReplicaRequest, controllerId=1, controllerEpoch=1, deletePartitions=false, partitions=RestartClusterTest-1537933085672-1) to broker 127.0.0.1:46796 (id: 1 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:13 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 05:38:13 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 05:38:13 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:13 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:13 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:13 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:13 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:13 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:13 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-09-26 05:38:13 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-09-26 05:38:13 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:13 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 05:38:13 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 05:38:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 05:38:13 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:13 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 05:38:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 05:38:13 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 05:38:13 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 05:38:13 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 05:38:13 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 05:38:13 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 05:38:13 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 05:38:13 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 05:38:13 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 05:38:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 05:38:13 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:13 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:13 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:13 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 05:38:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 05:38:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 05:38:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 05:38:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 05:38:13 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 05:38:13 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 05:38:13 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:38:13 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:38:13 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:38:13 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 05:38:13 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 05:38:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 05:38:13 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:13 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:14 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:14 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 05:38:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 05:38:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 05:38:14 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:14 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:14 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:14 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 05:38:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 05:38:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 05:38:14 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:14 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:14 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:14 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 05:38:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 05:38:14 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 05:38:14 INFO  LogManager:72 - Shutting down.
2018-09-26 05:38:14 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:38:14 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:38:14 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:38:14 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:38:14 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537933085672-0] Writing producer snapshot at offset 2
2018-09-26 05:38:14 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537933085672-1] Writing producer snapshot at offset 2
2018-09-26 05:38:14 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:14 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:14 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:38:14 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:38:14 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:38:14 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:38:14 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 05:38:14 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 05:38:14 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 05:38:14 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 05:38:14 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 05:38:14 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 05:38:14 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 05:38:14 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 05:38:14 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:38:14 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1017077c1280000
2018-09-26 05:38:14 INFO  ZooKeeper:687 - Session: 0x1017077c1280000 closed
2018-09-26 05:38:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:38:14 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55484 which had sessionid 0x1017077c1280000
2018-09-26 05:38:14 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1017077c1280000
2018-09-26 05:38:14 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:38:14 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 2
2018-09-26 05:38:14 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2)
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set(RestartClusterTest-1537933085672)
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: RestartClusterTest-1537933085672
2018-09-26 05:38:14 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1537933085672,Partition=1,Replica=2],[Topic=RestartClusterTest-1537933085672,Partition=0,Replica=2]
2018-09-26 05:38:14 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:42378 (id: 2 rack: null) for sending state change requests
2018-09-26 05:38:14 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map([Topic=RestartClusterTest-1537933085672,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537933085672,Partition=1,Replica=2] -> OnlineReplica, [Topic=RestartClusterTest-1537933085672,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537933085672,Partition=0,Replica=2] -> OnlineReplica)
2018-09-26 05:38:14 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map(RestartClusterTest-1537933085672-1 -> OnlinePartition, RestartClusterTest-1537933085672-0 -> OnlinePartition)
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 2
2018-09-26 05:38:14 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 2 for partition RestartClusterTest-1537933085672-0 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-09-26 05:38:14 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 2 for partition RestartClusterTest-1537933085672-1 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-09-26 05:38:14 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:38:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017077c9fd0000 type:delete cxid:0x43 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:38:14 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-09-26 05:38:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:38:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:38:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:38:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:38:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:38:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:38:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:38:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:38:17 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 05:38:17 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 05:38:17 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 05:38:17 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 05:38:17 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 05:38:17 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 05:38:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:17 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
2018-09-26 05:38:17 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537933085672-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 05:38:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:17 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
2018-09-26 05:38:17 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537933085672-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 05:38:17 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537933085672-0,RestartClusterTest-1537933085672-1
2018-09-26 05:38:17 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 05:38:22 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 05:38:22 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 05:38:22 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:22 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
2018-09-26 05:38:22 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537933085672-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 05:38:22 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:22 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
2018-09-26 05:38:22 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537933085672-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 05:38:22 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537933085672-0,RestartClusterTest-1537933085672-1
2018-09-26 05:38:22 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 05:38:27 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 05:38:27 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 05:38:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:27 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
2018-09-26 05:38:27 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537933085672-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 05:38:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:27 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
2018-09-26 05:38:27 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537933085672-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 05:38:27 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537933085672-0,RestartClusterTest-1537933085672-1
2018-09-26 05:38:27 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 05:38:32 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 05:38:32 WARN  KafkaServer:87 - [KafkaServer id=2] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-09-26 05:38:32 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 05:38:32 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 05:38:32 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 05:38:32 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 05:38:32 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 05:38:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 05:38:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 05:38:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 05:38:32 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 05:38:32 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-09-26 05:38:32 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 05:38:32 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 05:38:32 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 05:38:32 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 05:38:32 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 05:38:32 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 05:38:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 05:38:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 05:38:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 05:38:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 05:38:33 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 05:38:33 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 05:38:33 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:38:33 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:38:33 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:38:33 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 05:38:33 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 05:38:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 05:38:33 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 05:38:33 INFO  LogManager:72 - Shutting down.
2018-09-26 05:38:33 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:38:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:38:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:38:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:38:33 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537933085672-0] Writing producer snapshot at offset 2
2018-09-26 05:38:33 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537933085672-1] Writing producer snapshot at offset 2
2018-09-26 05:38:33 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:38:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:38:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:38:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:38:33 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 05:38:33 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 05:38:33 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-09-26 05:38:33 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-09-26 05:38:33 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-09-26 05:38:33 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 05:38:33 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:38:33 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1017077c9fd0000
2018-09-26 05:38:33 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55470 which had sessionid 0x1017077c9fd0000
2018-09-26 05:38:33 INFO  ZooKeeper:687 - Session: 0x1017077c9fd0000 closed
2018-09-26 05:38:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:38:33 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1017077c9fd0000
2018-09-26 05:38:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:38:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:38:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:38:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:38:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:38:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:38:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:38:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:38:35 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 05:38:35 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 05:38:35 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 05:38:35 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:38:35 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:38:35 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:38:35 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:38:35 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:38:35 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:38:35 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:38:35 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:38:35 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:38:35 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:38:35 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:38:35 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:38:35 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:38:35 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:38:35 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:38:35 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34673
2018-09-26 05:38:35 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:38:36 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:38:36 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:38:36 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:38:36 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:38:36 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:38:36 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:38:36 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:38:36 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:38:36 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:38:36 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:38:36 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:38:36 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:38:36 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:38:36 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:38:36 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34673
2018-09-26 05:38:37 INFO  KafkaServer:72 - [KafkaServer id=1] starting
2018-09-26 05:38:37 INFO  KafkaServer:72 - [KafkaServer id=1] Connecting to zookeeper on 127.0.0.1:34673
2018-09-26 05:38:37 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:34673 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@23706db8
2018-09-26 05:38:37 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:38:37 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:38:37 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34673. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:38:37 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34673, initiating session
2018-09-26 05:38:37 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55556
2018-09-26 05:38:37 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:55556
2018-09-26 05:38:37 INFO  FileTxnLog:213 - Creating new log file: log.37
2018-09-26 05:38:37 INFO  ZooKeeperServer:693 - Established session 0x101707833cf0000 with negotiated timeout 30000 for client /127.0.0.1:55556
2018-09-26 05:38:37 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34673, sessionid = 0x101707833cf0000, negotiated timeout = 30000
2018-09-26 05:38:37 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:38:37 INFO  KafkaServer:72 - [KafkaServer id=1] Cluster ID = ICWF4hGrTiiHW6HepadwVg
2018-09-26 05:38:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:38:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:38:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:38:37 INFO  LogManager:72 - Loading logs.
2018-09-26 05:38:37 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-0, dir=/tmp/1537933087683-0] Loading producer state from offset 2 with message format version 2
2018-09-26 05:38:37 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537933085672-0] Loading producer state from snapshot file '/tmp/1537933087683-0/RestartClusterTest-1537933085672-0/00000000000000000002.snapshot'
2018-09-26 05:38:37 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-0, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 4 ms
2018-09-26 05:38:37 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-1, dir=/tmp/1537933087683-0] Loading producer state from offset 2 with message format version 2
2018-09-26 05:38:37 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537933085672-1] Loading producer state from snapshot file '/tmp/1537933087683-0/RestartClusterTest-1537933085672-1/00000000000000000002.snapshot'
2018-09-26 05:38:37 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-1, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 3 ms
2018-09-26 05:38:37 INFO  LogManager:72 - Logs loading complete in 10 ms.
2018-09-26 05:38:37 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:38:37 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:38:37 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:38:37 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:38:37 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:46796.
2018-09-26 05:38:37 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 05:38:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 05:38:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 05:38:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 05:38:37 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:38:37 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:38:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 05:38:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 05:38:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 05:38:37 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 05:38:37 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 05:38:37 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:38:37 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:38:37 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:38:37 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 05:38:37 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 05:38:37 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2018-09-26 05:38:37 INFO  KafkaController:72 - [Controller id=1] Initialized controller epoch to 2 and zk version 1
2018-09-26 05:38:37 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 05:38:37 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 05:38:37 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 05:38:37 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 3
2018-09-26 05:38:37 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 05:38:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x31 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:38:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x32 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:38:37 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:38:37 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,46796,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:38:37 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 05:38:37 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:37 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:37 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 05:38:37 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:38:37 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55556 which had sessionid 0x101707833cf0000
2018-09-26 05:38:37 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x101707833cf0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 05:38:37 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:38:37 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:38:37 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:38:37 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:38:37 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:38:37 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:38:37 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:38:37 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:38:37 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:38:37 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:38:37 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:38:37 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:38:37 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:38:37 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34673
2018-09-26 05:38:37 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:38:37 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 05:38:38 INFO  KafkaServer:72 - [KafkaServer id=2] starting
2018-09-26 05:38:38 INFO  KafkaServer:72 - [KafkaServer id=2] Connecting to zookeeper on 127.0.0.1:34673
2018-09-26 05:38:38 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:34673 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@7808f638
2018-09-26 05:38:38 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:38:38 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34673. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:38:38 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:38:38 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55558
2018-09-26 05:38:38 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34673, initiating session
2018-09-26 05:38:38 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:55558
2018-09-26 05:38:38 INFO  FileTxnLog:213 - Creating new log file: log.3e
2018-09-26 05:38:38 INFO  ZooKeeperServer:693 - Established session 0x1017078393c0000 with negotiated timeout 30000 for client /127.0.0.1:55558
2018-09-26 05:38:38 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34673, sessionid = 0x1017078393c0000, negotiated timeout = 30000
2018-09-26 05:38:38 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:38:38 INFO  KafkaServer:72 - [KafkaServer id=2] Cluster ID = ICWF4hGrTiiHW6HepadwVg
2018-09-26 05:38:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:38:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:38:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:38:38 INFO  LogManager:72 - Loading logs.
2018-09-26 05:38:38 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-1, dir=/tmp/1537933089945-0] Loading producer state from offset 2 with message format version 2
2018-09-26 05:38:38 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537933085672-1] Loading producer state from snapshot file '/tmp/1537933089945-0/RestartClusterTest-1537933085672-1/00000000000000000002.snapshot'
2018-09-26 05:38:38 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-1, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 2 ms
2018-09-26 05:38:38 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-0, dir=/tmp/1537933089945-0] Loading producer state from offset 2 with message format version 2
2018-09-26 05:38:38 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537933085672-0] Loading producer state from snapshot file '/tmp/1537933089945-0/RestartClusterTest-1537933085672-0/00000000000000000002.snapshot'
2018-09-26 05:38:38 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-0, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 2 ms
2018-09-26 05:38:38 INFO  LogManager:72 - Logs loading complete in 7 ms.
2018-09-26 05:38:38 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34673. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:38:38 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55560
2018-09-26 05:38:38 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34673, initiating session
2018-09-26 05:38:38 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x101707833cf0000 at /127.0.0.1:55560
2018-09-26 05:38:38 INFO  ZooKeeperServer:693 - Established session 0x101707833cf0000 with negotiated timeout 30000 for client /127.0.0.1:55560
2018-09-26 05:38:38 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34673, sessionid = 0x101707833cf0000, negotiated timeout = 30000
2018-09-26 05:38:38 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:38:38 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:38:38 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:38:38 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:38:38 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:38:38 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set(RestartClusterTest-1537933085672)
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: RestartClusterTest-1537933085672
2018-09-26 05:38:38 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1537933085672,Partition=1,Replica=1],[Topic=RestartClusterTest-1537933085672,Partition=0,Replica=1]
2018-09-26 05:38:38 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map([Topic=RestartClusterTest-1537933085672,Partition=1,Replica=1] -> OnlineReplica, [Topic=RestartClusterTest-1537933085672,Partition=1,Replica=2] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537933085672,Partition=0,Replica=1] -> OnlineReplica, [Topic=RestartClusterTest-1537933085672,Partition=0,Replica=2] -> ReplicaDeletionIneligible)
2018-09-26 05:38:38 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:46796 (id: 1 rack: null) for sending state change requests
2018-09-26 05:38:38 ERROR logger:107 - [Controller id=1 epoch=3] Initiated state change for partition RestartClusterTest-1537933085672-1 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition RestartClusterTest-1537933085672-1 is alive. Live brokers are: [Set(1)], ISR brokers are: [2]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:38 ERROR logger:107 - [Controller id=1 epoch=3] Initiated state change for partition RestartClusterTest-1537933085672-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition RestartClusterTest-1537933085672-0 is alive. Live brokers are: [Set(1)], ISR brokers are: [2]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map(RestartClusterTest-1537933085672-1 -> OfflinePartition, RestartClusterTest-1537933085672-0 -> OfflinePartition)
2018-09-26 05:38:38 ERROR logger:101 - [Broker id=1] Received LeaderAndIsrRequest with correlation id 1 from controller 1 epoch 3 for partition RestartClusterTest-1537933085672-0 (last update controller epoch 1) but cannot become follower since the new leader 2 is unavailable.
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 3
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 05:38:38 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-0 with initial high watermark 2
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:38:38 ERROR logger:101 - [Broker id=1] Received LeaderAndIsrRequest with correlation id 1 from controller 1 epoch 3 for partition RestartClusterTest-1537933085672-1 (last update controller epoch 1) but cannot become follower since the new leader 2 is unavailable.
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 05:38:38 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 05:38:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:38:38 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-1 with initial high watermark 1
2018-09-26 05:38:38 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions 
2018-09-26 05:38:38 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List()
2018-09-26 05:38:38 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:42378.
2018-09-26 05:38:38 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 05:38:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:delete cxid:0x49 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:38:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 05:38:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 05:38:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 05:38:38 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:38:38 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:38:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 05:38:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 05:38:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 05:38:38 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:38:38 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:38:39 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 05:38:39 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 05:38:39 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 05:38:39 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:38:39 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-09-26 05:38:39 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4
2018-09-26 05:38:39 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 05:38:39 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 05:38:39 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 05:38:39 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 05:38:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078393c0000 type:create cxid:0x1f zxid:0x41 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:38:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078393c0000 type:create cxid:0x20 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:38:39 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:38:39 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,42378,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:38:39 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 05:38:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:39 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 05:38:39 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46796, 127.0.0.1:42378]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:38:39 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 05:38:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:39 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 05:38:39 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 05:38:39 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1537933085672,Partition=1,Replica=2],[Topic=RestartClusterTest-1537933085672,Partition=0,Replica=2]
2018-09-26 05:38:39 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:42378 (id: 2 rack: null) for sending state change requests
2018-09-26 05:38:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":2,"leader_epoch":2,"isr":[2]} for offline partition RestartClusterTest-1537933085672-1
2018-09-26 05:38:39 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537933085672-0,RestartClusterTest-1537933085672-1
2018-09-26 05:38:39 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-0 with initial high watermark 2
2018-09-26 05:38:39 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-0 broker=2] RestartClusterTest-1537933085672-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1
2018-09-26 05:38:39 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-0 with initial high watermark 0
2018-09-26 05:38:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":2,"leader_epoch":2,"isr":[2]} for offline partition RestartClusterTest-1537933085672-0
2018-09-26 05:38:39 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-1 with initial high watermark 2
2018-09-26 05:38:39 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-1 broker=2] RestartClusterTest-1537933085672-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1
2018-09-26 05:38:39 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-1 with initial high watermark 0
2018-09-26 05:38:39 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537933085672-0,RestartClusterTest-1537933085672-1
2018-09-26 05:38:39 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-0 with initial high watermark 0
2018-09-26 05:38:39 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-0 broker=2] RestartClusterTest-1537933085672-0 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1
2018-09-26 05:38:39 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537933085672-1 with initial high watermark 0
2018-09-26 05:38:39 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537933085672-1,RestartClusterTest-1537933085672-0
2018-09-26 05:38:39 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 3 for partition RestartClusterTest-1537933085672-0 (last update controller epoch 3) since it is already the leader for the partition.
2018-09-26 05:38:39 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-1 broker=2] RestartClusterTest-1537933085672-1 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1
2018-09-26 05:38:39 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 3 for partition RestartClusterTest-1537933085672-1 (last update controller epoch 3) since it is already the leader for the partition.
2018-09-26 05:38:39 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([RestartClusterTest-1537933085672-1, initOffset 2 to broker BrokerEndPoint(2,127.0.0.1,42378)] , [RestartClusterTest-1537933085672-0, initOffset 2 to broker BrokerEndPoint(2,127.0.0.1,42378)] )
2018-09-26 05:38:39 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-09-26 05:38:39 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 2 >= the follower's log end offset 2 in RestartClusterTest-1537933085672-0. No truncation needed.
2018-09-26 05:38:39 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-0, dir=/tmp/1537933087683-0] Truncating to 2 has no effect as the largest offset in the log is 1
2018-09-26 05:38:39 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 2 >= the follower's log end offset 2 in RestartClusterTest-1537933085672-1. No truncation needed.
2018-09-26 05:38:39 INFO  Log:72 - [Log partition=RestartClusterTest-1537933085672-1, dir=/tmp/1537933087683-0] Truncating to 2 has no effect as the largest offset in the log is 1
2018-09-26 05:38:39 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-1 broker=2] Expanding ISR from 2 to 2,1
2018-09-26 05:38:39 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-09-26 05:38:39 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46796, 127.0.0.1:42378]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:38:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:39 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-0 broker=2] Expanding ISR from 2 to 2,1
2018-09-26 05:38:39 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:46796, 127.0.0.1:42378]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 05:38:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:38:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:38:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:setData cxid:0x5a zxid:0x48 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 05:38:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x5c zxid:0x49 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:38:43 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[2],"34":[1],"12":[1],"8":[1],"19":[2],"23":[2],"4":[1],"40":[1],"15":[2],"11":[2],"9":[2],"44":[1],"33":[2],"22":[1],"26":[1],"37":[2],"13":[2],"46":[1],"24":[1],"35":[2],"16":[1],"5":[2],"10":[1],"48":[1],"21":[2],"43":[2],"32":[1],"49":[2],"6":[1],"36":[1],"1":[2],"39":[2],"17":[2],"25":[2],"14":[1],"47":[2],"31":[2],"42":[1],"0":[1],"20":[1],"27":[2],"2":[1],"38":[1],"18":[1],"30":[1],"7":[2],"29":[2],"41":[2],"3":[2],"28":[1]}}
2018-09-26 05:38:43 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 05:38:43 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(2), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(2), __consumer_offsets-29 -> Vector(2), __consumer_offsets-41 -> Vector(2), __consumer_offsets-39 -> Vector(2), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(2), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(2), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(2), __consumer_offsets-3 -> Vector(2), __consumer_offsets-5 -> Vector(2), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(2), __consumer_offsets-15 -> Vector(2), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(2), __consumer_offsets-13 -> Vector(2), __consumer_offsets-49 -> Vector(2), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(2), __consumer_offsets-31 -> Vector(2), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(2), __consumer_offsets-45 -> Vector(2), __consumer_offsets-27 -> Vector(2), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(2), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(2), __consumer_offsets-7 -> Vector(2), __consumer_offsets-9 -> Vector(2), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(2), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 05:38:43 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:38:43 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:38:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:38:43 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=2],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=2],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=2],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=2],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=2],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=2],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=2],[Topic=__consumer_offsets,Partition=15,Replica=2],[Topic=__consumer_offsets,Partition=7,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=2],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=2],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=2],[Topic=__consumer_offsets,Partition=49,Replica=2],[Topic=__consumer_offsets,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=2],[Topic=__consumer_offsets,Partition=21,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=2],[Topic=__consumer_offsets,Partition=5,Replica=2],[Topic=__consumer_offsets,Partition=41,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=2],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=2],[Topic=__consumer_offsets,Partition=24,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=2]
2018-09-26 05:38:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:38:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x99 zxid:0x4c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 05:38:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x9a zxid:0x4d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 05:38:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x9e zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 05:38:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xa4 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 05:38:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xa8 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 05:38:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xab zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 05:38:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xb0 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 05:38:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xb7 zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 05:38:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xbc zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 05:38:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xbf zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 05:38:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xc2 zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 05:38:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xc5 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 05:38:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xcb zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 05:38:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xcf zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 05:38:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xd4 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 05:38:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xd9 zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 05:38:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xde zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 05:38:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xe3 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 05:38:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xe6 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 05:38:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xeb zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 05:38:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xf0 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 05:38:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xf3 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 05:38:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xf8 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 05:38:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0xfd zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 05:38:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x100 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 05:38:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x103 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 05:38:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x108 zxid:0x9a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 05:38:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x10d zxid:0x9d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 05:38:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x112 zxid:0xa0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 05:38:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x115 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 05:38:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x11a zxid:0xa6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 05:38:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x121 zxid:0xa9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 05:38:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x126 zxid:0xac txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 05:38:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x129 zxid:0xaf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 05:38:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x12e zxid:0xb2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 05:38:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x133 zxid:0xb5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 05:38:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x138 zxid:0xb8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 05:38:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x13f zxid:0xbb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 05:38:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x146 zxid:0xbe txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 05:38:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x14d zxid:0xc1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 05:38:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x152 zxid:0xc4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 05:38:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x157 zxid:0xc7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 05:38:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x15e zxid:0xca txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 05:38:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x165 zxid:0xcd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 05:38:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x16a zxid:0xd0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 05:38:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x16d zxid:0xd3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 05:38:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x170 zxid:0xd6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 05:38:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x173 zxid:0xd9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 05:38:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x17a zxid:0xdc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 05:38:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x17d zxid:0xdf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 05:38:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707833cf0000 type:create cxid:0x183 zxid:0xe2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 05:38:49 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=2],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=2],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=2],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=2],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=2],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=2],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=2],[Topic=__consumer_offsets,Partition=15,Replica=2],[Topic=__consumer_offsets,Partition=7,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=2],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=2],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=2],[Topic=__consumer_offsets,Partition=49,Replica=2],[Topic=__consumer_offsets,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=2],[Topic=__consumer_offsets,Partition=21,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=2],[Topic=__consumer_offsets,Partition=5,Replica=2],[Topic=__consumer_offsets,Partition=41,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=2],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=2],[Topic=__consumer_offsets,Partition=24,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=2]
2018-09-26 05:38:49 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions __consumer_offsets-21,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-31,__consumer_offsets-3,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-17,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-43,__consumer_offsets-39,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-29
2018-09-26 05:38:49 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-4,__consumer_offsets-46,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-18,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-48,__consumer_offsets-2,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-12,__consumer_offsets-26,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=2] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=2] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=2] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=2] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=2] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=2] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=2] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=2] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=2] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=2] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=2] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=2] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=2] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=2] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=2] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=2] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933089945-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933089945-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537933089945-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933087683-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 05:38:49 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933087683-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 05:38:49 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537933087683-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 05:38:49 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 05:38:49 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 2 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 05:38:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 05:38:49 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:46796 (id: 2147483646 rack: null)
2018-09-26 05:38:49 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-09-26 05:38:50 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 05:38:50 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 05:38:50 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:38:50 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=RestartClusterTest-1537933085672,Partition=0,Replica=1]
2018-09-26 05:38:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:50 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition RestartClusterTest-1537933085672-0 is {"leader":2,"leader_epoch":3,"isr":[2]}
2018-09-26 05:38:50 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=RestartClusterTest-1537933085672,Partition=1,Replica=1]
2018-09-26 05:38:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:50 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-0 broker=2] RestartClusterTest-1537933085672-0 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2
2018-09-26 05:38:50 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 8 from controller 1 epoch 3 for partition RestartClusterTest-1537933085672-0 (last update controller epoch 3) since it is already the leader for the partition.
2018-09-26 05:38:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:50 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-09-26 05:38:50 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition RestartClusterTest-1537933085672-1 is {"leader":2,"leader_epoch":3,"isr":[2]}
2018-09-26 05:38:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:50 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 05:38:50 INFO  Partition:72 - [Partition RestartClusterTest-1537933085672-1 broker=2] RestartClusterTest-1537933085672-1 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2
2018-09-26 05:38:50 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 10 from controller 1 epoch 3 for partition RestartClusterTest-1537933085672-1 (last update controller epoch 3) since it is already the leader for the partition.
2018-09-26 05:38:50 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 05:38:50 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1 epoch 3 fails to send request (type=StopReplicaRequest, controllerId=1, controllerEpoch=3, deletePartitions=false, partitions=RestartClusterTest-1537933085672-1) to broker 127.0.0.1:46796 (id: 1 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:50 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 05:38:50 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 05:38:50 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:50 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:50 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:50 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:50 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-09-26 05:38:50 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-09-26 05:38:50 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:50 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:50 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 05:38:50 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 05:38:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 05:38:50 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:50 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 05:38:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 05:38:50 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 05:38:50 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 2000
2018-09-26 05:38:50 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 05:38:50 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 05:38:50 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 05:38:50 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 05:38:50 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 05:38:50 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 05:38:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 05:38:50 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:50 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:50 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:50 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 05:38:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 05:38:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 05:38:50 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:50 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:50 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:50 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 05:38:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 05:38:50 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 05:38:50 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 05:38:50 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:38:50 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:38:50 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:38:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 05:38:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 05:38:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 05:38:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 05:38:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 05:38:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 05:38:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 05:38:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 05:38:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 05:38:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 05:38:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 05:38:51 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 05:38:51 INFO  LogManager:72 - Shutting down.
2018-09-26 05:38:51 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:38:51 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:38:51 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:38:51 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:38:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2
2018-09-26 05:38:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 05:38:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:46796 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46796 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:38:52 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:38:52 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:38:52 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:38:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 05:38:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 05:38:52 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 05:38:52 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 05:38:52 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 05:38:52 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 05:38:52 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 05:38:52 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 05:38:52 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:38:52 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x101707833cf0000
2018-09-26 05:38:52 INFO  ZooKeeper:687 - Session: 0x101707833cf0000 closed
2018-09-26 05:38:52 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55560 which had sessionid 0x101707833cf0000
2018-09-26 05:38:52 INFO  ClientCnxn:521 - EventThread shut down for session: 0x101707833cf0000
2018-09-26 05:38:52 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:38:52 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:38:52 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 3 and zk version 2
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 4
2018-09-26 05:38:52 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2)
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set(RestartClusterTest-1537933085672, __consumer_offsets)
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: __consumer_offsets,RestartClusterTest-1537933085672
2018-09-26 05:38:52 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:42378 (id: 2 rack: null) for sending state change requests
2018-09-26 05:38:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=17,Replica=2],[Topic=__consumer_offsets,Partition=39,Replica=2],[Topic=__consumer_offsets,Partition=23,Replica=2],[Topic=RestartClusterTest-1537933085672,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=13,Replica=2],[Topic=__consumer_offsets,Partition=33,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=2],[Topic=__consumer_offsets,Partition=11,Replica=2],[Topic=__consumer_offsets,Partition=27,Replica=2],[Topic=__consumer_offsets,Partition=15,Replica=2],[Topic=__consumer_offsets,Partition=7,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=2],[Topic=__consumer_offsets,Partition=35,Replica=2],[Topic=RestartClusterTest-1537933085672,Partition=0,Replica=2],[Topic=__consumer_offsets,Partition=45,Replica=2],[Topic=__consumer_offsets,Partition=49,Replica=2],[Topic=__consumer_offsets,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=2],[Topic=__consumer_offsets,Partition=31,Replica=2],[Topic=__consumer_offsets,Partition=21,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=2],[Topic=__consumer_offsets,Partition=5,Replica=2],[Topic=__consumer_offsets,Partition=41,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=2],[Topic=__consumer_offsets,Partition=29,Replica=2],[Topic=__consumer_offsets,Partition=9,Replica=2]
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-15 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-13 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map([Topic=RestartClusterTest-1537933085672,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=48,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=45,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=23,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=34,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=26,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=44,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=46,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=41,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=11,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=37,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=2,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=3,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=47,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=39,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=22,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=38,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=16,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=8,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=36,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=33,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537933085672,Partition=1,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=31,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=29,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=14,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537933085672,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=18,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=17,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=2] -> OnlineReplica, [Topic=RestartClusterTest-1537933085672,Partition=0,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=2] -> OnlineReplica)
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-11 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-9 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-23 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-21 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-19 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-17 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-7 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-5 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-3 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition RestartClusterTest-1537933085672-1 since its associated leader epoch 3 is not higher than the current leader epoch 3
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-1 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-47 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-45 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-43 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-41 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-49 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-31 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-29 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-27 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-25 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-39 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-37 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-35 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition RestartClusterTest-1537933085672-0 since its associated leader epoch 3 is not higher than the current leader epoch 3
2018-09-26 05:38:52 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-33 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-30 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-30 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-10 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-10 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-14 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-14 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-40 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-40 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-18 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-18 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-26 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-26 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-0 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-24 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-24 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-20 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-20 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-22 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-22 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-12 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-12 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-8 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-8 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-48 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-48 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-6 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-6 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-28 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-28 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-4 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-4 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-44 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-44 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-42 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-42 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-34 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-34 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-46 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-46 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-32 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-32 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-36 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-36 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-38 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-38 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-2 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-2 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-16 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-16 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:38:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map(__consumer_offsets-19 -> OnlinePartition, __consumer_offsets-30 -> OfflinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-10 -> OfflinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-14 -> OfflinePartition, __consumer_offsets-40 -> OfflinePartition, __consumer_offsets-18 -> OfflinePartition, __consumer_offsets-26 -> OfflinePartition, __consumer_offsets-0 -> OfflinePartition, __consumer_offsets-24 -> OfflinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-20 -> OfflinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-22 -> OfflinePartition, __consumer_offsets-5 -> OnlinePartition, RestartClusterTest-1537933085672-1 -> OnlinePartition, __consumer_offsets-12 -> OfflinePartition, __consumer_offsets-8 -> OfflinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, RestartClusterTest-1537933085672-0 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-48 -> OfflinePartition, __consumer_offsets-13 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-6 -> OfflinePartition, __consumer_offsets-28 -> OfflinePartition, __consumer_offsets-4 -> OfflinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-44 -> OfflinePartition, __consumer_offsets-42 -> OfflinePartition, __consumer_offsets-34 -> OfflinePartition, __consumer_offsets-46 -> OfflinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-32 -> OfflinePartition, __consumer_offsets-43 -> OnlinePartition, __consumer_offsets-36 -> OfflinePartition, __consumer_offsets-35 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-38 -> OfflinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-2 -> OfflinePartition, __consumer_offsets-16 -> OfflinePartition)
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 4
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-09-26 05:38:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:38:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078393c0000 type:delete cxid:0x130 zxid:0xeb txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:38:52 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-09-26 05:38:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:38:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:38:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:38:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:38:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:38:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:38:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:38:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:38:54 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 05:38:54 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 05:38:54 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 05:38:54 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 05:38:54 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 05:38:54 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 05:38:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:54 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
2018-09-26 05:38:54 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537933085672-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 05:38:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:54 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
2018-09-26 05:38:54 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537933085672-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 05:38:54 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537933085672-0,RestartClusterTest-1537933085672-1
2018-09-26 05:38:54 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 05:38:59 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 05:38:59 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 05:38:59 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:38:59 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
2018-09-26 05:38:59 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537933085672-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 05:38:59 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:38:59 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
2018-09-26 05:38:59 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537933085672-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 05:38:59 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537933085672-0,RestartClusterTest-1537933085672-1
2018-09-26 05:38:59 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 05:39:04 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 05:39:04 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 05:39:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-0
2018-09-26 05:39:04 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
2018-09-26 05:39:04 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537933085672-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 05:39:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537933085672-1
2018-09-26 05:39:04 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
2018-09-26 05:39:04 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537933085672-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537933085672-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537933085672-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 05:39:04 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537933085672-0,RestartClusterTest-1537933085672-1
2018-09-26 05:39:04 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 05:39:09 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 05:39:09 WARN  KafkaServer:87 - [KafkaServer id=2] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-09-26 05:39:09 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 05:39:09 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 05:39:09 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 05:39:09 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 05:39:09 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 05:39:09 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 05:39:09 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 3000
2018-09-26 05:39:09 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 05:39:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 05:39:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 05:39:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 05:39:09 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 05:39:09 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 05:39:09 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 05:39:09 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 05:39:09 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:39:09 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:39:09 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:39:09 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 05:39:09 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 05:39:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 05:39:10 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 05:39:10 INFO  LogManager:72 - Shutting down.
2018-09-26 05:39:10 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:39:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:39:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:39:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:39:10 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:39:10 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:39:10 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:39:10 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:39:10 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 05:39:10 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 05:39:10 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-09-26 05:39:10 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-09-26 05:39:10 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-09-26 05:39:10 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 05:39:10 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:39:10 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1017078393c0000
2018-09-26 05:39:10 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55558 which had sessionid 0x1017078393c0000
2018-09-26 05:39:10 INFO  ZooKeeper:687 - Session: 0x1017078393c0000 closed
2018-09-26 05:39:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:39:10 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1017078393c0000
2018-09-26 05:39:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:39:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:39:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:39:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:39:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:39:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:39:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:39:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:39:12 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 05:39:12 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 05:39:12 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 05:39:12 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:39:12 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:39:12 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:39:12 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:39:12 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:39:12 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:39:12 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:39:12 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:39:12 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:39:12 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:39:12 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:39:12 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:39:12 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:39:12 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:39:12 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:39:12 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38585
2018-09-26 05:39:13 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:39:13 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:39:13 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:39:13 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:39:13 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:39:13 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:39:13 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:39:13 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:39:13 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:39:13 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:39:13 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:39:13 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:39:13 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:39:13 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:39:13 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38585
2018-09-26 05:39:14 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:46572
	advertised.port = 46572
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:46572
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933154510-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 46572
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38585
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:39:14 INFO  KafkaServer:72 - starting
2018-09-26 05:39:14 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:38585
2018-09-26 05:39:14 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:38585 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@4a14c44f
2018-09-26 05:39:14 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:39:14 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:39:14 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38585. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:39:14 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38585, initiating session
2018-09-26 05:39:14 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:45768
2018-09-26 05:39:14 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:45768
2018-09-26 05:39:14 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:39:14 INFO  ZooKeeperServer:693 - Established session 0x1017078c6330000 with negotiated timeout 30000 for client /127.0.0.1:45768
2018-09-26 05:39:14 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38585, sessionid = 0x1017078c6330000, negotiated timeout = 30000
2018-09-26 05:39:14 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:39:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 05:39:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 05:39:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 05:39:14 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:39:14 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:39:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 05:39:15 INFO  KafkaServer:72 - Cluster ID = 9TqTKGyUTuiqPOuITGBbuA
2018-09-26 05:39:15 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933154510-0/meta.properties
2018-09-26 05:39:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:39:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:39:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:39:15 INFO  LogManager:72 - Loading logs.
2018-09-26 05:39:15 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 05:39:15 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:39:15 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:39:15 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:39:15 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:39:15 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:46572.
2018-09-26 05:39:15 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 05:39:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 05:39:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 05:39:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 05:39:15 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:39:15 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:39:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 05:39:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 05:39:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 05:39:15 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 05:39:15 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:39:15 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 05:39:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:39:15 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 05:39:15 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 05:39:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 05:39:15 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 05:39:15 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 05:39:15 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 05:39:15 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 05:39:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:39:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x43 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:39:15 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:39:15 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,46572,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:39:15 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933154510-0/meta.properties
2018-09-26 05:39:15 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 05:39:15 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 05:39:15 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 05:39:15 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:46572 (id: 1 rack: null) for sending state change requests
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 05:39:15 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 05:39:15 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:39:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:delete cxid:0x4e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:39:15 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 05:39:15 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:15 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:15 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 05:39:15 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:39:15 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:45768 which had sessionid 0x1017078c6330000
2018-09-26 05:39:15 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1017078c6330000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 05:39:15 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:39:15 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:39:15 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:39:15 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:39:15 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:39:15 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:39:15 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:39:15 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:39:15 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:39:15 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:39:15 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:39:15 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:39:15 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:39:15 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38585
2018-09-26 05:39:15 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:39:15 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 05:39:16 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:46024
	advertised.port = 46024
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:46024
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933156722-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 46024
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38585
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:39:16 INFO  KafkaServer:72 - starting
2018-09-26 05:39:16 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:38585
2018-09-26 05:39:16 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:38585 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@288214b1
2018-09-26 05:39:16 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:39:16 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:39:16 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38585. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:39:16 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38585, initiating session
2018-09-26 05:39:16 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:45772
2018-09-26 05:39:16 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:45772
2018-09-26 05:39:16 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-09-26 05:39:16 INFO  ZooKeeperServer:693 - Established session 0x1017078ced70000 with negotiated timeout 30000 for client /127.0.0.1:45772
2018-09-26 05:39:16 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38585, sessionid = 0x1017078ced70000, negotiated timeout = 30000
2018-09-26 05:39:16 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:39:16 INFO  KafkaServer:72 - Cluster ID = 9TqTKGyUTuiqPOuITGBbuA
2018-09-26 05:39:16 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933156722-0/meta.properties
2018-09-26 05:39:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:39:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:39:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:39:16 INFO  LogManager:72 - Loading logs.
2018-09-26 05:39:16 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 05:39:17 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:39:17 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:39:17 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:39:17 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:39:17 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:46024.
2018-09-26 05:39:17 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 05:39:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 05:39:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 05:39:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 05:39:17 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:39:17 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:39:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 05:39:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 05:39:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 05:39:17 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 05:39:17 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 05:39:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:39:17 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 05:39:17 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 05:39:17 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 05:39:17 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 05:39:17 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 05:39:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078ced70000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:39:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078ced70000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:39:17 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:39:17 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,46024,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:39:17 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933156722-0/meta.properties
2018-09-26 05:39:17 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 05:39:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:17 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 05:39:17 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46572, 127.0.0.1:46024]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:39:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:17 INFO  KafkaTestCluster:260 - Found 1 of 1 brokers ready, continuing to wait for cluster to start.
2018-09-26 05:39:17 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38585. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:39:17 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38585, initiating session
2018-09-26 05:39:17 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:45780
2018-09-26 05:39:17 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1017078c6330000 at /127.0.0.1:45780
2018-09-26 05:39:17 INFO  ZooKeeperServer:693 - Established session 0x1017078c6330000 with negotiated timeout 30000 for client /127.0.0.1:45780
2018-09-26 05:39:17 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38585, sessionid = 0x1017078c6330000, negotiated timeout = 30000
2018-09-26 05:39:17 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:39:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:delete cxid:0x50 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:39:17 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 05:39:17 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 05:39:17 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 05:39:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 05:39:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:46024 (id: 2 rack: null) for sending state change requests
2018-09-26 05:39:17 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46572, 127.0.0.1:46024]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:39:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:17 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-09-26 05:39:17 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46572, 127.0.0.1:46024]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:39:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:17 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:39:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:setData cxid:0x57 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/topics/MultiBrokerTest3-1537933152498 Error:KeeperErrorCode = NoNode for /config/topics/MultiBrokerTest3-1537933152498
2018-09-26 05:39:18 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x58 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:39:18 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"1":[1,2],"0":[2,1]}}
2018-09-26 05:39:18 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(MultiBrokerTest3-1537933152498)], deleted topics: [Set()], new partition replica assignment [Map(MultiBrokerTest3-1537933152498-0 -> Vector(2, 1), MultiBrokerTest3-1537933152498-1 -> Vector(1, 2))]
2018-09-26 05:39:18 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for MultiBrokerTest3-1537933152498-0,MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:18 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for MultiBrokerTest3-1537933152498-0,MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:18 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions MultiBrokerTest3-1537933152498-0,MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:18 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=MultiBrokerTest3-1537933152498,Partition=0,Replica=2],[Topic=MultiBrokerTest3-1537933152498,Partition=0,Replica=1],[Topic=MultiBrokerTest3-1537933152498,Partition=1,Replica=1],[Topic=MultiBrokerTest3-1537933152498,Partition=1,Replica=2]
2018-09-26 05:39:18 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537933152498-0,MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:18 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x63 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest3-1537933152498/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest3-1537933152498/partitions/0
2018-09-26 05:39:18 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x64 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest3-1537933152498/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest3-1537933152498/partitions
2018-09-26 05:39:18 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x68 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest3-1537933152498/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest3-1537933152498/partitions/1
2018-09-26 05:39:18 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=MultiBrokerTest3-1537933152498,Partition=0,Replica=2],[Topic=MultiBrokerTest3-1537933152498,Partition=0,Replica=1],[Topic=MultiBrokerTest3-1537933152498,Partition=1,Replica=1],[Topic=MultiBrokerTest3-1537933152498,Partition=1,Replica=2]
2018-09-26 05:39:18 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:18 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1537933152498-0
2018-09-26 05:39:18 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537933152498-1, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:18 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537933152498-0, dir=/tmp/1537933156722-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:18 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537933152498-1, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:18 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537933152498-0, dir=/tmp/1537933156722-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:18 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1537933152498,1] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:18 INFO  Partition:72 - [Partition MultiBrokerTest3-1537933152498-1 broker=1] No checkpointed highwatermark is found for partition MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:18 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1537933152498,0] in /tmp/1537933156722-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:18 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537933152498-1 with initial high watermark 0
2018-09-26 05:39:18 INFO  Partition:72 - [Partition MultiBrokerTest3-1537933152498-0 broker=2] No checkpointed highwatermark is found for partition MultiBrokerTest3-1537933152498-0
2018-09-26 05:39:18 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537933152498-0 with initial high watermark 0
2018-09-26 05:39:18 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537933152498-0 with initial high watermark 0
2018-09-26 05:39:18 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537933152498-1 with initial high watermark 0
2018-09-26 05:39:18 INFO  Partition:72 - [Partition MultiBrokerTest3-1537933152498-0 broker=2] MultiBrokerTest3-1537933152498-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:18 INFO  Partition:72 - [Partition MultiBrokerTest3-1537933152498-1 broker=1] MultiBrokerTest3-1537933152498-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:18 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537933152498-1 with initial high watermark 0
2018-09-26 05:39:18 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537933152498-0 with initial high watermark 0
2018-09-26 05:39:18 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537933152498-0, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:18 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537933152498-1, dir=/tmp/1537933156722-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:18 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537933152498-0, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:18 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537933152498-1, dir=/tmp/1537933156722-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:18 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1537933152498,0] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:18 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1537933152498,1] in /tmp/1537933156722-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:18 INFO  Partition:72 - [Partition MultiBrokerTest3-1537933152498-0 broker=1] No checkpointed highwatermark is found for partition MultiBrokerTest3-1537933152498-0
2018-09-26 05:39:18 INFO  Partition:72 - [Partition MultiBrokerTest3-1537933152498-1 broker=2] No checkpointed highwatermark is found for partition MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:18 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537933152498-0 with initial high watermark 0
2018-09-26 05:39:18 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537933152498-1 with initial high watermark 0
2018-09-26 05:39:18 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1537933152498-0
2018-09-26 05:39:18 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:18 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([MultiBrokerTest3-1537933152498-0, initOffset 0 to broker BrokerEndPoint(2,127.0.0.1,46024)] )
2018-09-26 05:39:18 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-09-26 05:39:18 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting
2018-09-26 05:39:18 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([MultiBrokerTest3-1537933152498-1, initOffset 0 to broker BrokerEndPoint(1,127.0.0.1,46572)] )
2018-09-26 05:39:18 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in MultiBrokerTest3-1537933152498-1. High watermark 0 will be used for truncation.
2018-09-26 05:39:18 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537933152498-1, dir=/tmp/1537933156722-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-09-26 05:39:18 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in MultiBrokerTest3-1537933152498-0. High watermark 0 will be used for truncation.
2018-09-26 05:39:18 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537933152498-0, dir=/tmp/1537933154510-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-09-26 05:39:18 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46572, 127.0.0.1:46024]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:39:18 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:18 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:18 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:46572, 127.0.0.1:46024]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 05:39:18 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:18 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:18 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1537933152498-0. Cache now contains 0 entries.
2018-09-26 05:39:18 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1537933152498-0. Cache now contains 0 entries.
2018-09-26 05:39:18 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 05:39:18 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:46572, 127.0.0.1:46024]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 05:39:18 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:18 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:18 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1537933152498-1. Cache now contains 0 entries.
2018-09-26 05:39:18 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1537933152498-1. Cache now contains 0 entries.
2018-09-26 05:39:19 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 05:39:19 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 05:39:19 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 05:39:19 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 2
2018-09-26 05:39:19 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=MultiBrokerTest3-1537933152498,Partition=1,Replica=2]
2018-09-26 05:39:19 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:19 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down
2018-09-26 05:39:19 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition MultiBrokerTest3-1537933152498-1 is {"leader":1,"leader_epoch":1,"isr":[1]}
2018-09-26 05:39:19 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537933152498-0
2018-09-26 05:39:19 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:19 INFO  Partition:72 - [Partition MultiBrokerTest3-1537933152498-1 broker=1] MultiBrokerTest3-1537933152498-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-09-26 05:39:19 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 4 from controller 1 epoch 1 for partition MultiBrokerTest3-1537933152498-1 (last update controller epoch 1) since it is already the leader for the partition.
2018-09-26 05:39:19 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-09-26 05:39:19 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1537933152498-0
2018-09-26 05:39:19 INFO  Partition:72 - [Partition MultiBrokerTest3-1537933152498-0 broker=1] MultiBrokerTest3-1537933152498-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-09-26 05:39:19 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-09-26 05:39:19 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 05:39:19 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-09-26 05:39:19 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-09-26 05:39:19 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1 epoch 1 fails to send request (type=StopReplicaRequest, controllerId=1, controllerEpoch=1, deletePartitions=false, partitions=MultiBrokerTest3-1537933152498-1) to broker 127.0.0.1:46024 (id: 2 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:19 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 05:39:19 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 05:39:19 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:19 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:19 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:19 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:19 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:19 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:19 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:19 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:19 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped
2018-09-26 05:39:19 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed
2018-09-26 05:39:19 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:19 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 05:39:19 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 05:39:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 05:39:19 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:19 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 05:39:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 05:39:19 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 05:39:19 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-09-26 05:39:19 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 05:39:19 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 05:39:19 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 05:39:19 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 05:39:19 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 05:39:19 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 05:39:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 05:39:19 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:19 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:19 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:19 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 05:39:20 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 05:39:20 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 05:39:20 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:39:20 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:39:20 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:39:20 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 05:39:20 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 05:39:20 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:20 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:20 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:20 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 05:39:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 05:39:20 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 05:39:20 INFO  LogManager:72 - Shutting down.
2018-09-26 05:39:20 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:39:20 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:39:20 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:39:20 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:39:20 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1537933152498-0] Writing producer snapshot at offset 2
2018-09-26 05:39:20 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:20 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:20 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1537933152498-1] Writing producer snapshot at offset 2
2018-09-26 05:39:20 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:39:20 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:39:20 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:39:20 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:39:20 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 05:39:20 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 05:39:20 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 05:39:20 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:39:20 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1017078ced70000
2018-09-26 05:39:20 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 05:39:20 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:46024 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:46024 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 05:39:20 INFO  ZooKeeper:687 - Session: 0x1017078ced70000 closed
2018-09-26 05:39:20 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:39:20 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:45772 which had sessionid 0x1017078ced70000
2018-09-26 05:39:20 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1017078ced70000
2018-09-26 05:39:20 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: 2, all live brokers: 1
2018-09-26 05:39:20 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 05:39:20 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 05:39:20 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 05:39:20 INFO  KafkaController:72 - [Controller id=1] Broker failure callback for 2
2018-09-26 05:39:20 INFO  KafkaController:72 - [Controller id=1] Removed ArrayBuffer(2) from list of shutting down brokers.
2018-09-26 05:39:20 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OfflinePartition for partitions 
2018-09-26 05:39:20 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=MultiBrokerTest3-1537933152498,Partition=1,Replica=2],[Topic=MultiBrokerTest3-1537933152498,Partition=0,Replica=2]
2018-09-26 05:39:20 WARN  KafkaController:87 - [Controller id=1] Cannot remove replica 2 from ISR of partition MultiBrokerTest3-1537933152498-1 since it is not in the ISR. Leader = 1 ; ISR = List(1)
2018-09-26 05:39:20 WARN  KafkaController:87 - [Controller id=1] Cannot remove replica 2 from ISR of partition MultiBrokerTest3-1537933152498-0 since it is not in the ISR. Leader = 1 ; ISR = List(1)
2018-09-26 05:39:20 WARN  logger:87 - [Broker id=1] Ignoring LeaderAndIsr request from controller 1 with correlation id 8 epoch 1 for partition MultiBrokerTest3-1537933152498-0 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-09-26 05:39:20 WARN  logger:87 - [Broker id=1] Ignoring LeaderAndIsr request from controller 1 with correlation id 8 epoch 1 for partition MultiBrokerTest3-1537933152498-1 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-09-26 05:39:20 WARN  ControllerChannelManager:87 - [Channel manager on controller 1]: Not sending request (type=StopReplicaRequest, controllerId=1, controllerEpoch=1, deletePartitions=false, partitions=MultiBrokerTest3-1537933152498-1,MultiBrokerTest3-1537933152498-0) to broker 2, since it is offline.
2018-09-26 05:39:20 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:39:20 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:39:20 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:39:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:39:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:39:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:39:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:39:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:39:22 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 05:39:22 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 05:39:22 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 05:39:22 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46572, 127.0.0.1:46024]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 05:39:22 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:22 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:22 WARN  NetworkClient:241 - [AdminClient clientId=test-consumer-id] Connection to node -2 could not be established. Broker may not be available.
2018-09-26 05:39:22 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:46572, 127.0.0.1:46024]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 05:39:22 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:22 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:22 WARN  NetworkClient:241 - [Consumer clientId=test-consumer-id, groupId=] Connection to node -2 could not be established. Broker may not be available.
2018-09-26 05:39:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:setData cxid:0x7b zxid:0x33 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 05:39:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x7c zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 05:39:27 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-09-26 05:39:27 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 05:39:27 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 05:39:27 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:39:27 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:39:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:39:27 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:39:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 05:39:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xb8 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 05:39:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xb9 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 05:39:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xc2 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 05:39:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xc8 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 05:39:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xce zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 05:39:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xd4 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 05:39:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xda zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 05:39:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xe0 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 05:39:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xe6 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 05:39:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xec zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 05:39:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xf2 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 05:39:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xf8 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 05:39:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0xfe zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 05:39:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x104 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 05:39:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x10a zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 05:39:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x110 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 05:39:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x116 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 05:39:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x11c zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 05:39:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x122 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 05:39:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x128 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 05:39:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x12e zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 05:39:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x134 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 05:39:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x13a zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 05:39:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x140 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 05:39:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x147 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 05:39:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x14d zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 05:39:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x153 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 05:39:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x159 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 05:39:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x15f zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 05:39:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x167 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 05:39:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x16d zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 05:39:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x173 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 05:39:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x179 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 05:39:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x17f zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 05:39:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x185 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 05:39:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x18b zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 05:39:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x191 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 05:39:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x197 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 05:39:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x19d zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 05:39:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1a3 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 05:39:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1a9 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 05:39:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1af zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 05:39:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1b5 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 05:39:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1bb zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 05:39:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1c1 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 05:39:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1c7 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 05:39:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1cd zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 05:39:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1d3 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 05:39:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1d9 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 05:39:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1df zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 05:39:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1017078c6330000 type:create cxid:0x1e5 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 05:39:33 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 05:39:33 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933154510-0] Loading producer state from offset 0 with message format version 2
2018-09-26 05:39:33 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537933154510-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 05:39:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537933154510-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 05:39:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 05:39:33 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 05:39:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 05:39:33 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:46572 (id: 2147483646 rack: null)
2018-09-26 05:39:33 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-09-26 05:39:33 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 05:39:33 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 05:39:33 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:39:33 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537933152498-0
2018-09-26 05:39:33 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-0 besides shutting down brokers 1
2018-09-26 05:39:33 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537933152498-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-0 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-0 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 05:39:33 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:33 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-1 besides shutting down brokers 1
2018-09-26 05:39:33 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537933152498-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-1 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-1 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-09-26 05:39:33 INFO  KafkaServer:72 - [KafkaServer id=1] Remaining partitions to move: MultiBrokerTest3-1537933152498-0,MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:33 INFO  KafkaServer:72 - [KafkaServer id=1] Error code from controller: 0
2018-09-26 05:39:38 WARN  KafkaServer:87 - [KafkaServer id=1] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 05:39:38 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:39:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537933152498-0
2018-09-26 05:39:38 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-0 besides shutting down brokers 1
2018-09-26 05:39:38 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537933152498-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-0 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-0 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 05:39:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:38 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-1 besides shutting down brokers 1
2018-09-26 05:39:38 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537933152498-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-1 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-1 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-09-26 05:39:38 INFO  KafkaServer:72 - [KafkaServer id=1] Remaining partitions to move: MultiBrokerTest3-1537933152498-0,MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:38 INFO  KafkaServer:72 - [KafkaServer id=1] Error code from controller: 0
2018-09-26 05:39:43 WARN  KafkaServer:87 - [KafkaServer id=1] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 05:39:43 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 05:39:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537933152498-0
2018-09-26 05:39:43 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-0 besides shutting down brokers 1
2018-09-26 05:39:43 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537933152498-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-0 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-0 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 05:39:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:43 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-1 besides shutting down brokers 1
2018-09-26 05:39:43 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537933152498-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537933152498-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-1 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537933152498-1 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-09-26 05:39:43 INFO  KafkaServer:72 - [KafkaServer id=1] Remaining partitions to move: MultiBrokerTest3-1537933152498-0,MultiBrokerTest3-1537933152498-1
2018-09-26 05:39:43 INFO  KafkaServer:72 - [KafkaServer id=1] Error code from controller: 0
2018-09-26 05:39:48 WARN  KafkaServer:87 - [KafkaServer id=1] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 05:39:48 WARN  KafkaServer:87 - [KafkaServer id=1] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-09-26 05:39:48 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 05:39:48 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 05:39:48 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 05:39:48 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 05:39:48 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 05:39:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 05:39:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 05:39:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 05:39:48 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 05:39:48 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 05:39:48 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 05:39:48 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 05:39:48 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 05:39:48 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 05:39:48 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 05:39:48 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 05:39:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 05:39:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 05:39:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 05:39:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 05:39:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 05:39:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 05:39:48 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 05:39:48 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 05:39:48 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 05:39:48 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 05:39:48 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 05:39:48 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 05:39:48 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 05:39:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 05:39:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 05:39:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 05:39:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 05:39:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 05:39:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 05:39:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 05:39:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 05:39:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 05:39:49 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 05:39:49 INFO  LogManager:72 - Shutting down.
2018-09-26 05:39:49 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 05:39:49 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 05:39:49 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 05:39:49 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 05:39:49 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1537933152498-0] Writing producer snapshot at offset 2
2018-09-26 05:39:49 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1537933152498-1] Writing producer snapshot at offset 2
2018-09-26 05:39:49 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2
2018-09-26 05:39:49 INFO  LogManager:72 - Shutdown complete.
2018-09-26 05:39:49 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 05:39:49 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 05:39:49 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 05:39:49 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 05:39:49 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 05:39:49 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 05:39:49 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 05:39:49 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 05:39:49 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 05:39:49 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:39:49 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1017078c6330000
2018-09-26 05:39:49 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:45780 which had sessionid 0x1017078c6330000
2018-09-26 05:39:49 INFO  ZooKeeper:687 - Session: 0x1017078c6330000 closed
2018-09-26 05:39:49 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:39:49 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1017078c6330000
2018-09-26 05:39:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:39:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:39:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:39:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:39:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:39:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:39:52 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:39:52 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:39:52 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 05:39:52 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 05:39:52 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 05:39:52 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 05:39:52 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 05:39:52 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:39:52 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:39:52 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:39:52 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:39:52 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:39:52 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:39:52 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:39:52 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:39:52 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:39:52 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:39:52 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:39:52 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:39:52 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:39:52 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:39:52 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38099
2018-09-26 05:39:53 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:39:53 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:39:53 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:39:53 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:39:53 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:39:53 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:39:53 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:39:53 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:39:53 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:39:53 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:39:53 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:39:53 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:39:53 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:39:53 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:39:53 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38099
2018-09-26 05:39:53 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:39:53 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:39:54 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:43031
	advertised.port = 43031
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:43031
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933194361-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 43031
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38099
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:39:54 INFO  KafkaServer:72 - starting
2018-09-26 05:39:54 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:38099
2018-09-26 05:39:54 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:38099 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@10f19647
2018-09-26 05:39:54 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:39:54 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:39:54 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38099. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:39:54 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38099, initiating session
2018-09-26 05:39:54 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:49340
2018-09-26 05:39:54 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:49340
2018-09-26 05:39:54 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 05:39:54 INFO  ZooKeeperServer:693 - Established session 0x101707961dd0000 with negotiated timeout 30000 for client /127.0.0.1:49340
2018-09-26 05:39:54 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38099, sessionid = 0x101707961dd0000, negotiated timeout = 30000
2018-09-26 05:39:54 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:39:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707961dd0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 05:39:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707961dd0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 05:39:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707961dd0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 05:39:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707961dd0000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 05:39:55 INFO  KafkaServer:72 - Cluster ID = _dqj1HqXT6eZpunmnt1t7Q
2018-09-26 05:39:55 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933194361-0/meta.properties
2018-09-26 05:39:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:39:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:39:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:39:55 INFO  LogManager:72 - Loading logs.
2018-09-26 05:39:55 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 05:39:55 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:39:55 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:39:55 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:39:55 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:39:55 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:43031.
2018-09-26 05:39:55 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 05:39:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 05:39:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 05:39:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 05:39:55 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:39:55 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:39:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 05:39:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 05:39:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 05:39:55 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 05:39:55 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 05:39:55 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 05:39:55 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:39:55 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 05:39:55 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 05:39:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707961dd0000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 05:39:55 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 05:39:55 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 05:39:55 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 05:39:55 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 05:39:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707961dd0000 type:create cxid:0x47 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:39:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707961dd0000 type:create cxid:0x48 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:39:55 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 05:39:55 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,43031,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set()
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 05:39:55 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933194361-0/meta.properties
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 05:39:55 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 05:39:55 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 05:39:55 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 05:39:55 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 05:39:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707961dd0000 type:delete cxid:0x4f zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:39:55 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 05:39:55 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:55 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:55 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 05:39:55 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:39:55 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:49340 which had sessionid 0x101707961dd0000
2018-09-26 05:39:55 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:39:55 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x101707961dd0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 05:39:55 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:39:55 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:39:55 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:39:55 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:39:55 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:39:55 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:39:55 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:39:55 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:39:55 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:39:55 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:39:55 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:39:55 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:39:55 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38099
2018-09-26 05:39:55 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:39:55 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 05:39:56 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:36529
	advertised.port = 36529
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:36529
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933196629-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 36529
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38099
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:39:56 INFO  KafkaServer:72 - starting
2018-09-26 05:39:56 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:38099
2018-09-26 05:39:56 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:38099 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@65c86db8
2018-09-26 05:39:56 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:39:56 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:39:56 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38099. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:39:56 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38099, initiating session
2018-09-26 05:39:56 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:49342
2018-09-26 05:39:56 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:49342
2018-09-26 05:39:56 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-09-26 05:39:56 INFO  ZooKeeperServer:693 - Established session 0x10170796ab70000 with negotiated timeout 30000 for client /127.0.0.1:49342
2018-09-26 05:39:56 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38099, sessionid = 0x10170796ab70000, negotiated timeout = 30000
2018-09-26 05:39:56 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:39:56 INFO  KafkaServer:72 - Cluster ID = _dqj1HqXT6eZpunmnt1t7Q
2018-09-26 05:39:56 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933196629-0/meta.properties
2018-09-26 05:39:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:39:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:39:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:39:56 INFO  LogManager:72 - Loading logs.
2018-09-26 05:39:56 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 05:39:56 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 05:39:56 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 05:39:56 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 05:39:56 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 05:39:56 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:36529.
2018-09-26 05:39:56 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 05:39:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 05:39:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 05:39:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 05:39:57 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:39:57 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 05:39:57 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 05:39:57 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38099. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:39:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 05:39:57 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38099, initiating session
2018-09-26 05:39:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 05:39:57 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:49344
2018-09-26 05:39:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 05:39:57 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x101707961dd0000 at /127.0.0.1:49344
2018-09-26 05:39:57 INFO  ZooKeeperServer:693 - Established session 0x101707961dd0000 with negotiated timeout 30000 for client /127.0.0.1:49344
2018-09-26 05:39:57 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38099, sessionid = 0x101707961dd0000, negotiated timeout = 30000
2018-09-26 05:39:57 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:39:57 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 05:39:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x101707961dd0000 type:delete cxid:0x51 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 05:39:57 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 05:39:57 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 05:39:57 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 05:39:57 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 05:39:57 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 1, deleted brokers: , all live brokers: 1
2018-09-26 05:39:57 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 05:39:57 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 1
2018-09-26 05:39:57 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 05:39:57 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 05:39:57 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 05:39:57 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:43031 (id: 1 rack: null) for sending state change requests
2018-09-26 05:39:57 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 05:39:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170796ab70000 type:create cxid:0x1d zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 05:39:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10170796ab70000 type:create cxid:0x1e zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 05:39:57 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 05:39:57 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,36529,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 05:39:57 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933196629-0/meta.properties
2018-09-26 05:39:57 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 05:39:57 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 05:39:57 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 05:39:57 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:36529 (id: 2 rack: null) for sending state change requests
2018-09-26 05:39:57 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 05:39:57 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 05:39:57 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 05:39:57 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 05:39:57 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 05:39:57 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:49344 which had sessionid 0x101707961dd0000
2018-09-26 05:39:57 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:49342 which had sessionid 0x10170796ab70000
2018-09-26 05:39:57 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x101707961dd0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 05:39:57 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x10170796ab70000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 05:39:57 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 05:39:57 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 05:39:57 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 05:39:57 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 05:39:57 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 05:39:57 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 05:39:57 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 05:39:57 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 05:39:57 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 05:39:57 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 05:39:57 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 05:39:57 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 05:39:57 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 05:39:57 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38099
2018-09-26 05:39:57 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 05:39:57 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 05:39:58 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:37475
	advertised.port = 37475
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:37475
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537933198701-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 37475
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38099
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 05:39:58 INFO  KafkaServer:72 - starting
2018-09-26 05:39:58 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:38099
2018-09-26 05:39:58 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:38099 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@c35af2a
2018-09-26 05:39:58 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 05:39:58 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 05:39:58 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38099. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:39:58 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38099, initiating session
2018-09-26 05:39:58 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:49350
2018-09-26 05:39:58 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:49350
2018-09-26 05:39:58 INFO  FileTxnLog:213 - Creating new log file: log.24
2018-09-26 05:39:58 INFO  ZooKeeperServer:693 - Established session 0x101707972d20000 with negotiated timeout 30000 for client /127.0.0.1:49350
2018-09-26 05:39:58 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38099, sessionid = 0x101707972d20000, negotiated timeout = 30000
2018-09-26 05:39:58 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:39:58 INFO  KafkaServer:72 - Cluster ID = _dqj1HqXT6eZpunmnt1t7Q
2018-09-26 05:39:58 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537933198701-0/meta.properties
2018-09-26 05:39:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 05:39:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 05:39:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 05:39:58 INFO  LogManager:72 - Loading logs.
2018-09-26 05:39:58 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 05:39:59 FATAL KafkaServer:120 - [KafkaServer id=3] Fatal error during KafkaServer startup. Prepare to shutdown
java.lang.OutOfMemoryError: Java heap space
	at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
	at java.nio.ByteBuffer.allocate(ByteBuffer.java:335)
	at kafka.log.SkimpyOffsetMap.<init>(OffsetMap.scala:45)
	at kafka.log.LogCleaner$CleanerThread.<init>(LogCleaner.scala:221)
	at kafka.log.LogCleaner$$anonfun$3.apply(LogCleaner.scala:108)
	at kafka.log.LogCleaner$$anonfun$3.apply(LogCleaner.scala:108)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.immutable.Range.foreach(Range.scala:160)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.log.LogCleaner.<init>(LogCleaner.scala:108)
	at kafka.log.LogManager.<init>(LogManager.scala:105)
	at kafka.log.LogManager$.apply(LogManager.scala:799)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:222)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at com.salesforce.kafka.test.KafkaTestServer.start(KafkaTestServer.java:247)
	at com.salesforce.kafka.test.KafkaTestCluster.start(KafkaTestCluster.java:134)
	at com.salesforce.kafka.test.KafkaTestClusterTest.testGetKafkaConnectString(KafkaTestClusterTest.java:194)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:513)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:170)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$167/553871028.execute(Unknown Source)
	at org.junit.jupiter.engine.execution.ThrowableCollector.execute(ThrowableCollector.java:40)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:166)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:113)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:58)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor$NodeExecutor.lambda$executeRecursively$3(HierarchicalTestExecutor.java:113)
2018-09-26 05:39:59 INFO  KafkaServer:72 - [KafkaServer id=3] shutting down
2018-09-26 05:39:59 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 05:39:59 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x101707972d20000
2018-09-26 05:39:59 INFO  ZooKeeper:687 - Session: 0x101707972d20000 closed
2018-09-26 05:39:59 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:49350 which had sessionid 0x101707972d20000
2018-09-26 05:39:59 INFO  ClientCnxn:521 - EventThread shut down for session: 0x101707972d20000
2018-09-26 05:39:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 05:39:59 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38099. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:39:59 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38099, initiating session
2018-09-26 05:39:59 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:49352
2018-09-26 05:39:59 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x10170796ab70000 at /127.0.0.1:49352
2018-09-26 05:39:59 INFO  ZooKeeperServer:693 - Established session 0x10170796ab70000 with negotiated timeout 30000 for client /127.0.0.1:49352
2018-09-26 05:39:59 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38099, sessionid = 0x10170796ab70000, negotiated timeout = 30000
2018-09-26 05:39:59 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:39:59 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38099. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 05:39:59 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38099, initiating session
2018-09-26 05:39:59 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:49354
2018-09-26 05:39:59 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x101707961dd0000 at /127.0.0.1:49354
2018-09-26 05:39:59 INFO  ZooKeeperServer:693 - Established session 0x101707961dd0000 with negotiated timeout 30000 for client /127.0.0.1:49354
2018-09-26 05:39:59 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38099, sessionid = 0x101707961dd0000, negotiated timeout = 30000
2018-09-26 05:39:59 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 05:39:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 05:39:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 05:39:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 05:39:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 05:39:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 05:39:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 05:39:59 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 05:40:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 05:40:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 05:40:00 INFO  KafkaServer:72 - [KafkaServer id=3] shut down completed
2018-09-26 05:40:00 FATAL KafkaServerStartable:114 - Exiting Kafka.
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Failures: 
[ERROR]   KafkaTestServerTest.testExactlyOnceTransaction:104 Should not be empty! ==> expected: <false> but was: <true>
[INFO] 
[ERROR] Tests run: 17, Failures: 1, Errors: 0, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] kafka-junit ........................................ SUCCESS [  1.889 s]
[INFO] kafka-junit-core ................................... FAILURE [03:52 min]
[INFO] kafka-junit4 ....................................... SKIPPED
[INFO] kafka-junit5 ....................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 03:54 min
[INFO] Finished at: 2018-09-26T05:40:01+02:00
[INFO] Final Memory: 32M/492M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.22.0:test (default-test) on project kafka-junit-core: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
[ERROR] The forked VM terminated without properly saying goodbye. VM crash or System.exit called?
[ERROR] Command was /bin/sh -c cd /root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -Xmx2048M -jar /root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core/target/surefire/surefirebooter4656721473780729541.jar /root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core/target/surefire 2018-09-26T05-36-10_286-jvmRun1 surefire3824529328432257670tmp surefire_0556936619066425474tmp
[ERROR] Error occurred in starting fork, check output in log
[ERROR] Process Exit Code: 1
[ERROR] Crashed tests:
[ERROR] com.salesforce.kafka.test.KafkaTestClusterTest
[ERROR] org.apache.maven.surefire.booter.SurefireBooterForkException: The forked VM terminated without properly saying goodbye. VM crash or System.exit called?
[ERROR] Command was /bin/sh -c cd /root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -Xmx2048M -jar /root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core/target/surefire/surefirebooter4656721473780729541.jar /root/workspace/salesforce/kafka-junit/433262372/kafka-junit-core/target/surefire 2018-09-26T05-36-10_286-jvmRun1 surefire3824529328432257670tmp surefire_0556936619066425474tmp
[ERROR] Error occurred in starting fork, check output in log
[ERROR] Process Exit Code: 1
[ERROR] Crashed tests:
[ERROR] com.salesforce.kafka.test.KafkaTestClusterTest
[ERROR] at org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:671)
[ERROR] at org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:533)
[ERROR] at org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:278)
[ERROR] at org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:244)
[ERROR] at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1194)
[ERROR] at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1022)
[ERROR] at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:868)
[ERROR] at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)
[ERROR] at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)
[ERROR] at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)
[ERROR] at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)
[ERROR] at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)
[ERROR] at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)
[ERROR] at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)
[ERROR] at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
[ERROR] at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)
[ERROR] at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)
[ERROR] at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)
[ERROR] at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)
[ERROR] at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)
[ERROR] at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)
[ERROR] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[ERROR] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[ERROR] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[ERROR] at java.lang.reflect.Method.invoke(Method.java:498)
[ERROR] at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)
[ERROR] at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)
[ERROR] at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)
[ERROR] at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :kafka-junit-core
