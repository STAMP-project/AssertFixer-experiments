[INFO] Scanning for projects...
[INFO] Inspecting build with total of 4 modules...
[INFO] Installing Nexus Staging features:
[INFO]   ... total of 4 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] kafka-junit
[INFO] kafka-junit-core
[INFO] kafka-junit4
[INFO] kafka-junit5
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building kafka-junit 3.0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:checkstyle (checkstyle-validate) @ kafka-junit ---
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:check (checkstyle-validate) @ kafka-junit ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- license-maven-plugin:3.0:check (default) @ kafka-junit ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building kafka-junit-core 3.0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:checkstyle (checkstyle-validate) @ kafka-junit-core ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:check (checkstyle-validate) @ kafka-junit-core ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ kafka-junit-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/salesforce/kafka-junit/416262473/kafka-junit-core/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ kafka-junit-core ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- license-maven-plugin:3.0:check (default) @ kafka-junit-core ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ kafka-junit-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ kafka-junit-core ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.22.0:test (default-test) @ kafka-junit-core ---
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.pom (2 KB at 6.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon/1.0-beta-6/wagon-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon/1.0-beta-6/wagon-1.0-beta-6.pom (13 KB at 549.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.pom (4 KB at 112.5 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-providers/1.0-beta-6/wagon-providers-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-providers/1.0-beta-6/wagon-providers-1.0-beta-6.pom (3 KB at 103.0 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.pom (3 KB at 57.2 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.pom (390 B at 18.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.pom (704 B at 24.6 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.pom (8 KB at 315.9 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.pom (4 KB at 186.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.pom (4 KB at 149.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.pom (4 KB at 95.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-parent/1.5.0/jackrabbit-parent-1.5.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-parent/1.5.0/jackrabbit-parent-1.5.0.pom (25 KB at 711.3 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.pom (3 KB at 108.0 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-api/1.5.3/slf4j-api-1.5.3.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-api/1.5.3/slf4j-api-1.5.3.pom (3 KB at 145.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-parent/1.5.3/slf4j-parent-1.5.3.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-parent/1.5.3/slf4j-parent-1.5.3.pom (8 KB at 359.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.0/commons-httpclient-3.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.0/commons-httpclient-3.0.pom (8 KB at 356.4 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.pom (2 KB at 79.3 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.pom (2 KB at 100.5 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting/2.2.1/maven-reporting-2.2.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting/2.2.1/maven-reporting-2.2.1.pom (2 KB at 82.9 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.pom (2 KB at 85.4 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia/1.1/doxia-1.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia/1.1/doxia-1.1.pom (15 KB at 741.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.jar (39 KB at 1143.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.jar (11 KB at 228.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.jar (25 KB at 466.6 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.jar (52 KB at 824.4 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.jar (110 KB at 1496.5 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.jar (18 KB at 744.3 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.jar (30 KB at 890.3 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar (298 KB at 4804.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.jar (6 KB at 230.9 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.jar (10 KB at 455.1 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.jar (199 KB at 4604.8 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.jar (296 KB at 5285.4 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.jar (12 KB at 503.2 KB/sec)
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running com.salesforce.kafka.test.KafkaTestServerTest
log4j: reset attribute= "false".
log4j: Threshold ="null".
log4j: Level value for root is  [INFO].
log4j: root level set to INFO
log4j: Class name: [org.apache.log4j.ConsoleAppender]
log4j: Parsing layout of class: "org.apache.log4j.PatternLayout"
log4j: Setting property [conversionPattern] to [%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n].
log4j: Adding appender named [console] to category [root].
2018-08-15 10:40:35 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:40:35 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:zookeeper.version=3.4.12--1, built on 03/27/2018 04:49 GMT
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:host.name=cyclone1
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:java.version=1.8.0_121
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:java.vendor=Oracle Corporation
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:java.class.path=/root/workspace/salesforce/kafka-junit/416262473/kafka-junit-core/target/test-classes:/root/workspace/salesforce/kafka-junit/416262473/kafka-junit-core/target/classes:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/junit/jupiter/junit-jupiter-api/5.2.0/junit-jupiter-api-5.2.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apiguardian/apiguardian-api/1.0.0/apiguardian-api-1.0.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/opentest4j/opentest4j/1.1.0/opentest4j-1.1.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/junit/platform/junit-platform-commons/1.2.0/junit-platform-commons-1.2.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/mockito/mockito-core/2.18.3/mockito-core-2.18.3.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/net/bytebuddy/byte-buddy/1.8.5/byte-buddy-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/net/bytebuddy/byte-buddy-agent/1.8.5/byte-buddy-agent-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/zookeeper/zookeeper/3.4.12/zookeeper-3.4.12.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/jline/jline/0.9.94/jline-0.9.94.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/kafka/kafka-streams/1.0.2/kafka-streams-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/kafka/connect-json/1.0.2/connect-json-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/kafka/connect-api/1.0.2/connect-api-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/rocksdb/rocksdbjni/5.7.3/rocksdbjni-5.7.3.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/kafka/kafka_2.11/1.0.2/kafka_2.11-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/kafka/kafka-clients/1.0.2/kafka-clients-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/lz4/lz4-java/1.4/lz4-java-1.4.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/slf4j/slf4j-simple/1.7.25/slf4j-simple-1.7.25.jar:
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:java.io.tmpdir=/tmp
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:java.compiler=<NA>
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:os.name=Linux
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:os.arch=amd64
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:os.version=3.10.0-862.3.2.el7.x86_64
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:user.name=root
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:user.home=/root
2018-08-15 10:40:35 INFO  ZooKeeperServer:100 - Server environment:user.dir=/root/workspace/salesforce/kafka-junit/416262473/kafka-junit-core
2018-08-15 10:40:35 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:40:35 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:40:35 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:40:35 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:40:35 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:45237
2018-08-15 10:40:37 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:38669
	advertised.port = 38669
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 22
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:38669
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322436694-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 38669
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:45237
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:40:37 INFO  KafkaServer:72 - starting
2018-08-15 10:40:37 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:45237
2018-08-15 10:40:37 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:zookeeper.version=3.4.12--1, built on 03/27/2018 04:49 GMT
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:host.name=cyclone1
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:java.version=1.8.0_121
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:java.vendor=Oracle Corporation
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:java.class.path=/root/workspace/salesforce/kafka-junit/416262473/kafka-junit-core/target/test-classes:/root/workspace/salesforce/kafka-junit/416262473/kafka-junit-core/target/classes:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/junit/jupiter/junit-jupiter-api/5.2.0/junit-jupiter-api-5.2.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apiguardian/apiguardian-api/1.0.0/apiguardian-api-1.0.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/opentest4j/opentest4j/1.1.0/opentest4j-1.1.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/junit/platform/junit-platform-commons/1.2.0/junit-platform-commons-1.2.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/mockito/mockito-core/2.18.3/mockito-core-2.18.3.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/net/bytebuddy/byte-buddy/1.8.5/byte-buddy-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/net/bytebuddy/byte-buddy-agent/1.8.5/byte-buddy-agent-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/zookeeper/zookeeper/3.4.12/zookeeper-3.4.12.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/jline/jline/0.9.94/jline-0.9.94.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/kafka/kafka-streams/1.0.2/kafka-streams-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/kafka/connect-json/1.0.2/connect-json-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/kafka/connect-api/1.0.2/connect-api-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/rocksdb/rocksdbjni/5.7.3/rocksdbjni-5.7.3.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/kafka/kafka_2.11/1.0.2/kafka_2.11-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/kafka/kafka-clients/1.0.2/kafka-clients-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/lz4/lz4-java/1.4/lz4-java-1.4.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/salesforce/kafka-junit/416262473/.m2/org/slf4j/slf4j-simple/1.7.25/slf4j-simple-1.7.25.jar:
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:java.io.tmpdir=/tmp
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:java.compiler=<NA>
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:os.name=Linux
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:os.arch=amd64
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:os.version=3.10.0-862.3.2.el7.x86_64
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:user.name=root
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:user.home=/root
2018-08-15 10:40:37 INFO  ZooKeeper:100 - Client environment:user.dir=/root/workspace/salesforce/kafka-junit/416262473/kafka-junit-core
2018-08-15 10:40:37 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:45237 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@76494737
2018-08-15 10:40:37 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:40:37 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:45237. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:40:37 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:45237, initiating session
2018-08-15 10:40:37 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:45512
2018-08-15 10:40:37 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:45512
2018-08-15 10:40:37 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:40:37 INFO  ZooKeeperServer:693 - Established session 0x100994197b20000 with negotiated timeout 30000 for client /127.0.0.1:45512
2018-08-15 10:40:37 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:45237, sessionid = 0x100994197b20000, negotiated timeout = 30000
2018-08-15 10:40:37 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:40:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994197b20000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:40:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994197b20000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:40:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994197b20000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:40:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994197b20000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:40:38 INFO  KafkaServer:72 - Cluster ID = hPZFHzj6TFOXXj8YSaN4hg
2018-08-15 10:40:38 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322436694-0/meta.properties
2018-08-15 10:40:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:40:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:40:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:40:38 INFO  LogManager:72 - Loading logs.
2018-08-15 10:40:38 INFO  LogManager:72 - Logs loading complete in 9 ms.
2018-08-15 10:40:38 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:40:38 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:40:38 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:40:38 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:40:38 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:38669.
2018-08-15 10:40:38 INFO  SocketServer:72 - [SocketServer brokerId=22] Started 1 acceptor threads
2018-08-15 10:40:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Starting
2018-08-15 10:40:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Starting
2018-08-15 10:40:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Starting
2018-08-15 10:40:38 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:40:38 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:40:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Starting
2018-08-15 10:40:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Starting
2018-08-15 10:40:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Starting
2018-08-15 10:40:38 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:40:38 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] 22 successfully elected as the controller
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Starting become controller state transition
2018-08-15 10:40:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994197b20000 type:setData cxid:0x2a zxid:0x17 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:40:38 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Starting up.
2018-08-15 10:40:38 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Startup complete.
2018-08-15 10:40:38 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=22] Removed 0 expired offsets in 2 milliseconds.
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Incremented epoch to 1
2018-08-15 10:40:38 INFO  ProducerIdManager:72 - [ProducerId Manager 22]: Acquired new producerId block (brokerId:22,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:40:38 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Starting up.
2018-08-15 10:40:38 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Starting
2018-08-15 10:40:38 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Startup complete.
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Partitions being reassigned: Map()
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Partitions already reassigned: Set()
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Resuming reassignment of partitions: Map()
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Currently active brokers in the cluster: Set()
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Currently shutting brokers in the cluster: Set()
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Current list of topics in the cluster: Set()
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] List of topics to be deleted: 
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] List of topics ineligible for deletion: 
2018-08-15 10:40:38 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=22] Started replica state machine with initial state -> Map()
2018-08-15 10:40:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=22] Started partition state machine with initial state -> Map()
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Ready to serve as the new controller with epoch 1
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Partitions undergoing preferred replica election: 
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Partitions that completed preferred replica election: 
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Resuming preferred replica election for partitions: 
2018-08-15 10:40:38 INFO  KafkaController:72 - [Controller id=22] Starting preferred replica leader election for partitions 
2018-08-15 10:40:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=22] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:40:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994197b20000 type:delete cxid:0x4a zxid:0x1a txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:40:38 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/22 (is it secure? false)
2018-08-15 10:40:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994197b20000 type:create cxid:0x4b zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:40:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994197b20000 type:create cxid:0x4c zxid:0x1c txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:40:39 INFO  KafkaController:72 - [Controller id=22] Starting the controller scheduler
2018-08-15 10:40:39 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:40:39 INFO  ZkUtils:72 - Registered broker 22 at path /brokers/ids/22 with addresses: EndPoint(127.0.0.1,38669,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:40:39 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322436694-0/meta.properties
2018-08-15 10:40:39 INFO  KafkaController:72 - [Controller id=22] Newly added brokers: 22, deleted brokers: , all live brokers: 22
2018-08-15 10:40:39 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Starting
2018-08-15 10:40:39 INFO  KafkaController:72 - [Controller id=22] New broker startup callback for 22
2018-08-15 10:40:39 INFO  SocketServer:72 - [SocketServer brokerId=22] Started processors for 1 acceptors
2018-08-15 10:40:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:40:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:40:39 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Controller 22 connected to 127.0.0.1:38669 (id: 22 rack: null) for sending state change requests
2018-08-15 10:40:39 INFO  KafkaServer:72 - [KafkaServer id=22] started
2018-08-15 10:40:39 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:38669]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:40:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:40:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:40:39 INFO  KafkaServer:72 - [KafkaServer id=22] shutting down
2018-08-15 10:40:39 INFO  KafkaServer:72 - [KafkaServer id=22] Starting controlled shutdown
2018-08-15 10:40:39 INFO  KafkaController:72 - [Controller id=22] Shutting down broker 22
2018-08-15 10:40:39 INFO  KafkaServer:72 - [KafkaServer id=22] Controlled shutdown succeeded
2018-08-15 10:40:39 INFO  SocketServer:72 - [SocketServer brokerId=22] Stopping socket server request processors
2018-08-15 10:40:39 INFO  SocketServer:72 - [SocketServer brokerId=22] Stopped socket server request processors
2018-08-15 10:40:39 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 22], shutting down
2018-08-15 10:40:39 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 22], shut down completely
2018-08-15 10:40:39 INFO  KafkaApis:72 - [KafkaApi-22] Shutdown complete.
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Shutting down
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Shutdown completed
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Stopped
2018-08-15 10:40:39 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Shutting down.
2018-08-15 10:40:39 INFO  ProducerIdManager:72 - [ProducerId Manager 22]: Shutdown complete: last producerId assigned 0
2018-08-15 10:40:39 INFO  TransactionStateManager:72 - [Transaction State Manager 22]: Shutdown complete
2018-08-15 10:40:39 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Shutting down
2018-08-15 10:40:39 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Stopped
2018-08-15 10:40:39 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Shutdown completed
2018-08-15 10:40:39 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Shutdown complete.
2018-08-15 10:40:39 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Shutting down.
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Shutting down
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Shutdown completed
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Stopped
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Shutting down
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Shutdown completed
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Stopped
2018-08-15 10:40:39 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Shutdown complete.
2018-08-15 10:40:39 INFO  ReplicaManager:72 - [ReplicaManager broker=22] Shutting down
2018-08-15 10:40:39 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:40:39 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:40:39 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:40:39 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 22] shutting down
2018-08-15 10:40:39 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 22] shutdown completed
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Shutting down
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Stopped
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Shutdown completed
2018-08-15 10:40:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Shutting down
2018-08-15 10:40:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Stopped
2018-08-15 10:40:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Shutdown completed
2018-08-15 10:40:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Shutting down
2018-08-15 10:40:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Stopped
2018-08-15 10:40:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Shutdown completed
2018-08-15 10:40:40 INFO  ReplicaManager:72 - [ReplicaManager broker=22] Shut down completely
2018-08-15 10:40:40 INFO  LogManager:72 - Shutting down.
2018-08-15 10:40:40 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:40:40 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:40:40 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:40:40 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:40:40 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:40:40 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:40:40 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:40:40 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:40:40 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=22] Stopped partition state machine
2018-08-15 10:40:40 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=22] Stopped replica state machine
2018-08-15 10:40:40 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Shutting down
2018-08-15 10:40:40 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Stopped
2018-08-15 10:40:40 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Shutdown completed
2018-08-15 10:40:40 INFO  KafkaController:72 - [Controller id=22] Resigned
2018-08-15 10:40:40 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:40:40 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994197b20000
2018-08-15 10:40:40 INFO  ZooKeeper:687 - Session: 0x100994197b20000 closed
2018-08-15 10:40:40 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:45512 which had sessionid 0x100994197b20000
2018-08-15 10:40:40 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994197b20000
2018-08-15 10:40:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:40:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:40:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:40:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:40:41 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:40:41 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:40:41 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:40:41 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:40:41 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:40:41 INFO  SocketServer:72 - [SocketServer brokerId=22] Shutting down socket server
2018-08-15 10:40:41 INFO  SocketServer:72 - [SocketServer brokerId=22] Shutdown completed
2018-08-15 10:40:41 INFO  KafkaServer:72 - [KafkaServer id=22] shut down completed
2018-08-15 10:40:41 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:40:41 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:40:41 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:40:41 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:40:41 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:40:41 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:40:41 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:40:41 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:40:41 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:40:41 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:40:41 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:40:41 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:40:41 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:40:41 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:40:41 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:40:41 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:36167
2018-08-15 10:40:41 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:40:42 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:46600
	advertised.port = 46600
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:46600
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322442339-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 46600
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:36167
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:40:42 INFO  KafkaServer:72 - starting
2018-08-15 10:40:42 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:36167
2018-08-15 10:40:42 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:36167 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@59aa20b3
2018-08-15 10:40:42 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:40:42 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:40:42 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:36167. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:40:42 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:36167, initiating session
2018-08-15 10:40:42 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55686
2018-08-15 10:40:42 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:55686
2018-08-15 10:40:42 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:40:42 INFO  ZooKeeperServer:693 - Established session 0x1009941adc80000 with negotiated timeout 30000 for client /127.0.0.1:55686
2018-08-15 10:40:42 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:36167, sessionid = 0x1009941adc80000, negotiated timeout = 30000
2018-08-15 10:40:42 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:40:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:40:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:40:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:40:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:40:43 INFO  KafkaServer:72 - Cluster ID = jn81Y1IhTc2knT8G9jl0EA
2018-08-15 10:40:43 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322442339-0/meta.properties
2018-08-15 10:40:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:40:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:40:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:40:43 INFO  LogManager:72 - Loading logs.
2018-08-15 10:40:43 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:40:43 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:40:43 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:40:43 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:40:43 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:40:43 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:46600.
2018-08-15 10:40:43 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:40:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:40:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:40:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:40:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:40:43 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:40:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:40:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:40:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:40:43 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:40:43 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:40:43 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:40:43 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:40:43 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:40:43 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:40:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:40:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:40:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:40:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:40:43 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:40:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:40:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:40:43 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:40:43 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,46600,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:40:43 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322442339-0/meta.properties
2018-08-15 10:40:43 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:40:43 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:40:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:40:43 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:46600 (id: 1 rack: null) for sending state change requests
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:40:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:40:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:40:43 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:40:43 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:40:43 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:40:43 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:40:43 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46600]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:40:43 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:40:43 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-08-15 10:40:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:setData cxid:0x54 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/transactional-topic1534322441332 Error:KeeperErrorCode = NoNode for /config/topics/transactional-topic1534322441332
2018-08-15 10:40:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x55 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:40:43 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(transactional-topic1534322441332)], deleted topics: [Set()], new partition replica assignment [Map(transactional-topic1534322441332-0 -> Vector(1))]
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for transactional-topic1534322441332-0
2018-08-15 10:40:43 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for transactional-topic1534322441332-0
2018-08-15 10:40:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions transactional-topic1534322441332-0
2018-08-15 10:40:43 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=transactional-topic1534322441332,Partition=0,Replica=1]
2018-08-15 10:40:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions transactional-topic1534322441332-0
2018-08-15 10:40:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x5d zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/transactional-topic1534322441332/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/transactional-topic1534322441332/partitions/0
2018-08-15 10:40:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x5e zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/transactional-topic1534322441332/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/transactional-topic1534322441332/partitions
2018-08-15 10:40:44 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=transactional-topic1534322441332,Partition=0,Replica=1]
2018-08-15 10:40:44 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions transactional-topic1534322441332-0
2018-08-15 10:40:44 INFO  Log:72 - [Log partition=transactional-topic1534322441332-0, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:44 INFO  Log:72 - [Log partition=transactional-topic1534322441332-0, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms
2018-08-15 10:40:44 INFO  LogManager:72 - Created log for partition [transactional-topic1534322441332,0] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:44 INFO  Partition:72 - [Partition transactional-topic1534322441332-0 broker=1] No checkpointed highwatermark is found for partition transactional-topic1534322441332-0
2018-08-15 10:40:44 INFO  Replica:72 - Replica loaded for partition transactional-topic1534322441332-0 with initial high watermark 0
2018-08-15 10:40:44 INFO  Partition:72 - [Partition transactional-topic1534322441332-0 broker=1] transactional-topic1534322441332-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:44 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46600]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-15 10:40:44 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:40:44 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:40:44 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:46600]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = MyRandomString1534322444280
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-08-15 10:40:44 INFO  KafkaProducer:336 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1534322444280] Instantiated a transactional producer.
2018-08-15 10:40:44 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1534322444280] Overriding the default acks to all since idempotence is enabled.
2018-08-15 10:40:44 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:40:44 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:40:44 INFO  TransactionManager:346 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1534322444280] ProducerId set to -1 with epoch -1
2018-08-15 10:40:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:setData cxid:0x67 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/__transaction_state Error:KeeperErrorCode = NoNode for /config/topics/__transaction_state
2018-08-15 10:40:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x68 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:40:44 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"2":[1],"1":[1],"3":[1],"0":[1]}}
2018-08-15 10:40:44 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __transaction_state with 4 partitions and replication factor 1 is successful
2018-08-15 10:40:44 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__transaction_state)], deleted topics: [Set()], new partition replica assignment [Map(__transaction_state-1 -> Vector(1), __transaction_state-0 -> Vector(1), __transaction_state-2 -> Vector(1), __transaction_state-3 -> Vector(1))]
2018-08-15 10:40:44 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-08-15 10:40:44 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-08-15 10:40:44 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-08-15 10:40:44 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__transaction_state,Partition=1,Replica=1],[Topic=__transaction_state,Partition=0,Replica=1],[Topic=__transaction_state,Partition=2,Replica=1],[Topic=__transaction_state,Partition=3,Replica=1]
2018-08-15 10:40:44 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-08-15 10:40:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x73 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/1
2018-08-15 10:40:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x74 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions
2018-08-15 10:40:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x7b zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/0
2018-08-15 10:40:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x7e zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/2
2018-08-15 10:40:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x84 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/3
2018-08-15 10:40:45 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__transaction_state,Partition=1,Replica=1],[Topic=__transaction_state,Partition=0,Replica=1],[Topic=__transaction_state,Partition=2,Replica=1],[Topic=__transaction_state,Partition=3,Replica=1]
2018-08-15 10:40:45 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __transaction_state-3,__transaction_state-0,__transaction_state-1,__transaction_state-2
2018-08-15 10:40:45 INFO  Log:72 - [Log partition=__transaction_state-3, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:45 INFO  Log:72 - [Log partition=__transaction_state-3, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2018-08-15 10:40:45 INFO  LogManager:72 - Created log for partition [__transaction_state,3] in /tmp/1534322442339-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:45 INFO  Partition:72 - [Partition __transaction_state-3 broker=1] No checkpointed highwatermark is found for partition __transaction_state-3
2018-08-15 10:40:45 INFO  Replica:72 - Replica loaded for partition __transaction_state-3 with initial high watermark 0
2018-08-15 10:40:45 INFO  Partition:72 - [Partition __transaction_state-3 broker=1] __transaction_state-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:45 INFO  Log:72 - [Log partition=__transaction_state-0, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:45 INFO  Log:72 - [Log partition=__transaction_state-0, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:45 INFO  LogManager:72 - Created log for partition [__transaction_state,0] in /tmp/1534322442339-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:45 INFO  Partition:72 - [Partition __transaction_state-0 broker=1] No checkpointed highwatermark is found for partition __transaction_state-0
2018-08-15 10:40:45 INFO  Replica:72 - Replica loaded for partition __transaction_state-0 with initial high watermark 0
2018-08-15 10:40:45 INFO  Partition:72 - [Partition __transaction_state-0 broker=1] __transaction_state-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:45 INFO  Log:72 - [Log partition=__transaction_state-1, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:45 INFO  Log:72 - [Log partition=__transaction_state-1, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:40:45 INFO  LogManager:72 - Created log for partition [__transaction_state,1] in /tmp/1534322442339-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:45 INFO  Partition:72 - [Partition __transaction_state-1 broker=1] No checkpointed highwatermark is found for partition __transaction_state-1
2018-08-15 10:40:45 INFO  Replica:72 - Replica loaded for partition __transaction_state-1 with initial high watermark 0
2018-08-15 10:40:45 INFO  Partition:72 - [Partition __transaction_state-1 broker=1] __transaction_state-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:45 INFO  Log:72 - [Log partition=__transaction_state-2, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:45 INFO  Log:72 - [Log partition=__transaction_state-2, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:40:45 INFO  LogManager:72 - Created log for partition [__transaction_state,2] in /tmp/1534322442339-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:45 INFO  Partition:72 - [Partition __transaction_state-2 broker=1] No checkpointed highwatermark is found for partition __transaction_state-2
2018-08-15 10:40:45 INFO  Replica:72 - Replica loaded for partition __transaction_state-2 with initial high watermark 0
2018-08-15 10:40:45 INFO  Partition:72 - [Partition __transaction_state-2 broker=1] __transaction_state-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:45 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-2
2018-08-15 10:40:45 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-1
2018-08-15 10:40:45 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-0
2018-08-15 10:40:45 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-3
2018-08-15 10:40:45 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __transaction_state-0. Cache now contains 0 entries.
2018-08-15 10:40:45 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Initialized transactionalId MyRandomString1534322444280 with producerId 0 and producer epoch 0 on partition __transaction_state-0
2018-08-15 10:40:45 INFO  TransactionManager:346 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1534322444280] ProducerId set to 0 with epoch 0
2018-08-15 10:40:45 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: transactional-topic1534322441332-0. Cache now contains 0 entries.
2018-08-15 10:40:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:setData cxid:0x96 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-08-15 10:40:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x97 zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:40:45 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-08-15 10:40:45 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-08-15 10:40:45 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-08-15 10:40:45 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:40:45 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:40:45 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:40:45 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:40:46 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:40:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0xd3 zxid:0x3d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-08-15 10:40:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0xd4 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-08-15 10:40:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0xdd zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-08-15 10:40:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0xe3 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-08-15 10:40:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0xe9 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-08-15 10:40:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0xef zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-08-15 10:40:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0xf5 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-08-15 10:40:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0xfb zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-08-15 10:40:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x101 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-08-15 10:40:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x107 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-08-15 10:40:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x10d zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-08-15 10:40:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x113 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-08-15 10:40:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x119 zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-08-15 10:40:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x11f zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-08-15 10:40:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x125 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-08-15 10:40:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x12b zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-08-15 10:40:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x131 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-08-15 10:40:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x137 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-08-15 10:40:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x13d zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-08-15 10:40:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x144 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-08-15 10:40:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x14a zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-08-15 10:40:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x150 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-08-15 10:40:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x156 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-08-15 10:40:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x15c zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-08-15 10:40:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x162 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-08-15 10:40:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x168 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-08-15 10:40:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x16e zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-08-15 10:40:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x174 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-08-15 10:40:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x17a zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-08-15 10:40:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x180 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-08-15 10:40:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x186 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-08-15 10:40:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x18c zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-08-15 10:40:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x192 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-08-15 10:40:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x198 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-08-15 10:40:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x19e zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-08-15 10:40:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1a4 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-08-15 10:40:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1aa zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-08-15 10:40:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1b0 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-08-15 10:40:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1b6 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-08-15 10:40:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1bc zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-08-15 10:40:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1c2 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-08-15 10:40:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1c8 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-08-15 10:40:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1ce zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-08-15 10:40:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1d4 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-08-15 10:40:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1da zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-08-15 10:40:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1e0 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-08-15 10:40:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1e6 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-08-15 10:40:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1ec zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-08-15 10:40:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1f2 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-08-15 10:40:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1f8 zxid:0xcf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-08-15 10:40:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941adc80000 type:create cxid:0x1fe zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-08-15 10:40:51 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:40:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322442339-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:40:51 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322442339-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:40:51 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1534322442339-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-08-15 10:40:51 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-08-15 10:40:51 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 3 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-08-15 10:40:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-08-15 10:40:51 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Discovered group coordinator 127.0.0.1:46600 (id: 2147483646 rack: null)
2018-08-15 10:40:51 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Revoking previously assigned partitions []
2018-08-15 10:40:51 INFO  AbstractCoordinator:336 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] (Re-)joining group
2018-08-15 10:40:52 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 0 (__consumer_offsets-31)
2018-08-15 10:40:55 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Stabilized group test-consumer-group generation 1 (__consumer_offsets-31)
2018-08-15 10:40:55 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Assignment received from leader for group test-consumer-group for generation 1
2018-08-15 10:40:55 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-31. Cache now contains 0 entries.
2018-08-15 10:40:55 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Successfully joined group with generation 1
2018-08-15 10:40:55 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Setting newly assigned partitions [transactional-topic1534322441332-0]
2018-08-15 10:40:55 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1534322444280] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-08-15 10:40:55 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 1 (__consumer_offsets-31)
2018-08-15 10:40:55 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Group test-consumer-group with generation 2 is now empty (__consumer_offsets-31)
2018-08-15 10:40:55 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:40:55 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:40:55 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:40:55 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:40:55 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:40:55 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:40:55 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:40:55 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:40:55 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:40:55 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:40:55 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1
2018-08-15 10:40:55 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:40:55 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:40:55 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:40:55 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:40:55 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:40:55 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:40:55 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:40:55 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:40:55 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:40:55 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:40:55 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:40:55 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:40:55 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:40:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:40:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:40:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:40:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:40:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:40:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:40:56 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:40:56 INFO  LogManager:72 - Shutting down.
2018-08-15 10:40:56 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:40:56 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:40:56 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:40:56 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:40:56 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__transaction_state-0] Writing producer snapshot at offset 4
2018-08-15 10:40:56 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2
2018-08-15 10:40:57 INFO  ProducerStateManager:72 - [ProducerStateManager partition=transactional-topic1534322441332-0] Writing producer snapshot at offset 2
2018-08-15 10:40:58 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:40:58 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:40:58 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:40:58 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:40:58 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:40:58 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:40:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:40:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:40:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:40:58 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:40:58 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:40:58 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009941adc80000
2018-08-15 10:40:58 INFO  ZooKeeper:687 - Session: 0x1009941adc80000 closed
2018-08-15 10:40:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:40:58 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009941adc80000
2018-08-15 10:40:58 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55686 which had sessionid 0x1009941adc80000
2018-08-15 10:40:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:40:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:40:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:41:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:41:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:41:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:41:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:41:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:41:01 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:41:01 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:41:01 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:41:01 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:41:01 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:41:01 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:41:01 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:41:01 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:41:01 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:41:01 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:41:01 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:41:01 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:41:01 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:41:01 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:41:01 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:41:01 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:41:01 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:41:01 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:41:01 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:37051
2018-08-15 10:41:02 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:42738
	advertised.port = 42738
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:42738
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322462223-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 42738
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:37051
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:41:02 INFO  KafkaServer:72 - starting
2018-08-15 10:41:02 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:37051
2018-08-15 10:41:02 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:37051 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@c074c0c
2018-08-15 10:41:02 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:41:02 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:41:02 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:37051. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:41:02 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:37051, initiating session
2018-08-15 10:41:02 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:47724
2018-08-15 10:41:02 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:47724
2018-08-15 10:41:02 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:41:02 INFO  ZooKeeperServer:693 - Established session 0x1009941fb740000 with negotiated timeout 30000 for client /127.0.0.1:47724
2018-08-15 10:41:02 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:37051, sessionid = 0x1009941fb740000, negotiated timeout = 30000
2018-08-15 10:41:02 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:41:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941fb740000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:41:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941fb740000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:41:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941fb740000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:41:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941fb740000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:41:02 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:41:02 INFO  KafkaServer:72 - Cluster ID = 3pevSNBUS3KBZ1GpVYnf8g
2018-08-15 10:41:02 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322462223-0/meta.properties
2018-08-15 10:41:02 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:41:02 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:41:02 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:41:02 INFO  LogManager:72 - Loading logs.
2018-08-15 10:41:02 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:41:03 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:41:03 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:41:03 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:41:03 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:41:03 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:42738.
2018-08-15 10:41:03 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:41:03 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:41:03 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:41:03 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:41:03 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:41:03 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:41:03 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:41:03 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:41:03 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:41:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941fb740000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:41:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:41:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:41:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:41:03 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:41:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941fb740000 type:create cxid:0x44 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:41:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941fb740000 type:create cxid:0x45 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:41:03 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:03 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,42738,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:41:03 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322462223-0/meta.properties
2018-08-15 10:41:03 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:41:03 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:41:03 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:41:03 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:42738 (id: 1 rack: null) for sending state change requests
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:41:03 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:41:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009941fb740000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:41:03 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:41:03 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:03 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:03 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:41:03 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:41:03 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-08-15 10:41:03 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:41:03 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:41:03 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:41:03 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:41:03 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:41:03 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:41:03 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:41:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:41:03 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:41:03 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:41:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:41:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:41:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:41:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:41:03 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:41:03 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:41:03 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:41:03 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:41:03 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:41:03 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:41:03 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:41:03 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:41:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:41:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:41:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:41:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:41:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:41:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:41:04 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:41:04 INFO  LogManager:72 - Shutting down.
2018-08-15 10:41:04 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:41:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:41:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:41:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:41:04 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:41:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:41:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:41:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:41:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:41:04 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:41:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:41:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:41:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:41:04 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:41:04 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:41:04 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009941fb740000
2018-08-15 10:41:04 INFO  ZooKeeper:687 - Session: 0x1009941fb740000 closed
2018-08-15 10:41:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:41:04 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:47724 which had sessionid 0x1009941fb740000
2018-08-15 10:41:04 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009941fb740000
2018-08-15 10:41:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:41:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:41:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:41:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:41:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:41:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:41:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:41:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:41:06 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:41:07 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:41:07 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:41:07 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:41:07 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:41:07 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:41:07 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:41:07 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:41:07 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:41:07 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:41:07 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:41:07 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:41:07 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:41:07 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:41:07 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:41:07 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:41:07 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:41:07 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:41:07 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34661
2018-08-15 10:41:08 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:40536
	advertised.port = 40536
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:40536
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322468028-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 40536
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:34661
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:41:08 INFO  KafkaServer:72 - starting
2018-08-15 10:41:08 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:34661
2018-08-15 10:41:08 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:34661 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@1dfd5f51
2018-08-15 10:41:08 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:41:08 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:41:08 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34661. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:41:08 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34661, initiating session
2018-08-15 10:41:08 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:38942
2018-08-15 10:41:08 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:38942
2018-08-15 10:41:08 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:41:08 INFO  ZooKeeperServer:693 - Established session 0x100994212210000 with negotiated timeout 30000 for client /127.0.0.1:38942
2018-08-15 10:41:08 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34661, sessionid = 0x100994212210000, negotiated timeout = 30000
2018-08-15 10:41:08 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:41:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:41:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:41:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:41:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:41:08 INFO  KafkaServer:72 - Cluster ID = G2nJFIFkR52x8D9Af99-_A
2018-08-15 10:41:08 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322468028-0/meta.properties
2018-08-15 10:41:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:41:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:41:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:41:08 INFO  LogManager:72 - Loading logs.
2018-08-15 10:41:08 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:41:08 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:41:08 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:41:08 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:41:08 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:41:08 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:40536.
2018-08-15 10:41:08 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:41:08 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:41:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:41:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:41:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:41:08 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:41:08 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:41:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:41:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:41:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:41:08 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:41:08 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:41:08 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:41:08 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:41:08 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:08 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:41:08 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:41:09 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:41:09 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:41:09 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:41:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:41:09 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:41:09 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:09 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,40536,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:41:09 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322468028-0/meta.properties
2018-08-15 10:41:09 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:41:09 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:41:09 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:41:09 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:40536 (id: 1 rack: null) for sending state change requests
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:41:09 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:41:09 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:41:09 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:09 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:09 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:41:09 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:40536]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:41:09 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:09 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:setData cxid:0x54 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/subscribe-topic1534322467024 Error:KeeperErrorCode = NoNode for /config/topics/subscribe-topic1534322467024
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x55 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:41:09 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(subscribe-topic1534322467024)], deleted topics: [Set()], new partition replica assignment [Map(subscribe-topic1534322467024-0 -> Vector(1))]
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for subscribe-topic1534322467024-0
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for subscribe-topic1534322467024-0
2018-08-15 10:41:09 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions subscribe-topic1534322467024-0
2018-08-15 10:41:09 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=subscribe-topic1534322467024,Partition=0,Replica=1]
2018-08-15 10:41:09 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions subscribe-topic1534322467024-0
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x5d zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/subscribe-topic1534322467024/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/subscribe-topic1534322467024/partitions/0
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x5e zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/subscribe-topic1534322467024/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/subscribe-topic1534322467024/partitions
2018-08-15 10:41:09 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=subscribe-topic1534322467024,Partition=0,Replica=1]
2018-08-15 10:41:09 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions subscribe-topic1534322467024-0
2018-08-15 10:41:09 INFO  Log:72 - [Log partition=subscribe-topic1534322467024-0, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:09 INFO  Log:72 - [Log partition=subscribe-topic1534322467024-0, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:09 INFO  LogManager:72 - Created log for partition [subscribe-topic1534322467024,0] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:09 INFO  Partition:72 - [Partition subscribe-topic1534322467024-0 broker=1] No checkpointed highwatermark is found for partition subscribe-topic1534322467024-0
2018-08-15 10:41:09 INFO  Replica:72 - Replica loaded for partition subscribe-topic1534322467024-0 with initial high watermark 0
2018-08-15 10:41:09 INFO  Partition:72 - [Partition subscribe-topic1534322467024-0 broker=1] subscribe-topic1534322467024-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:09 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:40536]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-08-15 10:41:09 WARN  ProducerConfig:246 - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2018-08-15 10:41:09 WARN  ProducerConfig:246 - The configuration 'group.id' was supplied but isn't a known config.
2018-08-15 10:41:09 WARN  ProducerConfig:246 - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2018-08-15 10:41:09 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:09 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:09 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: subscribe-topic1534322467024-0. Cache now contains 0 entries.
2018-08-15 10:41:09 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-08-15 10:41:09 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:40536]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-15 10:41:09 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:09 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:setData cxid:0x67 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x68 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:41:09 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-08-15 10:41:09 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:41:09 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:41:09 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:41:09 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:41:09 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:41:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xa4 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-08-15 10:41:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xa5 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-08-15 10:41:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xae zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-08-15 10:41:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xb4 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-08-15 10:41:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xba zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-08-15 10:41:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xc0 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-08-15 10:41:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xc6 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-08-15 10:41:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xcc zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-08-15 10:41:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xd2 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-08-15 10:41:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xd8 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-08-15 10:41:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xde zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-08-15 10:41:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xe4 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-08-15 10:41:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xea zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-08-15 10:41:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xf0 zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-08-15 10:41:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xf6 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-08-15 10:41:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0xfc zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-08-15 10:41:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x102 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-08-15 10:41:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x108 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-08-15 10:41:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x10e zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-08-15 10:41:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x114 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-08-15 10:41:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x11a zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-08-15 10:41:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x120 zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-08-15 10:41:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x126 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-08-15 10:41:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x12c zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-08-15 10:41:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x132 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-08-15 10:41:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x138 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-08-15 10:41:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x13e zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-08-15 10:41:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x144 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-08-15 10:41:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x14a zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-08-15 10:41:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x150 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-08-15 10:41:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x156 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-08-15 10:41:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x15c zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-08-15 10:41:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x162 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-08-15 10:41:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x168 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-08-15 10:41:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x16e zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-08-15 10:41:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x174 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-08-15 10:41:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x17a zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-08-15 10:41:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x180 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-08-15 10:41:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x186 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-08-15 10:41:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x18c zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-08-15 10:41:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x192 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-08-15 10:41:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x198 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-08-15 10:41:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x19e zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-08-15 10:41:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x1a4 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-08-15 10:41:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x1aa zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-08-15 10:41:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x1b0 zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-08-15 10:41:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x1b6 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-08-15 10:41:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x1bc zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-08-15 10:41:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x1c2 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-08-15 10:41:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x1c8 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-08-15 10:41:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994212210000 type:create cxid:0x1ce zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-08-15 10:41:15 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:41:15 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322468028-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:15 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322468028-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:15 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1534322468028-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-08-15 10:41:15 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-08-15 10:41:15 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-08-15 10:41:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-08-15 10:41:15 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Discovered group coordinator 127.0.0.1:40536 (id: 2147483646 rack: null)
2018-08-15 10:41:15 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Revoking previously assigned partitions []
2018-08-15 10:41:15 INFO  AbstractCoordinator:336 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] (Re-)joining group
2018-08-15 10:41:15 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 0 (__consumer_offsets-31)
2018-08-15 10:41:18 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Stabilized group test-consumer-group generation 1 (__consumer_offsets-31)
2018-08-15 10:41:18 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Assignment received from leader for group test-consumer-group for generation 1
2018-08-15 10:41:18 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-31. Cache now contains 0 entries.
2018-08-15 10:41:18 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Successfully joined group with generation 1
2018-08-15 10:41:18 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Setting newly assigned partitions [subscribe-topic1534322467024-0]
2018-08-15 10:41:18 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 1 (__consumer_offsets-31)
2018-08-15 10:41:18 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Group test-consumer-group with generation 2 is now empty (__consumer_offsets-31)
2018-08-15 10:41:18 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:41:18 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:41:18 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:41:18 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:41:18 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:41:18 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:41:18 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:41:18 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:41:18 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:41:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:41:19 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:41:19 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:41:19 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:41:19 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:41:19 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:41:19 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:41:19 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:41:19 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:41:19 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:41:19 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:41:19 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:41:19 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:41:19 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:41:19 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:41:19 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:41:19 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:41:19 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:41:19 INFO  LogManager:72 - Shutting down.
2018-08-15 10:41:19 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:41:19 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:41:19 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:41:19 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:41:20 INFO  ProducerStateManager:72 - [ProducerStateManager partition=subscribe-topic1534322467024-0] Writing producer snapshot at offset 1
2018-08-15 10:41:20 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2
2018-08-15 10:41:21 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:41:21 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:41:21 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:41:21 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:41:21 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:41:21 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:41:21 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:41:21 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:41:21 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:41:21 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:41:21 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:41:21 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994212210000
2018-08-15 10:41:21 INFO  ZooKeeper:687 - Session: 0x100994212210000 closed
2018-08-15 10:41:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:41:21 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994212210000
2018-08-15 10:41:21 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:38942 which had sessionid 0x100994212210000
2018-08-15 10:41:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:41:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:41:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:41:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:41:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:41:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:41:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:41:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:41:22 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:41:22 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:41:22 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:41:22 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:41:22 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:41:22 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:41:22 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:41:22 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:41:22 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:41:22 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:41:22 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:41:22 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:41:22 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:41:22 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:41:22 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:41:22 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:41:22 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:41:22 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:41:22 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:37348
2018-08-15 10:41:23 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:36032
	advertised.port = 36032
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:36032
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322483885-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 36032
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:37348
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:41:23 INFO  KafkaServer:72 - starting
2018-08-15 10:41:23 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:37348
2018-08-15 10:41:23 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:37348 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@df5f5c0
2018-08-15 10:41:23 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:41:23 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:41:23 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:37348. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:41:23 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:37348, initiating session
2018-08-15 10:41:23 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:60508
2018-08-15 10:41:23 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:60508
2018-08-15 10:41:23 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:41:23 INFO  ZooKeeperServer:693 - Established session 0x100994250120000 with negotiated timeout 30000 for client /127.0.0.1:60508
2018-08-15 10:41:23 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:37348, sessionid = 0x100994250120000, negotiated timeout = 30000
2018-08-15 10:41:23 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:41:23 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:41:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:41:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:41:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:41:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:41:24 INFO  KafkaServer:72 - Cluster ID = skva0-HRQbOEWdZczSY7iQ
2018-08-15 10:41:24 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322483885-0/meta.properties
2018-08-15 10:41:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:41:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:41:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:41:24 INFO  LogManager:72 - Loading logs.
2018-08-15 10:41:24 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-08-15 10:41:24 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:41:24 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:41:24 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:41:24 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:41:24 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:36032.
2018-08-15 10:41:24 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:41:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:41:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:41:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:41:24 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:41:24 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:41:24 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:41:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:41:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:41:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:41:24 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:24 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:41:24 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:41:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:41:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:setData cxid:0x2b zxid:0x17 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:41:24 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:41:24 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:41:24 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:41:24 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set()
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:41:24 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:41:24 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:41:24 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:41:24 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:41:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x49 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:41:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x4a zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:41:25 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:41:25 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,36032,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:41:25 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322483885-0/meta.properties
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:41:25 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:41:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:delete cxid:0x4f zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:41:25 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:41:25 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:25 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:25 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:41:25 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:36032]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:41:25 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:25 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 1, deleted brokers: , all live brokers: 1
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 1
2018-08-15 10:41:25 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:41:25 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:36032 (id: 1 rack: null) for sending state change requests
2018-08-15 10:41:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:setData cxid:0x53 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/testRestartingBroker-1534322482880 Error:KeeperErrorCode = NoNode for /config/topics/testRestartingBroker-1534322482880
2018-08-15 10:41:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x54 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:41:25 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(testRestartingBroker-1534322482880)], deleted topics: [Set()], new partition replica assignment [Map(testRestartingBroker-1534322482880-0 -> Vector(1))]
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for testRestartingBroker-1534322482880-0
2018-08-15 10:41:25 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for testRestartingBroker-1534322482880-0
2018-08-15 10:41:25 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions testRestartingBroker-1534322482880-0
2018-08-15 10:41:25 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=testRestartingBroker-1534322482880,Partition=0,Replica=1]
2018-08-15 10:41:25 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions testRestartingBroker-1534322482880-0
2018-08-15 10:41:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x5c zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/testRestartingBroker-1534322482880/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/testRestartingBroker-1534322482880/partitions/0
2018-08-15 10:41:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x5d zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/testRestartingBroker-1534322482880/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/testRestartingBroker-1534322482880/partitions
2018-08-15 10:41:25 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=testRestartingBroker-1534322482880,Partition=0,Replica=1]
2018-08-15 10:41:25 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions testRestartingBroker-1534322482880-0
2018-08-15 10:41:25 INFO  Log:72 - [Log partition=testRestartingBroker-1534322482880-0, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:25 INFO  Log:72 - [Log partition=testRestartingBroker-1534322482880-0, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:25 INFO  LogManager:72 - Created log for partition [testRestartingBroker-1534322482880,0] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:25 INFO  Partition:72 - [Partition testRestartingBroker-1534322482880-0 broker=1] No checkpointed highwatermark is found for partition testRestartingBroker-1534322482880-0
2018-08-15 10:41:25 INFO  Replica:72 - Replica loaded for partition testRestartingBroker-1534322482880-0 with initial high watermark 0
2018-08-15 10:41:25 INFO  Partition:72 - [Partition testRestartingBroker-1534322482880-0 broker=1] testRestartingBroker-1534322482880-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:25 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:36032]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-08-15 10:41:25 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:25 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:25 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: testRestartingBroker-1534322482880-0. Cache now contains 0 entries.
2018-08-15 10:41:25 INFO  KafkaTestUtils:126 - Produce completed
2018-08-15 10:41:25 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-08-15 10:41:25 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:36032]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:41:25 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:25 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:25 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:36032]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-08-15 10:41:25 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:25 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:25 INFO  KafkaTestUtils:256 - Found 2 records in kafka
2018-08-15 10:41:27 INFO  KafkaTestUtils:256 - Found 0 records in kafka
2018-08-15 10:41:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:setData cxid:0x66 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-08-15 10:41:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x67 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:41:27 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-08-15 10:41:27 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-08-15 10:41:27 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-08-15 10:41:27 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:41:27 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:41:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:41:27 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:41:28 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:41:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xa3 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-08-15 10:41:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xa4 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-08-15 10:41:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xad zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-08-15 10:41:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xb3 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-08-15 10:41:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xb9 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-08-15 10:41:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xbf zxid:0x39 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-08-15 10:41:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xc5 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-08-15 10:41:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xcb zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-08-15 10:41:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xd1 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-08-15 10:41:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xd7 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-08-15 10:41:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xdd zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-08-15 10:41:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xe3 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-08-15 10:41:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xe9 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-08-15 10:41:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xef zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-08-15 10:41:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xf5 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-08-15 10:41:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0xfb zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-08-15 10:41:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x101 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-08-15 10:41:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x107 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-08-15 10:41:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x10d zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-08-15 10:41:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x113 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-08-15 10:41:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x119 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-08-15 10:41:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x11f zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-08-15 10:41:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x125 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-08-15 10:41:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x12b zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-08-15 10:41:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x131 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-08-15 10:41:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x137 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-08-15 10:41:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x13d zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-08-15 10:41:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x143 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-08-15 10:41:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x149 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-08-15 10:41:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x14f zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-08-15 10:41:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x155 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-08-15 10:41:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x15b zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-08-15 10:41:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x161 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-08-15 10:41:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x167 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-08-15 10:41:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x16e zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-08-15 10:41:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x173 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-08-15 10:41:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x179 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-08-15 10:41:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x17f zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-08-15 10:41:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x185 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-08-15 10:41:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x18b zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-08-15 10:41:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x192 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-08-15 10:41:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x197 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-08-15 10:41:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x19d zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-08-15 10:41:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x1a4 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-08-15 10:41:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x1a9 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-08-15 10:41:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x1af zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-08-15 10:41:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x1b5 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-08-15 10:41:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x1bb zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-08-15 10:41:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x1c1 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-08-15 10:41:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x1c7 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-08-15 10:41:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994250120000 type:create cxid:0x1cd zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-08-15 10:41:33 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:41:33 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:33 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1534322483885-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-08-15 10:41:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-08-15 10:41:33 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-08-15 10:41:33 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-08-15 10:41:33 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:36032 (id: 2147483646 rack: null)
2018-08-15 10:41:33 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-08-15 10:41:33 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:41:33 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:41:33 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:41:33 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:41:33 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:41:33 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:41:33 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:41:33 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:41:33 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:41:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:41:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:41:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:41:33 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:41:33 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:41:33 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:41:33 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:41:33 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:41:33 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:41:33 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:41:33 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:41:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:41:34 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:41:34 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:41:34 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:41:34 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:41:34 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:41:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:41:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:41:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:41:34 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:41:34 INFO  LogManager:72 - Shutting down.
2018-08-15 10:41:34 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:41:34 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:41:34 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:41:34 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:41:34 INFO  ProducerStateManager:72 - [ProducerStateManager partition=testRestartingBroker-1534322482880-0] Writing producer snapshot at offset 2
2018-08-15 10:41:35 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 1
2018-08-15 10:41:35 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:41:35 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:41:35 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:41:35 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:41:35 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:41:35 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:41:35 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:41:35 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:41:35 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:41:35 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:41:35 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:41:35 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994250120000
2018-08-15 10:41:35 INFO  ZooKeeper:687 - Session: 0x100994250120000 closed
2018-08-15 10:41:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:41:35 WARN  NIOServerCnxn:376 - Unable to read additional data from client sessionid 0x100994250120000, likely client has closed socket
2018-08-15 10:41:35 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994250120000
2018-08-15 10:41:35 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:60508 which had sessionid 0x100994250120000
2018-08-15 10:41:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:41:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:41:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:41:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:41:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:41:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:41:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:41:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:41:37 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:41:37 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:41:37 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:41:37 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:41:37 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:41:37 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:41:37 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:41:37 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:41:37 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:41:37 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:41:37 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:41:37 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:41:37 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:41:37 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:41:37 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:41:37 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:41:37 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:41:37 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:37348
2018-08-15 10:41:38 INFO  KafkaServer:72 - [KafkaServer id=1] starting
2018-08-15 10:41:38 INFO  KafkaServer:72 - [KafkaServer id=1] Connecting to zookeeper on 127.0.0.1:37348
2018-08-15 10:41:38 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:37348 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@74518890
2018-08-15 10:41:38 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:41:38 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:41:38 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:37348. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:41:38 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:60556
2018-08-15 10:41:38 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:37348, initiating session
2018-08-15 10:41:38 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:60556
2018-08-15 10:41:38 INFO  FileTxnLog:213 - Creating new log file: log.c4
2018-08-15 10:41:38 INFO  ZooKeeperServer:693 - Established session 0x100994289f60000 with negotiated timeout 30000 for client /127.0.0.1:60556
2018-08-15 10:41:38 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:37348, sessionid = 0x100994289f60000, negotiated timeout = 30000
2018-08-15 10:41:38 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:41:38 INFO  KafkaServer:72 - [KafkaServer id=1] Cluster ID = skva0-HRQbOEWdZczSY7iQ
2018-08-15 10:41:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:41:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:41:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:41:38 INFO  LogManager:72 - Loading logs.
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=testRestartingBroker-1534322482880-0, dir=/tmp/1534322483885-0] Loading producer state from offset 2 with message format version 2
2018-08-15 10:41:38 INFO  ProducerStateManager:72 - [ProducerStateManager partition=testRestartingBroker-1534322482880-0] Loading producer state from snapshot file '/tmp/1534322483885-0/testRestartingBroker-1534322482880-0/00000000000000000002.snapshot'
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=testRestartingBroker-1534322482880-0, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 18 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322483885-0] Loading producer state from offset 1 with message format version 2
2018-08-15 10:41:38 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/1534322483885-0/__consumer_offsets-0/00000000000000000001.snapshot'
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 3 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322483885-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:38 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322483885-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:38 INFO  LogManager:72 - Logs loading complete in 143 ms.
2018-08-15 10:41:38 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:41:39 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:41:39 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:41:39 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:41:39 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:41:39 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:36032.
2018-08-15 10:41:39 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:41:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:41:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:41:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:41:39 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:41:39 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:41:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:41:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:41:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:41:39 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:41:39 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:41:39 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:41:39 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:41:39 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Initialized controller epoch to 1 and zk version 0
2018-08-15 10:41:39 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 2
2018-08-15 10:41:39 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:41:39 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:41:39 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:41:39 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:41:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994289f60000 type:create cxid:0x41 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:41:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994289f60000 type:create cxid:0x42 zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:41:39 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:39 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,36032,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:41:39 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:41:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:39 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:41:39 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:36032]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:41:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set()
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set(testRestartingBroker-1534322482880, __consumer_offsets)
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: __consumer_offsets,testRestartingBroker-1534322482880
2018-08-15 10:41:39 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map([Topic=__consumer_offsets,Partition=48,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=11,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=10,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=21,Replica=1] -> ReplicaDeletionIneligible, [Topic=testRestartingBroker-1534322482880,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=6,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=13,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=34,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=26,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=44,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=46,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=12,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=33,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=47,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=37,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=23,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=42,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=32,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=2,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=43,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=4,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=40,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=28,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=15,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=22,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=3,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=7,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=38,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=16,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=8,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=17,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=36,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=49,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=29,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=45,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=5,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=41,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=27,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=24,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=30,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=31,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=35,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=19,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=20,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=9,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=14,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=25,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=18,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=39,Replica=1] -> ReplicaDeletionIneligible)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-19 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-19 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-30 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-30 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-47 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-47 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-29 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-29 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-41 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-41 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-39 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-39 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-10 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-10 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-17 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-17 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-14 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-14 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-40 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-40 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-18 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-18 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-26 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-26 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-0 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-24 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-24 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-33 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-33 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-20 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-20 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-21 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-21 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-3 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-3 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-22 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-22 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-5 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-5 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-12 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-12 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-8 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-8 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-23 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-23 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-15 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-15 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-48 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-48 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-11 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-11 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-13 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-13 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition testRestartingBroker-1534322482880-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition testRestartingBroker-1534322482880-0 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-49 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-49 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-6 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-6 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-28 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-28 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-4 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-4 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-37 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-37 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-31 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-31 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-44 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-44 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-42 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-42 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-34 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-34 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-46 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-46 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-25 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-25 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-45 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-45 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-27 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-27 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-32 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-32 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-43 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-43 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-36 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-36 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-35 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-35 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-7 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-7 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-9 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-9 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-38 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-38 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-1 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-1 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-2 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-2 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-16 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-16 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:39 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map(__consumer_offsets-19 -> OfflinePartition, __consumer_offsets-30 -> OfflinePartition, __consumer_offsets-47 -> OfflinePartition, __consumer_offsets-29 -> OfflinePartition, __consumer_offsets-41 -> OfflinePartition, __consumer_offsets-39 -> OfflinePartition, __consumer_offsets-10 -> OfflinePartition, __consumer_offsets-17 -> OfflinePartition, __consumer_offsets-14 -> OfflinePartition, __consumer_offsets-40 -> OfflinePartition, __consumer_offsets-18 -> OfflinePartition, __consumer_offsets-26 -> OfflinePartition, __consumer_offsets-0 -> OfflinePartition, __consumer_offsets-24 -> OfflinePartition, __consumer_offsets-33 -> OfflinePartition, __consumer_offsets-20 -> OfflinePartition, __consumer_offsets-21 -> OfflinePartition, __consumer_offsets-3 -> OfflinePartition, __consumer_offsets-22 -> OfflinePartition, __consumer_offsets-5 -> OfflinePartition, __consumer_offsets-12 -> OfflinePartition, __consumer_offsets-8 -> OfflinePartition, __consumer_offsets-23 -> OfflinePartition, __consumer_offsets-15 -> OfflinePartition, __consumer_offsets-48 -> OfflinePartition, __consumer_offsets-11 -> OfflinePartition, __consumer_offsets-13 -> OfflinePartition, testRestartingBroker-1534322482880-0 -> OfflinePartition, __consumer_offsets-49 -> OfflinePartition, __consumer_offsets-6 -> OfflinePartition, __consumer_offsets-28 -> OfflinePartition, __consumer_offsets-4 -> OfflinePartition, __consumer_offsets-37 -> OfflinePartition, __consumer_offsets-31 -> OfflinePartition, __consumer_offsets-44 -> OfflinePartition, __consumer_offsets-42 -> OfflinePartition, __consumer_offsets-34 -> OfflinePartition, __consumer_offsets-46 -> OfflinePartition, __consumer_offsets-25 -> OfflinePartition, __consumer_offsets-45 -> OfflinePartition, __consumer_offsets-27 -> OfflinePartition, __consumer_offsets-32 -> OfflinePartition, __consumer_offsets-43 -> OfflinePartition, __consumer_offsets-36 -> OfflinePartition, __consumer_offsets-35 -> OfflinePartition, __consumer_offsets-7 -> OfflinePartition, __consumer_offsets-9 -> OfflinePartition, __consumer_offsets-38 -> OfflinePartition, __consumer_offsets-1 -> OfflinePartition, __consumer_offsets-2 -> OfflinePartition, __consumer_offsets-16 -> OfflinePartition)
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 2
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:41:39 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:41:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994289f60000 type:delete cxid:0xdb zxid:0xcb txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 1, deleted brokers: , all live brokers: 1
2018-08-15 10:41:39 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 1
2018-08-15 10:41:39 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:41:39 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:36032 (id: 1 rack: null) for sending state change requests
2018-08-15 10:41:39 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=testRestartingBroker-1534322482880,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-19
2018-08-15 10:41:39 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,testRestartingBroker-1534322482880-0,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-08-15 10:41:39 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:36032]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-08-15 10:41:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 1
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-30
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-47
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-29
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-41
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-39
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-10
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-17
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-14
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-40
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-18
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-26
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-0
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-24
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-33
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-20
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:39 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-21
2018-08-15 10:41:39 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-08-15 10:41:39 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-3
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-22
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-5
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-12
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-8
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-23
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-15
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-48
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-11
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-13
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition testRestartingBroker-1534322482880-0
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-49
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-6
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-28
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-4
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-37
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-31
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition testRestartingBroker-1534322482880-0 with initial high watermark 2
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-44
2018-08-15 10:41:40 INFO  Partition:72 - [Partition testRestartingBroker-1534322482880-0 broker=1] testRestartingBroker-1534322482880-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-42
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  KafkaTestUtils:256 - Found 2 records in kafka
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-34
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-46
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-25
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-45
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-27
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-32
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:40 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-08-15 10:41:40 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-43
2018-08-15 10:41:40 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:41 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-36
2018-08-15 10:41:41 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:41 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-35
2018-08-15 10:41:41 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:41 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-7
2018-08-15 10:41:41 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:41 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-9
2018-08-15 10:41:41 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:41 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-08-15 10:41:41 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-38
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:41 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-1
2018-08-15 10:41:41 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:41 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-08-15 10:41:41 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-2
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-08-15 10:41:41 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Loading group metadata for  with generation 0
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 20 milliseconds.
2018-08-15 10:41:41 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-16
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds.
2018-08-15 10:41:41 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-08-15 10:41:41 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,testRestartingBroker-1534322482880-0,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-0 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-29 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-48 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-10 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-45 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-26 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-7 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-42 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-4 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-23 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-1 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-20 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-39 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-17 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-36 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-14 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-33 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-49 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-11 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-30 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-46 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-27 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-8 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-24 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-43 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-5 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-21 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-2 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-40 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-37 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-18 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-34 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-15 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-12 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-31 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition testRestartingBroker-1534322482880-0 broker=1] testRestartingBroker-1534322482880-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition testRestartingBroker-1534322482880-0 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-9 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-47 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-19 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-28 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-38 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-35 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-44 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-6 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-25 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-16 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-22 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-41 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-32 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-3 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:41 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:41:41 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-13 (last update controller epoch 2) since it is already the leader for the partition.
2018-08-15 10:41:42 INFO  KafkaTestUtils:256 - Found 0 records in kafka
2018-08-15 10:41:42 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:36032 (id: 2147483646 rack: null)
2018-08-15 10:41:42 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:1, offset:1}, Current: {epoch:0, offset0} for Partition: __consumer_offsets-0. Cache now contains 1 entries.
2018-08-15 10:41:42 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:41:42 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:41:42 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:41:42 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:41:42 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:41:42 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:41:42 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:41:42 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:41:42 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:41:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:41:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:41:43 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1000
2018-08-15 10:41:43 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:41:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:41:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:41:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:41:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:41:43 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:41:43 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:41:43 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:41:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:41:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:41:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:41:43 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:41:43 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:41:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:41:43 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:41:43 INFO  LogManager:72 - Shutting down.
2018-08-15 10:41:43 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:41:43 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:41:43 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:41:43 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:41:43 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2
2018-08-15 10:41:43 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:41:43 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:41:43 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:41:43 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:41:43 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:41:43 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:41:43 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:41:43 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:41:43 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:41:43 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:41:43 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:41:43 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994289f60000
2018-08-15 10:41:43 INFO  ZooKeeper:687 - Session: 0x100994289f60000 closed
2018-08-15 10:41:43 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:60556 which had sessionid 0x100994289f60000
2018-08-15 10:41:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:41:43 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994289f60000
2018-08-15 10:41:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:41:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:41:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:41:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:41:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:41:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:41:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:41:45 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:41:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:41:45 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:41:45 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:41:45 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:41:45 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:41:45 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:41:45 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:41:45 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:41:45 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:41:45 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:41:45 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:41:45 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[ERROR] Tests run: 6, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 70.414 s <<< FAILURE! - in com.salesforce.kafka.test.KafkaTestServerTest
[ERROR] testOverrideBrokerProperties  Time elapsed: 5.945 s
[ERROR] testGetKafkaBrokersBeforeBrokerIsStarted  Time elapsed: 0 s
[ERROR] testExactlyOnceTransaction  Time elapsed: 19.887 s  <<< FAILURE!
org.opentest4j.AssertionFailedError: Should not be empty! ==> expected: <false> but was: <true>
	at com.salesforce.kafka.test.KafkaTestServerTest.testExactlyOnceTransaction(KafkaTestServerTest.java:104)

[ERROR] testGetKafkaBrokers  Time elapsed: 5.804 s
[ERROR] testProducerAndConsumerSubscribe  Time elapsed: 15.856 s
[ERROR] testRestartingBroker  Time elapsed: 22.912 s
[INFO] Running com.salesforce.kafka.test.KafkaTestClusterTest
2018-08-15 10:41:45 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:41:45 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:41:45 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:41:45 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:41:45 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:41:45 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:41:45 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42355
2018-08-15 10:41:46 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:41:46 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:41:46 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:41:46 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:41:46 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:41:46 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:41:46 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:41:46 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:41:46 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:41:46 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:41:46 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:41:46 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:41:46 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:41:46 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:41:46 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42355
2018-08-15 10:41:47 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:37334
	advertised.port = 37334
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:37334
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322507813-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 37334
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42355
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:41:47 INFO  KafkaServer:72 - starting
2018-08-15 10:41:47 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:42355
2018-08-15 10:41:47 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42355 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@341a8659
2018-08-15 10:41:47 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:41:47 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:41:47 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42355. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:41:47 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42355, initiating session
2018-08-15 10:41:47 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:50908
2018-08-15 10:41:47 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:50908
2018-08-15 10:41:47 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:41:47 INFO  ZooKeeperServer:693 - Established session 0x1009942ad8a0000 with negotiated timeout 30000 for client /127.0.0.1:50908
2018-08-15 10:41:47 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42355, sessionid = 0x1009942ad8a0000, negotiated timeout = 30000
2018-08-15 10:41:47 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:41:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:41:47 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:41:47 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:41:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:41:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:41:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:41:48 INFO  KafkaServer:72 - Cluster ID = BDfjfxyRQ3eTIMNHzSEFJQ
2018-08-15 10:41:48 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322507813-0/meta.properties
2018-08-15 10:41:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:41:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:41:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:41:48 INFO  LogManager:72 - Loading logs.
2018-08-15 10:41:48 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:41:48 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:41:48 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:41:48 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:41:48 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:41:48 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:37334.
2018-08-15 10:41:48 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:41:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:41:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:41:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:41:48 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:41:48 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:41:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:41:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:41:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:41:48 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:41:48 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:41:48 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:41:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:41:48 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:41:48 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:41:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:41:48 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:41:48 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:41:48 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:41:48 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:41:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:41:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:41:48 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:48 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,37334,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:41:48 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322507813-0/meta.properties
2018-08-15 10:41:48 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:41:48 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:41:48 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:41:48 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:37334 (id: 1 rack: null) for sending state change requests
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:41:48 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:41:48 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:41:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:41:48 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:41:48 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:48 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:48 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:41:48 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:41:48 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:50908 which had sessionid 0x1009942ad8a0000
2018-08-15 10:41:48 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:41:48 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1009942ad8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:41:48 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:41:48 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:41:48 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:41:48 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:41:48 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:41:48 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:41:48 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:41:48 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:41:48 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:41:48 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:41:48 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:41:48 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:41:48 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42355
2018-08-15 10:41:49 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:41:49 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:41:49 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:44124
	advertised.port = 44124
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:44124
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322509959-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 44124
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42355
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:41:49 INFO  KafkaServer:72 - starting
2018-08-15 10:41:49 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:42355
2018-08-15 10:41:49 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42355 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@70d8de
2018-08-15 10:41:49 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:41:49 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:41:49 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42355. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:41:49 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42355, initiating session
2018-08-15 10:41:49 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:50914
2018-08-15 10:41:49 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:50914
2018-08-15 10:41:49 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-08-15 10:41:49 INFO  ZooKeeperServer:693 - Established session 0x1009942b5ec0000 with negotiated timeout 30000 for client /127.0.0.1:50914
2018-08-15 10:41:49 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42355, sessionid = 0x1009942b5ec0000, negotiated timeout = 30000
2018-08-15 10:41:49 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:41:50 INFO  KafkaServer:72 - Cluster ID = BDfjfxyRQ3eTIMNHzSEFJQ
2018-08-15 10:41:50 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322509959-0/meta.properties
2018-08-15 10:41:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:41:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:41:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:41:50 INFO  LogManager:72 - Loading logs.
2018-08-15 10:41:50 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:41:50 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:41:50 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:41:50 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:41:50 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:41:50 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:44124.
2018-08-15 10:41:50 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-08-15 10:41:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-08-15 10:41:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-08-15 10:41:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-08-15 10:41:50 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:41:50 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:41:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-08-15 10:41:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-08-15 10:41:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-08-15 10:41:50 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-08-15 10:41:50 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-08-15 10:41:50 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:41:50 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42355. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:41:50 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42355, initiating session
2018-08-15 10:41:50 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:50916
2018-08-15 10:41:50 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1009942ad8a0000 at /127.0.0.1:50916
2018-08-15 10:41:50 INFO  ZooKeeperServer:693 - Established session 0x1009942ad8a0000 with negotiated timeout 30000 for client /127.0.0.1:50916
2018-08-15 10:41:50 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42355, sessionid = 0x1009942ad8a0000, negotiated timeout = 30000
2018-08-15 10:41:50 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:41:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:delete cxid:0x52 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:41:50 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-08-15 10:41:50 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:41:50 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-08-15 10:41:50 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-08-15 10:41:50 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-08-15 10:41:50 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-08-15 10:41:50 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-08-15 10:41:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942b5ec0000 type:create cxid:0x1d zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:41:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942b5ec0000 type:create cxid:0x1e zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:41:50 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:50 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,44124,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:41:50 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322509959-0/meta.properties
2018-08-15 10:41:50 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-08-15 10:41:50 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-08-15 10:41:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-08-15 10:41:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:44124 (id: 2 rack: null) for sending state change requests
2018-08-15 10:41:50 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-08-15 10:41:50 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:50 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:50 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-08-15 10:41:50 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37334, 127.0.0.1:44124]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:41:50 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:50 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:50 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-08-15 10:41:50 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37334, 127.0.0.1:44124]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:41:50 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:50 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:setData cxid:0x5b zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/topics/RestartClusterTest-1534322505799 Error:KeeperErrorCode = NoNode for /config/topics/RestartClusterTest-1534322505799
2018-08-15 10:41:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:create cxid:0x5c zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:41:50 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"1":[2,1],"0":[1,2]}}
2018-08-15 10:41:50 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(RestartClusterTest-1534322505799)], deleted topics: [Set()], new partition replica assignment [Map(RestartClusterTest-1534322505799-0 -> Vector(1, 2), RestartClusterTest-1534322505799-1 -> Vector(2, 1))]
2018-08-15 10:41:50 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for RestartClusterTest-1534322505799-0,RestartClusterTest-1534322505799-1
2018-08-15 10:41:50 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for RestartClusterTest-1534322505799-0,RestartClusterTest-1534322505799-1
2018-08-15 10:41:50 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions RestartClusterTest-1534322505799-0,RestartClusterTest-1534322505799-1
2018-08-15 10:41:50 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=1],[Topic=RestartClusterTest-1534322505799,Partition=0,Replica=2],[Topic=RestartClusterTest-1534322505799,Partition=1,Replica=2],[Topic=RestartClusterTest-1534322505799,Partition=1,Replica=1]
2018-08-15 10:41:50 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-0,RestartClusterTest-1534322505799-1
2018-08-15 10:41:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:create cxid:0x67 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1534322505799/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/RestartClusterTest-1534322505799/partitions/0
2018-08-15 10:41:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:create cxid:0x68 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1534322505799/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/RestartClusterTest-1534322505799/partitions
2018-08-15 10:41:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942ad8a0000 type:create cxid:0x6c zxid:0x2d txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1534322505799/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/RestartClusterTest-1534322505799/partitions/1
2018-08-15 10:41:50 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=1],[Topic=RestartClusterTest-1534322505799,Partition=0,Replica=2],[Topic=RestartClusterTest-1534322505799,Partition=1,Replica=2],[Topic=RestartClusterTest-1534322505799,Partition=1,Replica=1]
2018-08-15 10:41:50 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:41:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:41:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:41:50 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-1, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:50 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-0, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:50 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-1, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:41:50 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-0, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:50 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1534322505799,1] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:50 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1534322505799,0] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:50 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] No checkpointed highwatermark is found for partition RestartClusterTest-1534322505799-1
2018-08-15 10:41:50 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-0 broker=1] No checkpointed highwatermark is found for partition RestartClusterTest-1534322505799-0
2018-08-15 10:41:50 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-1 with initial high watermark 0
2018-08-15 10:41:50 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-0 with initial high watermark 0
2018-08-15 10:41:50 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-1 with initial high watermark 0
2018-08-15 10:41:50 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-0 with initial high watermark 0
2018-08-15 10:41:50 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] RestartClusterTest-1534322505799-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:50 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-0 broker=1] RestartClusterTest-1534322505799-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:41:50 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-1 with initial high watermark 0
2018-08-15 10:41:50 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-0 with initial high watermark 0
2018-08-15 10:41:50 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-1, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:50 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-0, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:41:50 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-1, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:50 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-0, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:41:50 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1534322505799,1] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:50 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1534322505799,0] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:41:50 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=1] No checkpointed highwatermark is found for partition RestartClusterTest-1534322505799-1
2018-08-15 10:41:50 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-1 with initial high watermark 0
2018-08-15 10:41:50 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-0 broker=2] No checkpointed highwatermark is found for partition RestartClusterTest-1534322505799-0
2018-08-15 10:41:50 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-0 with initial high watermark 0
2018-08-15 10:41:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:41:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:41:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-08-15 10:41:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting
2018-08-15 10:41:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([RestartClusterTest-1534322505799-1, initOffset 0 to broker BrokerEndPoint(2,127.0.0.1,44124)] )
2018-08-15 10:41:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([RestartClusterTest-1534322505799-0, initOffset 0 to broker BrokerEndPoint(1,127.0.0.1,37334)] )
2018-08-15 10:41:51 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:37334, 127.0.0.1:44124]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-08-15 10:41:51 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:51 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:51 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in RestartClusterTest-1534322505799-0. High watermark 0 will be used for truncation.
2018-08-15 10:41:51 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in RestartClusterTest-1534322505799-1. High watermark 0 will be used for truncation.
2018-08-15 10:41:51 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-1, dir=/tmp/1534322507813-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-08-15 10:41:51 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-0, dir=/tmp/1534322509959-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-08-15 10:41:51 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1534322505799-0. Cache now contains 0 entries.
2018-08-15 10:41:51 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1534322505799-0. Cache now contains 0 entries.
2018-08-15 10:41:51 INFO  KafkaTestUtils:126 - Produce completed
2018-08-15 10:41:51 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-08-15 10:41:51 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:37334, 127.0.0.1:44124]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-08-15 10:41:51 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:41:51 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:41:51 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1534322505799-1. Cache now contains 0 entries.
2018-08-15 10:41:51 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1534322505799-1. Cache now contains 0 entries.
2018-08-15 10:41:51 INFO  KafkaTestUtils:126 - Produce completed
2018-08-15 10:41:51 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-08-15 10:41:51 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:41:51 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:41:51 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:41:51 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:41:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:41:51 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-0 broker=2] RestartClusterTest-1534322505799-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-08-15 10:41:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down
2018-08-15 10:41:51 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=RestartClusterTest-1534322505799,Partition=1,Replica=1]
2018-08-15 10:41:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:41:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped
2018-08-15 10:41:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed
2018-08-15 10:41:51 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition RestartClusterTest-1534322505799-1 is {"leader":2,"leader_epoch":1,"isr":[2]}
2018-08-15 10:41:51 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:41:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:41:51 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] RestartClusterTest-1534322505799-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-08-15 10:41:51 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 5 from controller 1 epoch 1 for partition RestartClusterTest-1534322505799-1 (last update controller epoch 1) since it is already the leader for the partition.
2018-08-15 10:41:51 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:41:51 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:41:51 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:41:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1 epoch 1 fails to send request (type=LeaderAndIsRequest, controllerId=1, controllerEpoch=1, partitionStates={RestartClusterTest-1534322505799-0=PartitionState(controllerEpoch=1, leader=2, leaderEpoch=1, isr=2, zkVersion=1, replicas=1,2, isNew=false)}, liveLeaders=(127.0.0.1:44124 (id: 2 rack: null))) to broker 127.0.0.1:37334 (id: 1 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:51 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:41:51 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:41:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:41:51 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] Expanding ISR from 2 to 2,1
2018-08-15 10:41:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:41:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:41:51 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:41:51 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:41:51 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:41:51 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:41:51 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:41:51 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:41:51 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:41:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:41:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:41:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:41:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:41:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:41:51 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:41:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:41:52 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:41:52 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:41:52 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:41:52 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:41:52 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:41:52 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:41:52 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-08-15 10:41:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:52 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-08-15 10:41:52 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-08-15 10:41:52 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:41:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:41:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:41:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:41:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:41:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:41:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:41:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:41:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:53 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:53 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:41:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:41:53 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:41:53 INFO  LogManager:72 - Shutting down.
2018-08-15 10:41:53 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:41:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:41:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:41:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:41:53 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:53 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:53 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1534322505799-0] Writing producer snapshot at offset 2
2018-08-15 10:41:53 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1534322505799-1] Writing producer snapshot at offset 2
2018-08-15 10:41:53 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:41:53 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:41:53 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:41:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:41:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:41:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:41:53 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:41:53 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:41:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-08-15 10:41:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-08-15 10:41:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:41:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:41:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:41:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:41:53 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:41:53 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009942ad8a0000
2018-08-15 10:41:53 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:50916 which had sessionid 0x1009942ad8a0000
2018-08-15 10:41:53 INFO  ZooKeeper:687 - Session: 0x1009942ad8a0000 closed
2018-08-15 10:41:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:41:53 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009942ad8a0000
2018-08-15 10:41:53 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:41:53 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 2
2018-08-15 10:41:53 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2)
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set(RestartClusterTest-1534322505799)
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: RestartClusterTest-1534322505799
2018-08-15 10:41:53 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=2],[Topic=RestartClusterTest-1534322505799,Partition=1,Replica=2]
2018-08-15 10:41:53 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:44124 (id: 2 rack: null) for sending state change requests
2018-08-15 10:41:53 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map([Topic=RestartClusterTest-1534322505799,Partition=1,Replica=2] -> OnlineReplica, [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1534322505799,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=2] -> OnlineReplica)
2018-08-15 10:41:53 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map(RestartClusterTest-1534322505799-0 -> OnlinePartition, RestartClusterTest-1534322505799-1 -> OnlinePartition)
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 2
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-08-15 10:41:53 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:41:53 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 2 for partition RestartClusterTest-1534322505799-0 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-08-15 10:41:53 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009942b5ec0000 type:delete cxid:0x44 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:41:53 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 2 for partition RestartClusterTest-1534322505799-1 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-08-15 10:41:53 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-08-15 10:41:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:41:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:41:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:41:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:41:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:41:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:41:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:41:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:41:54 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:41:54 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:41:54 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:41:54 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-08-15 10:41:54 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-08-15 10:41:54 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:41:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:41:54 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
2018-08-15 10:41:54 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1534322505799-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:41:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:41:54 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2,1 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
2018-08-15 10:41:54 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1534322505799-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2,1 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2,1 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:41:54 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1534322505799-0,RestartClusterTest-1534322505799-1
2018-08-15 10:41:54 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-08-15 10:41:59 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:41:59 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:41:59 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:41:59 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
2018-08-15 10:41:59 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1534322505799-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:41:59 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:41:59 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2,1 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
2018-08-15 10:41:59 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1534322505799-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2,1 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2,1 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:41:59 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1534322505799-0,RestartClusterTest-1534322505799-1
2018-08-15 10:41:59 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-08-15 10:42:04 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:42:04 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:42:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:42:04 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
2018-08-15 10:42:04 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1534322505799-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:42:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:42:04 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2,1 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
2018-08-15 10:42:04 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1534322505799-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2,1 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2,1 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:42:04 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1534322505799-0,RestartClusterTest-1534322505799-1
2018-08-15 10:42:04 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-08-15 10:42:05 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] Shrinking ISR from 2,1 to 2
2018-08-15 10:42:09 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:42:09 WARN  KafkaServer:87 - [KafkaServer id=2] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-08-15 10:42:09 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-08-15 10:42:09 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-08-15 10:42:09 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-08-15 10:42:09 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-08-15 10:42:09 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-08-15 10:42:09 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-08-15 10:42:09 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-08-15 10:42:09 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-08-15 10:42:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-08-15 10:42:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-08-15 10:42:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-08-15 10:42:09 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-08-15 10:42:09 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-08-15 10:42:09 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-08-15 10:42:09 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-08-15 10:42:09 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:42:09 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:42:09 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:42:09 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-08-15 10:42:09 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-08-15 10:42:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-08-15 10:42:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-08-15 10:42:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-08-15 10:42:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-08-15 10:42:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-08-15 10:42:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-08-15 10:42:10 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-08-15 10:42:10 INFO  LogManager:72 - Shutting down.
2018-08-15 10:42:10 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:42:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:42:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:42:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:42:10 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1534322505799-0] Writing producer snapshot at offset 2
2018-08-15 10:42:10 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1534322505799-1] Writing producer snapshot at offset 2
2018-08-15 10:42:10 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:42:10 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:42:10 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:42:10 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:42:10 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-08-15 10:42:10 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-08-15 10:42:10 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-08-15 10:42:10 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-08-15 10:42:10 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:42:10 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-08-15 10:42:10 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:42:10 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009942b5ec0000
2018-08-15 10:42:10 INFO  ZooKeeper:687 - Session: 0x1009942b5ec0000 closed
2018-08-15 10:42:10 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:50914 which had sessionid 0x1009942b5ec0000
2018-08-15 10:42:10 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009942b5ec0000
2018-08-15 10:42:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:42:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:42:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:42:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:42:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:42:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:42:11 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:42:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:42:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:42:12 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-08-15 10:42:12 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-08-15 10:42:12 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-08-15 10:42:12 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:42:12 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:42:12 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:42:12 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:42:12 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:42:12 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:42:12 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:42:12 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:42:12 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:42:12 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:42:12 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:42:12 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:42:12 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:42:12 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:42:12 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:42:12 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42355
2018-08-15 10:42:13 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:42:13 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:42:13 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:42:13 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:42:13 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:42:13 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:42:13 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:42:13 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:42:13 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:42:13 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:42:13 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:42:13 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:42:13 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:42:13 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:42:13 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42355
2018-08-15 10:42:14 INFO  KafkaServer:72 - [KafkaServer id=1] starting
2018-08-15 10:42:14 INFO  KafkaServer:72 - [KafkaServer id=1] Connecting to zookeeper on 127.0.0.1:42355
2018-08-15 10:42:14 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42355 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@7a356a0d
2018-08-15 10:42:14 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:42:14 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:42:14 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42355. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:42:14 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42355, initiating session
2018-08-15 10:42:14 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:51014
2018-08-15 10:42:14 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:51014
2018-08-15 10:42:14 INFO  FileTxnLog:213 - Creating new log file: log.3b
2018-08-15 10:42:14 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:42:14 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:42:15 WARN  FileTxnLog:378 - fsync-ing the write ahead log in SyncThread:0 took 1644ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2018-08-15 10:42:15 INFO  ZooKeeperServer:693 - Established session 0x100994314020000 with negotiated timeout 30000 for client /127.0.0.1:51014
2018-08-15 10:42:15 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42355, sessionid = 0x100994314020000, negotiated timeout = 30000
2018-08-15 10:42:15 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:42:15 INFO  KafkaServer:72 - [KafkaServer id=1] Cluster ID = BDfjfxyRQ3eTIMNHzSEFJQ
2018-08-15 10:42:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:42:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:42:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:42:15 INFO  LogManager:72 - Loading logs.
2018-08-15 10:42:15 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-0, dir=/tmp/1534322507813-0] Loading producer state from offset 2 with message format version 2
2018-08-15 10:42:15 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1534322505799-0] Loading producer state from snapshot file '/tmp/1534322507813-0/RestartClusterTest-1534322505799-0/00000000000000000002.snapshot'
2018-08-15 10:42:15 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-0, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 2 ms
2018-08-15 10:42:15 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-1, dir=/tmp/1534322507813-0] Loading producer state from offset 2 with message format version 2
2018-08-15 10:42:15 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1534322505799-1] Loading producer state from snapshot file '/tmp/1534322507813-0/RestartClusterTest-1534322505799-1/00000000000000000002.snapshot'
2018-08-15 10:42:15 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-1, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 2 ms
2018-08-15 10:42:15 INFO  LogManager:72 - Logs loading complete in 7 ms.
2018-08-15 10:42:15 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:42:15 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:42:15 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:42:15 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:42:15 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:37334.
2018-08-15 10:42:15 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:42:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:42:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:42:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:42:15 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:42:15 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:42:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:42:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:42:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:42:15 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:42:15 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:42:15 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:42:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:42:15 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:42:15 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:42:15 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:42:15 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2018-08-15 10:42:15 INFO  KafkaController:72 - [Controller id=1] Initialized controller epoch to 2 and zk version 1
2018-08-15 10:42:15 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 3
2018-08-15 10:42:15 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:42:15 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:42:15 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:42:15 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:42:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x36 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:42:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x37 zxid:0x40 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:42:16 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:42:16 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,37334,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:42:16 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:42:16 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:42:16 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:42:16 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set()
2018-08-15 10:42:16 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:42:16 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:42:16 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set(RestartClusterTest-1534322505799)
2018-08-15 10:42:16 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:16 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:16 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:42:16 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:42:16 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:42:16 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: RestartClusterTest-1534322505799
2018-08-15 10:42:16 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:51014 which had sessionid 0x100994314020000
2018-08-15 10:42:16 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map([Topic=RestartClusterTest-1534322505799,Partition=1,Replica=2] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1534322505799,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=2] -> ReplicaDeletionIneligible)
2018-08-15 10:42:16 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:42:16 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x100994314020000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:42:16 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:42:16 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:42:16 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:42:16 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:42:16 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:42:16 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:42:16 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:42:16 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:42:16 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:42:16 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:42:16 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:42:16 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:42:16 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42355
2018-08-15 10:42:16 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:42:16 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:42:17 INFO  KafkaServer:72 - [KafkaServer id=2] starting
2018-08-15 10:42:17 INFO  KafkaServer:72 - [KafkaServer id=2] Connecting to zookeeper on 127.0.0.1:42355
2018-08-15 10:42:17 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42355 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@78f9ed3e
2018-08-15 10:42:17 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:42:17 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:42:17 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42355. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:42:17 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42355, initiating session
2018-08-15 10:42:17 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:51020
2018-08-15 10:42:17 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:51020
2018-08-15 10:42:17 INFO  FileTxnLog:213 - Creating new log file: log.42
2018-08-15 10:42:17 INFO  ZooKeeperServer:693 - Established session 0x10099431fa50000 with negotiated timeout 30000 for client /127.0.0.1:51020
2018-08-15 10:42:17 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42355, sessionid = 0x10099431fa50000, negotiated timeout = 30000
2018-08-15 10:42:17 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:42:17 INFO  KafkaServer:72 - [KafkaServer id=2] Cluster ID = BDfjfxyRQ3eTIMNHzSEFJQ
2018-08-15 10:42:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:42:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:42:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:42:17 INFO  LogManager:72 - Loading logs.
2018-08-15 10:42:17 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-1, dir=/tmp/1534322509959-0] Loading producer state from offset 2 with message format version 2
2018-08-15 10:42:17 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1534322505799-1] Loading producer state from snapshot file '/tmp/1534322509959-0/RestartClusterTest-1534322505799-1/00000000000000000002.snapshot'
2018-08-15 10:42:17 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-1, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 3 ms
2018-08-15 10:42:17 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-0, dir=/tmp/1534322509959-0] Loading producer state from offset 2 with message format version 2
2018-08-15 10:42:17 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1534322505799-0] Loading producer state from snapshot file '/tmp/1534322509959-0/RestartClusterTest-1534322505799-0/00000000000000000002.snapshot'
2018-08-15 10:42:17 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-0, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 3 ms
2018-08-15 10:42:17 INFO  LogManager:72 - Logs loading complete in 10 ms.
2018-08-15 10:42:17 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:42:17 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:42:17 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:42:17 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:42:17 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:44124.
2018-08-15 10:42:17 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-08-15 10:42:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-08-15 10:42:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-08-15 10:42:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-08-15 10:42:17 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:42:17 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:42:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-08-15 10:42:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-08-15 10:42:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-08-15 10:42:17 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-08-15 10:42:17 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-08-15 10:42:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:42:17 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4
2018-08-15 10:42:17 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-08-15 10:42:17 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-08-15 10:42:17 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-08-15 10:42:17 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-08-15 10:42:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099431fa50000 type:create cxid:0x1f zxid:0x44 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:42:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099431fa50000 type:create cxid:0x20 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:42:17 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:42:17 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,44124,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:42:17 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-08-15 10:42:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:17 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-08-15 10:42:17 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37334, 127.0.0.1:44124]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:42:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:17 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42355. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:42:17 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42355, initiating session
2018-08-15 10:42:17 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:51026
2018-08-15 10:42:17 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x100994314020000 at /127.0.0.1:51026
2018-08-15 10:42:17 INFO  ZooKeeperServer:693 - Established session 0x100994314020000 with negotiated timeout 30000 for client /127.0.0.1:51026
2018-08-15 10:42:17 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42355, sessionid = 0x100994314020000, negotiated timeout = 30000
2018-08-15 10:42:17 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:42:17 ERROR logger:107 - [Controller id=1 epoch=3] Initiated state change for partition RestartClusterTest-1534322505799-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition RestartClusterTest-1534322505799-0 is alive. Live brokers are: [Set()], ISR brokers are: [2]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:17 ERROR logger:107 - [Controller id=1 epoch=3] Initiated state change for partition RestartClusterTest-1534322505799-1 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition RestartClusterTest-1534322505799-1 is alive. Live brokers are: [Set()], ISR brokers are: [2]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map(RestartClusterTest-1534322505799-0 -> OfflinePartition, RestartClusterTest-1534322505799-1 -> OfflinePartition)
2018-08-15 10:42:17 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 3
2018-08-15 10:42:17 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:42:17 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:42:17 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:42:17 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:42:17 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:42:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:42:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:delete cxid:0x47 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:42:17 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:42:17 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 1,2, deleted brokers: , all live brokers: 1,2
2018-08-15 10:42:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:42:17 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 1,2
2018-08-15 10:42:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-08-15 10:42:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=1],[Topic=RestartClusterTest-1534322505799,Partition=1,Replica=1],[Topic=RestartClusterTest-1534322505799,Partition=0,Replica=2],[Topic=RestartClusterTest-1534322505799,Partition=1,Replica=2]
2018-08-15 10:42:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:37334 (id: 1 rack: null) for sending state change requests
2018-08-15 10:42:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:44124 (id: 2 rack: null) for sending state change requests
2018-08-15 10:42:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":2,"leader_epoch":2,"isr":[2]} for offline partition RestartClusterTest-1534322505799-0
2018-08-15 10:42:17 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-1 with initial high watermark 0
2018-08-15 10:42:17 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1534322505799-1,RestartClusterTest-1534322505799-0
2018-08-15 10:42:17 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-1 with initial high watermark 2
2018-08-15 10:42:17 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-1 with initial high watermark 2
2018-08-15 10:42:17 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] RestartClusterTest-1534322505799-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1
2018-08-15 10:42:17 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-1 with initial high watermark 0
2018-08-15 10:42:17 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-0 with initial high watermark 2
2018-08-15 10:42:17 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-0 with initial high watermark 2
2018-08-15 10:42:17 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-0 broker=2] RestartClusterTest-1534322505799-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1
2018-08-15 10:42:17 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-0 with initial high watermark 0
2018-08-15 10:42:17 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1534322505799-0 with initial high watermark 0
2018-08-15 10:42:17 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1534322505799-1,RestartClusterTest-1534322505799-0
2018-08-15 10:42:17 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-08-15 10:42:17 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37334, 127.0.0.1:44124]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:42:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":2,"leader_epoch":2,"isr":[2]} for offline partition RestartClusterTest-1534322505799-1
2018-08-15 10:42:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:17 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-08-15 10:42:17 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([RestartClusterTest-1534322505799-1, initOffset 2 to broker BrokerEndPoint(2,127.0.0.1,44124)] , [RestartClusterTest-1534322505799-0, initOffset 2 to broker BrokerEndPoint(2,127.0.0.1,44124)] )
2018-08-15 10:42:17 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 2 >= the follower's log end offset 2 in RestartClusterTest-1534322505799-0. No truncation needed.
2018-08-15 10:42:17 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-0, dir=/tmp/1534322507813-0] Truncating to 2 has no effect as the largest offset in the log is 1
2018-08-15 10:42:17 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 2 >= the follower's log end offset 2 in RestartClusterTest-1534322505799-1. No truncation needed.
2018-08-15 10:42:17 INFO  Log:72 - [Log partition=RestartClusterTest-1534322505799-1, dir=/tmp/1534322507813-0] Truncating to 2 has no effect as the largest offset in the log is 1
2018-08-15 10:42:17 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] Expanding ISR from 2 to 2,1
2018-08-15 10:42:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099431fa50000 type:setData cxid:0x24 zxid:0x4a txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1534322505799/partitions/1/state Error:KeeperErrorCode = BadVersion for /brokers/topics/RestartClusterTest-1534322505799/partitions/1/state
2018-08-15 10:42:17 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1534322505799-1,RestartClusterTest-1534322505799-0
2018-08-15 10:42:17 INFO  logger:72 - [Broker id=1] Skipped the become-follower state change after marking its partition as follower with correlation id 3 from controller 1 epoch 3 for partition RestartClusterTest-1534322505799-1 (last update controller epoch 3) since the new leader 2 is the same as the old leader
2018-08-15 10:42:17 INFO  logger:72 - [Broker id=1] Skipped the become-follower state change after marking its partition as follower with correlation id 3 from controller 1 epoch 3 for partition RestartClusterTest-1534322505799-0 (last update controller epoch 3) since the new leader 2 is the same as the old leader
2018-08-15 10:42:17 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions 
2018-08-15 10:42:17 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List()
2018-08-15 10:42:17 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:42:17 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1,2
2018-08-15 10:42:17 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] Cached zkVersion [3] not equal to that in zookeeper, skip updating ISR
2018-08-15 10:42:17 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-0 broker=2] Expanding ISR from 2 to 2,1
2018-08-15 10:42:17 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] RestartClusterTest-1534322505799-1 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1
2018-08-15 10:42:17 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 3 for partition RestartClusterTest-1534322505799-1 (last update controller epoch 3) since it is already the leader for the partition.
2018-08-15 10:42:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099431fa50000 type:setData cxid:0x26 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1534322505799/partitions/0/state Error:KeeperErrorCode = BadVersion for /brokers/topics/RestartClusterTest-1534322505799/partitions/0/state
2018-08-15 10:42:17 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-0 broker=2] Cached zkVersion [1] not equal to that in zookeeper, skip updating ISR
2018-08-15 10:42:17 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-0 broker=2] RestartClusterTest-1534322505799-0 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1
2018-08-15 10:42:17 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 3 for partition RestartClusterTest-1534322505799-0 (last update controller epoch 3) since it is already the leader for the partition.
2018-08-15 10:42:18 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:37334, 127.0.0.1:44124]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-08-15 10:42:18 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:18 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:18 INFO  KafkaTestUtils:256 - Found 4 records in kafka
2018-08-15 10:42:18 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] Expanding ISR from 2 to 2,1
2018-08-15 10:42:18 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-0 broker=2] Expanding ISR from 2 to 2,1
2018-08-15 10:42:20 INFO  KafkaTestUtils:256 - Found 0 records in kafka
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:setData cxid:0x59 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x5b zxid:0x4f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:42:20 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[2],"12":[2],"8":[2],"19":[1],"23":[1],"4":[2],"40":[2],"15":[1],"11":[1],"9":[1],"44":[2],"33":[1],"22":[2],"26":[2],"37":[1],"13":[1],"46":[2],"24":[2],"35":[1],"16":[2],"5":[1],"10":[2],"48":[2],"21":[1],"43":[1],"32":[2],"49":[1],"6":[2],"36":[2],"1":[1],"39":[1],"17":[1],"25":[1],"14":[2],"47":[1],"31":[1],"42":[2],"0":[2],"20":[2],"27":[1],"2":[2],"38":[2],"18":[2],"30":[2],"7":[1],"29":[1],"41":[1],"3":[1],"28":[2]}}
2018-08-15 10:42:20 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-08-15 10:42:20 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(2), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(2), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(2), __consumer_offsets-40 -> Vector(2), __consumer_offsets-18 -> Vector(2), __consumer_offsets-26 -> Vector(2), __consumer_offsets-0 -> Vector(2), __consumer_offsets-24 -> Vector(2), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(2), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(2), __consumer_offsets-12 -> Vector(2), __consumer_offsets-8 -> Vector(2), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(2), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(2), __consumer_offsets-28 -> Vector(2), __consumer_offsets-4 -> Vector(2), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(2), __consumer_offsets-42 -> Vector(2), __consumer_offsets-34 -> Vector(2), __consumer_offsets-46 -> Vector(2), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(2), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(2), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(2), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(2), __consumer_offsets-2 -> Vector(2))]
2018-08-15 10:42:20 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:42:20 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:42:20 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:42:20 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=2],[Topic=__consumer_offsets,Partition=48,Replica=2],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=2],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=2],[Topic=__consumer_offsets,Partition=22,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=2],[Topic=__consumer_offsets,Partition=40,Replica=2],[Topic=__consumer_offsets,Partition=24,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=28,Replica=2],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=2],[Topic=__consumer_offsets,Partition=12,Replica=2],[Topic=__consumer_offsets,Partition=32,Replica=2],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=2],[Topic=__consumer_offsets,Partition=26,Replica=2],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=2],[Topic=__consumer_offsets,Partition=8,Replica=2],[Topic=__consumer_offsets,Partition=44,Replica=2],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=2],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=2],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=2],[Topic=__consumer_offsets,Partition=17,Replica=1]
2018-08-15 10:42:20 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x98 zxid:0x52 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x99 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x9d zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xa0 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xa3 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xa6 zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xa9 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xac zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xaf zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xb2 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-08-15 10:42:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xb5 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xb8 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xbb zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xbe zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xc2 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xc8 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xce zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xd4 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xdb zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xe2 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xe7 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xea zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-08-15 10:42:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xf0 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xf4 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xf7 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0xfc zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x101 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x107 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x10b zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x10e zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x113 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x118 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x11e zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-08-15 10:42:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x122 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x127 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x12e zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x133 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x139 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x140 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x147 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x14b zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x14e zxid:0xcc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x151 zxid:0xcf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x154 zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x15a zxid:0xd5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-08-15 10:42:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x15e zxid:0xd8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-08-15 10:42:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x163 zxid:0xdb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-08-15 10:42:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x168 zxid:0xde txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-08-15 10:42:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x16b zxid:0xe1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-08-15 10:42:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x170 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-08-15 10:42:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994314020000 type:create cxid:0x175 zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-08-15 10:42:24 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=2],[Topic=__consumer_offsets,Partition=48,Replica=2],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=2],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=2],[Topic=__consumer_offsets,Partition=22,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=2],[Topic=__consumer_offsets,Partition=40,Replica=2],[Topic=__consumer_offsets,Partition=24,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=28,Replica=2],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=2],[Topic=__consumer_offsets,Partition=12,Replica=2],[Topic=__consumer_offsets,Partition=32,Replica=2],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=2],[Topic=__consumer_offsets,Partition=26,Replica=2],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=2],[Topic=__consumer_offsets,Partition=8,Replica=2],[Topic=__consumer_offsets,Partition=44,Replica=2],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=2],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=2],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=2],[Topic=__consumer_offsets,Partition=17,Replica=1]
2018-08-15 10:42:24 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-21,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-31,__consumer_offsets-3,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-17,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-43,__consumer_offsets-39,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-29
2018-08-15 10:42:24 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-4,__consumer_offsets-46,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-18,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-48,__consumer_offsets-2,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-12,__consumer_offsets-26,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=2] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=2] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=2] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=2] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=2] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=2] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=2] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=2] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=2] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=2] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=2] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=2] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=2] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=2] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=2] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=2] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322509959-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322509959-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1534322509959-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=2] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322507813-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-08-15 10:42:24 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322507813-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-08-15 10:42:24 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1534322507813-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-08-15 10:42:24 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-08-15 10:42:24 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-08-15 10:42:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-08-15 10:42:24 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:44124 (id: 2147483645 rack: null)
2018-08-15 10:42:24 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-08-15 10:42:24 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:42:24 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:42:24 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:42:24 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=RestartClusterTest-1534322505799,Partition=1,Replica=1]
2018-08-15 10:42:24 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:42:24 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition RestartClusterTest-1534322505799-1 is {"leader":2,"leader_epoch":3,"isr":[2]}
2018-08-15 10:42:24 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=1]
2018-08-15 10:42:24 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:42:24 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-1 broker=2] RestartClusterTest-1534322505799-1 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2
2018-08-15 10:42:24 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 8 from controller 1 epoch 3 for partition RestartClusterTest-1534322505799-1 (last update controller epoch 3) since it is already the leader for the partition.
2018-08-15 10:42:24 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:42:24 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:42:24 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-08-15 10:42:24 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition RestartClusterTest-1534322505799-0 is {"leader":2,"leader_epoch":3,"isr":[2]}
2018-08-15 10:42:24 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:42:24 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:42:24 INFO  Partition:72 - [Partition RestartClusterTest-1534322505799-0 broker=2] RestartClusterTest-1534322505799-0 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2
2018-08-15 10:42:24 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 10 from controller 1 epoch 3 for partition RestartClusterTest-1534322505799-0 (last update controller epoch 3) since it is already the leader for the partition.
2018-08-15 10:42:24 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:42:24 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1 epoch 3 fails to send request (type=StopReplicaRequest, controllerId=1, controllerEpoch=3, deletePartitions=false, partitions=RestartClusterTest-1534322505799-0) to broker 127.0.0.1:37334 (id: 1 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:24 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:42:24 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:42:24 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:24 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:25 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:25 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:25 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-08-15 10:42:25 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-08-15 10:42:25 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:42:25 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:42:25 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:42:25 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:25 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:42:25 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:42:25 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 2000
2018-08-15 10:42:25 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:42:25 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:42:25 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:42:25 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:42:25 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:42:25 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:42:25 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:25 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:25 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:25 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:42:25 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:25 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:25 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:25 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:42:25 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:42:25 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:42:25 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:42:25 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:42:25 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:42:25 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:42:25 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:42:25 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:25 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:25 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:25 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:42:25 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:42:25 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:25 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:25 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:25 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:42:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:42:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:42:26 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:26 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:26 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:26 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:42:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:42:26 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:42:26 INFO  LogManager:72 - Shutting down.
2018-08-15 10:42:26 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:42:26 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:42:26 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:42:26 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:42:26 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:26 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:26 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:26 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:26 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:26 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:26 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:26 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:26 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:26 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:26 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:26 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:26 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:42:26 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37334 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37334 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:26 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:42:26 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:42:26 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:42:26 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:42:26 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:42:26 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:42:26 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-08-15 10:42:26 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-08-15 10:42:26 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:42:26 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:42:26 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:42:26 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:42:26 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:42:26 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:42:26 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994314020000
2018-08-15 10:42:27 INFO  ZooKeeper:687 - Session: 0x100994314020000 closed
2018-08-15 10:42:27 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:51026 which had sessionid 0x100994314020000
2018-08-15 10:42:27 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:42:27 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994314020000
2018-08-15 10:42:27 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:42:27 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 3 and zk version 2
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 4
2018-08-15 10:42:27 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2)
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set(__consumer_offsets, RestartClusterTest-1534322505799)
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: __consumer_offsets,RestartClusterTest-1534322505799
2018-08-15 10:42:27 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:44124 (id: 2 rack: null) for sending state change requests
2018-08-15 10:42:27 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=38,Replica=2],[Topic=__consumer_offsets,Partition=48,Replica=2],[Topic=__consumer_offsets,Partition=42,Replica=2],[Topic=__consumer_offsets,Partition=2,Replica=2],[Topic=__consumer_offsets,Partition=22,Replica=2],[Topic=__consumer_offsets,Partition=34,Replica=2],[Topic=__consumer_offsets,Partition=40,Replica=2],[Topic=__consumer_offsets,Partition=24,Replica=2],[Topic=RestartClusterTest-1534322505799,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=20,Replica=2],[Topic=__consumer_offsets,Partition=30,Replica=2],[Topic=__consumer_offsets,Partition=28,Replica=2],[Topic=__consumer_offsets,Partition=10,Replica=2],[Topic=__consumer_offsets,Partition=12,Replica=2],[Topic=__consumer_offsets,Partition=32,Replica=2],[Topic=__consumer_offsets,Partition=4,Replica=2],[Topic=__consumer_offsets,Partition=26,Replica=2],[Topic=RestartClusterTest-1534322505799,Partition=0,Replica=2],[Topic=__consumer_offsets,Partition=46,Replica=2],[Topic=__consumer_offsets,Partition=6,Replica=2],[Topic=__consumer_offsets,Partition=8,Replica=2],[Topic=__consumer_offsets,Partition=44,Replica=2],[Topic=__consumer_offsets,Partition=36,Replica=2],[Topic=__consumer_offsets,Partition=14,Replica=2],[Topic=__consumer_offsets,Partition=16,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=2],[Topic=__consumer_offsets,Partition=18,Replica=2]
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-48 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map([Topic=__consumer_offsets,Partition=24,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=21,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1534322505799,Partition=1,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=0,Replica=2] -> OnlineReplica, [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=28,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=47,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=37,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=23,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=6,Replica=2] -> OnlineReplica, [Topic=RestartClusterTest-1534322505799,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=43,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=46,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=3,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=7,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=40,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=32,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=12,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=45,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=44,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=41,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1534322505799,Partition=0,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=31,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=35,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=19,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=34,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=20,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=8,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> ReplicaDeletionIneligible)
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-46 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-44 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-42 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition RestartClusterTest-1534322505799-0 since its associated leader epoch 3 is not higher than the current leader epoch 3
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-32 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-30 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-28 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-26 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-40 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-38 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-36 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-34 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-16 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-19 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-19 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-14 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-12 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-10 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-24 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-22 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-20 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-18 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition RestartClusterTest-1534322505799-1 since its associated leader epoch 3 is not higher than the current leader epoch 3
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-47 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-47 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-0 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-8 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-6 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-4 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-2 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-29 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-29 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-41 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-41 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-39 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-39 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-17 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-17 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-33 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-33 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-3 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-3 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-21 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-21 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-5 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-5 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-23 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-23 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-15 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-15 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-11 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-11 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-13 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-13 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-49 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-49 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-37 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-37 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-31 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-31 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-25 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-25 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-45 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-45 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-27 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-27 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-43 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-43 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-35 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-35 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-7 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-7 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-9 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-9 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-1 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-1 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map(__consumer_offsets-19 -> OfflinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-47 -> OfflinePartition, __consumer_offsets-29 -> OfflinePartition, __consumer_offsets-41 -> OfflinePartition, RestartClusterTest-1534322505799-0 -> OnlinePartition, __consumer_offsets-39 -> OfflinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-17 -> OfflinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-33 -> OfflinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-3 -> OfflinePartition, __consumer_offsets-21 -> OfflinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-5 -> OfflinePartition, RestartClusterTest-1534322505799-1 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-23 -> OfflinePartition, __consumer_offsets-15 -> OfflinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-11 -> OfflinePartition, __consumer_offsets-13 -> OfflinePartition, __consumer_offsets-49 -> OfflinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-37 -> OfflinePartition, __consumer_offsets-31 -> OfflinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-25 -> OfflinePartition, __consumer_offsets-45 -> OfflinePartition, __consumer_offsets-27 -> OfflinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-43 -> OfflinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-35 -> OfflinePartition, __consumer_offsets-7 -> OfflinePartition, __consumer_offsets-9 -> OfflinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-1 -> OfflinePartition, __consumer_offsets-2 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition)
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 4
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-08-15 10:42:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:42:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099431fa50000 type:delete cxid:0x128 zxid:0xf1 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:42:27 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-08-15 10:42:27 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:42:27 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:42:27 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:42:27 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:42:27 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:42:27 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:42:28 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:42:28 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:42:28 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:42:28 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:42:28 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:42:28 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-08-15 10:42:28 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-08-15 10:42:28 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:42:28 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:42:28 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
2018-08-15 10:42:28 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1534322505799-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-08-15 10:42:28 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:42:28 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
2018-08-15 10:42:28 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1534322505799-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-08-15 10:42:28 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1534322505799-0,RestartClusterTest-1534322505799-1
2018-08-15 10:42:28 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-08-15 10:42:33 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:42:33 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:42:33 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:42:33 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
2018-08-15 10:42:33 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1534322505799-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-08-15 10:42:33 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:42:33 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
2018-08-15 10:42:33 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1534322505799-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-08-15 10:42:33 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1534322505799-0,RestartClusterTest-1534322505799-1
2018-08-15 10:42:33 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-08-15 10:42:38 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:42:38 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:42:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-1
2018-08-15 10:42:38 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
2018-08-15 10:42:38 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1534322505799-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-1 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1534322505799-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-08-15 10:42:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1534322505799-0
2018-08-15 10:42:38 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
2018-08-15 10:42:38 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1534322505799-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1534322505799-0 due to: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1534322505799-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-08-15 10:42:38 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1534322505799-0,RestartClusterTest-1534322505799-1
2018-08-15 10:42:38 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-08-15 10:42:43 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:42:43 WARN  KafkaServer:87 - [KafkaServer id=2] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-08-15 10:42:43 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-08-15 10:42:43 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-08-15 10:42:43 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-08-15 10:42:43 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-08-15 10:42:43 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-08-15 10:42:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-08-15 10:42:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-08-15 10:42:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-08-15 10:42:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-08-15 10:42:43 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 3000
2018-08-15 10:42:43 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-08-15 10:42:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-08-15 10:42:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-08-15 10:42:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-08-15 10:42:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-08-15 10:42:43 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-08-15 10:42:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-08-15 10:42:44 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-08-15 10:42:44 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-08-15 10:42:44 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:42:44 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:42:44 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:42:44 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-08-15 10:42:44 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-08-15 10:42:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-08-15 10:42:44 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-08-15 10:42:44 INFO  LogManager:72 - Shutting down.
2018-08-15 10:42:44 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:42:44 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:42:44 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:42:44 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:42:44 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2
2018-08-15 10:42:44 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:42:44 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:42:44 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:42:44 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:42:44 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-08-15 10:42:44 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-08-15 10:42:44 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-08-15 10:42:44 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-08-15 10:42:44 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:42:44 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-08-15 10:42:44 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:42:44 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10099431fa50000
2018-08-15 10:42:44 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:51020 which had sessionid 0x10099431fa50000
2018-08-15 10:42:44 INFO  ZooKeeper:687 - Session: 0x10099431fa50000 closed
2018-08-15 10:42:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:42:44 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10099431fa50000
2018-08-15 10:42:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:42:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:42:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:42:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:42:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:42:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:42:46 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:42:46 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:42:46 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-08-15 10:42:46 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-08-15 10:42:46 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-08-15 10:42:46 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:42:46 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:42:46 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:42:46 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:42:46 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:42:46 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:42:46 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:42:46 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:42:46 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:42:46 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:42:46 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:42:46 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:42:46 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:42:46 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:42:46 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:42:46 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40956
2018-08-15 10:42:47 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:42:47 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:42:47 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:42:47 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:42:47 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:42:47 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:42:47 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:42:47 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:42:47 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:42:47 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:42:47 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:42:47 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:42:47 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:42:47 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:42:47 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40956
2018-08-15 10:42:47 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:42:47 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:42:48 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:41173
	advertised.port = 41173
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:41173
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322568106-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 41173
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:40956
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:42:48 INFO  KafkaServer:72 - starting
2018-08-15 10:42:48 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:40956
2018-08-15 10:42:48 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40956 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@4f7c0be3
2018-08-15 10:42:48 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:42:48 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:42:48 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40956. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:42:48 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40956, initiating session
2018-08-15 10:42:48 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:58238
2018-08-15 10:42:48 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:58238
2018-08-15 10:42:48 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:42:48 INFO  ZooKeeperServer:693 - Established session 0x1009943990f0000 with negotiated timeout 30000 for client /127.0.0.1:58238
2018-08-15 10:42:48 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40956, sessionid = 0x1009943990f0000, negotiated timeout = 30000
2018-08-15 10:42:48 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:42:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:42:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:42:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:42:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:42:48 INFO  KafkaServer:72 - Cluster ID = 6IgSTSgySnyxolgDr_R-iQ
2018-08-15 10:42:48 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322568106-0/meta.properties
2018-08-15 10:42:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:42:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:42:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:42:48 INFO  LogManager:72 - Loading logs.
2018-08-15 10:42:48 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:42:49 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:42:49 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:42:49 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:42:49 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:42:49 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:41173.
2018-08-15 10:42:49 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:42:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:42:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:42:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:42:49 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:42:49 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:42:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:42:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:42:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:42:49 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:42:49 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:42:49 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:42:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:42:49 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:42:49 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:42:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:42:49 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:42:49 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:42:49 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:42:49 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:42:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:42:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:42:49 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:42:49 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,41173,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:42:49 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322568106-0/meta.properties
2018-08-15 10:42:49 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:42:49 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:42:49 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:42:49 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:41173 (id: 1 rack: null) for sending state change requests
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:42:49 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:42:49 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:42:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:42:49 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:42:49 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:49 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:49 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:42:49 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:42:49 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:58238 which had sessionid 0x1009943990f0000
2018-08-15 10:42:49 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:42:49 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1009943990f0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:42:49 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:42:49 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:42:49 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:42:49 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:42:49 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:42:49 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:42:49 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:42:49 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:42:49 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:42:49 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:42:49 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:42:49 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:42:49 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40956
2018-08-15 10:42:49 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:42:49 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:42:50 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:41866
	advertised.port = 41866
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:41866
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322570347-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 41866
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:40956
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:42:50 INFO  KafkaServer:72 - starting
2018-08-15 10:42:50 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:40956
2018-08-15 10:42:50 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40956 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@51e37590
2018-08-15 10:42:50 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:42:50 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:42:50 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40956. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:42:50 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40956, initiating session
2018-08-15 10:42:50 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:58244
2018-08-15 10:42:50 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:58244
2018-08-15 10:42:50 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-08-15 10:42:50 INFO  ZooKeeperServer:693 - Established session 0x1009943a1d00000 with negotiated timeout 30000 for client /127.0.0.1:58244
2018-08-15 10:42:50 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40956, sessionid = 0x1009943a1d00000, negotiated timeout = 30000
2018-08-15 10:42:50 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:42:50 INFO  KafkaServer:72 - Cluster ID = 6IgSTSgySnyxolgDr_R-iQ
2018-08-15 10:42:50 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322570347-0/meta.properties
2018-08-15 10:42:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:42:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:42:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:42:50 INFO  LogManager:72 - Loading logs.
2018-08-15 10:42:50 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-08-15 10:42:50 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:42:50 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:42:50 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:42:50 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:42:50 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:41866.
2018-08-15 10:42:50 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-08-15 10:42:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-08-15 10:42:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-08-15 10:42:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-08-15 10:42:50 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:42:50 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:42:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-08-15 10:42:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-08-15 10:42:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-08-15 10:42:50 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-08-15 10:42:50 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-08-15 10:42:50 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:42:50 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-08-15 10:42:50 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-08-15 10:42:50 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-08-15 10:42:50 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-08-15 10:42:50 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-08-15 10:42:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943a1d00000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:42:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943a1d00000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:42:50 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:42:50 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,41866,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:42:50 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322570347-0/meta.properties
2018-08-15 10:42:50 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-08-15 10:42:50 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:50 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:50 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-08-15 10:42:50 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:41173, 127.0.0.1:41866]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:42:50 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:50 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:50 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40956. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:42:50 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40956, initiating session
2018-08-15 10:42:50 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:58246
2018-08-15 10:42:50 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1009943990f0000 at /127.0.0.1:58246
2018-08-15 10:42:50 INFO  ZooKeeperServer:693 - Established session 0x1009943990f0000 with negotiated timeout 30000 for client /127.0.0.1:58246
2018-08-15 10:42:50 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40956, sessionid = 0x1009943990f0000, negotiated timeout = 30000
2018-08-15 10:42:50 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:42:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:delete cxid:0x52 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:42:50 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:42:50 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-08-15 10:42:50 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-08-15 10:42:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-08-15 10:42:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:41866 (id: 2 rack: null) for sending state change requests
2018-08-15 10:42:50 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1,2
2018-08-15 10:42:50 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-08-15 10:42:50 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:41173, 127.0.0.1:41866]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:42:50 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:42:50 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:50 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:setData cxid:0x5c zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/topics/MultiBrokerTest3-1534322566094 Error:KeeperErrorCode = NoNode for /config/topics/MultiBrokerTest3-1534322566094
2018-08-15 10:42:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x5d zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:42:51 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"1":[2,1],"0":[1,2]}}
2018-08-15 10:42:51 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(MultiBrokerTest3-1534322566094)], deleted topics: [Set()], new partition replica assignment [Map(MultiBrokerTest3-1534322566094-0 -> Vector(1, 2), MultiBrokerTest3-1534322566094-1 -> Vector(2, 1))]
2018-08-15 10:42:51 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for MultiBrokerTest3-1534322566094-0,MultiBrokerTest3-1534322566094-1
2018-08-15 10:42:51 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for MultiBrokerTest3-1534322566094-0,MultiBrokerTest3-1534322566094-1
2018-08-15 10:42:51 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions MultiBrokerTest3-1534322566094-0,MultiBrokerTest3-1534322566094-1
2018-08-15 10:42:51 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=MultiBrokerTest3-1534322566094,Partition=0,Replica=1],[Topic=MultiBrokerTest3-1534322566094,Partition=0,Replica=2],[Topic=MultiBrokerTest3-1534322566094,Partition=1,Replica=2],[Topic=MultiBrokerTest3-1534322566094,Partition=1,Replica=1]
2018-08-15 10:42:51 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1534322566094-0,MultiBrokerTest3-1534322566094-1
2018-08-15 10:42:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x68 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest3-1534322566094/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest3-1534322566094/partitions/0
2018-08-15 10:42:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x69 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest3-1534322566094/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest3-1534322566094/partitions
2018-08-15 10:42:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x6d zxid:0x2d txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest3-1534322566094/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest3-1534322566094/partitions/1
2018-08-15 10:42:51 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=MultiBrokerTest3-1534322566094,Partition=0,Replica=1],[Topic=MultiBrokerTest3-1534322566094,Partition=0,Replica=2],[Topic=MultiBrokerTest3-1534322566094,Partition=1,Replica=2],[Topic=MultiBrokerTest3-1534322566094,Partition=1,Replica=1]
2018-08-15 10:42:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1534322566094-0
2018-08-15 10:42:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1534322566094-1
2018-08-15 10:42:51 INFO  Log:72 - [Log partition=MultiBrokerTest3-1534322566094-1, dir=/tmp/1534322570347-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:51 INFO  Log:72 - [Log partition=MultiBrokerTest3-1534322566094-0, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:51 INFO  Log:72 - [Log partition=MultiBrokerTest3-1534322566094-1, dir=/tmp/1534322570347-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:42:51 INFO  Log:72 - [Log partition=MultiBrokerTest3-1534322566094-0, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:51 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1534322566094,1] in /tmp/1534322570347-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:51 INFO  Partition:72 - [Partition MultiBrokerTest3-1534322566094-1 broker=2] No checkpointed highwatermark is found for partition MultiBrokerTest3-1534322566094-1
2018-08-15 10:42:51 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1534322566094,0] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:51 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1534322566094-1 with initial high watermark 0
2018-08-15 10:42:51 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1534322566094-1 with initial high watermark 0
2018-08-15 10:42:51 INFO  Partition:72 - [Partition MultiBrokerTest3-1534322566094-0 broker=1] No checkpointed highwatermark is found for partition MultiBrokerTest3-1534322566094-0
2018-08-15 10:42:51 INFO  Partition:72 - [Partition MultiBrokerTest3-1534322566094-1 broker=2] MultiBrokerTest3-1534322566094-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:51 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1534322566094-0 with initial high watermark 0
2018-08-15 10:42:51 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1534322566094-0 with initial high watermark 0
2018-08-15 10:42:51 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1534322566094-0 with initial high watermark 0
2018-08-15 10:42:51 INFO  Partition:72 - [Partition MultiBrokerTest3-1534322566094-0 broker=1] MultiBrokerTest3-1534322566094-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:42:51 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1534322566094-1 with initial high watermark 0
2018-08-15 10:42:51 INFO  Log:72 - [Log partition=MultiBrokerTest3-1534322566094-0, dir=/tmp/1534322570347-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:51 INFO  Log:72 - [Log partition=MultiBrokerTest3-1534322566094-1, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:42:51 INFO  Log:72 - [Log partition=MultiBrokerTest3-1534322566094-0, dir=/tmp/1534322570347-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:51 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1534322566094,0] in /tmp/1534322570347-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:51 INFO  Log:72 - [Log partition=MultiBrokerTest3-1534322566094-1, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:42:51 INFO  Partition:72 - [Partition MultiBrokerTest3-1534322566094-0 broker=2] No checkpointed highwatermark is found for partition MultiBrokerTest3-1534322566094-0
2018-08-15 10:42:51 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1534322566094-0 with initial high watermark 0
2018-08-15 10:42:51 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1534322566094,1] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:42:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1534322566094-0
2018-08-15 10:42:51 INFO  Partition:72 - [Partition MultiBrokerTest3-1534322566094-1 broker=1] No checkpointed highwatermark is found for partition MultiBrokerTest3-1534322566094-1
2018-08-15 10:42:51 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1534322566094-1 with initial high watermark 0
2018-08-15 10:42:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1534322566094-1
2018-08-15 10:42:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting
2018-08-15 10:42:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([MultiBrokerTest3-1534322566094-0, initOffset 0 to broker BrokerEndPoint(1,127.0.0.1,41173)] )
2018-08-15 10:42:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-08-15 10:42:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([MultiBrokerTest3-1534322566094-1, initOffset 0 to broker BrokerEndPoint(2,127.0.0.1,41866)] )
2018-08-15 10:42:51 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in MultiBrokerTest3-1534322566094-1. High watermark 0 will be used for truncation.
2018-08-15 10:42:51 INFO  Log:72 - [Log partition=MultiBrokerTest3-1534322566094-1, dir=/tmp/1534322568106-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-08-15 10:42:51 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in MultiBrokerTest3-1534322566094-0. High watermark 0 will be used for truncation.
2018-08-15 10:42:51 INFO  Log:72 - [Log partition=MultiBrokerTest3-1534322566094-0, dir=/tmp/1534322570347-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-08-15 10:42:51 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:41173, 127.0.0.1:41866]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:42:51 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:51 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:51 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:41173, 127.0.0.1:41866]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-08-15 10:42:51 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:51 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:51 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1534322566094-0. Cache now contains 0 entries.
2018-08-15 10:42:51 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1534322566094-0. Cache now contains 0 entries.
2018-08-15 10:42:51 INFO  KafkaTestUtils:126 - Produce completed
2018-08-15 10:42:51 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-08-15 10:42:51 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:41173, 127.0.0.1:41866]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-08-15 10:42:51 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:51 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:51 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1534322566094-1. Cache now contains 0 entries.
2018-08-15 10:42:51 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1534322566094-1. Cache now contains 0 entries.
2018-08-15 10:42:51 INFO  KafkaTestUtils:126 - Produce completed
2018-08-15 10:42:51 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-08-15 10:42:51 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-08-15 10:42:51 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-08-15 10:42:51 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 2
2018-08-15 10:42:51 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=MultiBrokerTest3-1534322566094,Partition=0,Replica=2]
2018-08-15 10:42:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1534322566094-0
2018-08-15 10:42:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down
2018-08-15 10:42:51 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition MultiBrokerTest3-1534322566094-0 is {"leader":1,"leader_epoch":1,"isr":[1]}
2018-08-15 10:42:51 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1534322566094-1
2018-08-15 10:42:51 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-08-15 10:42:51 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-08-15 10:42:51 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1 epoch 1 fails to send request (type=StopReplicaRequest, controllerId=1, controllerEpoch=1, deletePartitions=false, partitions=MultiBrokerTest3-1534322566094-0) to broker 127.0.0.1:41866 (id: 2 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:51 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-08-15 10:42:51 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-08-15 10:42:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1534322566094-0
2018-08-15 10:42:51 INFO  Partition:72 - [Partition MultiBrokerTest3-1534322566094-0 broker=1] MultiBrokerTest3-1534322566094-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-08-15 10:42:51 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 4 from controller 1 epoch 1 for partition MultiBrokerTest3-1534322566094-0 (last update controller epoch 1) since it is already the leader for the partition.
2018-08-15 10:42:51 WARN  NetworkClient:241 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:51 WARN  ReplicaFetcherThread:93 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in fetch to broker 2, request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={MultiBrokerTest3-1534322566094-1=(offset=1, logStartOffset=0, maxBytes=1048576)}, isolationLevel=READ_UNCOMMITTED)
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:91)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:209)
	at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:41)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:149)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1534322566094-1
2018-08-15 10:42:51 INFO  Partition:72 - [Partition MultiBrokerTest3-1534322566094-1 broker=1] MultiBrokerTest3-1534322566094-1 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0
2018-08-15 10:42:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-08-15 10:42:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-08-15 10:42:51 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-08-15 10:42:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:52 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped
2018-08-15 10:42:52 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed
2018-08-15 10:42:52 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1534322566094-0
2018-08-15 10:42:52 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-08-15 10:42:52 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-08-15 10:42:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-08-15 10:42:52 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-08-15 10:42:52 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-08-15 10:42:52 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-08-15 10:42:52 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-08-15 10:42:52 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-08-15 10:42:52 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-08-15 10:42:52 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-08-15 10:42:52 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-08-15 10:42:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-08-15 10:42:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-08-15 10:42:52 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-08-15 10:42:52 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-08-15 10:42:52 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:42:52 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:42:52 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:42:52 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-08-15 10:42:52 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-08-15 10:42:52 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:52 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-08-15 10:42:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-08-15 10:42:53 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:53 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-08-15 10:42:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-08-15 10:42:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-08-15 10:42:53 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:53 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:53 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:53 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-08-15 10:42:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-08-15 10:42:53 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-08-15 10:42:53 INFO  LogManager:72 - Shutting down.
2018-08-15 10:42:53 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:42:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:42:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:42:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:42:53 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1534322566094-1] Writing producer snapshot at offset 2
2018-08-15 10:42:53 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1534322566094-0] Writing producer snapshot at offset 2
2018-08-15 10:42:53 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:42:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:42:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:42:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:42:53 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-08-15 10:42:53 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-08-15 10:42:53 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-08-15 10:42:53 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:42:53 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009943a1d00000
2018-08-15 10:42:53 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-08-15 10:42:53 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:41866 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:41866 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:42:53 INFO  ZooKeeper:687 - Session: 0x1009943a1d00000 closed
2018-08-15 10:42:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:42:53 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009943a1d00000
2018-08-15 10:42:53 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:58244 which had sessionid 0x1009943a1d00000
2018-08-15 10:42:53 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: 2, all live brokers: 1
2018-08-15 10:42:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-08-15 10:42:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-08-15 10:42:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:42:53 INFO  KafkaController:72 - [Controller id=1] Broker failure callback for 2
2018-08-15 10:42:53 INFO  KafkaController:72 - [Controller id=1] Removed ArrayBuffer(2) from list of shutting down brokers.
2018-08-15 10:42:53 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OfflinePartition for partitions 
2018-08-15 10:42:53 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=MultiBrokerTest3-1534322566094,Partition=0,Replica=2],[Topic=MultiBrokerTest3-1534322566094,Partition=1,Replica=2]
2018-08-15 10:42:53 WARN  KafkaController:87 - [Controller id=1] Cannot remove replica 2 from ISR of partition MultiBrokerTest3-1534322566094-0 since it is not in the ISR. Leader = 1 ; ISR = List(1)
2018-08-15 10:42:53 WARN  KafkaController:87 - [Controller id=1] Cannot remove replica 2 from ISR of partition MultiBrokerTest3-1534322566094-1 since it is not in the ISR. Leader = 1 ; ISR = List(1)
2018-08-15 10:42:53 WARN  logger:87 - [Broker id=1] Ignoring LeaderAndIsr request from controller 1 with correlation id 8 epoch 1 for partition MultiBrokerTest3-1534322566094-1 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-08-15 10:42:53 WARN  ControllerChannelManager:87 - [Channel manager on controller 1]: Not sending request (type=StopReplicaRequest, controllerId=1, controllerEpoch=1, deletePartitions=false, partitions=MultiBrokerTest3-1534322566094-0,MultiBrokerTest3-1534322566094-1) to broker 2, since it is offline.
2018-08-15 10:42:53 WARN  logger:87 - [Broker id=1] Ignoring LeaderAndIsr request from controller 1 with correlation id 8 epoch 1 for partition MultiBrokerTest3-1534322566094-0 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-08-15 10:42:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:42:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:42:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:42:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:42:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:42:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:42:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:42:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:42:54 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-08-15 10:42:54 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-08-15 10:42:54 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-08-15 10:42:54 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:41173, 127.0.0.1:41866]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:42:54 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:54 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:54 WARN  NetworkClient:241 - [AdminClient clientId=test-consumer-id] Connection to node -2 could not be established. Broker may not be available.
2018-08-15 10:42:54 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:41173, 127.0.0.1:41866]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-08-15 10:42:54 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:42:54 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:42:54 WARN  NetworkClient:241 - [Consumer clientId=test-consumer-id, groupId=] Connection to node -2 could not be established. Broker may not be available.
2018-08-15 10:42:54 INFO  KafkaTestUtils:256 - Found 3 records in kafka
2018-08-15 10:42:56 INFO  KafkaTestUtils:256 - Found 0 records in kafka
2018-08-15 10:42:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:setData cxid:0x80 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-08-15 10:42:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x81 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:42:56 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-08-15 10:42:56 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-08-15 10:42:56 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-08-15 10:42:56 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:42:56 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:42:56 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:42:56 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:42:56 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:42:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xbd zxid:0x37 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-08-15 10:42:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xbe zxid:0x38 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-08-15 10:42:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xc5 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-08-15 10:42:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xcb zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xd0 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xd6 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xdc zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xe2 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xe8 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xee zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xf2 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xf8 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0xfe zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x104 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-08-15 10:42:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x10a zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-08-15 10:42:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x10f zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-08-15 10:42:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x115 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-08-15 10:42:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x11b zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-08-15 10:42:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x121 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-08-15 10:42:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x126 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-08-15 10:42:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x12d zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-08-15 10:42:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x131 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-08-15 10:42:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x137 zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-08-15 10:42:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x13d zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-08-15 10:42:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x143 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-08-15 10:42:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x149 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-08-15 10:42:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x14f zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x155 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x15b zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x160 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x166 zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x16c zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x172 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x176 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x17c zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x182 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x187 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x18d zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-08-15 10:43:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x191 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x197 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x19d zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1a2 zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1a8 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1ae zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1b3 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1ba zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1c0 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1c4 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1ca zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-08-15 10:43:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1d0 zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-08-15 10:43:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009943990f0000 type:create cxid:0x1d5 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-08-15 10:43:02 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:43:02 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322568106-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:43:02 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322568106-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:43:02 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1534322568106-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-08-15 10:43:02 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-08-15 10:43:02 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds.
2018-08-15 10:43:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-08-15 10:43:02 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:41173 (id: 2147483646 rack: null)
2018-08-15 10:43:02 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-08-15 10:43:02 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:43:02 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:43:02 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:43:02 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1534322566094-1
2018-08-15 10:43:02 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-1 besides shutting down brokers 1
2018-08-15 10:43:02 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1534322566094-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-1 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-1 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-08-15 10:43:02 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1534322566094-0
2018-08-15 10:43:02 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-0 besides shutting down brokers 1
2018-08-15 10:43:02 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1534322566094-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-0 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-0 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-08-15 10:43:02 INFO  KafkaServer:72 - [KafkaServer id=1] Remaining partitions to move: MultiBrokerTest3-1534322566094-1,MultiBrokerTest3-1534322566094-0
2018-08-15 10:43:02 INFO  KafkaServer:72 - [KafkaServer id=1] Error code from controller: 0
2018-08-15 10:43:07 WARN  KafkaServer:87 - [KafkaServer id=1] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:43:07 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:43:07 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1534322566094-1
2018-08-15 10:43:07 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-1 besides shutting down brokers 1
2018-08-15 10:43:07 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1534322566094-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-1 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-1 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-08-15 10:43:07 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1534322566094-0
2018-08-15 10:43:07 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-0 besides shutting down brokers 1
2018-08-15 10:43:07 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1534322566094-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-0 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-0 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-08-15 10:43:07 INFO  KafkaServer:72 - [KafkaServer id=1] Remaining partitions to move: MultiBrokerTest3-1534322566094-1,MultiBrokerTest3-1534322566094-0
2018-08-15 10:43:07 INFO  KafkaServer:72 - [KafkaServer id=1] Error code from controller: 0
2018-08-15 10:43:12 WARN  KafkaServer:87 - [KafkaServer id=1] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:43:12 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:43:12 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1534322566094-1
2018-08-15 10:43:12 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-1 besides shutting down brokers 1
2018-08-15 10:43:12 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1534322566094-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-1 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-1 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-08-15 10:43:12 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1534322566094-0
2018-08-15 10:43:12 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-0 besides shutting down brokers 1
2018-08-15 10:43:12 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1534322566094-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1534322566094-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-0 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1534322566094-0 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-08-15 10:43:12 INFO  KafkaServer:72 - [KafkaServer id=1] Remaining partitions to move: MultiBrokerTest3-1534322566094-1,MultiBrokerTest3-1534322566094-0
2018-08-15 10:43:12 INFO  KafkaServer:72 - [KafkaServer id=1] Error code from controller: 0
2018-08-15 10:43:17 WARN  KafkaServer:87 - [KafkaServer id=1] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:43:17 WARN  KafkaServer:87 - [KafkaServer id=1] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-08-15 10:43:17 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:43:17 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:43:17 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:43:17 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:43:17 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:43:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:43:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:43:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:43:17 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:43:17 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:43:17 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:43:17 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:43:17 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:43:17 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:43:17 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:43:17 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:43:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:43:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:43:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:43:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:43:18 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:43:18 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:43:18 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:43:18 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:43:18 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:43:18 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:43:18 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:43:18 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:43:18 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:43:18 INFO  LogManager:72 - Shutting down.
2018-08-15 10:43:18 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:43:18 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:43:18 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:43:18 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:43:18 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1534322566094-1] Writing producer snapshot at offset 1
2018-08-15 10:43:19 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2
2018-08-15 10:43:19 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1534322566094-0] Writing producer snapshot at offset 2
2018-08-15 10:43:19 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:43:19 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:43:19 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:43:19 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:43:19 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:43:19 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:43:19 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:43:19 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:43:19 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:43:19 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:43:19 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:43:19 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009943990f0000
2018-08-15 10:43:19 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:58246 which had sessionid 0x1009943990f0000
2018-08-15 10:43:19 INFO  ZooKeeper:687 - Session: 0x1009943990f0000 closed
2018-08-15 10:43:19 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:43:19 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009943990f0000
2018-08-15 10:43:19 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:43:19 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:43:19 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:43:19 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:43:19 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:43:19 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:43:20 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:43:20 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:43:20 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:43:20 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:43:20 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:43:20 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-08-15 10:43:20 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:43:20 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:20 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:20 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:20 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:20 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:20 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:20 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:20 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:20 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:20 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:20 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:20 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:20 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:20 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:20 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38963
2018-08-15 10:43:20 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:21 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:21 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:21 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:21 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:21 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:21 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:21 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:21 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:21 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:21 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:21 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:21 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:21 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:21 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:21 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38963
2018-08-15 10:43:22 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:38887
	advertised.port = 38887
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:38887
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322602775-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 38887
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38963
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:43:22 INFO  KafkaServer:72 - starting
2018-08-15 10:43:22 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:38963
2018-08-15 10:43:22 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:38963 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@6999cd39
2018-08-15 10:43:22 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:43:22 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:22 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38963. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:22 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38963, initiating session
2018-08-15 10:43:22 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43728
2018-08-15 10:43:22 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:43728
2018-08-15 10:43:22 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:43:22 INFO  ZooKeeperServer:693 - Established session 0x1009944207c0000 with negotiated timeout 30000 for client /127.0.0.1:43728
2018-08-15 10:43:22 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38963, sessionid = 0x1009944207c0000, negotiated timeout = 30000
2018-08-15 10:43:22 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944207c0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:43:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944207c0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:43:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944207c0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:43:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944207c0000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:43:23 INFO  KafkaServer:72 - Cluster ID = djqZ0CpcQpmDSz2fpCOb5w
2018-08-15 10:43:23 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322602775-0/meta.properties
2018-08-15 10:43:23 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:43:23 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:43:23 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:43:23 INFO  LogManager:72 - Loading logs.
2018-08-15 10:43:23 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-08-15 10:43:23 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:43:23 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:43:23 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:43:23 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:43:23 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:38887.
2018-08-15 10:43:23 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:43:23 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:43:23 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:43:23 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:43:23 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:43:23 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:43:23 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:43:23 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:43:23 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:43:23 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:43:23 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:43:23 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:43:23 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:43:23 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:43:23 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:43:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944207c0000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:43:23 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:43:23 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:43:23 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:43:23 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:43:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944207c0000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:43:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944207c0000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:43:23 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:23 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,38887,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:43:23 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322602775-0/meta.properties
2018-08-15 10:43:23 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:43:23 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:43:23 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:43:23 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:38887 (id: 1 rack: null) for sending state change requests
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:43:23 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:43:23 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:43:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944207c0000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:43:23 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:43:23 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:23 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:23 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:43:23 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:23 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43728 which had sessionid 0x1009944207c0000
2018-08-15 10:43:23 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1009944207c0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:43:23 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:23 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:23 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:23 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:23 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:23 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:23 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:23 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:23 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:23 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:23 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:23 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:23 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:23 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38963
2018-08-15 10:43:23 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:23 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:43:23 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:23 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:24 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:46290
	advertised.port = 46290
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:46290
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322604729-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 46290
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38963
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:43:24 INFO  KafkaServer:72 - starting
2018-08-15 10:43:24 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:38963
2018-08-15 10:43:24 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:38963 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@1813f3e9
2018-08-15 10:43:24 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:43:24 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:24 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38963. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:24 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38963, initiating session
2018-08-15 10:43:24 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43732
2018-08-15 10:43:24 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:43732
2018-08-15 10:43:24 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-08-15 10:43:24 INFO  ZooKeeperServer:693 - Established session 0x1009944281d0000 with negotiated timeout 30000 for client /127.0.0.1:43732
2018-08-15 10:43:24 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38963, sessionid = 0x1009944281d0000, negotiated timeout = 30000
2018-08-15 10:43:24 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:24 INFO  KafkaServer:72 - Cluster ID = djqZ0CpcQpmDSz2fpCOb5w
2018-08-15 10:43:24 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322604729-0/meta.properties
2018-08-15 10:43:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:43:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:43:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:43:24 INFO  LogManager:72 - Loading logs.
2018-08-15 10:43:24 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:43:24 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:43:24 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:43:24 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:43:24 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:43:24 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:46290.
2018-08-15 10:43:24 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-08-15 10:43:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-08-15 10:43:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-08-15 10:43:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-08-15 10:43:24 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:43:24 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:43:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-08-15 10:43:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-08-15 10:43:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-08-15 10:43:24 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-08-15 10:43:24 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-08-15 10:43:24 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:43:24 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-08-15 10:43:24 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-08-15 10:43:24 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-08-15 10:43:24 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-08-15 10:43:24 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-08-15 10:43:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944281d0000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:43:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944281d0000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:43:24 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:24 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,46290,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:43:24 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322604729-0/meta.properties
2018-08-15 10:43:24 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-08-15 10:43:24 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:24 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:24 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-08-15 10:43:24 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:25 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43732 which had sessionid 0x1009944281d0000
2018-08-15 10:43:25 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:25 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1009944281d0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:43:25 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:25 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:25 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:25 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:25 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:25 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:25 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:25 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:25 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:25 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:25 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:25 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:25 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:38963
2018-08-15 10:43:25 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:43:25 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38963. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:25 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43734
2018-08-15 10:43:25 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38963, initiating session
2018-08-15 10:43:25 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1009944207c0000 at /127.0.0.1:43734
2018-08-15 10:43:25 INFO  ZooKeeperServer:693 - Established session 0x1009944207c0000 with negotiated timeout 30000 for client /127.0.0.1:43734
2018-08-15 10:43:25 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38963, sessionid = 0x1009944207c0000, negotiated timeout = 30000
2018-08-15 10:43:25 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944207c0000 type:delete cxid:0x52 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:43:25 INFO  FileTxnLog:213 - Creating new log file: log.23
2018-08-15 10:43:25 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:43:25 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-08-15 10:43:25 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-08-15 10:43:25 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-08-15 10:43:25 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:46290 (id: 2 rack: null) for sending state change requests
2018-08-15 10:43:25 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1,2
2018-08-15 10:43:26 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:38214
	advertised.port = 38214
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:38214
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322606011-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 38214
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38963
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:43:26 INFO  KafkaServer:72 - starting
2018-08-15 10:43:26 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:38963
2018-08-15 10:43:26 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:38963 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@43b0ade
2018-08-15 10:43:26 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:43:26 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:26 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38963. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:26 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38963, initiating session
2018-08-15 10:43:26 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43738
2018-08-15 10:43:26 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:43738
2018-08-15 10:43:26 INFO  ZooKeeperServer:693 - Established session 0x10099442d200000 with negotiated timeout 30000 for client /127.0.0.1:43738
2018-08-15 10:43:26 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38963, sessionid = 0x10099442d200000, negotiated timeout = 30000
2018-08-15 10:43:26 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:26 INFO  KafkaServer:72 - Cluster ID = djqZ0CpcQpmDSz2fpCOb5w
2018-08-15 10:43:26 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322606011-0/meta.properties
2018-08-15 10:43:26 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:43:26 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:43:26 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:43:26 INFO  LogManager:72 - Loading logs.
2018-08-15 10:43:26 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-08-15 10:43:26 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:43:26 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:43:26 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:43:26 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:43:26 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:38214.
2018-08-15 10:43:26 INFO  SocketServer:72 - [SocketServer brokerId=3] Started 1 acceptor threads
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Starting
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Starting
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Starting
2018-08-15 10:43:26 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:43:26 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Starting
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Starting
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Starting
2018-08-15 10:43:26 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Starting up.
2018-08-15 10:43:26 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Startup complete.
2018-08-15 10:43:26 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:43:26 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2018-08-15 10:43:26 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Starting up.
2018-08-15 10:43:26 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Startup complete.
2018-08-15 10:43:26 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Starting
2018-08-15 10:43:26 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/3 (is it secure? false)
2018-08-15 10:43:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099442d200000 type:create cxid:0x1d zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:43:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099442d200000 type:create cxid:0x1e zxid:0x27 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:43:26 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:26 INFO  ZkUtils:72 - Registered broker 3 at path /brokers/ids/3 with addresses: EndPoint(127.0.0.1,38214,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:43:26 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322606011-0/meta.properties
2018-08-15 10:43:26 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 3, deleted brokers: , all live brokers: 1,2,3
2018-08-15 10:43:26 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 3
2018-08-15 10:43:26 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Starting
2018-08-15 10:43:26 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Controller 1 connected to 127.0.0.1:38214 (id: 3 rack: null) for sending state change requests
2018-08-15 10:43:26 INFO  SocketServer:72 - [SocketServer brokerId=3] Started processors for 1 acceptors
2018-08-15 10:43:26 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:26 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:26 INFO  KafkaServer:72 - [KafkaServer id=3] started
2018-08-15 10:43:26 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:38887, 127.0.0.1:46290, 127.0.0.1:38214]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:43:26 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:26 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:26 INFO  KafkaTestCluster:253 - Found 3 brokers on-line, cluster is ready.
2018-08-15 10:43:26 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:38887, 127.0.0.1:46290, 127.0.0.1:38214]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:43:26 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:26 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:26 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:38963. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:26 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:38963, initiating session
2018-08-15 10:43:26 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43750
2018-08-15 10:43:26 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1009944281d0000 at /127.0.0.1:43750
2018-08-15 10:43:26 INFO  ZooKeeperServer:693 - Established session 0x1009944281d0000 with negotiated timeout 30000 for client /127.0.0.1:43750
2018-08-15 10:43:26 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:38963, sessionid = 0x1009944281d0000, negotiated timeout = 30000
2018-08-15 10:43:26 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:26 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:43:26 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:43:26 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:43:26 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:43:26 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:43:26 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:43:26 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:43:26 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:43:26 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:43:26 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:43:26 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:43:26 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:43:26 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:43:26 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:43:26 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:43:26 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:43:26 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:43:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:43:26 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:43:27 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:43:27 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:43:27 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:43:27 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:43:27 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:43:27 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:43:27 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:43:27 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:43:27 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:43:27 INFO  LogManager:72 - Shutting down.
2018-08-15 10:43:27 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:43:27 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:43:27 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:43:27 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:43:27 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:43:27 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:43:27 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:43:27 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:43:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:43:27 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutting down
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Stopped
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutdown completed
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:43:27 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:43:27 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009944207c0000
2018-08-15 10:43:27 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43734 which had sessionid 0x1009944207c0000
2018-08-15 10:43:27 INFO  ZooKeeper:687 - Session: 0x1009944207c0000 closed
2018-08-15 10:43:27 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:43:27 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009944207c0000
2018-08-15 10:43:27 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:43:27 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:43:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944281d0000 type:create cxid:0x25 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2018-08-15 10:43:27 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] 3 successfully elected as the controller
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Starting become controller state transition
2018-08-15 10:43:27 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: NODEEXISTS
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Initialized controller epoch to 1 and zk version 0
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Incremented epoch to 2
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Starting
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Starting
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Partitions being reassigned: Map()
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Partitions already reassigned: Set()
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Resuming reassignment of partitions: Map()
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Currently active brokers in the cluster: Set(2, 3)
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Current list of topics in the cluster: Set()
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] List of topics to be deleted: 
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] List of topics ineligible for deletion: 
2018-08-15 10:43:27 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2018-08-15 10:43:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Ready to serve as the new controller with epoch 2
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Controller 3 connected to 127.0.0.1:46290 (id: 2 rack: null) for sending state change requests
2018-08-15 10:43:27 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Controller 3 connected to 127.0.0.1:38214 (id: 3 rack: null) for sending state change requests
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Partitions undergoing preferred replica election: 
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Partitions that completed preferred replica election: 
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Resuming preferred replica election for partitions: 
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Starting preferred replica leader election for partitions 
2018-08-15 10:43:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:43:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099442d200000 type:delete cxid:0x3e zxid:0x2d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:43:27 INFO  KafkaController:72 - [Controller id=3] Starting the controller scheduler
2018-08-15 10:43:28 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:43:28 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:43:28 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:43:28 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:43:28 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:43:28 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:43:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:43:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:43:29 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:43:29 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:43:29 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:43:29 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-08-15 10:43:29 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-08-15 10:43:29 INFO  KafkaController:72 - [Controller id=3] Shutting down broker 2
2018-08-15 10:43:29 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-08-15 10:43:29 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-08-15 10:43:29 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-08-15 10:43:29 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-08-15 10:43:29 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-08-15 10:43:29 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-08-15 10:43:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-08-15 10:43:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-08-15 10:43:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-08-15 10:43:29 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-08-15 10:43:29 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-08-15 10:43:29 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-08-15 10:43:29 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-08-15 10:43:29 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-08-15 10:43:29 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-08-15 10:43:29 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-08-15 10:43:29 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-08-15 10:43:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-08-15 10:43:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-08-15 10:43:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-08-15 10:43:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-08-15 10:43:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-08-15 10:43:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-08-15 10:43:29 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-08-15 10:43:29 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-08-15 10:43:29 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:43:29 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:43:29 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:43:29 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-08-15 10:43:29 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-08-15 10:43:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-08-15 10:43:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-08-15 10:43:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-08-15 10:43:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-08-15 10:43:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-08-15 10:43:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-08-15 10:43:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-08-15 10:43:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-08-15 10:43:30 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-08-15 10:43:30 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-08-15 10:43:30 INFO  LogManager:72 - Shutting down.
2018-08-15 10:43:30 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:43:30 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:43:30 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:43:30 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:43:30 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:43:30 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:43:30 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:43:30 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:43:30 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-08-15 10:43:30 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-08-15 10:43:30 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-08-15 10:43:30 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:43:30 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009944281d0000
2018-08-15 10:43:30 INFO  ZooKeeper:687 - Session: 0x1009944281d0000 closed
2018-08-15 10:43:30 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:43:30 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43750 which had sessionid 0x1009944281d0000
2018-08-15 10:43:30 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009944281d0000
2018-08-15 10:43:30 INFO  KafkaController:72 - [Controller id=3] Newly added brokers: , deleted brokers: 2, all live brokers: 3
2018-08-15 10:43:30 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Shutting down
2018-08-15 10:43:30 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Stopped
2018-08-15 10:43:30 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:43:30 INFO  KafkaController:72 - [Controller id=3] Broker failure callback for 2
2018-08-15 10:43:30 INFO  KafkaController:72 - [Controller id=3] Removed ArrayBuffer(2) from list of shutting down brokers.
2018-08-15 10:43:30 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Invoking state change to OfflinePartition for partitions 
2018-08-15 10:43:30 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:43:30 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:43:30 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:43:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:43:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:43:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:43:32 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:43:32 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:43:32 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-08-15 10:43:32 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-08-15 10:43:32 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-08-15 10:43:32 INFO  KafkaServer:72 - [KafkaServer id=3] shutting down
2018-08-15 10:43:32 INFO  KafkaServer:72 - [KafkaServer id=3] Starting controlled shutdown
2018-08-15 10:43:32 INFO  KafkaController:72 - [Controller id=3] Shutting down broker 3
2018-08-15 10:43:32 INFO  KafkaServer:72 - [KafkaServer id=3] Controlled shutdown succeeded
2018-08-15 10:43:32 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopping socket server request processors
2018-08-15 10:43:32 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopped socket server request processors
2018-08-15 10:43:32 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shutting down
2018-08-15 10:43:32 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shut down completely
2018-08-15 10:43:32 INFO  KafkaApis:72 - [KafkaApi-3] Shutdown complete.
2018-08-15 10:43:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutting down
2018-08-15 10:43:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Stopped
2018-08-15 10:43:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutdown completed
2018-08-15 10:43:32 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutting down.
2018-08-15 10:43:32 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 2000
2018-08-15 10:43:32 INFO  TransactionStateManager:72 - [Transaction State Manager 3]: Shutdown complete
2018-08-15 10:43:32 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutting down
2018-08-15 10:43:32 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Stopped
2018-08-15 10:43:32 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutdown completed
2018-08-15 10:43:32 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutdown complete.
2018-08-15 10:43:32 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutting down.
2018-08-15 10:43:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutting down
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Stopped
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutting down
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Stopped
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2018-08-15 10:43:33 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutdown complete.
2018-08-15 10:43:33 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shutting down
2018-08-15 10:43:33 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:43:33 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:43:33 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:43:33 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutting down
2018-08-15 10:43:33 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutdown completed
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutting down
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Stopped
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutdown completed
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutting down
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Stopped
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutdown completed
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Stopped
2018-08-15 10:43:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2018-08-15 10:43:33 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shut down completely
2018-08-15 10:43:33 INFO  LogManager:72 - Shutting down.
2018-08-15 10:43:33 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:43:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:43:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:43:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:43:33 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:43:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:43:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:43:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:43:33 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2018-08-15 10:43:33 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2018-08-15 10:43:33 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutting down
2018-08-15 10:43:33 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Stopped
2018-08-15 10:43:33 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutdown completed
2018-08-15 10:43:33 INFO  KafkaController:72 - [Controller id=3] Resigned
2018-08-15 10:43:33 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:43:33 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10099442d200000
2018-08-15 10:43:33 INFO  ZooKeeper:687 - Session: 0x10099442d200000 closed
2018-08-15 10:43:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:43:33 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43738 which had sessionid 0x10099442d200000
2018-08-15 10:43:33 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10099442d200000
2018-08-15 10:43:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:43:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:43:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:43:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:43:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:43:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:43:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:43:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:43:35 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutting down socket server
2018-08-15 10:43:35 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutdown completed
2018-08-15 10:43:35 INFO  KafkaServer:72 - [KafkaServer id=3] shut down completed
2018-08-15 10:43:35 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:43:35 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:35 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:35 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:35 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:35 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:35 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:35 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:35 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:35 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:35 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:35 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:35 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:35 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:35 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:35 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42425
2018-08-15 10:43:35 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:36 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:36 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:36 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:36 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:36 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:36 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:36 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:36 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:36 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:36 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:36 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:36 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:36 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:36 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:36 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42425
2018-08-15 10:43:37 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:40711
	advertised.port = 40711
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:40711
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322617088-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 40711
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42425
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:43:37 INFO  KafkaServer:72 - starting
2018-08-15 10:43:37 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:42425
2018-08-15 10:43:37 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42425 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@715fb77
2018-08-15 10:43:37 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:43:37 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:37 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42425. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:37 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42425, initiating session
2018-08-15 10:43:37 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:52270
2018-08-15 10:43:37 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:52270
2018-08-15 10:43:37 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:43:37 INFO  ZooKeeperServer:693 - Established session 0x100994458640000 with negotiated timeout 30000 for client /127.0.0.1:52270
2018-08-15 10:43:37 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42425, sessionid = 0x100994458640000, negotiated timeout = 30000
2018-08-15 10:43:37 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994458640000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:43:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994458640000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:43:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994458640000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:43:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994458640000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:43:37 INFO  KafkaServer:72 - Cluster ID = X5OlXQQ6SiaUroIctdUVYA
2018-08-15 10:43:37 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322617088-0/meta.properties
2018-08-15 10:43:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:43:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:43:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:43:37 INFO  LogManager:72 - Loading logs.
2018-08-15 10:43:37 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:43:37 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:43:37 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:43:37 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:43:37 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:43:37 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:40711.
2018-08-15 10:43:37 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:43:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:43:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:43:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:43:37 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:43:37 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:43:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:43:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:43:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:43:37 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:43:37 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:43:37 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:43:37 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:43:37 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:37 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:43:37 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:43:37 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:43:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994458640000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:43:37 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:43:37 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:43:37 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:43:37 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:43:37 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:43:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994458640000 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:43:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994458640000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:43:38 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:38 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,40711,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:43:38 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322617088-0/meta.properties
2018-08-15 10:43:38 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:43:38 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:43:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:43:38 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:40711 (id: 1 rack: null) for sending state change requests
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:43:38 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:43:38 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:43:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994458640000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:43:38 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:43:38 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:38 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:38 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:43:38 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:38 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:52270 which had sessionid 0x100994458640000
2018-08-15 10:43:38 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:38 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x100994458640000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:43:38 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:38 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:38 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:38 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:38 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:38 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:38 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:38 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:38 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:38 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:38 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:38 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:38 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42425
2018-08-15 10:43:38 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:38 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:43:38 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:38 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:39 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:40553
	advertised.port = 40553
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:40553
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322619070-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 40553
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42425
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:43:39 INFO  KafkaServer:72 - starting
2018-08-15 10:43:39 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:42425
2018-08-15 10:43:39 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42425 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@6443b128
2018-08-15 10:43:39 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:43:39 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:39 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42425. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:39 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42425, initiating session
2018-08-15 10:43:39 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:52274
2018-08-15 10:43:39 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:52274
2018-08-15 10:43:39 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-08-15 10:43:39 INFO  ZooKeeperServer:693 - Established session 0x100994460230000 with negotiated timeout 30000 for client /127.0.0.1:52274
2018-08-15 10:43:39 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42425, sessionid = 0x100994460230000, negotiated timeout = 30000
2018-08-15 10:43:39 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:39 INFO  KafkaServer:72 - Cluster ID = X5OlXQQ6SiaUroIctdUVYA
2018-08-15 10:43:39 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322619070-0/meta.properties
2018-08-15 10:43:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:43:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:43:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:43:39 INFO  LogManager:72 - Loading logs.
2018-08-15 10:43:39 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:43:39 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:43:39 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:43:39 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:43:39 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:43:39 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:40553.
2018-08-15 10:43:39 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-08-15 10:43:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-08-15 10:43:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-08-15 10:43:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-08-15 10:43:39 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:43:39 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:43:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-08-15 10:43:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-08-15 10:43:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-08-15 10:43:39 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-08-15 10:43:39 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-08-15 10:43:39 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:43:39 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-08-15 10:43:39 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-08-15 10:43:39 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-08-15 10:43:39 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-08-15 10:43:39 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-08-15 10:43:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994460230000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:43:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994460230000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:43:39 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:39 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,40553,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:43:39 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322619070-0/meta.properties
2018-08-15 10:43:39 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-08-15 10:43:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:39 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-08-15 10:43:39 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:40711, 127.0.0.1:40553]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:43:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:39 INFO  KafkaTestCluster:260 - Found 1 of 1 brokers ready, continuing to wait for cluster to start.
2018-08-15 10:43:39 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:40711, 127.0.0.1:40553]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:43:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:39 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42425. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:39 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42425, initiating session
2018-08-15 10:43:39 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:52282
2018-08-15 10:43:39 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x100994458640000 at /127.0.0.1:52282
2018-08-15 10:43:39 INFO  ZooKeeperServer:693 - Established session 0x100994458640000 with negotiated timeout 30000 for client /127.0.0.1:52282
2018-08-15 10:43:39 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42425, sessionid = 0x100994458640000, negotiated timeout = 30000
2018-08-15 10:43:39 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994458640000 type:delete cxid:0x52 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:43:39 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:43:39 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-08-15 10:43:39 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-08-15 10:43:39 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-08-15 10:43:39 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:40553 (id: 2 rack: null) for sending state change requests
2018-08-15 10:43:39 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1,2
2018-08-15 10:43:39 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-08-15 10:43:39 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:40711, 127.0.0.1:40553]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:43:39 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:39 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:39 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:43:39 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:43:39 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:43:39 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:43:39 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:43:39 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:43:39 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:43:39 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:43:39 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:43:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:43:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:43:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:43:39 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:43:39 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:43:39 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:43:39 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:43:39 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:43:39 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:43:39 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:43:39 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:43:39 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:43:40 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:43:40 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:43:40 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:43:40 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:43:40 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:43:40 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:43:40 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:43:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:43:40 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:43:40 INFO  LogManager:72 - Shutting down.
2018-08-15 10:43:40 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:43:40 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:43:40 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:43:40 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:43:40 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:43:40 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:43:40 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:43:40 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:43:40 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:43:40 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:43:40 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-08-15 10:43:40 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-08-15 10:43:40 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:43:40 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:43:40 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:43:40 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:43:40 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:43:40 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994458640000
2018-08-15 10:43:40 INFO  ZooKeeper:687 - Session: 0x100994458640000 closed
2018-08-15 10:43:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:43:40 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:52282 which had sessionid 0x100994458640000
2018-08-15 10:43:40 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994458640000
2018-08-15 10:43:40 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:43:40 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2018-08-15 10:43:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:43:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:43:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:43:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:43:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:43:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 2
2018-08-15 10:43:40 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2)
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set()
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: 
2018-08-15 10:43:40 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map()
2018-08-15 10:43:40 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map()
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 2
2018-08-15 10:43:40 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:40553 (id: 2 rack: null) for sending state change requests
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-08-15 10:43:40 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:43:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994460230000 type:delete cxid:0x3d zxid:0x27 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:43:40 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-08-15 10:43:41 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:43:41 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:43:41 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:43:41 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:43:41 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:43:41 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-08-15 10:43:41 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-08-15 10:43:41 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:43:41 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-08-15 10:43:41 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-08-15 10:43:41 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-08-15 10:43:41 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-08-15 10:43:41 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-08-15 10:43:41 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-08-15 10:43:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-08-15 10:43:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-08-15 10:43:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-08-15 10:43:41 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-08-15 10:43:41 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-08-15 10:43:41 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-08-15 10:43:41 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-08-15 10:43:41 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-08-15 10:43:41 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-08-15 10:43:41 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-08-15 10:43:41 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-08-15 10:43:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-08-15 10:43:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-08-15 10:43:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-08-15 10:43:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-08-15 10:43:42 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-08-15 10:43:42 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-08-15 10:43:42 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:43:42 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:43:42 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:43:42 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-08-15 10:43:42 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-08-15 10:43:42 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-08-15 10:43:42 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-08-15 10:43:42 INFO  LogManager:72 - Shutting down.
2018-08-15 10:43:42 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:43:42 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:43:42 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:43:42 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:43:42 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:43:42 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:43:42 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:43:42 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:43:42 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-08-15 10:43:42 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-08-15 10:43:42 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-08-15 10:43:42 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-08-15 10:43:42 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:43:42 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-08-15 10:43:42 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:43:42 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994460230000
2018-08-15 10:43:42 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:52274 which had sessionid 0x100994460230000
2018-08-15 10:43:42 INFO  ZooKeeper:687 - Session: 0x100994460230000 closed
2018-08-15 10:43:42 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:43:42 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994460230000
2018-08-15 10:43:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:43:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:43:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:43:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:43:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:43:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:43:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:43:44 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-08-15 10:43:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:43:44 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-08-15 10:43:44 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-08-15 10:43:44 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:43:44 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:44 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:44 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:44 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:44 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:44 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:44 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:44 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:44 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:43:44 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:44 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:44 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:44 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:44 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:44 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:44 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46843
2018-08-15 10:43:44 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:45 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:45 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:45 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:45 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:45 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:45 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:45 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:45 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:45 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:45 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:45 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:45 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:45 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:45 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:45 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46843
2018-08-15 10:43:46 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:34849
	advertised.port = 34849
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:34849
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322626158-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 34849
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:46843
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:43:46 INFO  KafkaServer:72 - starting
2018-08-15 10:43:46 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:46843
2018-08-15 10:43:46 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46843 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@6edc4161
2018-08-15 10:43:46 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:43:46 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:46 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46843. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:46 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46843, initiating session
2018-08-15 10:43:46 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:53408
2018-08-15 10:43:46 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:53408
2018-08-15 10:43:46 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:43:46 INFO  ZooKeeperServer:693 - Established session 0x10099447bd20000 with negotiated timeout 30000 for client /127.0.0.1:53408
2018-08-15 10:43:46 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46843, sessionid = 0x10099447bd20000, negotiated timeout = 30000
2018-08-15 10:43:46 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099447bd20000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:43:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099447bd20000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:43:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099447bd20000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:43:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099447bd20000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:43:46 INFO  KafkaServer:72 - Cluster ID = ZdvgPfboQS-LAuRQiooLKg
2018-08-15 10:43:46 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322626158-0/meta.properties
2018-08-15 10:43:46 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:43:46 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:43:46 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:43:46 INFO  LogManager:72 - Loading logs.
2018-08-15 10:43:46 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:43:46 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:43:46 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:43:46 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:43:46 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:43:46 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:34849.
2018-08-15 10:43:46 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:43:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:43:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:43:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:43:46 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:43:46 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:43:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:43:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:43:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:43:46 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:43:46 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:43:46 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:43:46 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:43:46 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:46 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:43:46 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:43:46 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:43:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099447bd20000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:43:46 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:43:46 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:43:46 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:43:47 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:43:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099447bd20000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:43:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099447bd20000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:43:47 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:47 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,34849,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:43:47 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322626158-0/meta.properties
2018-08-15 10:43:47 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:43:47 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:43:47 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:43:47 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:34849 (id: 1 rack: null) for sending state change requests
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:43:47 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:43:47 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:43:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099447bd20000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:43:47 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:43:47 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:47 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:47 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:43:47 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:47 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:53408 which had sessionid 0x10099447bd20000
2018-08-15 10:43:47 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:47 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x10099447bd20000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:43:47 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:47 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:47 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:47 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:47 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:47 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:47 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:47 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:47 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:47 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:47 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:47 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:47 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46843
2018-08-15 10:43:47 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:43:47 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:47 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:47 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:48 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:41032
	advertised.port = 41032
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:41032
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322628128-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 41032
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:46843
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:43:48 INFO  KafkaServer:72 - starting
2018-08-15 10:43:48 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:46843
2018-08-15 10:43:48 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46843 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@78411116
2018-08-15 10:43:48 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:43:48 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:48 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46843. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:48 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46843, initiating session
2018-08-15 10:43:48 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:53412
2018-08-15 10:43:48 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:53412
2018-08-15 10:43:48 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-08-15 10:43:48 INFO  ZooKeeperServer:693 - Established session 0x100994483840000 with negotiated timeout 30000 for client /127.0.0.1:53412
2018-08-15 10:43:48 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46843, sessionid = 0x100994483840000, negotiated timeout = 30000
2018-08-15 10:43:48 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:48 INFO  KafkaServer:72 - Cluster ID = ZdvgPfboQS-LAuRQiooLKg
2018-08-15 10:43:48 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322628128-0/meta.properties
2018-08-15 10:43:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:43:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:43:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:43:48 INFO  LogManager:72 - Loading logs.
2018-08-15 10:43:48 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:43:48 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:43:48 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:43:48 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:43:48 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:43:48 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:41032.
2018-08-15 10:43:48 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-08-15 10:43:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-08-15 10:43:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-08-15 10:43:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-08-15 10:43:48 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:43:48 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:43:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-08-15 10:43:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-08-15 10:43:48 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-08-15 10:43:48 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-08-15 10:43:48 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-08-15 10:43:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:43:48 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-08-15 10:43:48 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-08-15 10:43:48 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-08-15 10:43:48 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-08-15 10:43:48 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-08-15 10:43:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994483840000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:43:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994483840000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:43:48 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:48 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,41032,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:43:48 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322628128-0/meta.properties
2018-08-15 10:43:48 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-08-15 10:43:48 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:48 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:48 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-08-15 10:43:48 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:48 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:53412 which had sessionid 0x100994483840000
2018-08-15 10:43:48 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x100994483840000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:43:48 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:48 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:48 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:48 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:48 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:48 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:48 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:48 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:48 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:48 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:48 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:48 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:48 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:48 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46843
2018-08-15 10:43:48 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:43:48 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46843. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:48 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46843, initiating session
2018-08-15 10:43:48 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:53416
2018-08-15 10:43:48 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x10099447bd20000 at /127.0.0.1:53416
2018-08-15 10:43:48 INFO  ZooKeeperServer:693 - Established session 0x10099447bd20000 with negotiated timeout 30000 for client /127.0.0.1:53416
2018-08-15 10:43:48 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46843, sessionid = 0x10099447bd20000, negotiated timeout = 30000
2018-08-15 10:43:48 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:48 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10099447bd20000 type:delete cxid:0x52 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:43:48 INFO  FileTxnLog:213 - Creating new log file: log.23
2018-08-15 10:43:48 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:43:48 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-08-15 10:43:48 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-08-15 10:43:48 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-08-15 10:43:48 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:41032 (id: 2 rack: null) for sending state change requests
2018-08-15 10:43:48 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1,2
2018-08-15 10:43:49 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:42752
	advertised.port = 42752
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:42752
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322629484-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 42752
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:46843
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:43:49 INFO  KafkaServer:72 - starting
2018-08-15 10:43:49 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:46843
2018-08-15 10:43:49 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46843 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@4c9e38
2018-08-15 10:43:49 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:43:49 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:49 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46843. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:49 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46843, initiating session
2018-08-15 10:43:49 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:53420
2018-08-15 10:43:49 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:53420
2018-08-15 10:43:49 INFO  ZooKeeperServer:693 - Established session 0x100994488d00000 with negotiated timeout 30000 for client /127.0.0.1:53420
2018-08-15 10:43:49 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46843, sessionid = 0x100994488d00000, negotiated timeout = 30000
2018-08-15 10:43:49 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:49 INFO  KafkaServer:72 - Cluster ID = ZdvgPfboQS-LAuRQiooLKg
2018-08-15 10:43:49 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322629484-0/meta.properties
2018-08-15 10:43:49 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:43:49 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:43:49 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:43:49 INFO  LogManager:72 - Loading logs.
2018-08-15 10:43:49 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-08-15 10:43:49 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:43:49 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:43:49 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:43:49 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:43:49 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:42752.
2018-08-15 10:43:49 INFO  SocketServer:72 - [SocketServer brokerId=3] Started 1 acceptor threads
2018-08-15 10:43:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Starting
2018-08-15 10:43:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Starting
2018-08-15 10:43:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Starting
2018-08-15 10:43:49 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:43:49 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:43:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Starting
2018-08-15 10:43:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Starting
2018-08-15 10:43:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Starting
2018-08-15 10:43:49 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Starting up.
2018-08-15 10:43:49 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Startup complete.
2018-08-15 10:43:49 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds.
2018-08-15 10:43:49 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2018-08-15 10:43:49 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Starting up.
2018-08-15 10:43:49 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Startup complete.
2018-08-15 10:43:49 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Starting
2018-08-15 10:43:49 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/3 (is it secure? false)
2018-08-15 10:43:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994488d00000 type:create cxid:0x1d zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:43:49 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994488d00000 type:create cxid:0x1e zxid:0x27 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:43:49 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46843. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:49 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46843, initiating session
2018-08-15 10:43:49 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:53422
2018-08-15 10:43:49 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x100994483840000 at /127.0.0.1:53422
2018-08-15 10:43:49 INFO  ZooKeeperServer:693 - Established session 0x100994483840000 with negotiated timeout 30000 for client /127.0.0.1:53422
2018-08-15 10:43:49 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46843, sessionid = 0x100994483840000, negotiated timeout = 30000
2018-08-15 10:43:49 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:49 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:49 INFO  ZkUtils:72 - Registered broker 3 at path /brokers/ids/3 with addresses: EndPoint(127.0.0.1,42752,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:43:49 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322629484-0/meta.properties
2018-08-15 10:43:49 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 3, deleted brokers: , all live brokers: 1,2,3
2018-08-15 10:43:49 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 3
2018-08-15 10:43:49 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Starting
2018-08-15 10:43:49 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Controller 1 connected to 127.0.0.1:42752 (id: 3 rack: null) for sending state change requests
2018-08-15 10:43:49 INFO  SocketServer:72 - [SocketServer brokerId=3] Started processors for 1 acceptors
2018-08-15 10:43:49 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:49 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:49 INFO  KafkaServer:72 - [KafkaServer id=3] started
2018-08-15 10:43:49 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:34849, 127.0.0.1:41032, 127.0.0.1:42752]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:43:49 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:43:49 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:43:49 INFO  KafkaTestCluster:253 - Found 3 brokers on-line, cluster is ready.
2018-08-15 10:43:49 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:43:49 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:43:49 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:43:49 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:43:49 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:43:49 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:43:49 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:43:49 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:43:49 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:43:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:43:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:43:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:43:49 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:43:49 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:43:49 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:43:49 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:43:49 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:43:49 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:43:49 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:43:49 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:43:49 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:43:50 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:43:50 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:43:50 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:43:50 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:43:50 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:43:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:43:50 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:43:50 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:43:50 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:43:50 INFO  LogManager:72 - Shutting down.
2018-08-15 10:43:50 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:43:50 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:43:50 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:43:50 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:43:50 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:43:50 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:43:50 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:43:50 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:43:50 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:43:50 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:43:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-08-15 10:43:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-08-15 10:43:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:43:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:43:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:43:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:43:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutting down
2018-08-15 10:43:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Stopped
2018-08-15 10:43:50 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutdown completed
2018-08-15 10:43:50 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:43:50 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:43:50 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10099447bd20000
2018-08-15 10:43:50 INFO  ZooKeeper:687 - Session: 0x10099447bd20000 closed
2018-08-15 10:43:50 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:43:50 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:53416 which had sessionid 0x10099447bd20000
2018-08-15 10:43:50 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10099447bd20000
2018-08-15 10:43:50 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:43:50 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:43:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994483840000 type:create cxid:0x25 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2018-08-15 10:43:50 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:50 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:43:50 INFO  KafkaController:72 - [Controller id=3] 3 successfully elected as the controller
2018-08-15 10:43:50 INFO  KafkaController:72 - [Controller id=3] Starting become controller state transition
2018-08-15 10:43:51 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: NODEEXISTS
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Initialized controller epoch to 1 and zk version 0
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Incremented epoch to 2
2018-08-15 10:43:51 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Starting
2018-08-15 10:43:51 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Starting
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Partitions being reassigned: Map()
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Partitions already reassigned: Set()
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Resuming reassignment of partitions: Map()
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Currently active brokers in the cluster: Set(2, 3)
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Current list of topics in the cluster: Set()
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] List of topics to be deleted: 
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] List of topics ineligible for deletion: 
2018-08-15 10:43:51 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2018-08-15 10:43:51 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Ready to serve as the new controller with epoch 2
2018-08-15 10:43:51 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Controller 3 connected to 127.0.0.1:41032 (id: 2 rack: null) for sending state change requests
2018-08-15 10:43:51 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Controller 3 connected to 127.0.0.1:42752 (id: 3 rack: null) for sending state change requests
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Partitions undergoing preferred replica election: 
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Partitions that completed preferred replica election: 
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Resuming preferred replica election for partitions: 
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Starting preferred replica leader election for partitions 
2018-08-15 10:43:51 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:43:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994488d00000 type:delete cxid:0x3e zxid:0x2d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:43:51 INFO  KafkaController:72 - [Controller id=3] Starting the controller scheduler
2018-08-15 10:43:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:43:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:43:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:43:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:43:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:43:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:43:52 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:43:52 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:43:52 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:43:52 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:43:52 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:43:52 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-08-15 10:43:52 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-08-15 10:43:52 INFO  KafkaController:72 - [Controller id=3] Shutting down broker 2
2018-08-15 10:43:52 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-08-15 10:43:52 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-08-15 10:43:52 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-08-15 10:43:52 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-08-15 10:43:52 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-08-15 10:43:52 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-08-15 10:43:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-08-15 10:43:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-08-15 10:43:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-08-15 10:43:52 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-08-15 10:43:52 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-08-15 10:43:52 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-08-15 10:43:52 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-08-15 10:43:52 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-08-15 10:43:52 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-08-15 10:43:52 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-08-15 10:43:52 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-08-15 10:43:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-08-15 10:43:53 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-08-15 10:43:53 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-08-15 10:43:53 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:43:53 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:43:53 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:43:53 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-08-15 10:43:53 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-08-15 10:43:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-08-15 10:43:53 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-08-15 10:43:53 INFO  LogManager:72 - Shutting down.
2018-08-15 10:43:53 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:43:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:43:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:43:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:43:53 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:43:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:43:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:43:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:43:53 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-08-15 10:43:53 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-08-15 10:43:53 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-08-15 10:43:53 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:43:53 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994483840000
2018-08-15 10:43:53 INFO  ZooKeeper:687 - Session: 0x100994483840000 closed
2018-08-15 10:43:53 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994483840000
2018-08-15 10:43:53 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:53422 which had sessionid 0x100994483840000
2018-08-15 10:43:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:43:53 INFO  KafkaController:72 - [Controller id=3] Newly added brokers: , deleted brokers: 2, all live brokers: 3
2018-08-15 10:43:53 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Shutting down
2018-08-15 10:43:53 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Stopped
2018-08-15 10:43:53 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:43:53 INFO  KafkaController:72 - [Controller id=3] Broker failure callback for 2
2018-08-15 10:43:53 INFO  KafkaController:72 - [Controller id=3] Removed ArrayBuffer(2) from list of shutting down brokers.
2018-08-15 10:43:53 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Invoking state change to OfflinePartition for partitions 
2018-08-15 10:43:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:43:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:43:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:43:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:43:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:43:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:43:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:43:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:43:55 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-08-15 10:43:55 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-08-15 10:43:55 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-08-15 10:43:55 INFO  KafkaServer:72 - [KafkaServer id=3] shutting down
2018-08-15 10:43:55 INFO  KafkaServer:72 - [KafkaServer id=3] Starting controlled shutdown
2018-08-15 10:43:55 INFO  KafkaController:72 - [Controller id=3] Shutting down broker 3
2018-08-15 10:43:55 INFO  KafkaServer:72 - [KafkaServer id=3] Controlled shutdown succeeded
2018-08-15 10:43:55 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopping socket server request processors
2018-08-15 10:43:55 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopped socket server request processors
2018-08-15 10:43:55 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shutting down
2018-08-15 10:43:55 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shut down completely
2018-08-15 10:43:55 INFO  KafkaApis:72 - [KafkaApi-3] Shutdown complete.
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutting down
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Stopped
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutdown completed
2018-08-15 10:43:55 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutting down.
2018-08-15 10:43:55 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 2000
2018-08-15 10:43:55 INFO  TransactionStateManager:72 - [Transaction State Manager 3]: Shutdown complete
2018-08-15 10:43:55 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutting down
2018-08-15 10:43:55 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Stopped
2018-08-15 10:43:55 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutdown completed
2018-08-15 10:43:55 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutdown complete.
2018-08-15 10:43:55 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutting down.
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutting down
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Stopped
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutting down
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Stopped
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2018-08-15 10:43:55 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutdown complete.
2018-08-15 10:43:55 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shutting down
2018-08-15 10:43:55 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:43:55 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:43:55 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:43:55 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutting down
2018-08-15 10:43:55 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutdown completed
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutting down
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Stopped
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutdown completed
2018-08-15 10:43:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutting down
2018-08-15 10:43:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Stopped
2018-08-15 10:43:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutdown completed
2018-08-15 10:43:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2018-08-15 10:43:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Stopped
2018-08-15 10:43:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2018-08-15 10:43:56 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shut down completely
2018-08-15 10:43:56 INFO  LogManager:72 - Shutting down.
2018-08-15 10:43:56 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:43:56 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:43:56 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:43:56 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:43:56 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:43:56 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:43:56 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:43:56 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:43:56 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2018-08-15 10:43:56 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2018-08-15 10:43:56 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutting down
2018-08-15 10:43:56 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Stopped
2018-08-15 10:43:56 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutdown completed
2018-08-15 10:43:56 INFO  KafkaController:72 - [Controller id=3] Resigned
2018-08-15 10:43:56 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:43:56 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994488d00000
2018-08-15 10:43:56 INFO  ZooKeeper:687 - Session: 0x100994488d00000 closed
2018-08-15 10:43:56 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:53420 which had sessionid 0x100994488d00000
2018-08-15 10:43:56 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994488d00000
2018-08-15 10:43:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:43:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:43:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:43:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:43:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:43:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:43:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:43:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:43:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:43:57 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutting down socket server
2018-08-15 10:43:57 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutdown completed
2018-08-15 10:43:57 INFO  KafkaServer:72 - [KafkaServer id=3] shut down completed
2018-08-15 10:43:57 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:43:57 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:57 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:57 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:57 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:57 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:57 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:57 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:57 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:57 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:57 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:57 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:57 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:57 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:57 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:57 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:43503
2018-08-15 10:43:58 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:43:58 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:43:58 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:43:58 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:43:58 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:43:58 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:43:58 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:43:58 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:43:58 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:43:58 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:43:58 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:43:58 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:43:58 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:43:58 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:43:58 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:43503
2018-08-15 10:43:59 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:38277
	advertised.port = 38277
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:38277
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322639559-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 38277
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:43503
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:43:59 INFO  KafkaServer:72 - starting
2018-08-15 10:43:59 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:43503
2018-08-15 10:43:59 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:43503 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@2b0b4d53
2018-08-15 10:43:59 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:43:59 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:43:59 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:43503. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:43:59 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:43503, initiating session
2018-08-15 10:43:59 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43282
2018-08-15 10:43:59 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:43282
2018-08-15 10:43:59 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:43:59 INFO  ZooKeeperServer:693 - Established session 0x1009944b02c0000 with negotiated timeout 30000 for client /127.0.0.1:43282
2018-08-15 10:43:59 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:43503, sessionid = 0x1009944b02c0000, negotiated timeout = 30000
2018-08-15 10:43:59 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:43:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b02c0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:43:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b02c0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:43:59 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:43:59 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b02c0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:44:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b02c0000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:44:00 INFO  KafkaServer:72 - Cluster ID = SjKmHe-2SsCBe2dd74WRQg
2018-08-15 10:44:00 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322639559-0/meta.properties
2018-08-15 10:44:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:44:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:44:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:44:00 INFO  LogManager:72 - Loading logs.
2018-08-15 10:44:00 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-08-15 10:44:00 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:44:00 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:44:00 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:44:00 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:44:00 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:38277.
2018-08-15 10:44:00 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:44:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:44:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:44:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:44:00 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:44:00 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:44:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:44:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:44:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:44:00 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:44:00 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:44:00 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:44:00 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:44:00 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:44:00 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:44:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b02c0000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:44:00 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:44:00 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:44:00 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:44:00 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:44:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b02c0000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:44:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b02c0000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:44:00 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:00 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,38277,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:44:00 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322639559-0/meta.properties
2018-08-15 10:44:00 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:44:00 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:44:00 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:44:00 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:38277 (id: 1 rack: null) for sending state change requests
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:44:00 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:44:00 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:44:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b02c0000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:44:00 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:44:00 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:00 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:00 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:44:00 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:00 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43282 which had sessionid 0x1009944b02c0000
2018-08-15 10:44:00 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1009944b02c0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:44:00 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:00 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:00 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:00 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:00 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:00 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:00 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:00 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:00 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:00 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:00 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:00 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:00 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:00 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:43503
2018-08-15 10:44:00 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:44:00 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:44:01 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:39720
	advertised.port = 39720
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:39720
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322641854-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 39720
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:43503
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:44:01 INFO  KafkaServer:72 - starting
2018-08-15 10:44:01 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:43503
2018-08-15 10:44:01 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:43503 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@21325036
2018-08-15 10:44:01 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:44:01 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:44:01 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:43503. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:01 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:43503, initiating session
2018-08-15 10:44:01 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43286
2018-08-15 10:44:01 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:43286
2018-08-15 10:44:01 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-08-15 10:44:01 INFO  ZooKeeperServer:693 - Established session 0x1009944b9220000 with negotiated timeout 30000 for client /127.0.0.1:43286
2018-08-15 10:44:01 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:43503, sessionid = 0x1009944b9220000, negotiated timeout = 30000
2018-08-15 10:44:01 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:44:01 INFO  KafkaServer:72 - Cluster ID = SjKmHe-2SsCBe2dd74WRQg
2018-08-15 10:44:01 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322641854-0/meta.properties
2018-08-15 10:44:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:44:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:44:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:44:01 INFO  LogManager:72 - Loading logs.
2018-08-15 10:44:01 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-08-15 10:44:01 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:44:01 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:44:01 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:44:01 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:44:01 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:39720.
2018-08-15 10:44:01 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-08-15 10:44:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-08-15 10:44:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-08-15 10:44:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-08-15 10:44:01 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:44:01 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:44:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-08-15 10:44:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-08-15 10:44:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-08-15 10:44:01 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-08-15 10:44:01 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-08-15 10:44:01 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:44:01 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-08-15 10:44:01 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-08-15 10:44:01 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-08-15 10:44:01 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-08-15 10:44:01 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-08-15 10:44:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b9220000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:44:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b9220000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:44:02 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:02 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,39720,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:44:02 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322641854-0/meta.properties
2018-08-15 10:44:02 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-08-15 10:44:02 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:02 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:02 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-08-15 10:44:02 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:02 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43286 which had sessionid 0x1009944b9220000
2018-08-15 10:44:02 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1009944b9220000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:44:02 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:02 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:02 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:02 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:02 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:02 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:02 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:02 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:02 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:02 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:02 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:02 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:02 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:02 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:43503
2018-08-15 10:44:02 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:44:02 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:43503. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:02 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:43503, initiating session
2018-08-15 10:44:02 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43288
2018-08-15 10:44:02 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1009944b02c0000 at /127.0.0.1:43288
2018-08-15 10:44:02 INFO  ZooKeeperServer:693 - Established session 0x1009944b02c0000 with negotiated timeout 30000 for client /127.0.0.1:43288
2018-08-15 10:44:02 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:43503, sessionid = 0x1009944b02c0000, negotiated timeout = 30000
2018-08-15 10:44:02 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:44:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b02c0000 type:delete cxid:0x52 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:44:02 INFO  FileTxnLog:213 - Creating new log file: log.23
2018-08-15 10:44:02 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:44:02 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-08-15 10:44:02 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-08-15 10:44:02 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-08-15 10:44:02 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:39720 (id: 2 rack: null) for sending state change requests
2018-08-15 10:44:02 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1,2
2018-08-15 10:44:02 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:02 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:03 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:44517
	advertised.port = 44517
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:44517
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322643077-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 44517
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:43503
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:44:03 INFO  KafkaServer:72 - starting
2018-08-15 10:44:03 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:43503
2018-08-15 10:44:03 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:43503 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@dffa30b
2018-08-15 10:44:03 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:44:03 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:44:03 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:43503. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:03 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:43503, initiating session
2018-08-15 10:44:03 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43292
2018-08-15 10:44:03 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:43292
2018-08-15 10:44:03 INFO  ZooKeeperServer:693 - Established session 0x1009944bde90000 with negotiated timeout 30000 for client /127.0.0.1:43292
2018-08-15 10:44:03 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:43503, sessionid = 0x1009944bde90000, negotiated timeout = 30000
2018-08-15 10:44:03 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:44:03 INFO  KafkaServer:72 - Cluster ID = SjKmHe-2SsCBe2dd74WRQg
2018-08-15 10:44:03 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322643077-0/meta.properties
2018-08-15 10:44:03 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:44:03 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:44:03 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:44:03 INFO  LogManager:72 - Loading logs.
2018-08-15 10:44:03 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-08-15 10:44:03 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:44:03 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:44:03 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:44:03 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:44:03 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:44517.
2018-08-15 10:44:03 INFO  SocketServer:72 - [SocketServer brokerId=3] Started 1 acceptor threads
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Starting
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Starting
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Starting
2018-08-15 10:44:03 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Starting
2018-08-15 10:44:03 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Starting
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Starting
2018-08-15 10:44:03 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Starting up.
2018-08-15 10:44:03 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Startup complete.
2018-08-15 10:44:03 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:44:03 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2018-08-15 10:44:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Starting up.
2018-08-15 10:44:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Startup complete.
2018-08-15 10:44:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Starting
2018-08-15 10:44:03 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/3 (is it secure? false)
2018-08-15 10:44:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944bde90000 type:create cxid:0x1d zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:44:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944bde90000 type:create cxid:0x1e zxid:0x27 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:44:03 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:03 INFO  ZkUtils:72 - Registered broker 3 at path /brokers/ids/3 with addresses: EndPoint(127.0.0.1,44517,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:44:03 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322643077-0/meta.properties
2018-08-15 10:44:03 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 3, deleted brokers: , all live brokers: 1,2,3
2018-08-15 10:44:03 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 3
2018-08-15 10:44:03 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Starting
2018-08-15 10:44:03 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Controller 1 connected to 127.0.0.1:44517 (id: 3 rack: null) for sending state change requests
2018-08-15 10:44:03 INFO  SocketServer:72 - [SocketServer brokerId=3] Started processors for 1 acceptors
2018-08-15 10:44:03 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:03 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:03 INFO  KafkaServer:72 - [KafkaServer id=3] started
2018-08-15 10:44:03 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:38277, 127.0.0.1:39720, 127.0.0.1:44517]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:44:03 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:03 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:03 INFO  KafkaTestCluster:253 - Found 3 brokers on-line, cluster is ready.
2018-08-15 10:44:03 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:44:03 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:44:03 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:44:03 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:44:03 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:44:03 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:44:03 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:44:03 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:44:03 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:44:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:44:03 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:44:03 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:44:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:44:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:44:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:44:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:44:03 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:44:03 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:44:03 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:44:03 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:44:03 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:44:03 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:44:03 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:44:03 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:44:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:44:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:44:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:44:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:44:04 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:43503. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:04 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:43503, initiating session
2018-08-15 10:44:04 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43306
2018-08-15 10:44:04 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1009944b9220000 at /127.0.0.1:43306
2018-08-15 10:44:04 INFO  ZooKeeperServer:693 - Established session 0x1009944b9220000 with negotiated timeout 30000 for client /127.0.0.1:43306
2018-08-15 10:44:04 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:43503, sessionid = 0x1009944b9220000, negotiated timeout = 30000
2018-08-15 10:44:04 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:44:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:44:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:44:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:44:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:44:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:44:04 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:44:04 INFO  LogManager:72 - Shutting down.
2018-08-15 10:44:04 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:44:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:44:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:44:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:44:04 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:44:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:44:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:44:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:44:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:44:04 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutting down
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Stopped
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutdown completed
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:44:04 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:44:04 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009944b02c0000
2018-08-15 10:44:04 INFO  ZooKeeper:687 - Session: 0x1009944b02c0000 closed
2018-08-15 10:44:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:44:04 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43288 which had sessionid 0x1009944b02c0000
2018-08-15 10:44:04 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009944b02c0000
2018-08-15 10:44:04 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:44:04 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:44:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944bde90000 type:create cxid:0x24 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2018-08-15 10:44:04 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-08-15 10:44:04 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: NODEEXISTS
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 2
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Starting
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2, 3)
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set()
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: 
2018-08-15 10:44:04 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map()
2018-08-15 10:44:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map()
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 2
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Controller 2 connected to 127.0.0.1:44517 (id: 3 rack: null) for sending state change requests
2018-08-15 10:44:04 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:39720 (id: 2 rack: null) for sending state change requests
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-08-15 10:44:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:44:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944b9220000 type:delete cxid:0x3f zxid:0x2d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:44:04 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-08-15 10:44:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:44:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:44:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:44:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:44:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:44:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:44:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:44:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:44:05 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:44:05 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:44:05 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:44:05 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-08-15 10:44:05 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-08-15 10:44:05 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:44:05 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-08-15 10:44:05 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-08-15 10:44:05 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-08-15 10:44:05 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-08-15 10:44:05 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-08-15 10:44:05 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-08-15 10:44:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-08-15 10:44:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-08-15 10:44:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-08-15 10:44:05 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-08-15 10:44:05 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-08-15 10:44:05 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-08-15 10:44:05 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-08-15 10:44:05 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-08-15 10:44:05 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-08-15 10:44:05 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-08-15 10:44:05 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-08-15 10:44:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-08-15 10:44:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-08-15 10:44:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-08-15 10:44:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-08-15 10:44:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-08-15 10:44:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-08-15 10:44:05 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-08-15 10:44:05 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-08-15 10:44:05 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:44:05 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:44:05 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:44:05 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-08-15 10:44:05 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-08-15 10:44:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-08-15 10:44:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-08-15 10:44:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-08-15 10:44:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-08-15 10:44:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-08-15 10:44:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-08-15 10:44:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-08-15 10:44:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-08-15 10:44:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-08-15 10:44:06 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-08-15 10:44:06 INFO  LogManager:72 - Shutting down.
2018-08-15 10:44:06 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:44:06 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:44:06 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:44:06 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:44:06 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:44:06 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:44:06 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:44:06 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:44:06 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-08-15 10:44:06 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-08-15 10:44:06 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-08-15 10:44:06 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-08-15 10:44:06 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:44:06 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Shutting down
2018-08-15 10:44:06 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Stopped
2018-08-15 10:44:06 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Shutdown completed
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-08-15 10:44:06 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:44:06 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009944b9220000
2018-08-15 10:44:06 INFO  ZooKeeper:687 - Session: 0x1009944b9220000 closed
2018-08-15 10:44:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:44:06 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43306 which had sessionid 0x1009944b9220000
2018-08-15 10:44:06 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009944b9220000
2018-08-15 10:44:06 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:44:06 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] 3 successfully elected as the controller
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Starting become controller state transition
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Initialized controller epoch to 2 and zk version 1
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Incremented epoch to 3
2018-08-15 10:44:06 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Starting
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Partitions being reassigned: Map()
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Partitions already reassigned: Set()
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Resuming reassignment of partitions: Map()
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Currently active brokers in the cluster: Set(3)
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Current list of topics in the cluster: Set()
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] List of topics to be deleted: 
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] List of topics ineligible for deletion: 
2018-08-15 10:44:06 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2018-08-15 10:44:06 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Ready to serve as the new controller with epoch 3
2018-08-15 10:44:06 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Controller 3 connected to 127.0.0.1:44517 (id: 3 rack: null) for sending state change requests
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Partitions undergoing preferred replica election: 
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Partitions that completed preferred replica election: 
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Resuming preferred replica election for partitions: 
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Starting preferred replica leader election for partitions 
2018-08-15 10:44:06 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:44:06 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944bde90000 type:delete cxid:0x46 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:44:06 INFO  KafkaController:72 - [Controller id=3] Starting the controller scheduler
2018-08-15 10:44:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:44:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:44:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:44:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:44:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:44:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:44:07 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:44:07 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:44:07 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-08-15 10:44:07 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-08-15 10:44:07 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-08-15 10:44:07 INFO  KafkaServer:72 - [KafkaServer id=3] shutting down
2018-08-15 10:44:07 INFO  KafkaServer:72 - [KafkaServer id=3] Starting controlled shutdown
2018-08-15 10:44:07 INFO  KafkaController:72 - [Controller id=3] Shutting down broker 3
2018-08-15 10:44:07 INFO  KafkaServer:72 - [KafkaServer id=3] Controlled shutdown succeeded
2018-08-15 10:44:07 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopping socket server request processors
2018-08-15 10:44:07 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopped socket server request processors
2018-08-15 10:44:07 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shutting down
2018-08-15 10:44:07 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shut down completely
2018-08-15 10:44:07 INFO  KafkaApis:72 - [KafkaApi-3] Shutdown complete.
2018-08-15 10:44:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutting down
2018-08-15 10:44:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Stopped
2018-08-15 10:44:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutdown completed
2018-08-15 10:44:07 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutting down.
2018-08-15 10:44:07 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 2000
2018-08-15 10:44:07 INFO  TransactionStateManager:72 - [Transaction State Manager 3]: Shutdown complete
2018-08-15 10:44:07 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutting down
2018-08-15 10:44:07 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Stopped
2018-08-15 10:44:07 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutdown completed
2018-08-15 10:44:07 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutdown complete.
2018-08-15 10:44:07 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutting down.
2018-08-15 10:44:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutting down
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Stopped
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutting down
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Stopped
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2018-08-15 10:44:08 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutdown complete.
2018-08-15 10:44:08 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shutting down
2018-08-15 10:44:08 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:44:08 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:44:08 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:44:08 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutting down
2018-08-15 10:44:08 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutdown completed
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutting down
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Stopped
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutdown completed
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutting down
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Stopped
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutdown completed
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Stopped
2018-08-15 10:44:08 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2018-08-15 10:44:08 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shut down completely
2018-08-15 10:44:08 INFO  LogManager:72 - Shutting down.
2018-08-15 10:44:08 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:44:08 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:44:08 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:44:08 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:44:08 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:44:08 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:44:08 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:44:08 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:44:08 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2018-08-15 10:44:08 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2018-08-15 10:44:08 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutting down
2018-08-15 10:44:08 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Stopped
2018-08-15 10:44:08 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutdown completed
2018-08-15 10:44:08 INFO  KafkaController:72 - [Controller id=3] Resigned
2018-08-15 10:44:08 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:44:08 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009944bde90000
2018-08-15 10:44:09 INFO  ZooKeeper:687 - Session: 0x1009944bde90000 closed
2018-08-15 10:44:09 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:44:09 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43292 which had sessionid 0x1009944bde90000
2018-08-15 10:44:09 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009944bde90000
2018-08-15 10:44:09 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:44:09 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:44:09 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:44:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:44:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:44:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:44:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:44:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:44:10 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutting down socket server
2018-08-15 10:44:10 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutdown completed
2018-08-15 10:44:10 INFO  KafkaServer:72 - [KafkaServer id=3] shut down completed
2018-08-15 10:44:10 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:10 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:10 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:10 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:10 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:10 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:10 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:10 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:10 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:10 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:10 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:10 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:10 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:10 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:10 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:10 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:10 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:10 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42314
2018-08-15 10:44:11 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:11 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:11 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:11 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:11 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:11 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:11 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:11 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:11 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:11 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:11 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:11 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:11 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:11 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:11 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42314
2018-08-15 10:44:11 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:11 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:12 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:35241
	advertised.port = 35241
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:35241
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322652163-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 35241
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42314
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:44:12 INFO  KafkaServer:72 - starting
2018-08-15 10:44:12 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:42314
2018-08-15 10:44:12 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42314 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@26dcd8c0
2018-08-15 10:44:12 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:44:12 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:44:12 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42314. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:12 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42314, initiating session
2018-08-15 10:44:12 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:52022
2018-08-15 10:44:12 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:52022
2018-08-15 10:44:12 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:44:12 INFO  ZooKeeperServer:693 - Established session 0x1009944e1670000 with negotiated timeout 30000 for client /127.0.0.1:52022
2018-08-15 10:44:12 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42314, sessionid = 0x1009944e1670000, negotiated timeout = 30000
2018-08-15 10:44:12 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:44:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:44:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:44:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:44:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:44:12 INFO  KafkaServer:72 - Cluster ID = ugOiurIXTueP40fFDgpb0g
2018-08-15 10:44:12 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322652163-0/meta.properties
2018-08-15 10:44:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:44:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:44:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:44:12 INFO  LogManager:72 - Loading logs.
2018-08-15 10:44:12 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-08-15 10:44:12 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:44:12 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:44:12 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:44:12 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:44:12 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:35241.
2018-08-15 10:44:12 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:44:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:44:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:44:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:44:12 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:44:12 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:44:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:44:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:44:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:44:12 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:44:12 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:44:12 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:44:12 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:44:13 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:44:13 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:44:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:44:13 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:44:13 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:44:13 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:44:13 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:44:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:44:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:create cxid:0x43 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:44:13 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:13 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,35241,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:44:13 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322652163-0/meta.properties
2018-08-15 10:44:13 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:44:13 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:44:13 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:44:13 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:35241 (id: 1 rack: null) for sending state change requests
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:44:13 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:44:13 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:44:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:delete cxid:0x4e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:44:13 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:44:13 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:13 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:13 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:44:13 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:13 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:52022 which had sessionid 0x1009944e1670000
2018-08-15 10:44:13 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1009944e1670000, likely server has closed socket, closing socket connection and attempting reconnect
2018-08-15 10:44:13 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:13 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:13 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:13 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:13 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:13 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:13 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:13 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:13 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:13 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:13 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:13 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:13 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:13 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42314
2018-08-15 10:44:13 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:44:13 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-08-15 10:44:14 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:37892
	advertised.port = 37892
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:37892
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322654254-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 37892
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42314
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:44:14 INFO  KafkaServer:72 - starting
2018-08-15 10:44:14 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:42314
2018-08-15 10:44:14 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42314 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@388b401d
2018-08-15 10:44:14 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:44:14 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:44:14 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42314. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:14 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42314, initiating session
2018-08-15 10:44:14 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:52026
2018-08-15 10:44:14 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:52026
2018-08-15 10:44:14 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-08-15 10:44:14 INFO  ZooKeeperServer:693 - Established session 0x1009944e9930000 with negotiated timeout 30000 for client /127.0.0.1:52026
2018-08-15 10:44:14 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42314, sessionid = 0x1009944e9930000, negotiated timeout = 30000
2018-08-15 10:44:14 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:44:14 INFO  KafkaServer:72 - Cluster ID = ugOiurIXTueP40fFDgpb0g
2018-08-15 10:44:14 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322654254-0/meta.properties
2018-08-15 10:44:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:44:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:44:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:44:14 INFO  LogManager:72 - Loading logs.
2018-08-15 10:44:14 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-08-15 10:44:14 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:44:14 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:44:14 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:44:14 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:44:14 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:37892.
2018-08-15 10:44:14 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-08-15 10:44:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-08-15 10:44:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-08-15 10:44:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-08-15 10:44:14 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:44:14 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:44:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-08-15 10:44:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-08-15 10:44:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-08-15 10:44:14 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-08-15 10:44:14 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-08-15 10:44:14 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:44:14 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-08-15 10:44:14 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-08-15 10:44:14 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-08-15 10:44:14 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-08-15 10:44:14 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-08-15 10:44:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e9930000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:44:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e9930000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:44:14 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:14 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,37892,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:44:14 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322654254-0/meta.properties
2018-08-15 10:44:14 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-08-15 10:44:14 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:14 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:14 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-08-15 10:44:14 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:35241, 127.0.0.1:37892]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:44:14 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:14 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:14 INFO  KafkaTestCluster:260 - Found 1 of 1 brokers ready, continuing to wait for cluster to start.
2018-08-15 10:44:14 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:35241, 127.0.0.1:37892]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:44:14 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:14 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:14 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:35241, 127.0.0.1:37892]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:44:14 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:14 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:14 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:15 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:35241, 127.0.0.1:37892]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:44:15 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:15 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:15 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42314. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:15 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42314, initiating session
2018-08-15 10:44:15 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:52052
2018-08-15 10:44:15 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1009944e1670000 at /127.0.0.1:52052
2018-08-15 10:44:15 INFO  ZooKeeperServer:693 - Established session 0x1009944e1670000 with negotiated timeout 30000 for client /127.0.0.1:52052
2018-08-15 10:44:15 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42314, sessionid = 0x1009944e1670000, negotiated timeout = 30000
2018-08-15 10:44:15 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:44:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:delete cxid:0x50 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:44:15 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:35241, 127.0.0.1:37892]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:44:15 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:15 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:15 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:44:15 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-08-15 10:44:15 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-08-15 10:44:15 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-08-15 10:44:15 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:37892 (id: 2 rack: null) for sending state change requests
2018-08-15 10:44:15 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-08-15 10:44:15 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:35241, 127.0.0.1:37892]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:44:15 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:15 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:setData cxid:0x57 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/topics/MultiBrokerTest2-1534322650150 Error:KeeperErrorCode = NoNode for /config/topics/MultiBrokerTest2-1534322650150
2018-08-15 10:44:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:create cxid:0x58 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:44:15 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"1":[1,2],"0":[2,1]}}
2018-08-15 10:44:15 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(MultiBrokerTest2-1534322650150)], deleted topics: [Set()], new partition replica assignment [Map(MultiBrokerTest2-1534322650150-0 -> Vector(2, 1), MultiBrokerTest2-1534322650150-1 -> Vector(1, 2))]
2018-08-15 10:44:15 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for MultiBrokerTest2-1534322650150-0,MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:15 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for MultiBrokerTest2-1534322650150-0,MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:15 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions MultiBrokerTest2-1534322650150-0,MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:15 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=MultiBrokerTest2-1534322650150,Partition=0,Replica=2],[Topic=MultiBrokerTest2-1534322650150,Partition=0,Replica=1],[Topic=MultiBrokerTest2-1534322650150,Partition=1,Replica=1],[Topic=MultiBrokerTest2-1534322650150,Partition=1,Replica=2]
2018-08-15 10:44:15 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1534322650150-0,MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:create cxid:0x63 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest2-1534322650150/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest2-1534322650150/partitions/0
2018-08-15 10:44:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:create cxid:0x64 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest2-1534322650150/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest2-1534322650150/partitions
2018-08-15 10:44:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e1670000 type:create cxid:0x68 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest2-1534322650150/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest2-1534322650150/partitions/1
2018-08-15 10:44:15 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=MultiBrokerTest2-1534322650150,Partition=0,Replica=2],[Topic=MultiBrokerTest2-1534322650150,Partition=0,Replica=1],[Topic=MultiBrokerTest2-1534322650150,Partition=1,Replica=1],[Topic=MultiBrokerTest2-1534322650150,Partition=1,Replica=2]
2018-08-15 10:44:15 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:15 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest2-1534322650150-0
2018-08-15 10:44:15 INFO  Log:72 - [Log partition=MultiBrokerTest2-1534322650150-0, dir=/tmp/1534322654254-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:15 INFO  Log:72 - [Log partition=MultiBrokerTest2-1534322650150-1, dir=/tmp/1534322652163-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:15 INFO  Log:72 - [Log partition=MultiBrokerTest2-1534322650150-0, dir=/tmp/1534322654254-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:15 INFO  Log:72 - [Log partition=MultiBrokerTest2-1534322650150-1, dir=/tmp/1534322652163-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:15 INFO  LogManager:72 - Created log for partition [MultiBrokerTest2-1534322650150,0] in /tmp/1534322654254-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:15 INFO  LogManager:72 - Created log for partition [MultiBrokerTest2-1534322650150,1] in /tmp/1534322652163-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:15 INFO  Partition:72 - [Partition MultiBrokerTest2-1534322650150-0 broker=2] No checkpointed highwatermark is found for partition MultiBrokerTest2-1534322650150-0
2018-08-15 10:44:15 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1534322650150-0 with initial high watermark 0
2018-08-15 10:44:15 INFO  Partition:72 - [Partition MultiBrokerTest2-1534322650150-1 broker=1] No checkpointed highwatermark is found for partition MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:15 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1534322650150-0 with initial high watermark 0
2018-08-15 10:44:15 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1534322650150-1 with initial high watermark 0
2018-08-15 10:44:15 INFO  Partition:72 - [Partition MultiBrokerTest2-1534322650150-0 broker=2] MultiBrokerTest2-1534322650150-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:15 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1534322650150-1 with initial high watermark 0
2018-08-15 10:44:15 INFO  Partition:72 - [Partition MultiBrokerTest2-1534322650150-1 broker=1] MultiBrokerTest2-1534322650150-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:15 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1534322650150-1 with initial high watermark 0
2018-08-15 10:44:15 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1534322650150-0 with initial high watermark 0
2018-08-15 10:44:15 INFO  Log:72 - [Log partition=MultiBrokerTest2-1534322650150-1, dir=/tmp/1534322654254-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:15 INFO  Log:72 - [Log partition=MultiBrokerTest2-1534322650150-0, dir=/tmp/1534322652163-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:15 INFO  Log:72 - [Log partition=MultiBrokerTest2-1534322650150-1, dir=/tmp/1534322654254-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:15 INFO  Log:72 - [Log partition=MultiBrokerTest2-1534322650150-0, dir=/tmp/1534322652163-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:15 INFO  LogManager:72 - Created log for partition [MultiBrokerTest2-1534322650150,1] in /tmp/1534322654254-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:15 INFO  LogManager:72 - Created log for partition [MultiBrokerTest2-1534322650150,0] in /tmp/1534322652163-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:15 INFO  Partition:72 - [Partition MultiBrokerTest2-1534322650150-1 broker=2] No checkpointed highwatermark is found for partition MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:15 INFO  Partition:72 - [Partition MultiBrokerTest2-1534322650150-0 broker=1] No checkpointed highwatermark is found for partition MultiBrokerTest2-1534322650150-0
2018-08-15 10:44:15 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1534322650150-1 with initial high watermark 0
2018-08-15 10:44:15 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1534322650150-0 with initial high watermark 0
2018-08-15 10:44:15 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:15 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest2-1534322650150-0
2018-08-15 10:44:15 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([MultiBrokerTest2-1534322650150-0, initOffset 0 to broker BrokerEndPoint(2,127.0.0.1,37892)] )
2018-08-15 10:44:15 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-08-15 10:44:15 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([MultiBrokerTest2-1534322650150-1, initOffset 0 to broker BrokerEndPoint(1,127.0.0.1,35241)] )
2018-08-15 10:44:15 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting
2018-08-15 10:44:15 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in MultiBrokerTest2-1534322650150-0. High watermark 0 will be used for truncation.
2018-08-15 10:44:15 INFO  Log:72 - [Log partition=MultiBrokerTest2-1534322650150-0, dir=/tmp/1534322652163-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-08-15 10:44:15 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in MultiBrokerTest2-1534322650150-1. High watermark 0 will be used for truncation.
2018-08-15 10:44:15 INFO  Log:72 - [Log partition=MultiBrokerTest2-1534322650150-1, dir=/tmp/1534322654254-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-08-15 10:44:15 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:35241, 127.0.0.1:37892]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:44:15 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:15 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:15 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:44:15 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:44:16 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:44:16 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=MultiBrokerTest2-1534322650150,Partition=0,Replica=1]
2018-08-15 10:44:16 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest2-1534322650150-0
2018-08-15 10:44:16 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-08-15 10:44:16 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition MultiBrokerTest2-1534322650150-0 is {"leader":2,"leader_epoch":1,"isr":[2]}
2018-08-15 10:44:16 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:16 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest2-1534322650150-0
2018-08-15 10:44:16 INFO  Partition:72 - [Partition MultiBrokerTest2-1534322650150-0 broker=2] MultiBrokerTest2-1534322650150-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:44:16 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 1 for partition MultiBrokerTest2-1534322650150-0 (last update controller epoch 1) since it is already the leader for the partition.
2018-08-15 10:44:16 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:44:16 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:16 INFO  Partition:72 - [Partition MultiBrokerTest2-1534322650150-1 broker=2] MultiBrokerTest2-1534322650150-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-08-15 10:44:16 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down
2018-08-15 10:44:16 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:44:16 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1 epoch 1 fails to send request (type=StopReplicaRequest, controllerId=1, controllerEpoch=1, deletePartitions=false, partitions=MultiBrokerTest2-1534322650150-0) to broker 127.0.0.1:35241 (id: 1 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:16 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped
2018-08-15 10:44:16 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed
2018-08-15 10:44:16 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:44:16 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:44:16 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:16 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:16 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:16 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:16 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:16 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:16 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-08-15 10:44:16 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-08-15 10:44:16 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest2-1534322650150-0
2018-08-15 10:44:16 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:44:16 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:44:16 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:44:16 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:44:16 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:44:16 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:44:16 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:44:16 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:44:16 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:44:16 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:44:16 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:16 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:16 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:16 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:44:16 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:16 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:16 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:16 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:44:16 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:44:16 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:44:16 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:44:16 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:44:16 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:44:16 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:44:16 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:44:16 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:16 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:16 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:16 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:44:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:44:17 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:17 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:17 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:17 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:44:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:44:17 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:44:17 INFO  LogManager:72 - Shutting down.
2018-08-15 10:44:17 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:44:17 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:44:17 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:44:17 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:44:17 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-08-15 10:44:17 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:35241 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:35241 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-08-15 10:44:17 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:44:17 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:44:17 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:44:17 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:44:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:44:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:44:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-08-15 10:44:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-08-15 10:44:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:44:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:44:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:44:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:44:17 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:44:17 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009944e1670000
2018-08-15 10:44:17 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:52052 which had sessionid 0x1009944e1670000
2018-08-15 10:44:17 INFO  ZooKeeper:687 - Session: 0x1009944e1670000 closed
2018-08-15 10:44:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:44:17 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009944e1670000
2018-08-15 10:44:17 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:44:17 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 2
2018-08-15 10:44:17 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2)
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set(MultiBrokerTest2-1534322650150)
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: MultiBrokerTest2-1534322650150
2018-08-15 10:44:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Invoking state change to OnlineReplica for replicas [Topic=MultiBrokerTest2-1534322650150,Partition=0,Replica=2],[Topic=MultiBrokerTest2-1534322650150,Partition=1,Replica=2]
2018-08-15 10:44:17 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:37892 (id: 2 rack: null) for sending state change requests
2018-08-15 10:44:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map([Topic=MultiBrokerTest2-1534322650150,Partition=0,Replica=2] -> OnlineReplica, [Topic=MultiBrokerTest2-1534322650150,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=MultiBrokerTest2-1534322650150,Partition=1,Replica=2] -> OnlineReplica, [Topic=MultiBrokerTest2-1534322650150,Partition=1,Replica=1] -> ReplicaDeletionIneligible)
2018-08-15 10:44:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map(MultiBrokerTest2-1534322650150-0 -> OnlinePartition, MultiBrokerTest2-1534322650150-1 -> OnlinePartition)
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 2
2018-08-15 10:44:17 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 2 for partition MultiBrokerTest2-1534322650150-0 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-08-15 10:44:17 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 2 for partition MultiBrokerTest2-1534322650150-1 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-08-15 10:44:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:44:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1009944e9930000 type:delete cxid:0x43 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:44:17 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-08-15 10:44:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:44:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:44:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:44:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:44:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:44:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:44:18 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:44:18 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:44:18 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:44:18 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:44:18 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:44:18 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-08-15 10:44:18 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-08-15 10:44:18 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:44:18 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1534322650150-0
2018-08-15 10:44:18 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-0 besides shutting down brokers 2
2018-08-15 10:44:18 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1534322650150-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:44:18 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:18 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-1 besides shutting down brokers 2
2018-08-15 10:44:18 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1534322650150-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:44:18 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: MultiBrokerTest2-1534322650150-0,MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:18 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-08-15 10:44:23 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:44:23 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:44:23 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1534322650150-0
2018-08-15 10:44:23 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-0 besides shutting down brokers 2
2018-08-15 10:44:23 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1534322650150-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:44:23 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:23 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-1 besides shutting down brokers 2
2018-08-15 10:44:23 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1534322650150-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:44:23 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: MultiBrokerTest2-1534322650150-0,MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:23 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-08-15 10:44:28 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:44:28 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-08-15 10:44:28 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1534322650150-0
2018-08-15 10:44:28 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-0 besides shutting down brokers 2
2018-08-15 10:44:28 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1534322650150-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:44:28 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:28 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-1 besides shutting down brokers 2
2018-08-15 10:44:28 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1534322650150-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1534322650150-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1534322650150-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-08-15 10:44:28 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: MultiBrokerTest2-1534322650150-0,MultiBrokerTest2-1534322650150-1
2018-08-15 10:44:28 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-08-15 10:44:33 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-08-15 10:44:33 WARN  KafkaServer:87 - [KafkaServer id=2] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-08-15 10:44:33 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-08-15 10:44:33 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-08-15 10:44:33 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-08-15 10:44:33 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-08-15 10:44:33 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-08-15 10:44:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-08-15 10:44:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-08-15 10:44:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-08-15 10:44:33 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-08-15 10:44:33 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-08-15 10:44:33 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-08-15 10:44:33 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-08-15 10:44:33 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-08-15 10:44:33 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-08-15 10:44:33 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-08-15 10:44:33 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-08-15 10:44:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-08-15 10:44:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-08-15 10:44:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-08-15 10:44:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-08-15 10:44:34 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-08-15 10:44:34 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-08-15 10:44:34 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:44:34 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:44:34 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:44:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-08-15 10:44:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-08-15 10:44:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-08-15 10:44:34 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-08-15 10:44:34 INFO  LogManager:72 - Shutting down.
2018-08-15 10:44:34 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:44:34 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:44:34 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:44:34 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:44:34 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:44:34 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:44:34 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:44:34 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:44:34 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-08-15 10:44:34 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-08-15 10:44:34 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-08-15 10:44:34 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-08-15 10:44:34 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-08-15 10:44:34 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-08-15 10:44:34 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:44:34 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009944e9930000
2018-08-15 10:44:34 INFO  ZooKeeper:687 - Session: 0x1009944e9930000 closed
2018-08-15 10:44:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:44:34 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:52026 which had sessionid 0x1009944e9930000
2018-08-15 10:44:34 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009944e9930000
2018-08-15 10:44:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:44:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:44:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:44:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:44:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:44:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:44:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:44:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:44:36 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-08-15 10:44:36 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-08-15 10:44:36 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-08-15 10:44:36 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:36 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:36 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:36 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:36 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:36 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:36 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:36 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:36 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[ERROR] Tests run: 10, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 170.478 s <<< FAILURE! - in com.salesforce.kafka.test.KafkaTestClusterTest
[ERROR] testRestartingCluster  Time elapsed: 60.245 s
[ERROR] testConsumingFromMultiBrokerClusterWhenBrokerIsStopped  Time elapsed: 34.668 s  <<< FAILURE!
org.opentest4j.AssertionFailedError: Found all records in kafka. ==> expected: <4> but was: <3>
	at com.salesforce.kafka.test.KafkaTestClusterTest.testConsumingFromMultiBrokerClusterWhenBrokerIsStopped(KafkaTestClusterTest.java:316)

[ERROR] testGetKafkaConnectString  Time elapsed: 14.312 s
[ERROR] testMultipleNodesInBroker  Time elapsed: 9.069 s
[ERROR] testGetKafkaBrokersBeforeClusterHasStarted  Time elapsed: 0.001 s
[ERROR] testGetKafkaBrokers  Time elapsed: 13.402 s
[ERROR] testGetKafkaBrokerById  Time elapsed: 12.596 s
[ERROR] testGetKafkaBrokerByIdBeforeClusterStarted  Time elapsed: 0.002 s
[ERROR] testGetKafkaConnectStringBeforeClusterIsStarted  Time elapsed: 0.001 s
[ERROR] testCreateTopicAcrossMultipleBrokers  Time elapsed: 26.177 s
[INFO] Running com.salesforce.kafka.test.KafkaBrokerTest
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.582 s - in com.salesforce.kafka.test.KafkaBrokerTest
[INFO] testStart  Time elapsed: 0.576 s
[INFO] testStop  Time elapsed: 0.001 s
[INFO] testGetConnectString  Time elapsed: 0.001 s
[INFO] testGetBrokerId  Time elapsed: 0 s
[INFO] Running com.salesforce.kafka.test.KafkaBrokersTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 s - in com.salesforce.kafka.test.KafkaBrokersTest
[INFO] testSize  Time elapsed: 0 s
[INFO] testGetBrokerById  Time elapsed: 0.001 s
[INFO] testAsList  Time elapsed: 0.002 s
[INFO] Running com.salesforce.kafka.test.ZookeeperTestServerTest
2018-08-15 10:44:36 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:36 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:36 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:36 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:36 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:36 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:36 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:36 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40652
2018-08-15 10:44:37 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40652 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$208/555943503@4f6b687e
2018-08-15 10:44:37 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40652. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:37 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40652, initiating session
2018-08-15 10:44:37 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:38828
2018-08-15 10:44:37 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:38828
2018-08-15 10:44:37 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:44:37 INFO  ZooKeeperServer:693 - Established session 0x100994546150000 with negotiated timeout 6000 for client /127.0.0.1:38828
2018-08-15 10:44:37 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40652, sessionid = 0x100994546150000, negotiated timeout = 6000
2018-08-15 10:44:38 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994546150000
2018-08-15 10:44:38 INFO  ZooKeeper:687 - Session: 0x100994546150000 closed
2018-08-15 10:44:38 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:38 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:38828 which had sessionid 0x100994546150000
2018-08-15 10:44:38 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994546150000
2018-08-15 10:44:38 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:38 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:38 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:38 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:38 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:38 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:38 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:38 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:38 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:38 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:38 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:38 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:38 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:38 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40652
2018-08-15 10:44:38 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:38 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:39 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40652 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$208/555943503@28cb3a25
2018-08-15 10:44:39 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40652. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:39 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40652, initiating session
2018-08-15 10:44:39 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:38830
2018-08-15 10:44:39 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:38830
2018-08-15 10:44:39 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-08-15 10:44:39 INFO  ZooKeeperServer:693 - Established session 0x10099454a7a0000 with negotiated timeout 6000 for client /127.0.0.1:38830
2018-08-15 10:44:39 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40652, sessionid = 0x10099454a7a0000, negotiated timeout = 6000
2018-08-15 10:44:39 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10099454a7a0000
2018-08-15 10:44:39 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:38830 which had sessionid 0x10099454a7a0000
2018-08-15 10:44:39 INFO  ZooKeeper:687 - Session: 0x10099454a7a0000 closed
2018-08-15 10:44:39 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:39 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10099454a7a0000
2018-08-15 10:44:39 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:39 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:39 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:39 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:39 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:39 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:39 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:39 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:39 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:39 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:39 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:39 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:39 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:39 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:39 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:36328
2018-08-15 10:44:40 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:36328 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$208/555943503@5555ffcf
2018-08-15 10:44:40 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:36328. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:40 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:36328, initiating session
2018-08-15 10:44:40 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:39048
2018-08-15 10:44:40 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:39048
2018-08-15 10:44:40 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:44:40 INFO  ZooKeeperServer:693 - Established session 0x10099454ec70000 with negotiated timeout 6000 for client /127.0.0.1:39048
2018-08-15 10:44:40 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:36328, sessionid = 0x10099454ec70000, negotiated timeout = 6000
2018-08-15 10:44:40 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10099454ec70000
2018-08-15 10:44:40 INFO  ZooKeeper:687 - Session: 0x10099454ec70000 closed
2018-08-15 10:44:40 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10099454ec70000
2018-08-15 10:44:40 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:39048 which had sessionid 0x10099454ec70000
2018-08-15 10:44:40 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:40 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:40 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:40 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:40 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:40 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:40 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:40 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:40 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:41 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:41 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:42 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:42 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:42 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:42 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:42 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:42 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:42 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:36328
2018-08-15 10:44:43 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:36328 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$208/555943503@6cfd9a54
2018-08-15 10:44:43 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:36328. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:43 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:36328, initiating session
2018-08-15 10:44:43 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:39050
2018-08-15 10:44:43 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:39050
2018-08-15 10:44:43 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-08-15 10:44:43 INFO  ZooKeeperServer:693 - Established session 0x10099455aed0000 with negotiated timeout 6000 for client /127.0.0.1:39050
2018-08-15 10:44:43 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:36328, sessionid = 0x10099455aed0000, negotiated timeout = 6000
2018-08-15 10:44:43 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10099455aed0000
2018-08-15 10:44:43 INFO  ZooKeeper:687 - Session: 0x10099455aed0000 closed
2018-08-15 10:44:43 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:43 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10099455aed0000
2018-08-15 10:44:43 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:39050 which had sessionid 0x10099455aed0000
2018-08-15 10:44:43 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:43 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:43 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:43 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:43 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:43 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:43 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:43 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:43 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:43 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:43 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:43 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:43 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:43 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:43 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:33593
2018-08-15 10:44:44 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:33593 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$208/555943503@78c1372d
2018-08-15 10:44:44 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:33593. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:44 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:33593, initiating session
2018-08-15 10:44:44 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:37656
2018-08-15 10:44:44 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:37656
2018-08-15 10:44:44 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:44:44 INFO  ZooKeeperServer:693 - Established session 0x10099455f300000 with negotiated timeout 6000 for client /127.0.0.1:37656
2018-08-15 10:44:44 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:33593, sessionid = 0x10099455f300000, negotiated timeout = 6000
2018-08-15 10:44:44 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10099455f300000
2018-08-15 10:44:44 INFO  ZooKeeper:687 - Session: 0x10099455f300000 closed
2018-08-15 10:44:44 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:37656 which had sessionid 0x10099455f300000
2018-08-15 10:44:44 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10099455f300000
2018-08-15 10:44:44 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:44 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:44 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:44 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:44 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:44 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:44 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:44 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:44 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:44 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:44 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:44 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:44 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:44 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:33593
2018-08-15 10:44:44 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:44 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:45 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:33593 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$208/555943503@9aa2002
2018-08-15 10:44:45 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:33593. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:45 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:33593, initiating session
2018-08-15 10:44:45 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:37658
2018-08-15 10:44:45 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:37658
2018-08-15 10:44:45 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-08-15 10:44:45 INFO  ZooKeeperServer:693 - Established session 0x1009945637c0000 with negotiated timeout 6000 for client /127.0.0.1:37658
2018-08-15 10:44:45 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:33593, sessionid = 0x1009945637c0000, negotiated timeout = 6000
2018-08-15 10:44:45 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1009945637c0000
2018-08-15 10:44:45 INFO  ZooKeeper:687 - Session: 0x1009945637c0000 closed
2018-08-15 10:44:45 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:37658 which had sessionid 0x1009945637c0000
2018-08-15 10:44:45 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:45 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1009945637c0000
2018-08-15 10:44:45 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:45 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:45 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:45 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:45 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:45 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:45 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:45 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:45 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:45 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:45 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:45 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:45 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:45 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:45 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42982
2018-08-15 10:44:46 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42982 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$208/555943503@73fb1d7f
2018-08-15 10:44:46 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42982. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:46 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42982, initiating session
2018-08-15 10:44:46 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55456
2018-08-15 10:44:46 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:55456
2018-08-15 10:44:46 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:44:46 INFO  ZooKeeperServer:693 - Established session 0x100994567a60000 with negotiated timeout 6000 for client /127.0.0.1:55456
2018-08-15 10:44:46 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42982, sessionid = 0x100994567a60000, negotiated timeout = 6000
2018-08-15 10:44:46 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994567a60000
2018-08-15 10:44:46 INFO  ZooKeeper:687 - Session: 0x100994567a60000 closed
2018-08-15 10:44:46 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:46 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55456 which had sessionid 0x100994567a60000
2018-08-15 10:44:46 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994567a60000
2018-08-15 10:44:46 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:46 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:46 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:46 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:46 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:46 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:46 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:46 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:46 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:46 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:46 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:46 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:46 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:46 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:46 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:36665
2018-08-15 10:44:47 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:36665 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$208/555943503@73d4066e
2018-08-15 10:44:47 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:36665. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:47 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:36665, initiating session
2018-08-15 10:44:47 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59204
2018-08-15 10:44:47 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:59204
2018-08-15 10:44:47 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:44:47 INFO  ZooKeeperServer:693 - Established session 0x10099456bfe0000 with negotiated timeout 6000 for client /127.0.0.1:59204
2018-08-15 10:44:47 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:36665, sessionid = 0x10099456bfe0000, negotiated timeout = 6000
2018-08-15 10:44:47 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10099456bfe0000
2018-08-15 10:44:47 INFO  ZooKeeper:687 - Session: 0x10099456bfe0000 closed
2018-08-15 10:44:47 INFO  ClientCnxn:521 - EventThread shut down for session: 0x10099456bfe0000
2018-08-15 10:44:47 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:59204 which had sessionid 0x10099456bfe0000
2018-08-15 10:44:47 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:47 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:47 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:47 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:47 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:47 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:47 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:47 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:47 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:47 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:47 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:47 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:47 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:47 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:36665
2018-08-15 10:44:47 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:47 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:47 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:48 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:36665 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$208/555943503@25d2f66
2018-08-15 10:44:48 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:36665. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:48 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:36665, initiating session
2018-08-15 10:44:48 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59206
2018-08-15 10:44:48 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:59206
2018-08-15 10:44:48 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-08-15 10:44:48 INFO  ZooKeeperServer:693 - Established session 0x100994570570000 with negotiated timeout 6000 for client /127.0.0.1:59206
2018-08-15 10:44:48 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:36665, sessionid = 0x100994570570000, negotiated timeout = 6000
2018-08-15 10:44:48 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994570570000
2018-08-15 10:44:48 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:59206 which had sessionid 0x100994570570000
2018-08-15 10:44:48 INFO  ZooKeeper:687 - Session: 0x100994570570000 closed
2018-08-15 10:44:48 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:48 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994570570000
2018-08-15 10:44:48 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:48 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:48 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:48 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:48 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:48 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:48 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:48 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-08-15 10:44:48 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:48 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:48 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:48 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:48 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:48 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:48 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34549
2018-08-15 10:44:49 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:34549 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$208/555943503@5a2fa51f
2018-08-15 10:44:49 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34549. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:49 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34549, initiating session
2018-08-15 10:44:49 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:55690
2018-08-15 10:44:49 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:55690
2018-08-15 10:44:49 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:44:49 INFO  ZooKeeperServer:693 - Established session 0x100994574a40000 with negotiated timeout 6000 for client /127.0.0.1:55690
2018-08-15 10:44:49 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34549, sessionid = 0x100994574a40000, negotiated timeout = 6000
2018-08-15 10:44:49 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994574a40000
2018-08-15 10:44:49 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:55690 which had sessionid 0x100994574a40000
2018-08-15 10:44:49 INFO  ZooKeeper:687 - Session: 0x100994574a40000 closed
2018-08-15 10:44:49 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:44:49 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994574a40000
2018-08-15 10:44:49 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:44:49 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:44:49 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:44:49 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:44:49 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:44:49 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:44:49 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:44:49 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.035 s - in com.salesforce.kafka.test.ZookeeperTestServerTest
[INFO] testGetConnectStringBeforeStartingService  Time elapsed: 0 s
[INFO] testStart  Time elapsed: 2.227 s
[INFO] testStopAndStartPreservesData  Time elapsed: 4.2 s
[INFO] testRestartPreservesData  Time elapsed: 2.166 s
[INFO] testRestartCold  Time elapsed: 1.112 s
[INFO] testRestart  Time elapsed: 2.213 s
[INFO] testGetConnectString  Time elapsed: 1.114 s
[INFO] Running com.salesforce.kafka.test.kafka_1_0_x.StreamsBuilderSmokeTest
2018-08-15 10:44:49 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-08-15 10:44:49 INFO  ZooKeeperServerMain:98 - Starting server
2018-08-15 10:44:49 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-08-15 10:44:49 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-08-15 10:44:49 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-08-15 10:44:49 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-08-15 10:44:49 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:39530
2018-08-15 10:44:50 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:50 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-08-15 10:44:50 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:45710
	advertised.port = 45710
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:45710
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1534322690972-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 45710
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:39530
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-08-15 10:44:50 INFO  KafkaServer:72 - starting
2018-08-15 10:44:50 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:39530
2018-08-15 10:44:50 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:39530 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@71945bc0
2018-08-15 10:44:50 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-08-15 10:44:50 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-08-15 10:44:50 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:39530. Will not attempt to authenticate using SASL (unknown error)
2018-08-15 10:44:50 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:39530, initiating session
2018-08-15 10:44:50 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:42822
2018-08-15 10:44:50 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:42822
2018-08-15 10:44:50 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-08-15 10:44:51 INFO  ZooKeeperServer:693 - Established session 0x100994579010000 with negotiated timeout 30000 for client /127.0.0.1:42822
2018-08-15 10:44:51 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:39530, sessionid = 0x100994579010000, negotiated timeout = 30000
2018-08-15 10:44:51 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-08-15 10:44:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-08-15 10:44:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-08-15 10:44:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-08-15 10:44:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-08-15 10:44:51 INFO  KafkaServer:72 - Cluster ID = SR2B-20NRxOhE8G2-xOUbQ
2018-08-15 10:44:51 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322690972-0/meta.properties
2018-08-15 10:44:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-08-15 10:44:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-08-15 10:44:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-08-15 10:44:51 INFO  LogManager:72 - Loading logs.
2018-08-15 10:44:51 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-08-15 10:44:51 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-08-15 10:44:51 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-08-15 10:44:51 INFO  LogCleaner:72 - Starting the log cleaner
2018-08-15 10:44:51 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-08-15 10:44:51 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:45710.
2018-08-15 10:44:51 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-08-15 10:44:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-08-15 10:44:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-08-15 10:44:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-08-15 10:44:51 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-08-15 10:44:51 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-08-15 10:44:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-08-15 10:44:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-08-15 10:44:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-08-15 10:44:51 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-08-15 10:44:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-08-15 10:44:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-08-15 10:44:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-08-15 10:44:51 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-08-15 10:44:51 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-08-15 10:44:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-08-15 10:44:51 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-08-15 10:44:51 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-08-15 10:44:51 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-08-15 10:44:51 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-08-15 10:44:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-08-15 10:44:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x43 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-08-15 10:44:51 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-08-15 10:44:51 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,45710,ListenerName(PLAINTEXT),PLAINTEXT)
2018-08-15 10:44:51 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1534322690972-0/meta.properties
2018-08-15 10:44:51 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-08-15 10:44:51 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-08-15 10:44:51 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-08-15 10:44:51 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:45710 (id: 1 rack: null) for sending state change requests
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-08-15 10:44:51 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-08-15 10:44:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:delete cxid:0x4e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-08-15 10:44:51 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-08-15 10:44:51 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:51 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:51 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-08-15 10:44:51 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45710]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:44:51 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:51 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:51 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-08-15 10:44:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:setData cxid:0x50 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/stream-input-topic1534322689967 Error:KeeperErrorCode = NoNode for /config/topics/stream-input-topic1534322689967
2018-08-15 10:44:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x51 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:44:52 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-08-15 10:44:52 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(stream-input-topic1534322689967)], deleted topics: [Set()], new partition replica assignment [Map(stream-input-topic1534322689967-0 -> Vector(1))]
2018-08-15 10:44:52 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for stream-input-topic1534322689967-0
2018-08-15 10:44:52 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for stream-input-topic1534322689967-0
2018-08-15 10:44:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions stream-input-topic1534322689967-0
2018-08-15 10:44:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=stream-input-topic1534322689967,Partition=0,Replica=1]
2018-08-15 10:44:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions stream-input-topic1534322689967-0
2018-08-15 10:44:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x59 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-input-topic1534322689967/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/stream-input-topic1534322689967/partitions/0
2018-08-15 10:44:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x5a zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-input-topic1534322689967/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/stream-input-topic1534322689967/partitions
2018-08-15 10:44:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=stream-input-topic1534322689967,Partition=0,Replica=1]
2018-08-15 10:44:52 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions stream-input-topic1534322689967-0
2018-08-15 10:44:52 INFO  Log:72 - [Log partition=stream-input-topic1534322689967-0, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:52 INFO  Log:72 - [Log partition=stream-input-topic1534322689967-0, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:52 INFO  LogManager:72 - Created log for partition [stream-input-topic1534322689967,0] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:52 INFO  Partition:72 - [Partition stream-input-topic1534322689967-0 broker=1] No checkpointed highwatermark is found for partition stream-input-topic1534322689967-0
2018-08-15 10:44:52 INFO  Replica:72 - Replica loaded for partition stream-input-topic1534322689967-0 with initial high watermark 0
2018-08-15 10:44:52 INFO  Partition:72 - [Partition stream-input-topic1534322689967-0 broker=1] stream-input-topic1534322689967-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:52 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45710]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:44:52 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:52 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:setData cxid:0x60 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/stream-output-topic1534322689967 Error:KeeperErrorCode = NoNode for /config/topics/stream-output-topic1534322689967
2018-08-15 10:44:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x61 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:44:52 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-08-15 10:44:52 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(stream-output-topic1534322689967)], deleted topics: [Set()], new partition replica assignment [Map(stream-output-topic1534322689967-0 -> Vector(1))]
2018-08-15 10:44:52 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for stream-output-topic1534322689967-0
2018-08-15 10:44:52 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for stream-output-topic1534322689967-0
2018-08-15 10:44:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions stream-output-topic1534322689967-0
2018-08-15 10:44:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=stream-output-topic1534322689967,Partition=0,Replica=1]
2018-08-15 10:44:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions stream-output-topic1534322689967-0
2018-08-15 10:44:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x69 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-output-topic1534322689967/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/stream-output-topic1534322689967/partitions/0
2018-08-15 10:44:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x6a zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-output-topic1534322689967/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/stream-output-topic1534322689967/partitions
2018-08-15 10:44:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=stream-output-topic1534322689967,Partition=0,Replica=1]
2018-08-15 10:44:52 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions stream-output-topic1534322689967-0
2018-08-15 10:44:52 INFO  Log:72 - [Log partition=stream-output-topic1534322689967-0, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:52 INFO  Log:72 - [Log partition=stream-output-topic1534322689967-0, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:52 INFO  LogManager:72 - Created log for partition [stream-output-topic1534322689967,0] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:52 INFO  Partition:72 - [Partition stream-output-topic1534322689967-0 broker=1] No checkpointed highwatermark is found for partition stream-output-topic1534322689967-0
2018-08-15 10:44:52 INFO  Replica:72 - Replica loaded for partition stream-output-topic1534322689967-0 with initial high watermark 0
2018-08-15 10:44:52 INFO  Partition:72 - [Partition stream-output-topic1534322689967-0 broker=1] stream-output-topic1534322689967-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:53 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:45710]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-08-15 10:44:53 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:53 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:53 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: stream-input-topic1534322689967-0. Cache now contains 0 entries.
2018-08-15 10:44:53 INFO  KafkaTestUtils:126 - Produce completed
2018-08-15 10:44:53 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-08-15 10:44:53 INFO  StreamsConfig:238 - StreamsConfig values: 
	application.id = testStreamProcessor
	application.server = 
	bootstrap.servers = [127.0.0.1:45710]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	upgrade.from = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-08-15 10:44:53 INFO  StreamThread:336 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] Creating restore consumer client
2018-08-15 10:44:53 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:45710]
	check.crcs = true
	client.id = testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-08-15 10:44:53 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:53 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:53 INFO  StreamThread:336 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] Creating shared producer client
2018-08-15 10:44:53 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:45710]
	buffer.memory = 33554432
	client.id = testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-08-15 10:44:53 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:53 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:53 INFO  StreamThread:336 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] Creating consumer client
2018-08-15 10:44:53 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:45710]
	check.crcs = true
	client.id = testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testStreamProcessor
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-08-15 10:44:53 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:44:53 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:44:54 INFO  StreamThread:336 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] Starting
2018-08-15 10:44:54 INFO  StreamThread:346 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] State transition from CREATED to RUNNING
2018-08-15 10:44:54 INFO  KafkaStreams:336 - stream-client [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec]Started Streams client
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:setData cxid:0x73 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x74 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-08-15 10:44:54 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-08-15 10:44:54 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-08-15 10:44:54 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-08-15 10:44:54 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:44:54 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:44:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:44:54 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:44:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xb0 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xb1 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xb8 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xbe zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xc3 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xc9 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xcf zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xd5 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-08-15 10:44:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xdb zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xe1 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xe7 zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xed zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xf3 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xf7 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0xfd zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x103 zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x109 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x10e zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x114 zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-08-15 10:44:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x11a zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-08-15 10:44:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x120 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-08-15 10:44:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x126 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-08-15 10:44:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x12d zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-08-15 10:44:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x132 zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-08-15 10:44:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x138 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-08-15 10:44:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x13e zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-08-15 10:44:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x144 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-08-15 10:44:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x14a zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-08-15 10:44:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x150 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-08-15 10:44:56 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x156 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x15c zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x160 zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x166 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x16c zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x172 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x178 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x17d zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x183 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x189 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x18f zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-08-15 10:44:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x193 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-08-15 10:44:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x199 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-08-15 10:44:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x19f zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-08-15 10:44:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x1a5 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-08-15 10:44:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x1ab zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-08-15 10:44:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x1b1 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-08-15 10:44:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x1b7 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-08-15 10:44:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x1bd zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-08-15 10:44:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x1c3 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-08-15 10:44:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x1c8 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-08-15 10:44:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100994579010000 type:create cxid:0x1ce zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-08-15 10:44:58 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-08-15 10:44:59 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322690972-0] Loading producer state from offset 0 with message format version 2
2018-08-15 10:44:59 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1534322690972-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-08-15 10:44:59 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1534322690972-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-08-15 10:44:59 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-08-15 10:44:59 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-08-15 10:44:59 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-08-15 10:44:59 INFO  AbstractCoordinator:341 - [Consumer clientId=testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1-consumer, groupId=testStreamProcessor] Discovered group coordinator 127.0.0.1:45710 (id: 2147483646 rack: null)
2018-08-15 10:44:59 INFO  ConsumerCoordinator:341 - [Consumer clientId=testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1-consumer, groupId=testStreamProcessor] Revoking previously assigned partitions []
2018-08-15 10:44:59 INFO  StreamThread:346 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-08-15 10:44:59 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec]State transition from RUNNING to REBALANCING
2018-08-15 10:44:59 INFO  StreamThread:351 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-08-15 10:44:59 INFO  AbstractCoordinator:336 - [Consumer clientId=testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1-consumer, groupId=testStreamProcessor] (Re-)joining group
2018-08-15 10:44:59 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group testStreamProcessor with old generation 0 (__consumer_offsets-8)
2018-08-15 10:45:02 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Stabilized group testStreamProcessor generation 1 (__consumer_offsets-8)
2018-08-15 10:45:02 INFO  StreamPartitionAssignor:341 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1-consumer] Assigned tasks to clients as {9bcc5d56-b8cb-4012-824d-28534d0d1bec=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-08-15 10:45:02 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Assignment received from leader for group testStreamProcessor for generation 1
2018-08-15 10:45:02 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-8. Cache now contains 0 entries.
2018-08-15 10:45:02 INFO  AbstractCoordinator:341 - [Consumer clientId=testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1-consumer, groupId=testStreamProcessor] Successfully joined group with generation 1
2018-08-15 10:45:02 INFO  ConsumerCoordinator:341 - [Consumer clientId=testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1-consumer, groupId=testStreamProcessor] Setting newly assigned partitions [stream-input-topic1534322689967-0]
2018-08-15 10:45:02 INFO  StreamThread:346 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-08-15 10:45:02 INFO  StreamThread:351 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] partition assignment took 20 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-08-15 10:45:02 INFO  StreamThread:346 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-08-15 10:45:02 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec]State transition from REBALANCING to RUNNING
2018-08-15 10:45:02 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: stream-output-topic1534322689967-0. Cache now contains 0 entries.
2018-08-15 10:45:03 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec]State transition from RUNNING to PENDING_SHUTDOWN
2018-08-15 10:45:03 INFO  StreamThread:336 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] Informed to shut down
2018-08-15 10:45:03 INFO  StreamThread:346 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-08-15 10:45:03 INFO  StreamThread:336 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] Shutting down
2018-08-15 10:45:03 INFO  KafkaProducer:341 - [Producer clientId=testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-08-15 10:45:03 INFO  StreamThread:346 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-08-15 10:45:03 INFO  StreamThread:336 - stream-thread [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec-StreamThread-1] Shutdown complete
2018-08-15 10:45:03 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec]State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-08-15 10:45:03 INFO  KafkaStreams:336 - stream-client [testStreamProcessor-9bcc5d56-b8cb-4012-824d-28534d0d1bec]Streams client stopped completely
2018-08-15 10:45:03 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45710]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-08-15 10:45:03 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:45:03 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:45:03 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:45710]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-15 10:45:03 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-08-15 10:45:03 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-08-15 10:45:03 INFO  KafkaTestUtils:256 - Found 25 records in kafka
2018-08-15 10:45:05 INFO  KafkaTestUtils:256 - Found 0 records in kafka
2018-08-15 10:45:05 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:45710 (id: 2147483646 rack: null)
2018-08-15 10:45:05 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-08-15 10:45:05 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-08-15 10:45:05 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-08-15 10:45:05 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-08-15 10:45:05 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-08-15 10:45:05 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-08-15 10:45:05 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-08-15 10:45:05 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-08-15 10:45:05 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-08-15 10:45:05 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-08-15 10:45:05 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-08-15 10:45:05 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-08-15 10:45:05 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-08-15 10:45:05 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-08-15 10:45:05 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-08-15 10:45:05 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-08-15 10:45:05 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-08-15 10:45:05 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-08-15 10:45:05 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-08-15 10:45:05 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-08-15 10:45:05 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-08-15 10:45:05 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-08-15 10:45:05 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-08-15 10:45:05 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-08-15 10:45:05 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-08-15 10:45:05 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-08-15 10:45:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-08-15 10:45:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-08-15 10:45:06 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-08-15 10:45:06 INFO  LogManager:72 - Shutting down.
2018-08-15 10:45:06 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-08-15 10:45:06 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-08-15 10:45:06 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-08-15 10:45:06 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-08-15 10:45:06 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 2
2018-08-15 10:45:06 INFO  ProducerStateManager:72 - [ProducerStateManager partition=stream-output-topic1534322689967-0] Writing producer snapshot at offset 25
2018-08-15 10:45:06 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 1
2018-08-15 10:45:06 INFO  ProducerStateManager:72 - [ProducerStateManager partition=stream-input-topic1534322689967-0] Writing producer snapshot at offset 25
2018-08-15 10:45:06 INFO  LogManager:72 - Shutdown complete.
2018-08-15 10:45:06 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-08-15 10:45:06 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-08-15 10:45:06 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-08-15 10:45:06 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-08-15 10:45:06 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-08-15 10:45:06 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-08-15 10:45:06 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-08-15 10:45:06 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-08-15 10:45:06 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-08-15 10:45:06 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-08-15 10:45:06 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100994579010000
2018-08-15 10:45:06 INFO  ZooKeeper:687 - Session: 0x100994579010000 closed
2018-08-15 10:45:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-08-15 10:45:06 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:42822 which had sessionid 0x100994579010000
2018-08-15 10:45:06 INFO  ClientCnxn:521 - EventThread shut down for session: 0x100994579010000
2018-08-15 10:45:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-08-15 10:45:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-08-15 10:45:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-08-15 10:45:07 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-08-15 10:45:07 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-08-15 10:45:07 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-08-15 10:45:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-08-15 10:45:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-08-15 10:45:08 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-08-15 10:45:08 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-08-15 10:45:08 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-08-15 10:45:08 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-08-15 10:45:08 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-08-15 10:45:08 INFO  ZooKeeperServer:501 - shutting down
2018-08-15 10:45:08 INFO  SessionTrackerImpl:226 - Shutting down
2018-08-15 10:45:09 INFO  PrepRequestProcessor:769 - Shutting down
2018-08-15 10:45:09 INFO  SyncRequestProcessor:208 - Shutting down
2018-08-15 10:45:09 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-08-15 10:45:09 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-08-15 10:45:09 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.093 s - in com.salesforce.kafka.test.kafka_1_0_x.StreamsBuilderSmokeTest
[INFO] testStreamConsumer  Time elapsed: 19.093 s
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Failures: 
[ERROR]   KafkaTestClusterTest.testConsumingFromMultiBrokerClusterWhenBrokerIsStopped:316 Found all records in kafka. ==> expected: <4> but was: <3>
[ERROR]   KafkaTestServerTest.testExactlyOnceTransaction:104 Should not be empty! ==> expected: <false> but was: <true>
[INFO] 
[ERROR] Tests run: 31, Failures: 2, Errors: 0, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] kafka-junit ........................................ SUCCESS [  1.830 s]
[INFO] kafka-junit-core ................................... FAILURE [04:38 min]
[INFO] kafka-junit4 ....................................... SKIPPED
[INFO] kafka-junit5 ....................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 04:40 min
[INFO] Finished at: 2018-08-15T10:45:09+02:00
[INFO] Final Memory: 32M/509M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.22.0:test (default-test) on project kafka-junit-core: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/salesforce/kafka-junit/416262473/kafka-junit-core/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :kafka-junit-core
