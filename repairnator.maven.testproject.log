[INFO] Scanning for projects...
[INFO] Inspecting build with total of 4 modules...
[INFO] Installing Nexus Staging features:
[INFO]   ... total of 4 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] kafka-junit
[INFO] kafka-junit-core
[INFO] kafka-junit4
[INFO] kafka-junit5
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building kafka-junit 3.0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:checkstyle (checkstyle-validate) @ kafka-junit ---
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:check (checkstyle-validate) @ kafka-junit ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- license-maven-plugin:3.0:check (default) @ kafka-junit ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building kafka-junit-core 3.0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:checkstyle (checkstyle-validate) @ kafka-junit-core ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:check (checkstyle-validate) @ kafka-junit-core ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ kafka-junit-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/salesforce/kafka-junit/433224675/kafka-junit-core/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ kafka-junit-core ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- license-maven-plugin:3.0:check (default) @ kafka-junit-core ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ kafka-junit-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ kafka-junit-core ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.22.0:test (default-test) @ kafka-junit-core ---
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.pom (2 KB at 5.5 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon/1.0-beta-6/wagon-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon/1.0-beta-6/wagon-1.0-beta-6.pom (13 KB at 288.0 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.pom (4 KB at 88.2 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-providers/1.0-beta-6/wagon-providers-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-providers/1.0-beta-6/wagon-providers-1.0-beta-6.pom (3 KB at 58.9 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.pom (3 KB at 57.2 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.pom (390 B at 10.9 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.pom (704 B at 20.2 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.pom (8 KB at 204.9 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.pom (4 KB at 109.9 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.pom (4 KB at 100.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.pom (4 KB at 95.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-parent/1.5.0/jackrabbit-parent-1.5.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-parent/1.5.0/jackrabbit-parent-1.5.0.pom (25 KB at 604.6 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.pom (3 KB at 85.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-api/1.5.3/slf4j-api-1.5.3.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-api/1.5.3/slf4j-api-1.5.3.pom (3 KB at 83.3 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-parent/1.5.3/slf4j-parent-1.5.3.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-parent/1.5.3/slf4j-parent-1.5.3.pom (8 KB at 222.3 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.0/commons-httpclient-3.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.0/commons-httpclient-3.0.pom (8 KB at 224.0 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.pom (2 KB at 42.0 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.pom (2 KB at 54.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting/2.2.1/maven-reporting-2.2.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting/2.2.1/maven-reporting-2.2.1.pom (2 KB at 42.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.pom (2 KB at 45.2 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia/1.1/doxia-1.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia/1.1/doxia-1.1.pom (15 KB at 390.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.jar
[INFO] Downloading: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/nekohtml/1.9.6.2/nekohtml-1.9.6.2.jar (110 KB at 1496.5 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http/1.0-beta-6/wagon-http-1.0-beta-6.jar (11 KB at 122.2 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-http-shared/1.0-beta-6/wagon-http-shared-1.0-beta-6.jar (25 KB at 260.3 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/nekohtml/xercesMinimal/1.9.6.2/xercesMinimal-1.9.6.2.jar (39 KB at 366.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-provider-api/1.0-beta-6/wagon-provider-api-1.0-beta-6.jar (52 KB at 422.3 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.jar (30 KB at 612.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/wagon/wagon-webdav-jackrabbit/1.0-beta-6/wagon-webdav-jackrabbit-1.0-beta-6.jar (18 KB at 435.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/slf4j/slf4j-nop/1.5.3/slf4j-nop-1.5.3.jar (6 KB at 130.2 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/reporting/maven-reporting-api/2.2.1/maven-reporting-api-2.2.1.jar (10 KB at 273.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar (298 KB at 2461.6 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/doxia/doxia-logging-api/1.1/doxia-logging-api-1.1.jar (12 KB at 299.2 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-jcr-commons/1.5.0/jackrabbit-jcr-commons-1.5.0.jar (199 KB at 2041.3 KB/sec)
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/jackrabbit/jackrabbit-webdav/1.5.0/jackrabbit-webdav-1.5.0.jar (296 KB at 2242.3 KB/sec)
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running com.salesforce.kafka.test.KafkaTestClusterTest
log4j: reset attribute= "false".
log4j: Threshold ="null".
log4j: Level value for root is  [INFO].
log4j: root level set to INFO
log4j: Class name: [org.apache.log4j.ConsoleAppender]
log4j: Parsing layout of class: "org.apache.log4j.PatternLayout"
log4j: Setting property [conversionPattern] to [%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n].
log4j: Adding appender named [console] to category [root].
2018-09-26 02:49:48 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:49:48 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:zookeeper.version=3.4.12--1, built on 03/27/2018 04:49 GMT
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:host.name=cyclone1
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:java.version=1.8.0_121
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:java.vendor=Oracle Corporation
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:java.class.path=/root/workspace/salesforce/kafka-junit/433224675/kafka-junit-core/target/test-classes:/root/workspace/salesforce/kafka-junit/433224675/kafka-junit-core/target/classes:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/junit/jupiter/junit-jupiter-api/5.2.0/junit-jupiter-api-5.2.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apiguardian/apiguardian-api/1.0.0/apiguardian-api-1.0.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/opentest4j/opentest4j/1.1.0/opentest4j-1.1.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/junit/platform/junit-platform-commons/1.2.0/junit-platform-commons-1.2.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/mockito/mockito-core/2.18.3/mockito-core-2.18.3.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/net/bytebuddy/byte-buddy/1.8.5/byte-buddy-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/net/bytebuddy/byte-buddy-agent/1.8.5/byte-buddy-agent-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/zookeeper/zookeeper/3.4.12/zookeeper-3.4.12.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/jline/jline/0.9.94/jline-0.9.94.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/kafka/kafka-streams/1.0.2/kafka-streams-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/kafka/connect-json/1.0.2/connect-json-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/kafka/connect-api/1.0.2/connect-api-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/rocksdb/rocksdbjni/5.7.3/rocksdbjni-5.7.3.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/kafka/kafka_2.11/1.0.2/kafka_2.11-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/kafka/kafka-clients/1.0.2/kafka-clients-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/lz4/lz4-java/1.4/lz4-java-1.4.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/slf4j/slf4j-simple/1.7.25/slf4j-simple-1.7.25.jar:
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:java.io.tmpdir=/tmp
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:java.compiler=<NA>
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:os.name=Linux
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:os.arch=amd64
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:os.version=3.10.0-862.3.2.el7.x86_64
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:user.name=root
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:user.home=/root
2018-09-26 02:49:48 INFO  ZooKeeperServer:100 - Server environment:user.dir=/root/workspace/salesforce/kafka-junit/433224675/kafka-junit-core
2018-09-26 02:49:48 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:49:48 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:49:48 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:49:48 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:49:48 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:33944
2018-09-26 02:49:49 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:49:49 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:49:49 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:49:49 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:49:49 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:49:49 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:49:49 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:49:49 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:49:49 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:49:49 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:49:49 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:49:49 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:49:49 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:49:49 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:49:49 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:33944
2018-09-26 02:49:50 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:37227
	advertised.port = 37227
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:37227
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537922990421-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 37227
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:33944
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:49:50 INFO  KafkaServer:72 - starting
2018-09-26 02:49:50 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:33944
2018-09-26 02:49:50 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:zookeeper.version=3.4.12--1, built on 03/27/2018 04:49 GMT
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:host.name=cyclone1
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:java.version=1.8.0_121
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:java.vendor=Oracle Corporation
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:java.class.path=/root/workspace/salesforce/kafka-junit/433224675/kafka-junit-core/target/test-classes:/root/workspace/salesforce/kafka-junit/433224675/kafka-junit-core/target/classes:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/junit/jupiter/junit-jupiter-api/5.2.0/junit-jupiter-api-5.2.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apiguardian/apiguardian-api/1.0.0/apiguardian-api-1.0.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/opentest4j/opentest4j/1.1.0/opentest4j-1.1.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/junit/platform/junit-platform-commons/1.2.0/junit-platform-commons-1.2.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/mockito/mockito-core/2.18.3/mockito-core-2.18.3.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/net/bytebuddy/byte-buddy/1.8.5/byte-buddy-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/net/bytebuddy/byte-buddy-agent/1.8.5/byte-buddy-agent-1.8.5.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/zookeeper/zookeeper/3.4.12/zookeeper-3.4.12.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/jline/jline/0.9.94/jline-0.9.94.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/kafka/kafka-streams/1.0.2/kafka-streams-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/kafka/connect-json/1.0.2/connect-json-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/kafka/connect-api/1.0.2/connect-api-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/rocksdb/rocksdbjni/5.7.3/rocksdbjni-5.7.3.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/kafka/kafka_2.11/1.0.2/kafka_2.11-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/kafka/kafka-clients/1.0.2/kafka-clients-1.0.2.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/lz4/lz4-java/1.4/lz4-java-1.4.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/salesforce/kafka-junit/433224675/.m2/org/slf4j/slf4j-simple/1.7.25/slf4j-simple-1.7.25.jar:
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:java.io.tmpdir=/tmp
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:java.compiler=<NA>
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:os.name=Linux
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:os.arch=amd64
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:os.version=3.10.0-862.3.2.el7.x86_64
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:user.name=root
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:user.home=/root
2018-09-26 02:49:50 INFO  ZooKeeper:100 - Client environment:user.dir=/root/workspace/salesforce/kafka-junit/433224675/kafka-junit-core
2018-09-26 02:49:50 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:33944 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@2b30a42c
2018-09-26 02:49:50 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:49:50 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:33944. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:49:50 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34010
2018-09-26 02:49:50 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:33944, initiating session
2018-09-26 02:49:50 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:34010
2018-09-26 02:49:50 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:49:50 INFO  ZooKeeperServer:693 - Established session 0x1016fddaeb90000 with negotiated timeout 30000 for client /127.0.0.1:34010
2018-09-26 02:49:50 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:33944, sessionid = 0x1016fddaeb90000, negotiated timeout = 30000
2018-09-26 02:49:50 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:49:50 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:49:50 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:49:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:49:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:49:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:49:51 INFO  KafkaServer:72 - Cluster ID = 6KNS1dtgRlaTpBy5C1c6aA
2018-09-26 02:49:51 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537922990421-0/meta.properties
2018-09-26 02:49:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:49:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:49:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:49:51 INFO  LogManager:72 - Loading logs.
2018-09-26 02:49:51 INFO  LogManager:72 - Logs loading complete in 7 ms.
2018-09-26 02:49:52 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:49:52 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:49:52 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:49:52 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:49:52 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:37227.
2018-09-26 02:49:52 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:49:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:49:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:49:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:49:52 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:49:52 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:49:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:49:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:49:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:49:52 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:49:52 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:49:52 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:49:52 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:49:52 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 2 milliseconds.
2018-09-26 02:49:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:setData cxid:0x2a zxid:0x17 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:49:52 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:49:52 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:49:52 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:49:52 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set()
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:49:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:49:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:49:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:49:52 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:49:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:create cxid:0x4a zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:49:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:delete cxid:0x4b zxid:0x1b txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:49:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:create cxid:0x4c zxid:0x1c txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:49:52 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:49:52 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,37227,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:49:52 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537922990421-0/meta.properties
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 1, deleted brokers: , all live brokers: 1
2018-09-26 02:49:52 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:49:52 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 1
2018-09-26 02:49:52 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:49:52 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:37227 (id: 1 rack: null) for sending state change requests
2018-09-26 02:49:52 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:49:52 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:49:52 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:49:52 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:49:52 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34010 which had sessionid 0x1016fddaeb90000
2018-09-26 02:49:52 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:49:52 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fddaeb90000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:49:52 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:49:52 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:49:52 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:49:52 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:49:52 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:49:52 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:49:52 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:49:52 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:49:52 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:49:52 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:49:52 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:49:52 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:49:52 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:33944
2018-09-26 02:49:52 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:49:53 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:32816
	advertised.port = 32816
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:32816
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537922993819-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 32816
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:33944
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:49:53 INFO  KafkaServer:72 - starting
2018-09-26 02:49:53 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:33944
2018-09-26 02:49:53 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:33944 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@3f2ef586
2018-09-26 02:49:53 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:49:53 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:49:53 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:33944. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:49:53 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:33944, initiating session
2018-09-26 02:49:53 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34022
2018-09-26 02:49:53 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:34022
2018-09-26 02:49:53 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-09-26 02:49:53 INFO  ZooKeeperServer:693 - Established session 0x1016fddbbfe0000 with negotiated timeout 30000 for client /127.0.0.1:34022
2018-09-26 02:49:53 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:33944, sessionid = 0x1016fddbbfe0000, negotiated timeout = 30000
2018-09-26 02:49:53 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:49:53 INFO  KafkaServer:72 - Cluster ID = 6KNS1dtgRlaTpBy5C1c6aA
2018-09-26 02:49:53 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537922993819-0/meta.properties
2018-09-26 02:49:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:49:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:49:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:49:53 INFO  LogManager:72 - Loading logs.
2018-09-26 02:49:53 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 02:49:53 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:49:53 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:49:53 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:49:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:49:53 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:49:54 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:32816.
2018-09-26 02:49:54 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 02:49:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 02:49:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 02:49:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 02:49:54 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:49:54 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:49:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 02:49:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 02:49:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 02:49:54 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 02:49:54 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 02:49:54 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:49:54 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 02:49:54 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 02:49:54 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 02:49:54 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 02:49:54 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 02:49:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddbbfe0000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:49:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddbbfe0000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:49:54 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:49:54 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,32816,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:49:54 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537922993819-0/meta.properties
2018-09-26 02:49:54 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 02:49:54 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:49:54 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:49:54 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 02:49:54 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37227, 127.0.0.1:32816]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:49:54 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:49:54 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:49:54 INFO  KafkaTestCluster:260 - Found 1 of 1 brokers ready, continuing to wait for cluster to start.
2018-09-26 02:49:54 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37227, 127.0.0.1:32816]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:49:54 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:49:54 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:49:54 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37227, 127.0.0.1:32816]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:49:54 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:49:54 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:49:54 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:33944. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:49:54 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:33944, initiating session
2018-09-26 02:49:54 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34044
2018-09-26 02:49:54 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fddaeb90000 at /127.0.0.1:34044
2018-09-26 02:49:54 INFO  ZooKeeperServer:693 - Established session 0x1016fddaeb90000 with negotiated timeout 30000 for client /127.0.0.1:34044
2018-09-26 02:49:54 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:33944, sessionid = 0x1016fddaeb90000, negotiated timeout = 30000
2018-09-26 02:49:54 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:49:54 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 02:49:54 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 02:49:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 02:49:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:32816 (id: 2 rack: null) for sending state change requests
2018-09-26 02:49:54 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37227, 127.0.0.1:32816]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:49:54 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:49:54 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:49:55 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-09-26 02:49:55 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37227, 127.0.0.1:32816]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:49:55 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:49:55 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:49:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:setData cxid:0x59 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/config/topics/RestartClusterTest-1537922987994 Error:KeeperErrorCode = NoNode for /config/topics/RestartClusterTest-1537922987994
2018-09-26 02:49:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:create cxid:0x5a zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:49:55 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"1":[2,1],"0":[1,2]}}
2018-09-26 02:49:55 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(RestartClusterTest-1537922987994)], deleted topics: [Set()], new partition replica assignment [Map(RestartClusterTest-1537922987994-1 -> Vector(2, 1), RestartClusterTest-1537922987994-0 -> Vector(1, 2))]
2018-09-26 02:49:55 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:49:55 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:49:55 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:49:55 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=2],[Topic=RestartClusterTest-1537922987994,Partition=1,Replica=1],[Topic=RestartClusterTest-1537922987994,Partition=0,Replica=1],[Topic=RestartClusterTest-1537922987994,Partition=0,Replica=2]
2018-09-26 02:49:55 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:49:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:create cxid:0x65 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1537922987994/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/RestartClusterTest-1537922987994/partitions/1
2018-09-26 02:49:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:create cxid:0x66 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1537922987994/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/RestartClusterTest-1537922987994/partitions
2018-09-26 02:49:55 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddaeb90000 type:create cxid:0x6a zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/RestartClusterTest-1537922987994/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/RestartClusterTest-1537922987994/partitions/0
2018-09-26 02:49:55 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=2],[Topic=RestartClusterTest-1537922987994,Partition=1,Replica=1],[Topic=RestartClusterTest-1537922987994,Partition=0,Replica=1],[Topic=RestartClusterTest-1537922987994,Partition=0,Replica=2]
2018-09-26 02:49:55 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:49:55 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:49:55 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:49:55 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-1, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:49:55 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms
2018-09-26 02:49:55 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-1, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms
2018-09-26 02:49:55 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1537922987994,0] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:49:55 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1537922987994,1] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:49:55 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-1 broker=2] No checkpointed highwatermark is found for partition RestartClusterTest-1537922987994-1
2018-09-26 02:49:55 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-0 broker=1] No checkpointed highwatermark is found for partition RestartClusterTest-1537922987994-0
2018-09-26 02:49:55 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-1 with initial high watermark 0
2018-09-26 02:49:55 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-0 with initial high watermark 0
2018-09-26 02:49:55 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-0 with initial high watermark 0
2018-09-26 02:49:55 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-1 with initial high watermark 0
2018-09-26 02:49:55 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-0 broker=1] RestartClusterTest-1537922987994-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:49:55 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-1 broker=2] RestartClusterTest-1537922987994-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:49:55 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-0 with initial high watermark 0
2018-09-26 02:49:55 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-1 with initial high watermark 0
2018-09-26 02:49:55 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:49:55 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-1, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:49:55 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:49:55 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-1, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:49:55 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1537922987994,0] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:49:55 INFO  LogManager:72 - Created log for partition [RestartClusterTest-1537922987994,1] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:49:55 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-0 broker=2] No checkpointed highwatermark is found for partition RestartClusterTest-1537922987994-0
2018-09-26 02:49:55 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-1 broker=1] No checkpointed highwatermark is found for partition RestartClusterTest-1537922987994-1
2018-09-26 02:49:55 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-0 with initial high watermark 0
2018-09-26 02:49:55 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-1 with initial high watermark 0
2018-09-26 02:49:55 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:49:55 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:49:55 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-09-26 02:49:55 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting
2018-09-26 02:49:55 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([RestartClusterTest-1537922987994-0, initOffset 0 to broker BrokerEndPoint(1,127.0.0.1,37227)] )
2018-09-26 02:49:55 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([RestartClusterTest-1537922987994-1, initOffset 0 to broker BrokerEndPoint(2,127.0.0.1,32816)] )
2018-09-26 02:49:55 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in RestartClusterTest-1537922987994-1. High watermark 0 will be used for truncation.
2018-09-26 02:49:55 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in RestartClusterTest-1537922987994-0. High watermark 0 will be used for truncation.
2018-09-26 02:49:55 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-1, dir=/tmp/1537922990421-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-09-26 02:49:55 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922993819-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-09-26 02:49:55 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:37227, 127.0.0.1:32816]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 02:49:55 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:49:55 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:49:55 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1537922987994-0. Cache now contains 0 entries.
2018-09-26 02:49:56 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1537922987994-0. Cache now contains 0 entries.
2018-09-26 02:49:56 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 02:49:56 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:37227, 127.0.0.1:32816]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 02:49:56 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:49:56 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:49:56 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1537922987994-1. Cache now contains 0 entries.
2018-09-26 02:49:56 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: RestartClusterTest-1537922987994-1. Cache now contains 0 entries.
2018-09-26 02:49:56 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 02:49:56 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:49:56 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:49:56 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:49:56 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=1]
2018-09-26 02:49:56 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:49:56 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-09-26 02:49:56 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition RestartClusterTest-1537922987994-1 is {"leader":2,"leader_epoch":1,"isr":[2]}
2018-09-26 02:49:56 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:49:56 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:49:56 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-1 broker=2] RestartClusterTest-1537922987994-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-09-26 02:49:56 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 1 for partition RestartClusterTest-1537922987994-1 (last update controller epoch 1) since it is already the leader for the partition.
2018-09-26 02:49:56 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:49:56 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-0 broker=2] RestartClusterTest-1537922987994-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-09-26 02:49:56 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down
2018-09-26 02:49:56 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:49:56 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:49:56 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1 epoch 1 fails to send request (type=StopReplicaRequest, controllerId=1, controllerEpoch=1, deletePartitions=false, partitions=RestartClusterTest-1537922987994-1) to broker 127.0.0.1:37227 (id: 1 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:56 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:49:56 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed
2018-09-26 02:49:56 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:49:56 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped
2018-09-26 02:49:56 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:56 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:56 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:56 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:56 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:56 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-09-26 02:49:57 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-09-26 02:49:57 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:49:57 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:49:57 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:49:57 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:57 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:57 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:49:57 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:49:57 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:49:57 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:49:57 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:49:57 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:49:57 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:49:57 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:49:57 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:49:57 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:57 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:57 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:49:57 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:57 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:57 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:49:57 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:49:57 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:49:57 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:49:57 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:49:57 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:49:57 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:49:57 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:49:57 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:57 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:49:57 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:57 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:57 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:49:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:49:57 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:57 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:57 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:49:57 INFO  LogManager:72 - Shutting down.
2018-09-26 02:49:57 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:49:57 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:49:57 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:49:57 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:49:57 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537922987994-1] Writing producer snapshot at offset 2
2018-09-26 02:49:58 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537922987994-0] Writing producer snapshot at offset 2
2018-09-26 02:49:58 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:49:58 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:49:58 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:49:58 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:49:58 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:49:58 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:49:58 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:49:58 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:49:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 02:49:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 02:49:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:49:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:49:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:49:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:49:58 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:49:58 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fddaeb90000
2018-09-26 02:49:58 INFO  ZooKeeper:687 - Session: 0x1016fddaeb90000 closed
2018-09-26 02:49:58 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34044 which had sessionid 0x1016fddaeb90000
2018-09-26 02:49:58 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fddaeb90000
2018-09-26 02:49:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:49:58 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:49:58 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 2
2018-09-26 02:49:58 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2)
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set(RestartClusterTest-1537922987994)
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: RestartClusterTest-1537922987994
2018-09-26 02:49:58 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:32816 (id: 2 rack: null) for sending state change requests
2018-09-26 02:49:58 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=2],[Topic=RestartClusterTest-1537922987994,Partition=0,Replica=2]
2018-09-26 02:49:58 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map([Topic=RestartClusterTest-1537922987994,Partition=0,Replica=2] -> OnlineReplica, [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=2] -> OnlineReplica, [Topic=RestartClusterTest-1537922987994,Partition=0,Replica=1] -> ReplicaDeletionIneligible)
2018-09-26 02:49:58 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map(RestartClusterTest-1537922987994-1 -> OnlinePartition, RestartClusterTest-1537922987994-0 -> OnlinePartition)
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 2
2018-09-26 02:49:58 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 2 for partition RestartClusterTest-1537922987994-1 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-09-26 02:49:58 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 2 for partition RestartClusterTest-1537922987994-0 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-09-26 02:49:58 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:49:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fddbbfe0000 type:delete cxid:0x43 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:49:58 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-09-26 02:49:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:49:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:49:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:49:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:49:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:49:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:49:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:49:59 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:49:59 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:49:59 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:49:59 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:49:59 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 02:49:59 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 02:49:59 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:49:59 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:50:00 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
2018-09-26 02:50:00 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537922987994-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:50:00 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:00 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
2018-09-26 02:50:00 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537922987994-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:50:00 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:50:00 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 02:50:05 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:50:05 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:50:05 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:50:05 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
2018-09-26 02:50:05 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537922987994-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:50:05 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:05 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
2018-09-26 02:50:05 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537922987994-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:50:05 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:50:05 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 02:50:10 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:50:10 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:50:10 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:50:10 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
2018-09-26 02:50:10 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537922987994-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:50:10 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:10 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
2018-09-26 02:50:10 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition RestartClusterTest-1537922987994-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:50:10 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:50:10 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 02:50:15 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:50:15 WARN  KafkaServer:87 - [KafkaServer id=2] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-09-26 02:50:15 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 02:50:15 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 02:50:15 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 02:50:15 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 02:50:15 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 02:50:15 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 02:50:15 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-09-26 02:50:15 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 02:50:15 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 02:50:15 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 02:50:15 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 02:50:15 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 02:50:15 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 02:50:15 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 02:50:15 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 02:50:15 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:50:15 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:50:15 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:50:15 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 02:50:15 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 02:50:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 02:50:15 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 02:50:15 INFO  LogManager:72 - Shutting down.
2018-09-26 02:50:15 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:50:15 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:50:15 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:50:15 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:50:15 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537922987994-1] Writing producer snapshot at offset 2
2018-09-26 02:50:15 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537922987994-0] Writing producer snapshot at offset 2
2018-09-26 02:50:15 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:50:15 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:50:15 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:50:15 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:50:15 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 02:50:15 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 02:50:15 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-09-26 02:50:15 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-09-26 02:50:15 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:50:15 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 02:50:15 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:50:15 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fddbbfe0000
2018-09-26 02:50:15 INFO  ZooKeeper:687 - Session: 0x1016fddbbfe0000 closed
2018-09-26 02:50:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:50:15 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34022 which had sessionid 0x1016fddbbfe0000
2018-09-26 02:50:15 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fddbbfe0000
2018-09-26 02:50:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:50:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:50:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:50:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:50:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:50:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:50:18 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:50:18 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:50:18 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 02:50:18 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 02:50:18 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 02:50:18 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:50:18 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:50:18 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:50:18 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:50:18 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:50:18 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:50:18 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:50:18 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:50:18 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:50:18 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:50:18 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:50:18 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:50:18 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:50:18 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:50:18 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:50:18 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:33944
2018-09-26 02:50:19 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:50:19 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:50:19 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:50:19 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:50:19 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:50:19 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:50:19 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:50:19 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:50:19 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:50:19 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:50:19 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:50:19 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:50:19 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:50:19 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:50:19 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:33944
2018-09-26 02:50:20 INFO  KafkaServer:72 - [KafkaServer id=1] starting
2018-09-26 02:50:20 INFO  KafkaServer:72 - [KafkaServer id=1] Connecting to zookeeper on 127.0.0.1:33944
2018-09-26 02:50:20 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:33944 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@6d6bc158
2018-09-26 02:50:20 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:50:20 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:50:20 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:33944. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:50:20 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:33944, initiating session
2018-09-26 02:50:20 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34188
2018-09-26 02:50:20 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:34188
2018-09-26 02:50:20 INFO  FileTxnLog:213 - Creating new log file: log.36
2018-09-26 02:50:20 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:50:20 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:50:21 INFO  ZooKeeperServer:693 - Established session 0x1016fde25ee0000 with negotiated timeout 30000 for client /127.0.0.1:34188
2018-09-26 02:50:21 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:33944, sessionid = 0x1016fde25ee0000, negotiated timeout = 30000
2018-09-26 02:50:21 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:50:21 INFO  KafkaServer:72 - [KafkaServer id=1] Cluster ID = 6KNS1dtgRlaTpBy5C1c6aA
2018-09-26 02:50:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:50:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:50:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:50:21 INFO  LogManager:72 - Loading logs.
2018-09-26 02:50:21 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922990421-0] Loading producer state from offset 2 with message format version 2
2018-09-26 02:50:21 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537922987994-0] Loading producer state from snapshot file '/tmp/1537922990421-0/RestartClusterTest-1537922987994-0/00000000000000000002.snapshot'
2018-09-26 02:50:21 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 15 ms
2018-09-26 02:50:21 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-1, dir=/tmp/1537922990421-0] Loading producer state from offset 2 with message format version 2
2018-09-26 02:50:21 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537922987994-1] Loading producer state from snapshot file '/tmp/1537922990421-0/RestartClusterTest-1537922987994-1/00000000000000000002.snapshot'
2018-09-26 02:50:21 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-1, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 2 ms
2018-09-26 02:50:21 INFO  LogManager:72 - Logs loading complete in 25 ms.
2018-09-26 02:50:21 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:50:21 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:50:21 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:50:21 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:50:21 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:37227.
2018-09-26 02:50:21 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:50:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:50:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:50:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:50:21 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:50:21 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:50:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:50:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:50:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:50:21 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:50:21 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:50:21 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:50:21 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:50:21 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:50:21 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Initialized controller epoch to 2 and zk version 1
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 3
2018-09-26 02:50:21 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:50:21 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:50:21 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set()
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set(RestartClusterTest-1537922987994)
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: RestartClusterTest-1537922987994
2018-09-26 02:50:21 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map([Topic=RestartClusterTest-1537922987994,Partition=0,Replica=2] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=2] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537922987994,Partition=0,Replica=1] -> ReplicaDeletionIneligible)
2018-09-26 02:50:21 ERROR logger:107 - [Controller id=1 epoch=3] Initiated state change for partition RestartClusterTest-1537922987994-1 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition RestartClusterTest-1537922987994-1 is alive. Live brokers are: [Set()], ISR brokers are: [2]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:21 ERROR logger:107 - [Controller id=1 epoch=3] Initiated state change for partition RestartClusterTest-1537922987994-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition RestartClusterTest-1537922987994-0 is alive. Live brokers are: [Set()], ISR brokers are: [2]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:21 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map(RestartClusterTest-1537922987994-1 -> OfflinePartition, RestartClusterTest-1537922987994-0 -> OfflinePartition)
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 3
2018-09-26 02:50:21 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:50:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x3f zxid:0x3a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:50:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x40 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:50:21 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:50:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:delete cxid:0x42 zxid:0x3d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:50:21 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:50:21 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,37227,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:50:21 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:50:21 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:50:21 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:50:21 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:50:21 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:50:21 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34188 which had sessionid 0x1016fde25ee0000
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 1, deleted brokers: , all live brokers: 1
2018-09-26 02:50:21 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fde25ee0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:50:21 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:50:21 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:50:21 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:50:21 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:50:21 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:50:21 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:50:21 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:50:21 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:50:21 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 1
2018-09-26 02:50:21 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:50:21 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=1],[Topic=RestartClusterTest-1537922987994,Partition=0,Replica=1]
2018-09-26 02:50:21 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:50:21 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:37227 (id: 1 rack: null) for sending state change requests
2018-09-26 02:50:21 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:50:21 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:50:21 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:50:21 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:50:21 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:33944
2018-09-26 02:50:21 ERROR logger:101 - [Broker id=1] Received LeaderAndIsrRequest with correlation id 1 from controller 1 epoch 3 for partition RestartClusterTest-1537922987994-0 (last update controller epoch 1) but cannot become follower since the new leader 2 is unavailable.
2018-09-26 02:50:21 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:50:21 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:50:21 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:50:22 INFO  KafkaServer:72 - [KafkaServer id=2] starting
2018-09-26 02:50:22 INFO  KafkaServer:72 - [KafkaServer id=2] Connecting to zookeeper on 127.0.0.1:33944
2018-09-26 02:50:22 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:33944 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@40bffbca
2018-09-26 02:50:22 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:50:22 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:50:22 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:33944. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:50:22 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:33944, initiating session
2018-09-26 02:50:22 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34196
2018-09-26 02:50:22 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:34196
2018-09-26 02:50:22 INFO  FileTxnLog:213 - Creating new log file: log.3e
2018-09-26 02:50:22 INFO  ZooKeeperServer:693 - Established session 0x1016fde2ba50000 with negotiated timeout 30000 for client /127.0.0.1:34196
2018-09-26 02:50:22 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:33944, sessionid = 0x1016fde2ba50000, negotiated timeout = 30000
2018-09-26 02:50:22 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:50:22 INFO  KafkaServer:72 - [KafkaServer id=2] Cluster ID = 6KNS1dtgRlaTpBy5C1c6aA
2018-09-26 02:50:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:50:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:50:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:50:22 INFO  LogManager:72 - Loading logs.
2018-09-26 02:50:22 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-1, dir=/tmp/1537922993819-0] Loading producer state from offset 2 with message format version 2
2018-09-26 02:50:22 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537922987994-1] Loading producer state from snapshot file '/tmp/1537922993819-0/RestartClusterTest-1537922987994-1/00000000000000000002.snapshot'
2018-09-26 02:50:22 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-1, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 3 ms
2018-09-26 02:50:22 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922993819-0] Loading producer state from offset 2 with message format version 2
2018-09-26 02:50:22 INFO  ProducerStateManager:72 - [ProducerStateManager partition=RestartClusterTest-1537922987994-0] Loading producer state from snapshot file '/tmp/1537922993819-0/RestartClusterTest-1537922987994-0/00000000000000000002.snapshot'
2018-09-26 02:50:22 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 3 ms
2018-09-26 02:50:22 INFO  LogManager:72 - Logs loading complete in 9 ms.
2018-09-26 02:50:22 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:50:22 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:50:22 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:50:22 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:50:22 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:32816.
2018-09-26 02:50:22 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 02:50:22 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 02:50:22 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 02:50:22 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 02:50:22 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:50:22 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:50:22 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 02:50:22 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 02:50:22 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 02:50:22 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 02:50:22 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 02:50:22 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:50:22 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4
2018-09-26 02:50:22 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 02:50:22 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 02:50:22 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 02:50:22 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 02:50:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde2ba50000 type:create cxid:0x1f zxid:0x40 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:50:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde2ba50000 type:create cxid:0x20 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:50:22 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:33944. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:50:22 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:33944, initiating session
2018-09-26 02:50:22 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34200
2018-09-26 02:50:22 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fde25ee0000 at /127.0.0.1:34200
2018-09-26 02:50:22 INFO  ZooKeeperServer:693 - Established session 0x1016fde25ee0000 with negotiated timeout 30000 for client /127.0.0.1:34200
2018-09-26 02:50:22 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:33944, sessionid = 0x1016fde25ee0000, negotiated timeout = 30000
2018-09-26 02:50:22 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:50:22 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:50:22 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,32816,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:50:22 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-0 with initial high watermark 2
2018-09-26 02:50:22 ERROR logger:101 - [Broker id=1] Received LeaderAndIsrRequest with correlation id 1 from controller 1 epoch 3 for partition RestartClusterTest-1537922987994-1 (last update controller epoch 1) but cannot become follower since the new leader 2 is unavailable.
2018-09-26 02:50:22 ERROR logger:107 - [Controller id=1 epoch=3] Initiated state change for partition RestartClusterTest-1537922987994-1 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition RestartClusterTest-1537922987994-1 is alive. Live brokers are: [Set(1)], ISR brokers are: [2]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.KafkaController.onBrokerStartup(KafkaController.scala:402)
	at kafka.controller.KafkaController$BrokerChange.process(KafkaController.scala:1226)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:22 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 02:50:22 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:50:22 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:50:22 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-1 with initial high watermark 1
2018-09-26 02:50:22 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 02:50:22 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions 
2018-09-26 02:50:22 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List()
2018-09-26 02:50:22 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37227, 127.0.0.1:32816]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:50:22 ERROR logger:107 - [Controller id=1 epoch=3] Initiated state change for partition RestartClusterTest-1537922987994-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition RestartClusterTest-1537922987994-0 is alive. Live brokers are: [Set(1)], ISR brokers are: [2]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.KafkaController.onBrokerStartup(KafkaController.scala:402)
	at kafka.controller.KafkaController$BrokerChange.process(KafkaController.scala:1226)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:22 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:50:22 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:50:22 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 02:50:22 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 02:50:22 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 02:50:22 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=2],[Topic=RestartClusterTest-1537922987994,Partition=0,Replica=2]
2018-09-26 02:50:22 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:32816 (id: 2 rack: null) for sending state change requests
2018-09-26 02:50:22 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537922987994-0,RestartClusterTest-1537922987994-1
2018-09-26 02:50:22 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":2,"leader_epoch":2,"isr":[2]} for offline partition RestartClusterTest-1537922987994-1
2018-09-26 02:50:22 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-0 with initial high watermark 2
2018-09-26 02:50:22 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-0 broker=2] RestartClusterTest-1537922987994-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1
2018-09-26 02:50:22 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-0 with initial high watermark 0
2018-09-26 02:50:22 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-1 with initial high watermark 2
2018-09-26 02:50:22 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-1 broker=2] RestartClusterTest-1537922987994-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1
2018-09-26 02:50:22 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-1 with initial high watermark 0
2018-09-26 02:50:22 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":2,"leader_epoch":2,"isr":[2]} for offline partition RestartClusterTest-1537922987994-0
2018-09-26 02:50:22 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537922987994-0,RestartClusterTest-1537922987994-1
2018-09-26 02:50:22 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-0 with initial high watermark 0
2018-09-26 02:50:22 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-0 broker=2] RestartClusterTest-1537922987994-0 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1
2018-09-26 02:50:22 INFO  Replica:72 - Replica loaded for partition RestartClusterTest-1537922987994-1 with initial high watermark 0
2018-09-26 02:50:22 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 3 for partition RestartClusterTest-1537922987994-0 (last update controller epoch 3) since it is already the leader for the partition.
2018-09-26 02:50:22 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:50:22 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-1 broker=2] RestartClusterTest-1537922987994-1 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1
2018-09-26 02:50:22 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 3 for partition RestartClusterTest-1537922987994-1 (last update controller epoch 3) since it is already the leader for the partition.
2018-09-26 02:50:22 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([RestartClusterTest-1537922987994-1, initOffset 2 to broker BrokerEndPoint(2,127.0.0.1,32816)] , [RestartClusterTest-1537922987994-0, initOffset 2 to broker BrokerEndPoint(2,127.0.0.1,32816)] )
2018-09-26 02:50:22 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-09-26 02:50:22 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 2 >= the follower's log end offset 2 in RestartClusterTest-1537922987994-1. No truncation needed.
2018-09-26 02:50:22 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-1, dir=/tmp/1537922990421-0] Truncating to 2 has no effect as the largest offset in the log is 1
2018-09-26 02:50:22 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 2 >= the follower's log end offset 2 in RestartClusterTest-1537922987994-0. No truncation needed.
2018-09-26 02:50:22 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922990421-0] Truncating to 2 has no effect as the largest offset in the log is 1
2018-09-26 02:50:22 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-09-26 02:50:22 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37227, 127.0.0.1:32816]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:50:22 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:50:22 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:50:22 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-1 broker=2] Expanding ISR from 2 to 2,1
2018-09-26 02:50:22 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-0 broker=2] Expanding ISR from 2 to 2,1
2018-09-26 02:50:22 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:37227, 127.0.0.1:32816]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 02:50:22 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:50:22 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:50:23 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:50:26 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:26 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:26 INFO  PreferredReplicaPartitionLeaderSelector:72 - [PreferredReplicaPartitionLeaderSelector]: Current leader 2 for partition RestartClusterTest-1537922987994-0 is not the preferred replica. Triggering preferred replica leader election
2018-09-26 02:50:26 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:26 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:26 INFO  KafkaController:72 - [Controller id=1] Partition RestartClusterTest-1537922987994-0 completed preferred replica leader election. New leader is 1
2018-09-26 02:50:26 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-0 broker=1] RestartClusterTest-1537922987994-0 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2
2018-09-26 02:50:26 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([RestartClusterTest-1537922987994-0, initOffset 2 to broker BrokerEndPoint(1,127.0.0.1,37227)] )
2018-09-26 02:50:26 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting
2018-09-26 02:50:26 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 2 >= the follower's log end offset 2 in RestartClusterTest-1537922987994-0. No truncation needed.
2018-09-26 02:50:26 INFO  Log:72 - [Log partition=RestartClusterTest-1537922987994-0, dir=/tmp/1537922993819-0] Truncating to 2 has no effect as the largest offset in the log is 1
2018-09-26 02:50:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:setData cxid:0x5e zxid:0x48 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 02:50:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x60 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:50:27 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[2],"34":[1],"12":[1],"8":[1],"19":[2],"23":[2],"4":[1],"40":[1],"15":[2],"11":[2],"9":[2],"44":[1],"33":[2],"22":[1],"26":[1],"37":[2],"13":[2],"46":[1],"24":[1],"35":[2],"16":[1],"5":[2],"10":[1],"48":[1],"21":[2],"43":[2],"32":[1],"49":[2],"6":[1],"36":[1],"1":[2],"39":[2],"17":[2],"25":[2],"14":[1],"47":[2],"31":[2],"42":[1],"0":[1],"20":[1],"27":[2],"2":[1],"38":[1],"18":[1],"30":[1],"7":[2],"29":[2],"41":[2],"3":[2],"28":[1]}}
2018-09-26 02:50:27 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 02:50:27 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(2), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(2), __consumer_offsets-29 -> Vector(2), __consumer_offsets-41 -> Vector(2), __consumer_offsets-39 -> Vector(2), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(2), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(2), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(2), __consumer_offsets-3 -> Vector(2), __consumer_offsets-5 -> Vector(2), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(2), __consumer_offsets-15 -> Vector(2), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(2), __consumer_offsets-13 -> Vector(2), __consumer_offsets-49 -> Vector(2), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(2), __consumer_offsets-31 -> Vector(2), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(2), __consumer_offsets-45 -> Vector(2), __consumer_offsets-27 -> Vector(2), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(2), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(2), __consumer_offsets-7 -> Vector(2), __consumer_offsets-9 -> Vector(2), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(2), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 02:50:27 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:50:27 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:50:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:50:27 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=2],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=2],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=2],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=2],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=2],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=2],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=2],[Topic=__consumer_offsets,Partition=15,Replica=2],[Topic=__consumer_offsets,Partition=7,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=2],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=2],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=2],[Topic=__consumer_offsets,Partition=49,Replica=2],[Topic=__consumer_offsets,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=2],[Topic=__consumer_offsets,Partition=21,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=2],[Topic=__consumer_offsets,Partition=5,Replica=2],[Topic=__consumer_offsets,Partition=41,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=2],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=2],[Topic=__consumer_offsets,Partition=24,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=2]
2018-09-26 02:50:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:50:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x9d zxid:0x4c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 02:50:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x9e zxid:0x4d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 02:50:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xa2 zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 02:50:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xa8 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 02:50:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xac zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 02:50:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xb1 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 02:50:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xb6 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 02:50:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xb9 zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 02:50:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xbe zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 02:50:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xc5 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 02:50:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xcc zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 02:50:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xd1 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 02:50:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xd4 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 02:50:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xd9 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 02:50:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xde zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 02:50:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xe3 zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 02:50:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xea zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 02:50:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xf1 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 02:50:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xf6 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 02:50:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0xfb zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 02:50:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x102 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 02:50:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x109 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 02:50:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x110 zxid:0x8e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 02:50:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x113 zxid:0x91 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 02:50:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x116 zxid:0x94 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 02:50:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x119 zxid:0x97 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 02:50:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x11c zxid:0x9a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 02:50:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x121 zxid:0x9d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 02:50:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x126 zxid:0xa0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 02:50:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x129 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 02:50:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x12e zxid:0xa6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 02:50:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x135 zxid:0xa9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 02:50:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x13c zxid:0xac txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 02:50:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x141 zxid:0xaf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 02:50:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x146 zxid:0xb2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 02:50:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x14b zxid:0xb5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 02:50:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x14e zxid:0xb8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 02:50:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x151 zxid:0xbb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 02:50:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x154 zxid:0xbe txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 02:50:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x157 zxid:0xc1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 02:50:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x15a zxid:0xc4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 02:50:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x160 zxid:0xc7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 02:50:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x167 zxid:0xca txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 02:50:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x16b zxid:0xcd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 02:50:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x171 zxid:0xd0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 02:50:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x178 zxid:0xd3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 02:50:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x17c zxid:0xd6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 02:50:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x17f zxid:0xd9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 02:50:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x182 zxid:0xdc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 02:50:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x185 zxid:0xdf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 02:50:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde25ee0000 type:create cxid:0x18b zxid:0xe2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 02:50:33 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=2],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=2],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=2],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=2],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=2],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=2],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=2],[Topic=__consumer_offsets,Partition=15,Replica=2],[Topic=__consumer_offsets,Partition=7,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=2],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=2],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=2],[Topic=__consumer_offsets,Partition=49,Replica=2],[Topic=__consumer_offsets,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=2],[Topic=__consumer_offsets,Partition=21,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=2],[Topic=__consumer_offsets,Partition=5,Replica=2],[Topic=__consumer_offsets,Partition=41,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=2],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=2],[Topic=__consumer_offsets,Partition=24,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=2]
2018-09-26 02:50:33 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-4,__consumer_offsets-46,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-18,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-48,__consumer_offsets-2,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-12,__consumer_offsets-26,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 02:50:33 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions __consumer_offsets-21,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-31,__consumer_offsets-3,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-17,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-43,__consumer_offsets-39,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-29
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=2] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=2] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=2] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=2] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=2] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=2] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=2] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=2] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:50:33 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 02:50:33 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 02:50:33 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=2] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 02:50:33 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=2] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=2] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=2] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=2] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=2] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=2] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=2] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537922993819-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537922993819-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537922993819-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 6 milliseconds.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537922990421-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:50:34 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537922990421-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:50:34 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537922990421-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 02:50:34 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds.
2018-09-26 02:50:34 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 02:50:34 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:37227 (id: 2147483646 rack: null)
2018-09-26 02:50:34 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-09-26 02:50:34 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:50:34 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:50:34 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:50:34 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:34 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=1]
2018-09-26 02:50:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:34 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-0 broker=2] RestartClusterTest-1537922987994-0 starts at Leader Epoch 4 from offset 2. Previous Leader Epoch was: 3
2018-09-26 02:50:34 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down
2018-09-26 02:50:34 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped
2018-09-26 02:50:34 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed
2018-09-26 02:50:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:50:34 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-09-26 02:50:34 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition RestartClusterTest-1537922987994-1 is {"leader":2,"leader_epoch":3,"isr":[2]}
2018-09-26 02:50:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:50:34 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:50:34 INFO  Partition:72 - [Partition RestartClusterTest-1537922987994-1 broker=2] RestartClusterTest-1537922987994-1 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2
2018-09-26 02:50:34 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 12 from controller 1 epoch 3 for partition RestartClusterTest-1537922987994-1 (last update controller epoch 3) since it is already the leader for the partition.
2018-09-26 02:50:34 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:50:34 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1 epoch 3 fails to send request (type=StopReplicaRequest, controllerId=1, controllerEpoch=3, deletePartitions=false, partitions=RestartClusterTest-1537922987994-1) to broker 127.0.0.1:37227 (id: 1 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:34 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:50:34 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:50:34 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-09-26 02:50:34 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-09-26 02:50:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:50:34 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:50:34 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:50:34 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:34 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:50:34 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:50:34 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 2000
2018-09-26 02:50:34 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:50:34 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:50:34 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:50:34 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:50:34 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:50:34 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:50:34 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:34 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:34 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:34 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:50:34 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:50:34 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:50:34 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:50:34 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:50:34 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:50:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:50:34 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:50:34 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:34 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:50:34 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:34 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:50:34 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:50:35 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:35 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:35 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:35 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:35 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:50:35 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:50:35 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:50:35 INFO  LogManager:72 - Shutting down.
2018-09-26 02:50:35 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:50:35 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:50:35 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:50:35 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:50:35 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:35 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:35 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:35 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:35 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:35 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:35 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:35 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:35 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:35 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:35 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:35 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:35 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:35 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:35 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:35 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:36 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:36 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:36 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:36 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:36 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:36 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:36 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:36 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:36 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2
2018-09-26 02:50:36 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:36 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:36 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:36 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:36 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:36 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:36 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:50:36 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:37227 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:37227 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:36 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:50:36 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:50:36 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:50:36 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:50:36 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:50:36 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:50:36 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 02:50:36 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 02:50:36 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:50:36 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:50:36 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:50:36 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:50:36 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:50:36 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:50:36 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fde25ee0000
2018-09-26 02:50:36 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34200 which had sessionid 0x1016fde25ee0000
2018-09-26 02:50:36 INFO  ZooKeeper:687 - Session: 0x1016fde25ee0000 closed
2018-09-26 02:50:36 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:50:36 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fde25ee0000
2018-09-26 02:50:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:50:36 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:50:36 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-09-26 02:50:36 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-09-26 02:50:36 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 3 and zk version 2
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 4
2018-09-26 02:50:37 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2)
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set(RestartClusterTest-1537922987994, __consumer_offsets)
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: __consumer_offsets,RestartClusterTest-1537922987994
2018-09-26 02:50:37 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:32816 (id: 2 rack: null) for sending state change requests
2018-09-26 02:50:37 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=17,Replica=2],[Topic=__consumer_offsets,Partition=39,Replica=2],[Topic=__consumer_offsets,Partition=23,Replica=2],[Topic=__consumer_offsets,Partition=13,Replica=2],[Topic=__consumer_offsets,Partition=33,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=2],[Topic=__consumer_offsets,Partition=11,Replica=2],[Topic=__consumer_offsets,Partition=27,Replica=2],[Topic=__consumer_offsets,Partition=15,Replica=2],[Topic=__consumer_offsets,Partition=7,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=2],[Topic=__consumer_offsets,Partition=35,Replica=2],[Topic=RestartClusterTest-1537922987994,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=45,Replica=2],[Topic=__consumer_offsets,Partition=49,Replica=2],[Topic=__consumer_offsets,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=2],[Topic=RestartClusterTest-1537922987994,Partition=0,Replica=2],[Topic=__consumer_offsets,Partition=31,Replica=2],[Topic=__consumer_offsets,Partition=21,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=2],[Topic=__consumer_offsets,Partition=5,Replica=2],[Topic=__consumer_offsets,Partition=41,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=2],[Topic=__consumer_offsets,Partition=29,Replica=2],[Topic=__consumer_offsets,Partition=9,Replica=2]
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-15 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-13 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-11 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-9 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map([Topic=__consumer_offsets,Partition=48,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=45,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=23,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537922987994,Partition=0,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=26,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=44,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=46,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=41,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=9,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> ReplicaDeletionIneligible, [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=2] -> OnlineReplica, [Topic=RestartClusterTest-1537922987994,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=32,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=2,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=3,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=2] -> OnlineReplica, [Topic=RestartClusterTest-1537922987994,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=7,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=47,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=39,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=22,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=38,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=16,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=8,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=36,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=33,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=24,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=31,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=29,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=14,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=18,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=17,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=2] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=2] -> OnlineReplica)
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-23 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-21 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-19 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition RestartClusterTest-1537922987994-1 since its associated leader epoch 3 is not higher than the current leader epoch 3
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-17 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-7 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-5 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-3 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-1 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-47 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-45 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-43 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-41 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-30 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-30 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-49 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition RestartClusterTest-1537922987994-0 since its associated leader epoch 4 is not higher than the current leader epoch 4
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-31 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-29 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-27 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-25 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-39 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-37 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-35 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 4 for partition __consumer_offsets-33 since its associated leader epoch 0 is not higher than the current leader epoch 0
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-10 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-10 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-14 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-14 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-40 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-40 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-18 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-18 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-26 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-26 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-0 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-24 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-24 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-20 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-20 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-22 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-22 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-12 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-12 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-8 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-8 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-48 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-48 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-6 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-6 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-28 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-28 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-4 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-4 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-44 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-44 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:50:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:50:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-42 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-42 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-34 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-34 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-46 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-46 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-32 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-32 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-36 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-36 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-38 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-38 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-2 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-2 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition __consumer_offsets-16 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-16 is alive. Live brokers are: [Set(2)], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Reelect$.process(KafkaController.scala:1610)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:50:37 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map(__consumer_offsets-19 -> OnlinePartition, __consumer_offsets-30 -> OfflinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-10 -> OfflinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-14 -> OfflinePartition, __consumer_offsets-40 -> OfflinePartition, __consumer_offsets-18 -> OfflinePartition, __consumer_offsets-26 -> OfflinePartition, __consumer_offsets-0 -> OfflinePartition, __consumer_offsets-24 -> OfflinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-20 -> OfflinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-22 -> OfflinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-12 -> OfflinePartition, __consumer_offsets-8 -> OfflinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-48 -> OfflinePartition, __consumer_offsets-13 -> OnlinePartition, __consumer_offsets-49 -> OnlinePartition, __consumer_offsets-6 -> OfflinePartition, __consumer_offsets-28 -> OfflinePartition, __consumer_offsets-4 -> OfflinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-44 -> OfflinePartition, __consumer_offsets-42 -> OfflinePartition, __consumer_offsets-34 -> OfflinePartition, __consumer_offsets-46 -> OfflinePartition, RestartClusterTest-1537922987994-1 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, RestartClusterTest-1537922987994-0 -> OnlinePartition, __consumer_offsets-32 -> OfflinePartition, __consumer_offsets-43 -> OnlinePartition, __consumer_offsets-36 -> OfflinePartition, __consumer_offsets-35 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-38 -> OfflinePartition, __consumer_offsets-1 -> OnlinePartition, __consumer_offsets-2 -> OfflinePartition, __consumer_offsets-16 -> OfflinePartition)
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 4
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-09-26 02:50:37 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:50:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fde2ba50000 type:delete cxid:0x13c zxid:0xeb txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:50:37 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-09-26 02:50:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:50:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:50:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:50:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:50:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:50:39 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:50:39 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:50:39 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:50:39 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 02:50:39 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 02:50:39 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:50:39 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:39 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
2018-09-26 02:50:39 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537922987994-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 02:50:39 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:50:39 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
2018-09-26 02:50:39 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537922987994-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-09-26 02:50:39 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:50:39 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 02:50:44 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:50:44 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:50:44 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:44 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
2018-09-26 02:50:44 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537922987994-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 02:50:44 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:50:44 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
2018-09-26 02:50:44 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537922987994-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-09-26 02:50:44 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:50:44 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 02:50:49 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:50:49 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:50:49 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-0
2018-09-26 02:50:49 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
2018-09-26 02:50:49 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537922987994-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-0 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 02:50:49 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions RestartClusterTest-1537922987994-1
2018-09-26 02:50:49 ERROR logger:101 - [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
2018-09-26 02:50:49 ERROR logger:107 - [Controller id=2 epoch=4] Initiated state change for partition RestartClusterTest-1537922987994-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=4] Encountered error while electing leader for partition RestartClusterTest-1537922987994-1 due to: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for RestartClusterTest-1537922987994-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 23 more
2018-09-26 02:50:49 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: RestartClusterTest-1537922987994-1,RestartClusterTest-1537922987994-0
2018-09-26 02:50:49 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 02:50:54 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:50:54 WARN  KafkaServer:87 - [KafkaServer id=2] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-09-26 02:50:54 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 02:50:54 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 02:50:54 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 02:50:54 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 02:50:54 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 02:50:54 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 02:50:54 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 3000
2018-09-26 02:50:54 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 02:50:54 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 02:50:54 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 02:50:54 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 02:50:54 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 02:50:54 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 02:50:54 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 02:50:54 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 02:50:54 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:50:54 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:50:54 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:50:54 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 02:50:54 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 02:50:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 02:50:54 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 02:50:54 INFO  LogManager:72 - Shutting down.
2018-09-26 02:50:54 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:50:54 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:50:54 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:50:54 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:50:54 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:50:54 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:50:54 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:50:54 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:50:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 02:50:54 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 02:50:54 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-09-26 02:50:54 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-09-26 02:50:54 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:50:54 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 02:50:54 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:50:54 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fde2ba50000
2018-09-26 02:50:54 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34196 which had sessionid 0x1016fde2ba50000
2018-09-26 02:50:54 INFO  ZooKeeper:687 - Session: 0x1016fde2ba50000 closed
2018-09-26 02:50:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:50:54 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fde2ba50000
2018-09-26 02:50:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:50:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:50:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:50:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:50:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:50:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:50:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:50:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:50:57 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 02:50:57 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 02:50:57 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 02:50:57 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:50:57 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:50:57 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:50:57 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:50:57 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:50:57 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:50:57 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:50:57 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:50:57 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:50:57 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:50:57 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:50:57 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:50:57 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:50:57 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:50:57 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:50:57 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46388
2018-09-26 02:50:58 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:50:58 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:50:58 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:50:58 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:50:58 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:50:58 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:50:58 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:50:58 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:50:58 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:50:58 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:50:58 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:50:58 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:50:58 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:50:58 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:50:58 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46388
2018-09-26 02:50:59 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:38827
	advertised.port = 38827
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:38827
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923059501-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 38827
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:46388
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:50:59 INFO  KafkaServer:72 - starting
2018-09-26 02:50:59 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:46388
2018-09-26 02:50:59 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46388 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@3a71c100
2018-09-26 02:50:59 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:50:59 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:50:59 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46388. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:50:59 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46388, initiating session
2018-09-26 02:50:59 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34380
2018-09-26 02:50:59 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:34380
2018-09-26 02:50:59 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:50:59 INFO  ZooKeeperServer:693 - Established session 0x1016fdebc920000 with negotiated timeout 30000 for client /127.0.0.1:34380
2018-09-26 02:50:59 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46388, sessionid = 0x1016fdebc920000, negotiated timeout = 30000
2018-09-26 02:50:59 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:50:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:50:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:50:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:50:59 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:50:59 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:51:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:51:00 INFO  KafkaServer:72 - Cluster ID = WfqWoV5FQOSwM0NMqkxHKg
2018-09-26 02:51:00 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923059501-0/meta.properties
2018-09-26 02:51:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:51:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:51:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:51:00 INFO  LogManager:72 - Loading logs.
2018-09-26 02:51:00 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:51:00 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:51:00 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:51:00 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:51:00 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:51:00 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:38827.
2018-09-26 02:51:00 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:51:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:51:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:51:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:51:00 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:51:00 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:51:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:51:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:51:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:51:00 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:51:00 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:51:00 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:51:00 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:51:00 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:51:00 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:51:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:51:00 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:51:00 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:51:00 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:51:00 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:51:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x45 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:51:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x46 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:51:00 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:00 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,38827,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:51:00 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923059501-0/meta.properties
2018-09-26 02:51:00 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:51:00 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:51:00 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:51:00 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:38827 (id: 1 rack: null) for sending state change requests
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:51:00 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:51:00 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:51:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:51:00 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:51:00 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:00 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:00 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:51:00 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:51:00 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34380 which had sessionid 0x1016fdebc920000
2018-09-26 02:51:00 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:51:00 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fdebc920000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:51:00 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:51:00 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:51:00 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:51:00 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:51:00 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:51:00 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:51:00 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:51:00 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:51:00 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:51:00 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:51:00 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:51:00 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:51:00 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46388
2018-09-26 02:51:00 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:51:00 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:51:01 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:39714
	advertised.port = 39714
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:39714
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923061681-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 39714
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:46388
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:51:01 INFO  KafkaServer:72 - starting
2018-09-26 02:51:01 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:46388
2018-09-26 02:51:01 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46388 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@1c4ee95c
2018-09-26 02:51:01 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:51:01 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:51:01 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46388. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:01 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46388, initiating session
2018-09-26 02:51:01 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34386
2018-09-26 02:51:01 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:34386
2018-09-26 02:51:01 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-09-26 02:51:01 INFO  ZooKeeperServer:693 - Established session 0x1016fdec5150000 with negotiated timeout 30000 for client /127.0.0.1:34386
2018-09-26 02:51:01 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46388, sessionid = 0x1016fdec5150000, negotiated timeout = 30000
2018-09-26 02:51:01 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:01 INFO  KafkaServer:72 - Cluster ID = WfqWoV5FQOSwM0NMqkxHKg
2018-09-26 02:51:01 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923061681-0/meta.properties
2018-09-26 02:51:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:51:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:51:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:51:01 INFO  LogManager:72 - Loading logs.
2018-09-26 02:51:01 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 02:51:01 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:51:01 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:51:01 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:51:01 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:51:01 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:39714.
2018-09-26 02:51:01 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 02:51:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 02:51:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 02:51:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 02:51:01 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:51:01 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:51:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 02:51:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 02:51:01 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 02:51:01 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 02:51:01 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 02:51:01 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:51:01 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46388. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:01 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34390
2018-09-26 02:51:01 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46388, initiating session
2018-09-26 02:51:01 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fdebc920000 at /127.0.0.1:34390
2018-09-26 02:51:01 INFO  ZooKeeperServer:693 - Established session 0x1016fdebc920000 with negotiated timeout 30000 for client /127.0.0.1:34390
2018-09-26 02:51:01 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46388, sessionid = 0x1016fdebc920000, negotiated timeout = 30000
2018-09-26 02:51:01 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:delete cxid:0x52 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:51:01 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 02:51:01 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:51:01 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 02:51:01 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 02:51:01 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 02:51:01 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-09-26 02:51:01 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 02:51:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdec5150000 type:create cxid:0x1d zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:51:01 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdec5150000 type:create cxid:0x1e zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:51:02 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:02 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,39714,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:51:02 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923061681-0/meta.properties
2018-09-26 02:51:02 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 02:51:02 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 02:51:02 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 02:51:02 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:39714 (id: 2 rack: null) for sending state change requests
2018-09-26 02:51:02 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 02:51:02 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:02 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:02 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 02:51:02 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:38827, 127.0.0.1:39714]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:51:02 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:02 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:02 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-09-26 02:51:02 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:38827, 127.0.0.1:39714]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:51:02 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:02 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:setData cxid:0x5b zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/topics/MultiBrokerTest3-1537923057488 Error:KeeperErrorCode = NoNode for /config/topics/MultiBrokerTest3-1537923057488
2018-09-26 02:51:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x5c zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:51:02 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"1":[1,2],"0":[2,1]}}
2018-09-26 02:51:02 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(MultiBrokerTest3-1537923057488)], deleted topics: [Set()], new partition replica assignment [Map(MultiBrokerTest3-1537923057488-1 -> Vector(1, 2), MultiBrokerTest3-1537923057488-0 -> Vector(2, 1))]
2018-09-26 02:51:02 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for MultiBrokerTest3-1537923057488-1,MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:02 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for MultiBrokerTest3-1537923057488-1,MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:02 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions MultiBrokerTest3-1537923057488-1,MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:02 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=MultiBrokerTest3-1537923057488,Partition=1,Replica=1],[Topic=MultiBrokerTest3-1537923057488,Partition=1,Replica=2],[Topic=MultiBrokerTest3-1537923057488,Partition=0,Replica=2],[Topic=MultiBrokerTest3-1537923057488,Partition=0,Replica=1]
2018-09-26 02:51:02 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537923057488-1,MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x67 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest3-1537923057488/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest3-1537923057488/partitions/1
2018-09-26 02:51:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x68 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest3-1537923057488/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest3-1537923057488/partitions
2018-09-26 02:51:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x6c zxid:0x2d txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest3-1537923057488/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest3-1537923057488/partitions/0
2018-09-26 02:51:02 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=MultiBrokerTest3-1537923057488,Partition=1,Replica=1],[Topic=MultiBrokerTest3-1537923057488,Partition=1,Replica=2],[Topic=MultiBrokerTest3-1537923057488,Partition=0,Replica=2],[Topic=MultiBrokerTest3-1537923057488,Partition=0,Replica=1]
2018-09-26 02:51:02 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1537923057488-1
2018-09-26 02:51:02 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:02 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537923057488-1, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:02 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537923057488-0, dir=/tmp/1537923061681-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:02 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537923057488-1, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:51:02 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537923057488-0, dir=/tmp/1537923061681-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:51:02 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1537923057488,1] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:02 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1537923057488,0] in /tmp/1537923061681-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:02 INFO  Partition:72 - [Partition MultiBrokerTest3-1537923057488-1 broker=1] No checkpointed highwatermark is found for partition MultiBrokerTest3-1537923057488-1
2018-09-26 02:51:02 INFO  Partition:72 - [Partition MultiBrokerTest3-1537923057488-0 broker=2] No checkpointed highwatermark is found for partition MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:02 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537923057488-1 with initial high watermark 0
2018-09-26 02:51:02 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537923057488-0 with initial high watermark 0
2018-09-26 02:51:02 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537923057488-1 with initial high watermark 0
2018-09-26 02:51:02 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537923057488-0 with initial high watermark 0
2018-09-26 02:51:02 INFO  Partition:72 - [Partition MultiBrokerTest3-1537923057488-1 broker=1] MultiBrokerTest3-1537923057488-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:02 INFO  Partition:72 - [Partition MultiBrokerTest3-1537923057488-0 broker=2] MultiBrokerTest3-1537923057488-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:02 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537923057488-0 with initial high watermark 0
2018-09-26 02:51:02 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537923057488-1 with initial high watermark 0
2018-09-26 02:51:02 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537923057488-0, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:02 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537923057488-1, dir=/tmp/1537923061681-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:02 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537923057488-0, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:51:02 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537923057488-1, dir=/tmp/1537923061681-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:51:02 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1537923057488,0] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:02 INFO  LogManager:72 - Created log for partition [MultiBrokerTest3-1537923057488,1] in /tmp/1537923061681-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:02 INFO  Partition:72 - [Partition MultiBrokerTest3-1537923057488-0 broker=1] No checkpointed highwatermark is found for partition MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:02 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537923057488-0 with initial high watermark 0
2018-09-26 02:51:02 INFO  Partition:72 - [Partition MultiBrokerTest3-1537923057488-1 broker=2] No checkpointed highwatermark is found for partition MultiBrokerTest3-1537923057488-1
2018-09-26 02:51:02 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:02 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest3-1537923057488-1 with initial high watermark 0
2018-09-26 02:51:02 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1537923057488-1
2018-09-26 02:51:02 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([MultiBrokerTest3-1537923057488-0, initOffset 0 to broker BrokerEndPoint(2,127.0.0.1,39714)] )
2018-09-26 02:51:02 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([MultiBrokerTest3-1537923057488-1, initOffset 0 to broker BrokerEndPoint(1,127.0.0.1,38827)] )
2018-09-26 02:51:02 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting
2018-09-26 02:51:02 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-09-26 02:51:02 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in MultiBrokerTest3-1537923057488-1. High watermark 0 will be used for truncation.
2018-09-26 02:51:02 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in MultiBrokerTest3-1537923057488-0. High watermark 0 will be used for truncation.
2018-09-26 02:51:02 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537923057488-1, dir=/tmp/1537923061681-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-09-26 02:51:02 INFO  Log:72 - [Log partition=MultiBrokerTest3-1537923057488-0, dir=/tmp/1537923059501-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-09-26 02:51:02 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:38827, 127.0.0.1:39714]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:51:02 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:02 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:02 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:38827, 127.0.0.1:39714]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 02:51:02 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:51:02 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:02 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:02 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1537923057488-0. Cache now contains 0 entries.
2018-09-26 02:51:03 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1537923057488-0. Cache now contains 0 entries.
2018-09-26 02:51:03 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 02:51:03 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:38827, 127.0.0.1:39714]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 02:51:03 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:03 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:03 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1537923057488-1. Cache now contains 0 entries.
2018-09-26 02:51:03 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: MultiBrokerTest3-1537923057488-1. Cache now contains 0 entries.
2018-09-26 02:51:03 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 02:51:03 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 02:51:03 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 02:51:03 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 2
2018-09-26 02:51:03 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=MultiBrokerTest3-1537923057488,Partition=1,Replica=2]
2018-09-26 02:51:03 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1537923057488-1
2018-09-26 02:51:03 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down
2018-09-26 02:51:03 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition MultiBrokerTest3-1537923057488-1 is {"leader":1,"leader_epoch":1,"isr":[1]}
2018-09-26 02:51:03 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:03 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1537923057488-1
2018-09-26 02:51:03 INFO  Partition:72 - [Partition MultiBrokerTest3-1537923057488-1 broker=1] MultiBrokerTest3-1537923057488-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-09-26 02:51:03 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 4 from controller 1 epoch 1 for partition MultiBrokerTest3-1537923057488-1 (last update controller epoch 1) since it is already the leader for the partition.
2018-09-26 02:51:03 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-09-26 02:51:03 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:03 INFO  Partition:72 - [Partition MultiBrokerTest3-1537923057488-0 broker=1] MultiBrokerTest3-1537923057488-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-09-26 02:51:03 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-09-26 02:51:03 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 02:51:03 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-09-26 02:51:03 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-09-26 02:51:03 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1 epoch 1 fails to send request (type=StopReplicaRequest, controllerId=1, controllerEpoch=1, deletePartitions=false, partitions=MultiBrokerTest3-1537923057488-1) to broker 127.0.0.1:39714 (id: 2 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:03 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 02:51:03 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 02:51:03 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:03 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:03 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:03 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:03 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:03 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:04 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:04 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:04 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped
2018-09-26 02:51:04 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed
2018-09-26 02:51:04 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest3-1537923057488-1
2018-09-26 02:51:04 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 02:51:04 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 02:51:04 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:04 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 02:51:04 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 02:51:04 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-09-26 02:51:04 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 02:51:04 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 02:51:04 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 02:51:04 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 02:51:04 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 02:51:04 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 02:51:04 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:04 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:04 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:04 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 02:51:04 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 02:51:04 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 02:51:04 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:51:04 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:51:04 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:51:04 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 02:51:04 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 02:51:04 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:04 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:04 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:04 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 02:51:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 02:51:04 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:04 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:04 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 02:51:04 INFO  LogManager:72 - Shutting down.
2018-09-26 02:51:04 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:51:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:51:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:51:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:51:04 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1537923057488-1] Writing producer snapshot at offset 2
2018-09-26 02:51:04 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1537923057488-0] Writing producer snapshot at offset 2
2018-09-26 02:51:04 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=2] Connection to node 2 could not be established. Broker may not be available.
2018-09-26 02:51:04 WARN  RequestSendThread:93 - [Controller-1-to-broker-2-send-thread]: Controller 1's connection to broker 127.0.0.1:39714 (id: 2 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:39714 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:51:04 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:51:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:51:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:51:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:51:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 02:51:04 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 02:51:04 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 02:51:04 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:51:04 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdec5150000
2018-09-26 02:51:04 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34386 which had sessionid 0x1016fdec5150000
2018-09-26 02:51:04 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdec5150000
2018-09-26 02:51:04 INFO  ZooKeeper:687 - Session: 0x1016fdec5150000 closed
2018-09-26 02:51:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:51:04 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: 2, all live brokers: 1
2018-09-26 02:51:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 02:51:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 02:51:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:51:04 INFO  KafkaController:72 - [Controller id=1] Broker failure callback for 2
2018-09-26 02:51:04 INFO  KafkaController:72 - [Controller id=1] Removed ArrayBuffer(2) from list of shutting down brokers.
2018-09-26 02:51:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OfflinePartition for partitions 
2018-09-26 02:51:04 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=MultiBrokerTest3-1537923057488,Partition=1,Replica=2],[Topic=MultiBrokerTest3-1537923057488,Partition=0,Replica=2]
2018-09-26 02:51:04 WARN  KafkaController:87 - [Controller id=1] Cannot remove replica 2 from ISR of partition MultiBrokerTest3-1537923057488-1 since it is not in the ISR. Leader = 1 ; ISR = List(1)
2018-09-26 02:51:04 WARN  KafkaController:87 - [Controller id=1] Cannot remove replica 2 from ISR of partition MultiBrokerTest3-1537923057488-0 since it is not in the ISR. Leader = 1 ; ISR = List(1)
2018-09-26 02:51:04 WARN  logger:87 - [Broker id=1] Ignoring LeaderAndIsr request from controller 1 with correlation id 8 epoch 1 for partition MultiBrokerTest3-1537923057488-1 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-09-26 02:51:04 WARN  ControllerChannelManager:87 - [Channel manager on controller 1]: Not sending request (type=StopReplicaRequest, controllerId=1, controllerEpoch=1, deletePartitions=false, partitions=MultiBrokerTest3-1537923057488-1,MultiBrokerTest3-1537923057488-0) to broker 2, since it is offline.
2018-09-26 02:51:04 WARN  logger:87 - [Broker id=1] Ignoring LeaderAndIsr request from controller 1 with correlation id 8 epoch 1 for partition MultiBrokerTest3-1537923057488-0 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-09-26 02:51:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:51:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:51:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:51:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:51:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:51:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:51:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:51:06 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 02:51:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:51:06 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 02:51:06 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 02:51:06 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:38827, 127.0.0.1:39714]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:51:06 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:06 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:06 WARN  NetworkClient:241 - [AdminClient clientId=test-consumer-id] Connection to node -2 could not be established. Broker may not be available.
2018-09-26 02:51:06 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:38827, 127.0.0.1:39714]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 02:51:06 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:06 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:06 WARN  NetworkClient:241 - [Consumer clientId=test-consumer-id, groupId=] Connection to node -2 could not be established. Broker may not be available.
2018-09-26 02:51:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:setData cxid:0x7f zxid:0x33 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 02:51:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x80 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:51:11 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-09-26 02:51:11 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 02:51:11 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 02:51:11 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:51:11 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:51:11 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:51:11 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:51:11 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:51:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xbc zxid:0x37 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 02:51:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xbd zxid:0x38 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 02:51:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xc6 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 02:51:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xcc zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 02:51:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xd2 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 02:51:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xd8 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 02:51:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xde zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 02:51:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xe4 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 02:51:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xea zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 02:51:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xf0 zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 02:51:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xf6 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 02:51:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0xfc zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 02:51:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x102 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 02:51:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x108 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 02:51:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x10e zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 02:51:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x114 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 02:51:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x11a zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 02:51:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x120 zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 02:51:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x126 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 02:51:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x12c zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 02:51:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x132 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 02:51:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x138 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 02:51:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x13e zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 02:51:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x144 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 02:51:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x14a zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 02:51:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x150 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 02:51:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x156 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 02:51:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x15c zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 02:51:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x162 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 02:51:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x168 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 02:51:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x16e zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 02:51:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x174 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 02:51:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x17a zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 02:51:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x181 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 02:51:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x187 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 02:51:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x18d zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 02:51:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x193 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 02:51:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x19b zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 02:51:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1a1 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 02:51:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1a7 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 02:51:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1ad zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 02:51:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1b3 zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 02:51:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1b9 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 02:51:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1bf zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 02:51:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1c5 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 02:51:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1cb zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 02:51:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1d1 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 02:51:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1d7 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 02:51:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1dd zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 02:51:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1e3 zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 02:51:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdebc920000 type:create cxid:0x1e9 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 02:51:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:51:17 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923059501-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:51:17 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923059501-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:51:17 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537923059501-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 02:51:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 02:51:17 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 02:51:17 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 02:51:17 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:38827 (id: 2147483646 rack: null)
2018-09-26 02:51:17 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-09-26 02:51:17 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:51:17 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:51:17 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:51:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537923057488-1
2018-09-26 02:51:17 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-1 besides shutting down brokers 1
2018-09-26 02:51:17 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537923057488-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-1 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-1 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 02:51:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:17 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-0 besides shutting down brokers 1
2018-09-26 02:51:17 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537923057488-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-0 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-0 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 02:51:17 INFO  KafkaServer:72 - [KafkaServer id=1] Remaining partitions to move: MultiBrokerTest3-1537923057488-1,MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:17 INFO  KafkaServer:72 - [KafkaServer id=1] Error code from controller: 0
2018-09-26 02:51:22 WARN  KafkaServer:87 - [KafkaServer id=1] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:51:22 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:51:22 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537923057488-1
2018-09-26 02:51:22 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-1 besides shutting down brokers 1
2018-09-26 02:51:22 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537923057488-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-1 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-1 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 02:51:22 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:22 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-0 besides shutting down brokers 1
2018-09-26 02:51:22 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537923057488-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-0 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-0 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 02:51:22 INFO  KafkaServer:72 - [KafkaServer id=1] Remaining partitions to move: MultiBrokerTest3-1537923057488-1,MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:22 INFO  KafkaServer:72 - [KafkaServer id=1] Error code from controller: 0
2018-09-26 02:51:27 WARN  KafkaServer:87 - [KafkaServer id=1] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:51:27 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:51:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537923057488-1
2018-09-26 02:51:27 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-1 besides shutting down brokers 1
2018-09-26 02:51:27 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537923057488-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-1 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-1 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-1 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 02:51:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:27 ERROR logger:101 - [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-0 besides shutting down brokers 1
2018-09-26 02:51:27 ERROR logger:107 - [Controller id=1 epoch=1] Initiated state change for partition MultiBrokerTest3-1537923057488-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=1 epoch=1] Encountered error while electing leader for partition MultiBrokerTest3-1537923057488-0 due to: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-0 besides shutting down brokers 1
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:316)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for MultiBrokerTest3-1537923057488-0 besides shutting down brokers 1
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 24 more
2018-09-26 02:51:27 INFO  KafkaServer:72 - [KafkaServer id=1] Remaining partitions to move: MultiBrokerTest3-1537923057488-1,MultiBrokerTest3-1537923057488-0
2018-09-26 02:51:27 INFO  KafkaServer:72 - [KafkaServer id=1] Error code from controller: 0
2018-09-26 02:51:32 WARN  KafkaServer:87 - [KafkaServer id=1] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:51:32 WARN  KafkaServer:87 - [KafkaServer id=1] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-09-26 02:51:32 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:51:32 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:51:32 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:51:32 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:51:32 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:51:32 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:51:32 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:51:32 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:51:32 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:51:32 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:51:32 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:51:32 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:51:32 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:51:32 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:51:32 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:51:32 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:51:32 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:51:32 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:51:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:51:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:51:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:51:33 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:51:33 INFO  LogManager:72 - Shutting down.
2018-09-26 02:51:33 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:51:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:51:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:51:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:51:33 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1537923057488-0] Writing producer snapshot at offset 2
2018-09-26 02:51:33 INFO  ProducerStateManager:72 - [ProducerStateManager partition=MultiBrokerTest3-1537923057488-1] Writing producer snapshot at offset 2
2018-09-26 02:51:33 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2
2018-09-26 02:51:33 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:51:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:51:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:51:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:51:33 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:51:33 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:51:33 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:51:33 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:51:33 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:51:33 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:51:33 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:51:33 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdebc920000
2018-09-26 02:51:33 INFO  ZooKeeper:687 - Session: 0x1016fdebc920000 closed
2018-09-26 02:51:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:51:33 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34390 which had sessionid 0x1016fdebc920000
2018-09-26 02:51:33 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdebc920000
2018-09-26 02:51:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:51:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:51:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:51:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:51:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:51:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:51:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:51:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:51:34 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:51:34 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:51:34 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:51:34 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 02:51:34 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:51:34 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:51:34 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:51:34 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:51:34 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:51:34 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:51:34 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:51:34 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:51:34 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:51:34 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:51:34 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:51:34 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:51:34 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:51:34 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:51:34 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:51:34 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40827
2018-09-26 02:51:35 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:51:35 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:51:35 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:51:35 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:51:35 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:51:35 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:51:35 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:51:35 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:51:35 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:51:35 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:51:35 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:51:35 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:51:35 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:51:35 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:51:35 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40827
2018-09-26 02:51:35 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:51:35 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:51:36 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:34954
	advertised.port = 34954
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:34954
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923096330-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 34954
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:40827
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:51:36 INFO  KafkaServer:72 - starting
2018-09-26 02:51:36 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:40827
2018-09-26 02:51:36 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40827 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@4c7a078
2018-09-26 02:51:36 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:51:36 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:51:36 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40827. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:36 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40827, initiating session
2018-09-26 02:51:36 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34346
2018-09-26 02:51:36 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:34346
2018-09-26 02:51:36 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:51:36 INFO  ZooKeeperServer:693 - Established session 0x1016fdf4c6f0000 with negotiated timeout 30000 for client /127.0.0.1:34346
2018-09-26 02:51:36 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40827, sessionid = 0x1016fdf4c6f0000, negotiated timeout = 30000
2018-09-26 02:51:36 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:36 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf4c6f0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:51:36 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf4c6f0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:51:36 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf4c6f0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:51:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf4c6f0000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:51:37 INFO  KafkaServer:72 - Cluster ID = yrAEpqGeSMWCCTTjgIVbVQ
2018-09-26 02:51:37 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923096330-0/meta.properties
2018-09-26 02:51:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:51:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:51:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:51:37 INFO  LogManager:72 - Loading logs.
2018-09-26 02:51:37 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 02:51:37 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:51:37 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:51:37 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:51:37 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:51:37 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:34954.
2018-09-26 02:51:37 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:51:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:51:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:51:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:51:37 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:51:37 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:51:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:51:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:51:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:51:37 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:51:37 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:51:37 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:51:37 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:51:37 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:51:37 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:51:37 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:51:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf4c6f0000 type:setData cxid:0x2d zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:51:37 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:51:37 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:51:37 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:51:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf4c6f0000 type:create cxid:0x41 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:51:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf4c6f0000 type:create cxid:0x42 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:51:37 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:37 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,34954,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:51:37 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923096330-0/meta.properties
2018-09-26 02:51:37 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:51:37 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:51:37 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:51:37 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:34954 (id: 1 rack: null) for sending state change requests
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:51:37 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:51:37 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:51:37 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf4c6f0000 type:delete cxid:0x4e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:51:37 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:51:37 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:37 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:37 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:51:37 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:51:37 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34346 which had sessionid 0x1016fdf4c6f0000
2018-09-26 02:51:37 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fdf4c6f0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:51:37 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:51:37 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:51:37 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:51:37 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:51:37 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:51:37 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:51:37 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:51:37 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:51:37 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:51:37 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:51:37 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:51:37 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:51:37 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:51:37 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40827
2018-09-26 02:51:37 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:51:37 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:51:38 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:46184
	advertised.port = 46184
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:46184
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923098565-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 46184
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:40827
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:51:38 INFO  KafkaServer:72 - starting
2018-09-26 02:51:38 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:40827
2018-09-26 02:51:38 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40827 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@1b1637e1
2018-09-26 02:51:38 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:51:38 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:51:38 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40827. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:38 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34350
2018-09-26 02:51:38 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40827, initiating session
2018-09-26 02:51:38 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:34350
2018-09-26 02:51:38 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-09-26 02:51:38 INFO  ZooKeeperServer:693 - Established session 0x1016fdf552a0000 with negotiated timeout 30000 for client /127.0.0.1:34350
2018-09-26 02:51:38 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40827, sessionid = 0x1016fdf552a0000, negotiated timeout = 30000
2018-09-26 02:51:38 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:38 INFO  KafkaServer:72 - Cluster ID = yrAEpqGeSMWCCTTjgIVbVQ
2018-09-26 02:51:38 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923098565-0/meta.properties
2018-09-26 02:51:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:51:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:51:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:51:38 INFO  LogManager:72 - Loading logs.
2018-09-26 02:51:38 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:51:38 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:51:38 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:51:38 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:51:38 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:51:38 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:46184.
2018-09-26 02:51:38 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 02:51:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 02:51:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 02:51:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 02:51:38 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:51:38 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:51:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 02:51:38 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 02:51:38 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 02:51:38 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:51:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 02:51:38 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 02:51:38 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 02:51:38 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 02:51:38 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 02:51:38 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 02:51:38 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 02:51:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf552a0000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:51:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf552a0000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:51:38 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:38 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,46184,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:51:38 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923098565-0/meta.properties
2018-09-26 02:51:38 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 02:51:38 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:38 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:38 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 02:51:38 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:51:38 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34350 which had sessionid 0x1016fdf552a0000
2018-09-26 02:51:38 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fdf552a0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:51:38 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:51:38 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:51:38 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:51:38 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:51:38 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:51:38 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:51:38 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:51:38 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:51:38 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:51:38 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:51:38 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:51:38 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:51:38 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:51:38 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40827
2018-09-26 02:51:38 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40827. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:38 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34352
2018-09-26 02:51:38 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40827, initiating session
2018-09-26 02:51:38 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fdf4c6f0000 at /127.0.0.1:34352
2018-09-26 02:51:38 INFO  ZooKeeperServer:693 - Established session 0x1016fdf4c6f0000 with negotiated timeout 30000 for client /127.0.0.1:34352
2018-09-26 02:51:38 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40827, sessionid = 0x1016fdf4c6f0000, negotiated timeout = 30000
2018-09-26 02:51:38 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:38 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf4c6f0000 type:delete cxid:0x50 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:51:38 INFO  FileTxnLog:213 - Creating new log file: log.23
2018-09-26 02:51:38 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:51:38 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 02:51:38 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 02:51:38 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 02:51:38 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:46184 (id: 2 rack: null) for sending state change requests
2018-09-26 02:51:38 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:51:38 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:51:38 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:51:39 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:41508
	advertised.port = 41508
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:41508
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923099898-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 41508
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:40827
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:51:39 INFO  KafkaServer:72 - starting
2018-09-26 02:51:39 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:40827
2018-09-26 02:51:39 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40827 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@718607eb
2018-09-26 02:51:39 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:51:39 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:51:39 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40827. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:39 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40827, initiating session
2018-09-26 02:51:39 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34356
2018-09-26 02:51:39 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:34356
2018-09-26 02:51:39 INFO  ZooKeeperServer:693 - Established session 0x1016fdf5a5e0000 with negotiated timeout 30000 for client /127.0.0.1:34356
2018-09-26 02:51:39 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40827, sessionid = 0x1016fdf5a5e0000, negotiated timeout = 30000
2018-09-26 02:51:39 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:39 INFO  KafkaServer:72 - Cluster ID = yrAEpqGeSMWCCTTjgIVbVQ
2018-09-26 02:51:39 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923099898-0/meta.properties
2018-09-26 02:51:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:51:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:51:39 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:51:39 INFO  LogManager:72 - Loading logs.
2018-09-26 02:51:39 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 02:51:40 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:51:40 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:51:40 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:51:40 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:51:40 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:41508.
2018-09-26 02:51:40 INFO  SocketServer:72 - [SocketServer brokerId=3] Started 1 acceptor threads
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Starting
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Starting
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Starting
2018-09-26 02:51:40 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:51:40 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Starting
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Starting
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Starting
2018-09-26 02:51:40 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Starting up.
2018-09-26 02:51:40 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Startup complete.
2018-09-26 02:51:40 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:51:40 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2018-09-26 02:51:40 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Starting up.
2018-09-26 02:51:40 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Startup complete.
2018-09-26 02:51:40 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Starting
2018-09-26 02:51:40 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/3 (is it secure? false)
2018-09-26 02:51:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf5a5e0000 type:create cxid:0x1d zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:51:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf5a5e0000 type:create cxid:0x1e zxid:0x27 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:51:40 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:40 INFO  ZkUtils:72 - Registered broker 3 at path /brokers/ids/3 with addresses: EndPoint(127.0.0.1,41508,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:51:40 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923099898-0/meta.properties
2018-09-26 02:51:40 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 3, deleted brokers: , all live brokers: 1,2,3
2018-09-26 02:51:40 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 3
2018-09-26 02:51:40 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Starting
2018-09-26 02:51:40 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Controller 1 connected to 127.0.0.1:41508 (id: 3 rack: null) for sending state change requests
2018-09-26 02:51:40 INFO  SocketServer:72 - [SocketServer brokerId=3] Started processors for 1 acceptors
2018-09-26 02:51:40 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:40 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:40 INFO  KafkaServer:72 - [KafkaServer id=3] started
2018-09-26 02:51:40 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:34954, 127.0.0.1:46184, 127.0.0.1:41508]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:51:40 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:40 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:40 INFO  KafkaTestCluster:253 - Found 3 brokers on-line, cluster is ready.
2018-09-26 02:51:40 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:34954, 127.0.0.1:46184, 127.0.0.1:41508]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:51:40 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40827. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:40 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40827, initiating session
2018-09-26 02:51:40 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34368
2018-09-26 02:51:40 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:40 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:40 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fdf552a0000 at /127.0.0.1:34368
2018-09-26 02:51:40 INFO  ZooKeeperServer:693 - Established session 0x1016fdf552a0000 with negotiated timeout 30000 for client /127.0.0.1:34368
2018-09-26 02:51:40 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40827, sessionid = 0x1016fdf552a0000, negotiated timeout = 30000
2018-09-26 02:51:40 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:40 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:51:40 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:51:40 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:51:40 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:51:40 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:51:40 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:51:40 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:51:40 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:51:40 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:51:40 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:51:40 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:51:40 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:51:40 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:51:40 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:51:40 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:51:40 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:51:40 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:51:40 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:51:40 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:51:40 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:51:40 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:51:40 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:51:40 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:51:40 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:51:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:51:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:51:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:51:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:51:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:51:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:51:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:51:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:51:41 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:51:41 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:51:41 INFO  LogManager:72 - Shutting down.
2018-09-26 02:51:41 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:51:41 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:51:41 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:51:41 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:51:41 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:51:41 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:51:41 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:51:41 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:51:41 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:51:41 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutting down
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutdown completed
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Stopped
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:51:41 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:51:41 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdf4c6f0000
2018-09-26 02:51:41 INFO  ZooKeeper:687 - Session: 0x1016fdf4c6f0000 closed
2018-09-26 02:51:41 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34352 which had sessionid 0x1016fdf4c6f0000
2018-09-26 02:51:41 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdf4c6f0000
2018-09-26 02:51:41 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:51:41 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:51:41 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:51:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf5a5e0000 type:create cxid:0x24 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2018-09-26 02:51:41 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-09-26 02:51:41 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: NODEEXISTS
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 2
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Starting
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2, 3)
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set()
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: 
2018-09-26 02:51:41 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map()
2018-09-26 02:51:41 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map()
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:46184 (id: 2 rack: null) for sending state change requests
2018-09-26 02:51:41 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Controller 2 connected to 127.0.0.1:41508 (id: 3 rack: null) for sending state change requests
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 2
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-09-26 02:51:41 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:51:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf552a0000 type:delete cxid:0x3f zxid:0x2d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:51:41 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-09-26 02:51:42 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:51:42 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:51:42 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:51:42 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:51:42 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:51:42 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:51:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:51:43 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:51:43 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:51:43 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:51:43 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:51:43 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 02:51:43 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 02:51:43 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:51:43 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-09-26 02:51:43 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 02:51:43 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 02:51:43 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 02:51:43 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 02:51:43 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 02:51:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 02:51:43 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-09-26 02:51:43 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 02:51:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 02:51:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 02:51:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 02:51:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 02:51:43 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 02:51:43 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 02:51:43 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 02:51:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:51:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:51:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:51:43 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 02:51:43 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 02:51:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 02:51:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 02:51:44 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 02:51:44 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 02:51:44 INFO  LogManager:72 - Shutting down.
2018-09-26 02:51:44 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:51:44 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:51:44 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:51:44 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:51:44 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:51:44 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:51:44 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:51:44 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:51:44 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 02:51:44 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 02:51:44 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-09-26 02:51:44 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-09-26 02:51:44 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:51:44 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Shutting down
2018-09-26 02:51:44 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Stopped
2018-09-26 02:51:44 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Shutdown completed
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 02:51:44 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:51:44 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdf552a0000
2018-09-26 02:51:44 INFO  ZooKeeper:687 - Session: 0x1016fdf552a0000 closed
2018-09-26 02:51:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:51:44 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34368 which had sessionid 0x1016fdf552a0000
2018-09-26 02:51:44 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdf552a0000
2018-09-26 02:51:44 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:51:44 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] 3 successfully elected as the controller
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Starting become controller state transition
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Initialized controller epoch to 2 and zk version 1
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Incremented epoch to 3
2018-09-26 02:51:44 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Starting
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Partitions being reassigned: Map()
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Partitions already reassigned: Set()
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Resuming reassignment of partitions: Map()
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Currently active brokers in the cluster: Set(3)
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Current list of topics in the cluster: Set()
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] List of topics to be deleted: 
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] List of topics ineligible for deletion: 
2018-09-26 02:51:44 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2018-09-26 02:51:44 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2018-09-26 02:51:44 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Controller 3 connected to 127.0.0.1:41508 (id: 3 rack: null) for sending state change requests
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Ready to serve as the new controller with epoch 3
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Partitions undergoing preferred replica election: 
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Partitions that completed preferred replica election: 
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Resuming preferred replica election for partitions: 
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Starting preferred replica leader election for partitions 
2018-09-26 02:51:44 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:51:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf5a5e0000 type:delete cxid:0x46 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:51:44 INFO  KafkaController:72 - [Controller id=3] Starting the controller scheduler
2018-09-26 02:51:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:51:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:51:44 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:51:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:51:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:51:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:51:46 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:51:46 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:51:46 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 02:51:46 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 02:51:46 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 02:51:46 INFO  KafkaServer:72 - [KafkaServer id=3] shutting down
2018-09-26 02:51:46 INFO  KafkaServer:72 - [KafkaServer id=3] Starting controlled shutdown
2018-09-26 02:51:46 INFO  KafkaController:72 - [Controller id=3] Shutting down broker 3
2018-09-26 02:51:46 INFO  KafkaServer:72 - [KafkaServer id=3] Controlled shutdown succeeded
2018-09-26 02:51:46 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopping socket server request processors
2018-09-26 02:51:46 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopped socket server request processors
2018-09-26 02:51:46 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shutting down
2018-09-26 02:51:46 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shut down completely
2018-09-26 02:51:46 INFO  KafkaApis:72 - [KafkaApi-3] Shutdown complete.
2018-09-26 02:51:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutting down
2018-09-26 02:51:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Stopped
2018-09-26 02:51:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutdown completed
2018-09-26 02:51:46 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutting down.
2018-09-26 02:51:46 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 2000
2018-09-26 02:51:46 INFO  TransactionStateManager:72 - [Transaction State Manager 3]: Shutdown complete
2018-09-26 02:51:46 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutting down
2018-09-26 02:51:46 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Stopped
2018-09-26 02:51:46 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutdown completed
2018-09-26 02:51:46 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutdown complete.
2018-09-26 02:51:46 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutting down.
2018-09-26 02:51:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutting down
2018-09-26 02:51:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Stopped
2018-09-26 02:51:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2018-09-26 02:51:46 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutting down
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Stopped
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2018-09-26 02:51:47 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutdown complete.
2018-09-26 02:51:47 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shutting down
2018-09-26 02:51:47 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:51:47 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:51:47 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:51:47 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutting down
2018-09-26 02:51:47 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutdown completed
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutting down
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Stopped
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutdown completed
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutting down
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Stopped
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutdown completed
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Stopped
2018-09-26 02:51:47 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2018-09-26 02:51:47 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shut down completely
2018-09-26 02:51:47 INFO  LogManager:72 - Shutting down.
2018-09-26 02:51:47 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:51:47 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:51:47 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:51:47 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:51:47 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:51:47 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:51:47 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:51:47 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:51:47 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2018-09-26 02:51:47 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2018-09-26 02:51:47 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutting down
2018-09-26 02:51:47 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Stopped
2018-09-26 02:51:47 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutdown completed
2018-09-26 02:51:47 INFO  KafkaController:72 - [Controller id=3] Resigned
2018-09-26 02:51:47 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:51:47 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdf5a5e0000
2018-09-26 02:51:47 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34356 which had sessionid 0x1016fdf5a5e0000
2018-09-26 02:51:47 INFO  ZooKeeper:687 - Session: 0x1016fdf5a5e0000 closed
2018-09-26 02:51:47 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:51:47 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdf5a5e0000
2018-09-26 02:51:47 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:51:47 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:51:47 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:51:47 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:51:47 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:51:47 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:51:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:51:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:51:48 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutting down socket server
2018-09-26 02:51:48 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutdown completed
2018-09-26 02:51:48 INFO  KafkaServer:72 - [KafkaServer id=3] shut down completed
2018-09-26 02:51:48 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:51:48 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:51:48 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:51:48 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:51:48 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:51:48 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:51:48 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:51:48 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:51:48 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:51:48 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:51:48 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:51:48 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:51:48 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:51:48 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:51:48 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:51:48 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42772
2018-09-26 02:51:49 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:51:49 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:51:49 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:51:49 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:51:49 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:51:49 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:51:49 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:51:49 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:51:49 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:51:49 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:51:49 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:51:49 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:51:49 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:51:49 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:51:49 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42772
2018-09-26 02:51:50 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:51:50 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:51:50 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:36655
	advertised.port = 36655
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:36655
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923110987-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 36655
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42772
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:51:50 INFO  KafkaServer:72 - starting
2018-09-26 02:51:50 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:42772
2018-09-26 02:51:50 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42772 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@347bdeef
2018-09-26 02:51:50 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:51:50 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42772. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:50 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:51:50 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42772, initiating session
2018-09-26 02:51:50 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:48424
2018-09-26 02:51:50 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:48424
2018-09-26 02:51:50 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:51:51 INFO  ZooKeeperServer:693 - Established session 0x1016fdf85b00000 with negotiated timeout 30000 for client /127.0.0.1:48424
2018-09-26 02:51:51 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42772, sessionid = 0x1016fdf85b00000, negotiated timeout = 30000
2018-09-26 02:51:51 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf85b00000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:51:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf85b00000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:51:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf85b00000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:51:51 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf85b00000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:51:51 INFO  KafkaServer:72 - Cluster ID = _4BymtijRKGM5wP9bq205w
2018-09-26 02:51:51 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923110987-0/meta.properties
2018-09-26 02:51:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:51:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:51:51 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:51:51 INFO  LogManager:72 - Loading logs.
2018-09-26 02:51:51 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:51:51 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:51:51 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:51:51 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:51:51 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:51:51 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:36655.
2018-09-26 02:51:51 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:51:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:51:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:51:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:51:51 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:51:51 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:51:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:51:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:51:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:51:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:51:51 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:51:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:51:51 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:51:51 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:51 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:51:51 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:51:52 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:51:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf85b00000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:51:52 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:51:52 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:51:52 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:51:52 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:51:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf85b00000 type:create cxid:0x44 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:51:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf85b00000 type:create cxid:0x45 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:51:52 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:52 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,36655,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:51:52 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923110987-0/meta.properties
2018-09-26 02:51:52 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:51:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:51:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:51:52 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:36655 (id: 1 rack: null) for sending state change requests
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:51:52 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:51:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:51:52 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf85b00000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:51:52 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:51:52 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:52 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:52 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:51:52 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:51:52 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:48424 which had sessionid 0x1016fdf85b00000
2018-09-26 02:51:52 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:51:52 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fdf85b00000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:51:52 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:51:52 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:51:52 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:51:52 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:51:52 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:51:52 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:51:52 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:51:52 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:51:52 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:51:52 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:51:52 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:51:52 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:51:52 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42772
2018-09-26 02:51:52 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:51:52 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:51:53 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:40915
	advertised.port = 40915
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:40915
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923113251-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 40915
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42772
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:51:53 INFO  KafkaServer:72 - starting
2018-09-26 02:51:53 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:42772
2018-09-26 02:51:53 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42772 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@55caeb35
2018-09-26 02:51:53 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:51:53 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:51:53 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42772. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:53 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42772, initiating session
2018-09-26 02:51:53 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:48428
2018-09-26 02:51:53 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:48428
2018-09-26 02:51:53 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-09-26 02:51:53 INFO  ZooKeeperServer:693 - Established session 0x1016fdf8e870000 with negotiated timeout 30000 for client /127.0.0.1:48428
2018-09-26 02:51:53 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42772, sessionid = 0x1016fdf8e870000, negotiated timeout = 30000
2018-09-26 02:51:53 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:53 INFO  KafkaServer:72 - Cluster ID = _4BymtijRKGM5wP9bq205w
2018-09-26 02:51:53 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923113251-0/meta.properties
2018-09-26 02:51:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:51:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:51:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:51:53 INFO  LogManager:72 - Loading logs.
2018-09-26 02:51:53 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:51:53 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:51:53 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:51:53 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:51:53 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:51:53 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:40915.
2018-09-26 02:51:53 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 02:51:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 02:51:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 02:51:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 02:51:53 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:51:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:51:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 02:51:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 02:51:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 02:51:53 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 02:51:53 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 02:51:53 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:51:53 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42772. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:53 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42772, initiating session
2018-09-26 02:51:53 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:48430
2018-09-26 02:51:53 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fdf85b00000 at /127.0.0.1:48430
2018-09-26 02:51:53 INFO  ZooKeeperServer:693 - Established session 0x1016fdf85b00000 with negotiated timeout 30000 for client /127.0.0.1:48430
2018-09-26 02:51:53 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42772, sessionid = 0x1016fdf85b00000, negotiated timeout = 30000
2018-09-26 02:51:53 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:53 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf85b00000 type:delete cxid:0x52 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:51:53 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 02:51:53 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:51:53 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 02:51:53 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 02:51:53 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 02:51:53 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-09-26 02:51:53 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 02:51:53 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf8e870000 type:create cxid:0x1d zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:51:53 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf8e870000 type:create cxid:0x1e zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:51:53 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:53 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,40915,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:51:53 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923113251-0/meta.properties
2018-09-26 02:51:53 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 02:51:53 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 02:51:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 02:51:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:40915 (id: 2 rack: null) for sending state change requests
2018-09-26 02:51:53 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 02:51:53 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:53 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:53 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 02:51:53 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:36655, 127.0.0.1:40915]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:51:53 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:53 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:53 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-09-26 02:51:53 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:36655, 127.0.0.1:40915]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:51:53 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:51:53 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:51:53 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:51:53 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:51:53 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:51:53 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:51:53 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:51:53 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:51:53 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:51:53 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:51:53 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:51:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:51:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:51:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:51:53 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:51:53 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:51:53 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:51:53 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:51:53 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:51:53 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:51:53 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:51:53 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:51:53 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:51:53 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:51:54 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:51:54 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:51:54 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:51:54 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:51:54 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:51:54 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:51:54 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:51:54 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:51:54 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:51:54 INFO  LogManager:72 - Shutting down.
2018-09-26 02:51:54 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:51:54 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:51:54 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:51:54 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:51:54 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:51:54 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:51:54 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:51:54 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:51:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:51:54 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:51:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 02:51:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 02:51:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:51:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:51:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:51:54 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:51:54 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:51:54 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdf85b00000
2018-09-26 02:51:54 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:48430 which had sessionid 0x1016fdf85b00000
2018-09-26 02:51:54 INFO  ZooKeeper:687 - Session: 0x1016fdf85b00000 closed
2018-09-26 02:51:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:51:54 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdf85b00000
2018-09-26 02:51:54 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:51:54 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2018-09-26 02:51:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:51:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:51:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:51:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:51:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:51:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 2
2018-09-26 02:51:54 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2)
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set()
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: 
2018-09-26 02:51:54 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map()
2018-09-26 02:51:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map()
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 2
2018-09-26 02:51:54 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:40915 (id: 2 rack: null) for sending state change requests
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-09-26 02:51:54 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:51:54 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdf8e870000 type:delete cxid:0x3d zxid:0x27 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:51:54 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-09-26 02:51:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:51:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:51:55 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:51:55 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:51:55 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:51:55 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 02:51:55 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 02:51:55 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:51:55 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-09-26 02:51:55 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 02:51:55 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 02:51:55 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 02:51:55 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 02:51:55 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 02:51:55 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 02:51:56 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 02:51:56 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-09-26 02:51:56 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 02:51:56 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 02:51:56 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 02:51:56 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 02:51:56 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 02:51:56 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 02:51:56 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 02:51:56 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 02:51:56 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:51:56 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:51:56 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:51:56 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 02:51:56 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 02:51:56 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 02:51:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 02:51:57 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 02:51:57 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 02:51:57 INFO  LogManager:72 - Shutting down.
2018-09-26 02:51:57 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:51:57 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:51:57 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:51:57 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:51:57 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:51:57 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:51:57 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:51:57 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:51:57 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 02:51:57 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 02:51:57 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-09-26 02:51:57 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-09-26 02:51:57 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:51:57 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 02:51:57 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:51:57 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdf8e870000
2018-09-26 02:51:57 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:48428 which had sessionid 0x1016fdf8e870000
2018-09-26 02:51:57 INFO  ZooKeeper:687 - Session: 0x1016fdf8e870000 closed
2018-09-26 02:51:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:51:57 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdf8e870000
2018-09-26 02:51:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:51:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:51:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:51:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:51:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:51:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:51:57 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 02:51:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:51:57 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:51:57 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 02:51:57 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 02:51:57 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:51:57 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:51:57 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:51:57 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:51:57 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:51:57 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:51:57 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:51:57 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:51:57 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:51:57 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:51:57 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:51:57 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:51:57 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:51:57 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:51:57 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:51:57 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:51:57 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:41592
2018-09-26 02:51:58 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:51:58 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:51:58 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:51:58 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:51:58 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:51:58 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:51:58 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:51:58 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:51:58 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:51:58 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:51:58 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:51:58 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:51:58 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:51:58 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:51:58 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:41592
2018-09-26 02:51:59 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:39663
	advertised.port = 39663
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:39663
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923119343-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 39663
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:41592
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:51:59 INFO  KafkaServer:72 - starting
2018-09-26 02:51:59 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:41592
2018-09-26 02:51:59 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:41592 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@34448e6c
2018-09-26 02:51:59 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:51:59 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:51:59 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:41592. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:51:59 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43978
2018-09-26 02:51:59 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:41592, initiating session
2018-09-26 02:51:59 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:43978
2018-09-26 02:51:59 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:51:59 INFO  ZooKeeperServer:693 - Established session 0x1016fdfa6530000 with negotiated timeout 30000 for client /127.0.0.1:43978
2018-09-26 02:51:59 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:41592, sessionid = 0x1016fdfa6530000, negotiated timeout = 30000
2018-09-26 02:51:59 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:51:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfa6530000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:51:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfa6530000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:51:59 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfa6530000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:51:59 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:51:59 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfa6530000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:52:00 INFO  KafkaServer:72 - Cluster ID = K-Zl_06YRn-4I19zC7tFMQ
2018-09-26 02:52:00 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923119343-0/meta.properties
2018-09-26 02:52:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:52:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:52:00 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:52:00 INFO  LogManager:72 - Loading logs.
2018-09-26 02:52:00 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:52:00 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:52:00 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:52:00 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:52:00 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:52:00 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:39663.
2018-09-26 02:52:00 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:52:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:52:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:52:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:52:00 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:52:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:52:00 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:52:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:52:00 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:52:00 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:52:00 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:52:00 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:52:00 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:52:00 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:52:00 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:52:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfa6530000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:52:00 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:52:00 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:52:00 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:52:00 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:52:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfa6530000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:52:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfa6530000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:52:00 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:00 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,39663,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:52:00 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923119343-0/meta.properties
2018-09-26 02:52:00 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:52:00 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:52:00 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:52:00 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:39663 (id: 1 rack: null) for sending state change requests
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:52:00 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:52:00 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:52:00 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfa6530000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:52:00 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:52:00 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:00 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:00 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:52:00 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:00 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43978 which had sessionid 0x1016fdfa6530000
2018-09-26 02:52:00 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fdfa6530000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:52:00 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:00 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:00 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:00 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:00 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:00 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:00 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:00 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:00 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:00 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:00 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:00 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:00 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:00 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:41592
2018-09-26 02:52:00 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:52:00 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:52:01 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:45619
	advertised.port = 45619
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:45619
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923121860-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 45619
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:41592
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:52:01 INFO  KafkaServer:72 - starting
2018-09-26 02:52:01 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:41592
2018-09-26 02:52:01 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:41592 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@288a4658
2018-09-26 02:52:01 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:52:01 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:52:01 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:41592. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:01 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:41592, initiating session
2018-09-26 02:52:01 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43984
2018-09-26 02:52:01 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:43984
2018-09-26 02:52:01 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-09-26 02:52:01 INFO  ZooKeeperServer:693 - Established session 0x1016fdfb0290000 with negotiated timeout 30000 for client /127.0.0.1:43984
2018-09-26 02:52:01 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:41592, sessionid = 0x1016fdfb0290000, negotiated timeout = 30000
2018-09-26 02:52:01 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:01 INFO  KafkaServer:72 - Cluster ID = K-Zl_06YRn-4I19zC7tFMQ
2018-09-26 02:52:01 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923121860-0/meta.properties
2018-09-26 02:52:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:52:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:52:01 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:52:01 INFO  LogManager:72 - Loading logs.
2018-09-26 02:52:01 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:52:02 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:52:02 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:52:02 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:52:02 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:52:02 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:45619.
2018-09-26 02:52:02 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 02:52:02 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 02:52:02 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 02:52:02 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 02:52:02 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:52:02 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:52:02 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 02:52:02 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 02:52:02 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 02:52:02 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 02:52:02 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 02:52:02 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:52:02 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 02:52:02 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 02:52:02 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 02:52:02 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 02:52:02 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 02:52:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfb0290000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:52:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfb0290000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:52:02 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:41592. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:02 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:41592, initiating session
2018-09-26 02:52:02 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43986
2018-09-26 02:52:02 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fdfa6530000 at /127.0.0.1:43986
2018-09-26 02:52:02 INFO  ZooKeeperServer:693 - Established session 0x1016fdfa6530000 with negotiated timeout 30000 for client /127.0.0.1:43986
2018-09-26 02:52:02 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:41592, sessionid = 0x1016fdfa6530000, negotiated timeout = 30000
2018-09-26 02:52:02 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:02 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfa6530000 type:delete cxid:0x52 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:52:02 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:02 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,45619,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:52:02 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923121860-0/meta.properties
2018-09-26 02:52:02 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:52:02 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 02:52:02 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 02:52:02 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 02:52:02 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:45619 (id: 2 rack: null) for sending state change requests
2018-09-26 02:52:02 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1,2
2018-09-26 02:52:02 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 02:52:02 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:02 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:02 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 02:52:02 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:02 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43986 which had sessionid 0x1016fdfa6530000
2018-09-26 02:52:02 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43984 which had sessionid 0x1016fdfb0290000
2018-09-26 02:52:02 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fdfa6530000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:52:02 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:02 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fdfb0290000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:52:02 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:02 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:02 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:02 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:02 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:02 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:02 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:02 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:02 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:02 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:02 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:02 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:02 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:41592
2018-09-26 02:52:02 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:52:02 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:52:02 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:02 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:03 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:42379
	advertised.port = 42379
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:42379
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923123227-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 42379
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:41592
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:52:03 INFO  KafkaServer:72 - starting
2018-09-26 02:52:03 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:41592
2018-09-26 02:52:03 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:41592 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@29d37757
2018-09-26 02:52:03 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:52:03 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:52:03 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:41592. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:03 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:41592, initiating session
2018-09-26 02:52:03 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43990
2018-09-26 02:52:03 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:43990
2018-09-26 02:52:03 INFO  FileTxnLog:213 - Creating new log file: log.24
2018-09-26 02:52:03 INFO  ZooKeeperServer:693 - Established session 0x1016fdfb57f0000 with negotiated timeout 30000 for client /127.0.0.1:43990
2018-09-26 02:52:03 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:41592, sessionid = 0x1016fdfb57f0000, negotiated timeout = 30000
2018-09-26 02:52:03 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:03 INFO  KafkaServer:72 - Cluster ID = K-Zl_06YRn-4I19zC7tFMQ
2018-09-26 02:52:03 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923123227-0/meta.properties
2018-09-26 02:52:03 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:52:03 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:52:03 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:52:03 INFO  LogManager:72 - Loading logs.
2018-09-26 02:52:03 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:52:03 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:52:03 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:52:03 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:52:03 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:52:03 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:42379.
2018-09-26 02:52:03 INFO  SocketServer:72 - [SocketServer brokerId=3] Started 1 acceptor threads
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Starting
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Starting
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Starting
2018-09-26 02:52:03 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:52:03 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Starting
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Starting
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Starting
2018-09-26 02:52:03 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Starting up.
2018-09-26 02:52:03 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Startup complete.
2018-09-26 02:52:03 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:52:03 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2018-09-26 02:52:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Starting up.
2018-09-26 02:52:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Startup complete.
2018-09-26 02:52:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Starting
2018-09-26 02:52:03 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/3 (is it secure? false)
2018-09-26 02:52:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfb57f0000 type:create cxid:0x1d zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:52:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfb57f0000 type:create cxid:0x1e zxid:0x27 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:52:03 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:03 INFO  ZkUtils:72 - Registered broker 3 at path /brokers/ids/3 with addresses: EndPoint(127.0.0.1,42379,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:52:03 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923123227-0/meta.properties
2018-09-26 02:52:03 INFO  SocketServer:72 - [SocketServer brokerId=3] Started processors for 1 acceptors
2018-09-26 02:52:03 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:03 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:03 INFO  KafkaServer:72 - [KafkaServer id=3] started
2018-09-26 02:52:03 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:39663, 127.0.0.1:45619, 127.0.0.1:42379]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:52:03 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:03 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:03 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:41592. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:03 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:41592, initiating session
2018-09-26 02:52:03 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:43992
2018-09-26 02:52:03 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fdfa6530000 at /127.0.0.1:43992
2018-09-26 02:52:03 INFO  ZooKeeperServer:693 - Established session 0x1016fdfa6530000 with negotiated timeout 30000 for client /127.0.0.1:43992
2018-09-26 02:52:03 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:41592, sessionid = 0x1016fdfa6530000, negotiated timeout = 30000
2018-09-26 02:52:03 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:03 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 3, deleted brokers: , all live brokers: 1,2,3
2018-09-26 02:52:03 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 3
2018-09-26 02:52:03 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Starting
2018-09-26 02:52:03 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Controller 1 connected to 127.0.0.1:42379 (id: 3 rack: null) for sending state change requests
2018-09-26 02:52:03 INFO  KafkaTestCluster:253 - Found 3 brokers on-line, cluster is ready.
2018-09-26 02:52:03 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:52:03 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:52:03 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:52:03 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:52:03 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:52:03 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:52:03 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:52:03 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:52:03 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:52:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:52:03 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:52:03 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:52:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:52:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:52:03 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:52:03 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:52:03 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:52:03 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:52:04 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:52:04 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:52:04 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:52:04 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:52:04 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:52:04 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:52:04 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:52:04 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:41592. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:04 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:41592, initiating session
2018-09-26 02:52:04 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:44006
2018-09-26 02:52:04 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fdfb0290000 at /127.0.0.1:44006
2018-09-26 02:52:04 INFO  ZooKeeperServer:693 - Established session 0x1016fdfb0290000 with negotiated timeout 30000 for client /127.0.0.1:44006
2018-09-26 02:52:04 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:41592, sessionid = 0x1016fdfb0290000, negotiated timeout = 30000
2018-09-26 02:52:04 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:52:04 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:52:04 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:52:04 INFO  LogManager:72 - Shutting down.
2018-09-26 02:52:04 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:52:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:52:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:52:04 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:52:04 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:52:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:52:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:52:04 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:52:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:52:04 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutting down
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Stopped
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutdown completed
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:52:04 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:52:04 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdfa6530000
2018-09-26 02:52:04 INFO  ZooKeeper:687 - Session: 0x1016fdfa6530000 closed
2018-09-26 02:52:04 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43992 which had sessionid 0x1016fdfa6530000
2018-09-26 02:52:04 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:52:04 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdfa6530000
2018-09-26 02:52:04 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:52:04 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:52:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfb0290000 type:create cxid:0x25 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2018-09-26 02:52:04 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] 3 successfully elected as the controller
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Starting become controller state transition
2018-09-26 02:52:04 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: NODEEXISTS
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Initialized controller epoch to 1 and zk version 0
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Incremented epoch to 2
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Starting
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Starting
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Partitions being reassigned: Map()
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Partitions already reassigned: Set()
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Resuming reassignment of partitions: Map()
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Currently active brokers in the cluster: Set(2, 3)
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Current list of topics in the cluster: Set()
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] List of topics to be deleted: 
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] List of topics ineligible for deletion: 
2018-09-26 02:52:04 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2018-09-26 02:52:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Ready to serve as the new controller with epoch 2
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Controller 3 connected to 127.0.0.1:45619 (id: 2 rack: null) for sending state change requests
2018-09-26 02:52:04 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Controller 3 connected to 127.0.0.1:42379 (id: 3 rack: null) for sending state change requests
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Partitions undergoing preferred replica election: 
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Partitions that completed preferred replica election: 
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Resuming preferred replica election for partitions: 
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Starting preferred replica leader election for partitions 
2018-09-26 02:52:04 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:52:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfb57f0000 type:delete cxid:0x3e zxid:0x2d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:52:04 INFO  KafkaController:72 - [Controller id=3] Starting the controller scheduler
2018-09-26 02:52:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:52:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:52:05 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:52:06 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:52:06 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:52:06 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:52:06 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 02:52:06 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 02:52:06 INFO  KafkaController:72 - [Controller id=3] Shutting down broker 2
2018-09-26 02:52:06 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-09-26 02:52:06 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 02:52:06 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 02:52:06 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 02:52:06 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 02:52:06 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 02:52:06 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 02:52:06 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-09-26 02:52:06 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 02:52:06 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 02:52:06 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 02:52:06 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 02:52:06 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 02:52:06 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 02:52:06 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 02:52:06 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 02:52:06 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:52:06 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:52:06 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:52:06 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 02:52:06 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 02:52:06 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 02:52:06 INFO  LogManager:72 - Shutting down.
2018-09-26 02:52:06 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:52:06 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:52:06 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:52:06 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:52:06 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:52:06 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:52:06 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:52:06 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:52:06 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 02:52:06 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 02:52:06 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 02:52:06 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:52:06 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdfb0290000
2018-09-26 02:52:06 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:44006 which had sessionid 0x1016fdfb0290000
2018-09-26 02:52:06 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdfb0290000
2018-09-26 02:52:06 INFO  ZooKeeper:687 - Session: 0x1016fdfb0290000 closed
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:52:06 INFO  KafkaController:72 - [Controller id=3] Newly added brokers: , deleted brokers: 2, all live brokers: 3
2018-09-26 02:52:06 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Shutting down
2018-09-26 02:52:06 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Stopped
2018-09-26 02:52:06 INFO  RequestSendThread:72 - [Controller-3-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:52:06 INFO  KafkaController:72 - [Controller id=3] Broker failure callback for 2
2018-09-26 02:52:06 INFO  KafkaController:72 - [Controller id=3] Removed ArrayBuffer(2) from list of shutting down brokers.
2018-09-26 02:52:06 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Invoking state change to OfflinePartition for partitions 
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:52:06 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:52:06 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 02:52:06 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 02:52:06 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 02:52:06 INFO  KafkaServer:72 - [KafkaServer id=3] shutting down
2018-09-26 02:52:06 INFO  KafkaServer:72 - [KafkaServer id=3] Starting controlled shutdown
2018-09-26 02:52:06 INFO  KafkaController:72 - [Controller id=3] Shutting down broker 3
2018-09-26 02:52:06 INFO  KafkaServer:72 - [KafkaServer id=3] Controlled shutdown succeeded
2018-09-26 02:52:06 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopping socket server request processors
2018-09-26 02:52:06 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopped socket server request processors
2018-09-26 02:52:06 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shutting down
2018-09-26 02:52:06 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shut down completely
2018-09-26 02:52:06 INFO  KafkaApis:72 - [KafkaApi-3] Shutdown complete.
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutting down
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Stopped
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutdown completed
2018-09-26 02:52:06 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutting down.
2018-09-26 02:52:06 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 2000
2018-09-26 02:52:06 INFO  TransactionStateManager:72 - [Transaction State Manager 3]: Shutdown complete
2018-09-26 02:52:06 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutting down
2018-09-26 02:52:06 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Stopped
2018-09-26 02:52:06 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutdown completed
2018-09-26 02:52:06 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutdown complete.
2018-09-26 02:52:06 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutting down.
2018-09-26 02:52:06 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutting down
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Stopped
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutting down
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Stopped
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2018-09-26 02:52:07 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutdown complete.
2018-09-26 02:52:07 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shutting down
2018-09-26 02:52:07 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:52:07 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:52:07 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:52:07 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutting down
2018-09-26 02:52:07 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutdown completed
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutting down
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Stopped
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutdown completed
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutting down
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Stopped
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutdown completed
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Stopped
2018-09-26 02:52:07 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2018-09-26 02:52:07 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shut down completely
2018-09-26 02:52:07 INFO  LogManager:72 - Shutting down.
2018-09-26 02:52:07 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:52:07 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:52:07 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:52:07 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:52:07 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:52:07 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:52:07 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:52:07 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:52:07 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2018-09-26 02:52:07 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2018-09-26 02:52:07 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutting down
2018-09-26 02:52:07 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Stopped
2018-09-26 02:52:07 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutdown completed
2018-09-26 02:52:07 INFO  KafkaController:72 - [Controller id=3] Resigned
2018-09-26 02:52:07 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:52:07 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdfb57f0000
2018-09-26 02:52:08 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:43990 which had sessionid 0x1016fdfb57f0000
2018-09-26 02:52:08 INFO  ZooKeeper:687 - Session: 0x1016fdfb57f0000 closed
2018-09-26 02:52:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:52:08 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdfb57f0000
2018-09-26 02:52:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:52:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:52:08 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:52:09 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:52:09 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:52:09 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:52:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:52:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:52:10 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutting down socket server
2018-09-26 02:52:10 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutdown completed
2018-09-26 02:52:10 INFO  KafkaServer:72 - [KafkaServer id=3] shut down completed
2018-09-26 02:52:10 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:52:10 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:10 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:10 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:10 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:10 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:10 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:10 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:10 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:10 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:10 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:10 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:10 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:10 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:10 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:10 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46757
2018-09-26 02:52:11 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:11 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:11 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:11 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:11 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:11 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:11 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:11 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:11 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:11 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:11 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:11 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:11 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:11 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:11 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46757
2018-09-26 02:52:11 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:11 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:12 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:41001
	advertised.port = 41001
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:41001
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923132311-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 41001
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:46757
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:52:12 INFO  KafkaServer:72 - starting
2018-09-26 02:52:12 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:46757
2018-09-26 02:52:12 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46757 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@5f212d84
2018-09-26 02:52:12 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:52:12 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:52:12 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46757. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:12 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46757, initiating session
2018-09-26 02:52:12 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:41162
2018-09-26 02:52:12 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:41162
2018-09-26 02:52:12 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:52:12 INFO  ZooKeeperServer:693 - Established session 0x1016fdfd8fb0000 with negotiated timeout 30000 for client /127.0.0.1:41162
2018-09-26 02:52:12 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46757, sessionid = 0x1016fdfd8fb0000, negotiated timeout = 30000
2018-09-26 02:52:12 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfd8fb0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:52:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfd8fb0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:52:12 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfd8fb0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:52:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfd8fb0000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:52:13 INFO  KafkaServer:72 - Cluster ID = 9ejSmbtDQVKSIk-EPlhIIA
2018-09-26 02:52:13 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923132311-0/meta.properties
2018-09-26 02:52:13 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:52:13 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:52:13 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:52:13 INFO  LogManager:72 - Loading logs.
2018-09-26 02:52:13 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 02:52:13 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:52:13 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:52:13 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:52:13 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:52:13 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:41001.
2018-09-26 02:52:13 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:52:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:52:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:52:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:52:13 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:52:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:52:13 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:52:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:52:13 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:52:13 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:52:13 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:52:13 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:52:13 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:52:13 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:52:13 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:52:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfd8fb0000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:52:13 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:52:13 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:52:13 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:52:13 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:52:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfd8fb0000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:52:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfd8fb0000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:52:13 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:13 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,41001,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:52:13 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923132311-0/meta.properties
2018-09-26 02:52:13 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:52:13 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:52:13 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:52:13 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:41001 (id: 1 rack: null) for sending state change requests
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:52:13 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:52:13 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:52:13 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfd8fb0000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:52:13 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:52:13 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:13 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:13 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:52:13 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:13 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:41162 which had sessionid 0x1016fdfd8fb0000
2018-09-26 02:52:13 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:13 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fdfd8fb0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:52:13 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:13 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:13 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:13 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:13 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:13 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:13 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:13 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:13 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:13 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:13 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:13 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:13 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46757
2018-09-26 02:52:13 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:52:13 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:52:14 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:42314
	advertised.port = 42314
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:42314
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923134577-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 42314
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:46757
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:52:14 INFO  KafkaServer:72 - starting
2018-09-26 02:52:14 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:46757
2018-09-26 02:52:14 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46757 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@77bb0ab5
2018-09-26 02:52:14 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:52:14 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:52:14 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46757. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:14 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46757, initiating session
2018-09-26 02:52:14 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:41166
2018-09-26 02:52:14 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:41166
2018-09-26 02:52:14 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-09-26 02:52:14 INFO  ZooKeeperServer:693 - Established session 0x1016fdfe1d50000 with negotiated timeout 30000 for client /127.0.0.1:41166
2018-09-26 02:52:14 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46757, sessionid = 0x1016fdfe1d50000, negotiated timeout = 30000
2018-09-26 02:52:14 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:14 INFO  KafkaServer:72 - Cluster ID = 9ejSmbtDQVKSIk-EPlhIIA
2018-09-26 02:52:14 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923134577-0/meta.properties
2018-09-26 02:52:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:52:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:52:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:52:14 INFO  LogManager:72 - Loading logs.
2018-09-26 02:52:14 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:52:14 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:52:14 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:52:14 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:52:14 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:52:14 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:42314.
2018-09-26 02:52:14 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 02:52:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 02:52:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 02:52:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 02:52:14 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:52:14 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:52:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 02:52:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 02:52:14 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 02:52:14 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 02:52:14 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 02:52:14 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:52:14 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 02:52:14 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 02:52:14 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 02:52:14 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 02:52:14 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 02:52:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfe1d50000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:52:14 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfe1d50000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:52:14 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:14 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,42314,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:52:14 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923134577-0/meta.properties
2018-09-26 02:52:14 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 02:52:14 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:14 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:14 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 02:52:14 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:14 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:41166 which had sessionid 0x1016fdfe1d50000
2018-09-26 02:52:14 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fdfe1d50000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:52:14 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:14 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:14 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:14 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:14 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:14 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:14 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:14 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:14 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:14 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:14 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:14 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:14 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:14 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46757
2018-09-26 02:52:14 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:14 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:15 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:52:15 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46757. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:15 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:41170
2018-09-26 02:52:15 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46757, initiating session
2018-09-26 02:52:15 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fdfd8fb0000 at /127.0.0.1:41170
2018-09-26 02:52:15 INFO  ZooKeeperServer:693 - Established session 0x1016fdfd8fb0000 with negotiated timeout 30000 for client /127.0.0.1:41170
2018-09-26 02:52:15 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46757, sessionid = 0x1016fdfd8fb0000, negotiated timeout = 30000
2018-09-26 02:52:15 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfd8fb0000 type:delete cxid:0x52 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:52:15 INFO  FileTxnLog:213 - Creating new log file: log.23
2018-09-26 02:52:15 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:52:15 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 02:52:15 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 02:52:15 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 02:52:15 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:42314 (id: 2 rack: null) for sending state change requests
2018-09-26 02:52:15 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1,2
2018-09-26 02:52:15 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:41108
	advertised.port = 41108
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:41108
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923135912-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 41108
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:46757
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:52:15 INFO  KafkaServer:72 - starting
2018-09-26 02:52:15 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:46757
2018-09-26 02:52:15 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46757 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@7180e701
2018-09-26 02:52:15 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:52:15 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:52:15 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46757. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:15 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46757, initiating session
2018-09-26 02:52:15 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:41174
2018-09-26 02:52:15 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:41174
2018-09-26 02:52:15 INFO  ZooKeeperServer:693 - Established session 0x1016fdfe70d0000 with negotiated timeout 30000 for client /127.0.0.1:41174
2018-09-26 02:52:15 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46757, sessionid = 0x1016fdfe70d0000, negotiated timeout = 30000
2018-09-26 02:52:15 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:15 INFO  KafkaServer:72 - Cluster ID = 9ejSmbtDQVKSIk-EPlhIIA
2018-09-26 02:52:15 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923135912-0/meta.properties
2018-09-26 02:52:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:52:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:52:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:52:15 INFO  LogManager:72 - Loading logs.
2018-09-26 02:52:15 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 02:52:16 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:52:16 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:52:16 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:52:16 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:52:16 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:41108.
2018-09-26 02:52:16 INFO  SocketServer:72 - [SocketServer brokerId=3] Started 1 acceptor threads
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Starting
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Starting
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Starting
2018-09-26 02:52:16 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:52:16 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Starting
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Starting
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Starting
2018-09-26 02:52:16 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Starting up.
2018-09-26 02:52:16 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Startup complete.
2018-09-26 02:52:16 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:52:16 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2018-09-26 02:52:16 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Starting up.
2018-09-26 02:52:16 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Startup complete.
2018-09-26 02:52:16 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Starting
2018-09-26 02:52:16 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/3 (is it secure? false)
2018-09-26 02:52:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfe70d0000 type:create cxid:0x1d zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:52:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfe70d0000 type:create cxid:0x1e zxid:0x27 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:52:16 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:16 INFO  ZkUtils:72 - Registered broker 3 at path /brokers/ids/3 with addresses: EndPoint(127.0.0.1,41108,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:52:16 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923135912-0/meta.properties
2018-09-26 02:52:16 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 3, deleted brokers: , all live brokers: 1,2,3
2018-09-26 02:52:16 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 3
2018-09-26 02:52:16 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Starting
2018-09-26 02:52:16 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Controller 1 connected to 127.0.0.1:41108 (id: 3 rack: null) for sending state change requests
2018-09-26 02:52:16 INFO  SocketServer:72 - [SocketServer brokerId=3] Started processors for 1 acceptors
2018-09-26 02:52:16 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:16 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:16 INFO  KafkaServer:72 - [KafkaServer id=3] started
2018-09-26 02:52:16 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:41001, 127.0.0.1:42314, 127.0.0.1:41108]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:52:16 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:16 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:16 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46757. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:16 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46757, initiating session
2018-09-26 02:52:16 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:41178
2018-09-26 02:52:16 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fdfe1d50000 at /127.0.0.1:41178
2018-09-26 02:52:16 INFO  ZooKeeperServer:693 - Established session 0x1016fdfe1d50000 with negotiated timeout 30000 for client /127.0.0.1:41178
2018-09-26 02:52:16 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46757, sessionid = 0x1016fdfe1d50000, negotiated timeout = 30000
2018-09-26 02:52:16 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:16 INFO  KafkaTestCluster:253 - Found 3 brokers on-line, cluster is ready.
2018-09-26 02:52:16 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:52:16 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:52:16 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:52:16 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:52:16 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:52:16 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:52:16 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:52:16 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:52:16 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:52:16 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:52:16 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:52:16 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:52:16 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:52:16 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:52:16 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:52:16 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:52:16 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:52:16 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:52:16 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:52:16 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:52:16 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:52:16 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:52:16 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:52:16 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:52:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:52:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:52:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:52:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:52:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:52:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:52:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:52:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:52:17 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:52:17 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:52:17 INFO  LogManager:72 - Shutting down.
2018-09-26 02:52:17 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:52:17 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:52:17 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:52:17 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:52:17 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:52:17 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:52:17 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:52:17 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:52:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:52:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutting down
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Stopped
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-3-send-thread]: Shutdown completed
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:52:17 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:52:17 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdfd8fb0000
2018-09-26 02:52:17 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:41170 which had sessionid 0x1016fdfd8fb0000
2018-09-26 02:52:17 INFO  ZooKeeper:687 - Session: 0x1016fdfd8fb0000 closed
2018-09-26 02:52:17 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:52:17 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdfd8fb0000
2018-09-26 02:52:17 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:52:17 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:52:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfe70d0000 type:create cxid:0x24 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2018-09-26 02:52:17 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2018-09-26 02:52:17 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: NODEEXISTS
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 2
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Starting
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2, 3)
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set()
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: 
2018-09-26 02:52:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map()
2018-09-26 02:52:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map()
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 2
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Controller 2 connected to 127.0.0.1:41108 (id: 3 rack: null) for sending state change requests
2018-09-26 02:52:17 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:42314 (id: 2 rack: null) for sending state change requests
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-09-26 02:52:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:52:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfe1d50000 type:delete cxid:0x3f zxid:0x2d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:52:17 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-09-26 02:52:18 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:52:18 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:52:18 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:52:19 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:52:19 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:52:19 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:52:20 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:52:20 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:52:20 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:52:20 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:52:20 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:52:20 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 02:52:20 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 02:52:20 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:52:20 INFO  KafkaServer:72 - [KafkaServer id=2] Controlled shutdown succeeded
2018-09-26 02:52:20 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 02:52:20 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 02:52:20 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 02:52:20 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 02:52:20 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 02:52:20 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 02:52:20 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-09-26 02:52:20 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 02:52:20 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 02:52:20 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 02:52:20 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 02:52:20 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 02:52:20 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 02:52:20 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 02:52:20 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 02:52:20 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:52:20 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:52:20 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:52:20 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 02:52:20 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 02:52:20 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 02:52:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 02:52:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 02:52:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 02:52:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 02:52:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 02:52:21 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 02:52:21 INFO  LogManager:72 - Shutting down.
2018-09-26 02:52:21 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:52:21 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:52:21 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:52:21 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:52:21 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:52:21 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:52:21 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:52:21 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:52:21 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 02:52:21 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 02:52:21 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-09-26 02:52:21 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-09-26 02:52:21 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:52:21 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Shutting down
2018-09-26 02:52:21 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Stopped
2018-09-26 02:52:21 INFO  RequestSendThread:72 - [Controller-2-to-broker-3-send-thread]: Shutdown completed
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 02:52:21 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:52:21 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdfe1d50000
2018-09-26 02:52:21 INFO  ZooKeeper:687 - Session: 0x1016fdfe1d50000 closed
2018-09-26 02:52:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:52:21 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:41178 which had sessionid 0x1016fdfe1d50000
2018-09-26 02:52:21 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdfe1d50000
2018-09-26 02:52:21 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:52:21 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] 3 successfully elected as the controller
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Starting become controller state transition
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Initialized controller epoch to 2 and zk version 1
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Incremented epoch to 3
2018-09-26 02:52:21 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Starting
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Partitions being reassigned: Map()
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Partitions already reassigned: Set()
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Resuming reassignment of partitions: Map()
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Currently active brokers in the cluster: Set(3)
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Current list of topics in the cluster: Set()
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] List of topics to be deleted: 
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] List of topics ineligible for deletion: 
2018-09-26 02:52:21 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2018-09-26 02:52:21 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Ready to serve as the new controller with epoch 3
2018-09-26 02:52:21 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Controller 3 connected to 127.0.0.1:41108 (id: 3 rack: null) for sending state change requests
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Partitions undergoing preferred replica election: 
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Partitions that completed preferred replica election: 
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Resuming preferred replica election for partitions: 
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Starting preferred replica leader election for partitions 
2018-09-26 02:52:21 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:52:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fdfe70d0000 type:delete cxid:0x46 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:52:21 INFO  KafkaController:72 - [Controller id=3] Starting the controller scheduler
2018-09-26 02:52:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:52:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:52:21 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:52:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:52:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:52:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:52:23 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:52:23 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:52:23 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 02:52:23 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 02:52:23 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 02:52:23 INFO  KafkaServer:72 - [KafkaServer id=3] shutting down
2018-09-26 02:52:23 INFO  KafkaServer:72 - [KafkaServer id=3] Starting controlled shutdown
2018-09-26 02:52:23 INFO  KafkaController:72 - [Controller id=3] Shutting down broker 3
2018-09-26 02:52:23 INFO  KafkaServer:72 - [KafkaServer id=3] Controlled shutdown succeeded
2018-09-26 02:52:23 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopping socket server request processors
2018-09-26 02:52:23 INFO  SocketServer:72 - [SocketServer brokerId=3] Stopped socket server request processors
2018-09-26 02:52:23 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shutting down
2018-09-26 02:52:23 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 3], shut down completely
2018-09-26 02:52:23 INFO  KafkaApis:72 - [KafkaApi-3] Shutdown complete.
2018-09-26 02:52:23 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutting down
2018-09-26 02:52:23 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Stopped
2018-09-26 02:52:23 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-topic]: Shutdown completed
2018-09-26 02:52:23 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutting down.
2018-09-26 02:52:23 INFO  ProducerIdManager:72 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 2000
2018-09-26 02:52:23 INFO  TransactionStateManager:72 - [Transaction State Manager 3]: Shutdown complete
2018-09-26 02:52:23 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutting down
2018-09-26 02:52:23 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Stopped
2018-09-26 02:52:23 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 3]: Shutdown completed
2018-09-26 02:52:23 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=3] Shutdown complete.
2018-09-26 02:52:23 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutting down.
2018-09-26 02:52:23 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutting down
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Stopped
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutting down
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Stopped
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2018-09-26 02:52:24 INFO  GroupCoordinator:72 - [GroupCoordinator 3]: Shutdown complete.
2018-09-26 02:52:24 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shutting down
2018-09-26 02:52:24 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:52:24 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:52:24 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:52:24 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutting down
2018-09-26 02:52:24 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 3] shutdown completed
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutting down
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Stopped
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Fetch]: Shutdown completed
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutting down
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Stopped
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-Produce]: Shutdown completed
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Stopped
2018-09-26 02:52:24 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2018-09-26 02:52:24 INFO  ReplicaManager:72 - [ReplicaManager broker=3] Shut down completely
2018-09-26 02:52:24 INFO  LogManager:72 - Shutting down.
2018-09-26 02:52:24 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:52:24 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:52:24 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:52:24 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:52:24 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:52:24 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:52:24 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:52:24 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:52:24 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2018-09-26 02:52:24 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2018-09-26 02:52:24 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutting down
2018-09-26 02:52:24 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Stopped
2018-09-26 02:52:24 INFO  RequestSendThread:72 - [Controller-3-to-broker-3-send-thread]: Shutdown completed
2018-09-26 02:52:24 INFO  KafkaController:72 - [Controller id=3] Resigned
2018-09-26 02:52:24 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:52:24 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fdfe70d0000
2018-09-26 02:52:24 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:41174 which had sessionid 0x1016fdfe70d0000
2018-09-26 02:52:24 INFO  ZooKeeper:687 - Session: 0x1016fdfe70d0000 closed
2018-09-26 02:52:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:52:24 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fdfe70d0000
2018-09-26 02:52:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:52:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:52:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:52:25 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:52:25 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:52:25 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:52:26 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:52:26 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:52:26 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutting down socket server
2018-09-26 02:52:26 INFO  SocketServer:72 - [SocketServer brokerId=3] Shutdown completed
2018-09-26 02:52:26 INFO  KafkaServer:72 - [KafkaServer id=3] shut down completed
2018-09-26 02:52:26 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:52:26 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:26 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:26 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:26 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:26 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:26 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:26 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:26 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:26 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:52:26 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:52:26 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:26 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:26 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:26 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:26 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:26 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:26 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40028
2018-09-26 02:52:27 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:27 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:27 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:27 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:27 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:27 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:27 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:27 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:27 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:28 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:28 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:28 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:28 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:28 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:28 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40028
2018-09-26 02:52:29 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:45151
	advertised.port = 45151
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:45151
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923149003-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 45151
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:40028
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:52:29 INFO  KafkaServer:72 - starting
2018-09-26 02:52:29 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:40028
2018-09-26 02:52:29 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40028 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@759d81f3
2018-09-26 02:52:29 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:52:29 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:52:29 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40028. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:29 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40028, initiating session
2018-09-26 02:52:29 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:51302
2018-09-26 02:52:29 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:51302
2018-09-26 02:52:29 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:52:29 INFO  ZooKeeperServer:693 - Established session 0x1016fe01a2f0000 with negotiated timeout 30000 for client /127.0.0.1:51302
2018-09-26 02:52:29 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40028, sessionid = 0x1016fe01a2f0000, negotiated timeout = 30000
2018-09-26 02:52:29 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:52:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:52:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:52:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:52:29 INFO  KafkaServer:72 - Cluster ID = C66QPCXqTY2rb_9tYrHnBQ
2018-09-26 02:52:29 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923149003-0/meta.properties
2018-09-26 02:52:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:52:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:52:29 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:52:29 INFO  LogManager:72 - Loading logs.
2018-09-26 02:52:29 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:52:29 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:52:29 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:52:29 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:52:29 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:52:29 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:45151.
2018-09-26 02:52:29 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:52:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:52:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:52:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:52:29 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:52:29 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:52:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:52:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:52:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:52:29 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:52:29 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:52:29 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:52:29 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:52:29 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:29 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:52:29 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:52:29 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:52:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:52:29 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:29 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:29 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:52:29 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:52:29 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:52:30 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:52:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:52:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:52:30 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:30 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,45151,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:52:30 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923149003-0/meta.properties
2018-09-26 02:52:30 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:52:30 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:52:30 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:52:30 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:45151 (id: 1 rack: null) for sending state change requests
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:52:30 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:52:30 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:52:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:52:30 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:52:30 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:30 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:30 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:52:30 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:30 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:51302 which had sessionid 0x1016fe01a2f0000
2018-09-26 02:52:30 INFO  ClientCnxn:1161 - Unable to read additional data from server sessionid 0x1016fe01a2f0000, likely server has closed socket, closing socket connection and attempting reconnect
2018-09-26 02:52:30 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:30 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:30 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:30 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:30 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:30 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:30 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:30 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:30 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:30 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:30 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:30 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:30 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:30 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:40028
2018-09-26 02:52:30 INFO  ZkClient:713 - zookeeper state changed (Disconnected)
2018-09-26 02:52:30 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:52:31 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:44729
	advertised.port = 44729
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:44729
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923151163-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 44729
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:40028
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:52:31 INFO  KafkaServer:72 - starting
2018-09-26 02:52:31 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:40028
2018-09-26 02:52:31 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:40028 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@6bff19ff
2018-09-26 02:52:31 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:52:31 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:52:31 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40028. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:31 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40028, initiating session
2018-09-26 02:52:31 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:51310
2018-09-26 02:52:31 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:51310
2018-09-26 02:52:31 INFO  FileTxnLog:213 - Creating new log file: log.1e
2018-09-26 02:52:31 INFO  ZooKeeperServer:693 - Established session 0x1016fe0229f0000 with negotiated timeout 30000 for client /127.0.0.1:51310
2018-09-26 02:52:31 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40028, sessionid = 0x1016fe0229f0000, negotiated timeout = 30000
2018-09-26 02:52:31 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:31 INFO  KafkaServer:72 - Cluster ID = C66QPCXqTY2rb_9tYrHnBQ
2018-09-26 02:52:31 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923151163-0/meta.properties
2018-09-26 02:52:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:52:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:52:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:52:31 INFO  LogManager:72 - Loading logs.
2018-09-26 02:52:31 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:52:31 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:52:31 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:52:31 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:52:31 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:52:31 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:44729.
2018-09-26 02:52:31 INFO  SocketServer:72 - [SocketServer brokerId=2] Started 1 acceptor threads
2018-09-26 02:52:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Starting
2018-09-26 02:52:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Starting
2018-09-26 02:52:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Starting
2018-09-26 02:52:31 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:52:31 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:52:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Starting
2018-09-26 02:52:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Starting
2018-09-26 02:52:31 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Starting
2018-09-26 02:52:31 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Starting up.
2018-09-26 02:52:31 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Startup complete.
2018-09-26 02:52:31 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds.
2018-09-26 02:52:31 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 02:52:31 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Starting up.
2018-09-26 02:52:31 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Startup complete.
2018-09-26 02:52:31 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Starting
2018-09-26 02:52:31 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/2 (is it secure? false)
2018-09-26 02:52:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0229f0000 type:create cxid:0x1d zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:52:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0229f0000 type:create cxid:0x1e zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:52:31 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:31 INFO  ZkUtils:72 - Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(127.0.0.1,44729,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:52:31 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923151163-0/meta.properties
2018-09-26 02:52:31 INFO  SocketServer:72 - [SocketServer brokerId=2] Started processors for 1 acceptors
2018-09-26 02:52:31 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:31 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:31 INFO  KafkaServer:72 - [KafkaServer id=2] started
2018-09-26 02:52:31 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45151, 127.0.0.1:44729]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:52:31 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:31 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:31 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:40028. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:31 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:40028, initiating session
2018-09-26 02:52:31 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:51312
2018-09-26 02:52:31 INFO  ZooKeeperServer:941 - Client attempting to renew session 0x1016fe01a2f0000 at /127.0.0.1:51312
2018-09-26 02:52:31 INFO  ZooKeeperServer:693 - Established session 0x1016fe01a2f0000 with negotiated timeout 30000 for client /127.0.0.1:51312
2018-09-26 02:52:31 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:40028, sessionid = 0x1016fe01a2f0000, negotiated timeout = 30000
2018-09-26 02:52:31 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:52:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:delete cxid:0x52 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:52:31 INFO  KafkaTestCluster:260 - Found 1 of 1 brokers ready, continuing to wait for cluster to start.
2018-09-26 02:52:31 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:52:31 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 2, deleted brokers: , all live brokers: 1,2
2018-09-26 02:52:31 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 2
2018-09-26 02:52:31 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Starting
2018-09-26 02:52:31 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Controller 1 connected to 127.0.0.1:44729 (id: 2 rack: null) for sending state change requests
2018-09-26 02:52:31 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1,2
2018-09-26 02:52:31 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45151, 127.0.0.1:44729]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:52:31 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:31 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:31 INFO  KafkaTestCluster:253 - Found 2 brokers on-line, cluster is ready.
2018-09-26 02:52:31 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45151, 127.0.0.1:44729]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:52:31 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:31 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:setData cxid:0x5c zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/topics/MultiBrokerTest2-1537923146990 Error:KeeperErrorCode = NoNode for /config/topics/MultiBrokerTest2-1537923146990
2018-09-26 02:52:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:create cxid:0x5d zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:52:32 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"1":[1,2],"0":[2,1]}}
2018-09-26 02:52:32 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(MultiBrokerTest2-1537923146990)], deleted topics: [Set()], new partition replica assignment [Map(MultiBrokerTest2-1537923146990-1 -> Vector(1, 2), MultiBrokerTest2-1537923146990-0 -> Vector(2, 1))]
2018-09-26 02:52:32 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for MultiBrokerTest2-1537923146990-1,MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for MultiBrokerTest2-1537923146990-1,MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions MultiBrokerTest2-1537923146990-1,MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=MultiBrokerTest2-1537923146990,Partition=1,Replica=1],[Topic=MultiBrokerTest2-1537923146990,Partition=1,Replica=2],[Topic=MultiBrokerTest2-1537923146990,Partition=0,Replica=2],[Topic=MultiBrokerTest2-1537923146990,Partition=0,Replica=1]
2018-09-26 02:52:32 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1537923146990-1,MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:create cxid:0x68 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest2-1537923146990/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest2-1537923146990/partitions/1
2018-09-26 02:52:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:create cxid:0x69 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest2-1537923146990/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest2-1537923146990/partitions
2018-09-26 02:52:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe01a2f0000 type:create cxid:0x6d zxid:0x2d txntype:-1 reqpath:n/a Error Path:/brokers/topics/MultiBrokerTest2-1537923146990/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/MultiBrokerTest2-1537923146990/partitions/0
2018-09-26 02:52:32 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=MultiBrokerTest2-1537923146990,Partition=1,Replica=1],[Topic=MultiBrokerTest2-1537923146990,Partition=1,Replica=2],[Topic=MultiBrokerTest2-1537923146990,Partition=0,Replica=2],[Topic=MultiBrokerTest2-1537923146990,Partition=0,Replica=1]
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  Log:72 - [Log partition=MultiBrokerTest2-1537923146990-1, dir=/tmp/1537923149003-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:52:32 INFO  Log:72 - [Log partition=MultiBrokerTest2-1537923146990-0, dir=/tmp/1537923151163-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:52:32 INFO  Log:72 - [Log partition=MultiBrokerTest2-1537923146990-1, dir=/tmp/1537923149003-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:52:32 INFO  Log:72 - [Log partition=MultiBrokerTest2-1537923146990-0, dir=/tmp/1537923151163-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:52:32 INFO  LogManager:72 - Created log for partition [MultiBrokerTest2-1537923146990,1] in /tmp/1537923149003-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:52:32 INFO  Partition:72 - [Partition MultiBrokerTest2-1537923146990-1 broker=1] No checkpointed highwatermark is found for partition MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:32 INFO  LogManager:72 - Created log for partition [MultiBrokerTest2-1537923146990,0] in /tmp/1537923151163-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:52:32 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1537923146990-1 with initial high watermark 0
2018-09-26 02:52:32 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1537923146990-1 with initial high watermark 0
2018-09-26 02:52:32 INFO  Partition:72 - [Partition MultiBrokerTest2-1537923146990-0 broker=2] No checkpointed highwatermark is found for partition MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  Partition:72 - [Partition MultiBrokerTest2-1537923146990-1 broker=1] MultiBrokerTest2-1537923146990-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:52:32 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1537923146990-0 with initial high watermark 0
2018-09-26 02:52:32 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1537923146990-0 with initial high watermark 0
2018-09-26 02:52:32 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1537923146990-0 with initial high watermark 0
2018-09-26 02:52:32 INFO  Partition:72 - [Partition MultiBrokerTest2-1537923146990-0 broker=2] MultiBrokerTest2-1537923146990-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:52:32 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1537923146990-1 with initial high watermark 0
2018-09-26 02:52:32 INFO  Log:72 - [Log partition=MultiBrokerTest2-1537923146990-0, dir=/tmp/1537923149003-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:52:32 INFO  Log:72 - [Log partition=MultiBrokerTest2-1537923146990-1, dir=/tmp/1537923151163-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:52:32 INFO  Log:72 - [Log partition=MultiBrokerTest2-1537923146990-0, dir=/tmp/1537923149003-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:52:32 INFO  Log:72 - [Log partition=MultiBrokerTest2-1537923146990-1, dir=/tmp/1537923151163-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:52:32 INFO  LogManager:72 - Created log for partition [MultiBrokerTest2-1537923146990,0] in /tmp/1537923149003-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:52:32 INFO  Partition:72 - [Partition MultiBrokerTest2-1537923146990-0 broker=1] No checkpointed highwatermark is found for partition MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1537923146990-0 with initial high watermark 0
2018-09-26 02:52:32 INFO  LogManager:72 - Created log for partition [MultiBrokerTest2-1537923146990,1] in /tmp/1537923151163-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  Partition:72 - [Partition MultiBrokerTest2-1537923146990-1 broker=2] No checkpointed highwatermark is found for partition MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:32 INFO  Replica:72 - Replica loaded for partition MultiBrokerTest2-1537923146990-1 with initial high watermark 0
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([MultiBrokerTest2-1537923146990-0, initOffset 0 to broker BrokerEndPoint(2,127.0.0.1,44729)] )
2018-09-26 02:52:32 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([MultiBrokerTest2-1537923146990-1, initOffset 0 to broker BrokerEndPoint(1,127.0.0.1,45151)] )
2018-09-26 02:52:32 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting
2018-09-26 02:52:32 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in MultiBrokerTest2-1537923146990-1. High watermark 0 will be used for truncation.
2018-09-26 02:52:32 WARN  ReplicaFetcherThread:87 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on follower's leader epoch, leader replied with an unknown offset in MultiBrokerTest2-1537923146990-0. High watermark 0 will be used for truncation.
2018-09-26 02:52:32 INFO  Log:72 - [Log partition=MultiBrokerTest2-1537923146990-1, dir=/tmp/1537923151163-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-09-26 02:52:32 INFO  Log:72 - [Log partition=MultiBrokerTest2-1537923146990-0, dir=/tmp/1537923149003-0] Truncating to 0 has no effect as the largest offset in the log is -1
2018-09-26 02:52:32 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45151, 127.0.0.1:44729]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:52:32 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:52:32 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:52:32 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:52:32 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:52:32 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:52:32 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:32 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OfflineReplica for replicas [Topic=MultiBrokerTest2-1537923146990,Partition=0,Replica=1]
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:32 INFO  Partition:72 - [Partition MultiBrokerTest2-1537923146990-1 broker=2] MultiBrokerTest2-1537923146990-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:52:32 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down
2018-09-26 02:52:32 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped
2018-09-26 02:52:32 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down
2018-09-26 02:52:32 INFO  KafkaController:72 - [Controller id=1] New leader and ISR for partition MultiBrokerTest2-1537923146990-0 is {"leader":2,"leader_epoch":1,"isr":[2]}
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] Removed fetcher for partitions MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:52:32 INFO  Partition:72 - [Partition MultiBrokerTest2-1537923146990-0 broker=2] MultiBrokerTest2-1537923146990-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:52:32 INFO  logger:72 - [Broker id=2] Skipped the become-leader state change after marking its partition as leader with correlation id 5 from controller 1 epoch 1 for partition MultiBrokerTest2-1537923146990-0 (last update controller epoch 1) since it is already the leader for the partition.
2018-09-26 02:52:32 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:52:32 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1 epoch 1 fails to send request (type=StopReplicaRequest, controllerId=1, controllerEpoch=1, deletePartitions=false, partitions=MultiBrokerTest2-1537923146990-0) to broker 127.0.0.1:45151 (id: 1 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:32 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:52:32 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:52:32 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:32 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:32 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:32 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:32 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:32 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:32 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped
2018-09-26 02:52:32 INFO  ReplicaFetcherThread:72 - [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed
2018-09-26 02:52:32 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:32 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:52:32 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:52:32 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:52:32 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:32 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:32 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:52:33 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:52:33 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:52:33 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:52:33 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:52:33 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:52:33 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:52:33 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:52:33 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:52:33 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:33 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:33 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:33 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:52:33 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:33 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:33 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:33 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:52:33 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:52:33 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:52:33 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:52:33 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:52:33 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:52:33 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:52:33 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:52:33 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:33 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:52:33 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:33 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:52:33 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:33 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:33 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:33 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:52:33 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:52:33 WARN  NetworkClient:241 - [Controller id=1, targetBrokerId=1] Connection to node 1 could not be established. Broker may not be available.
2018-09-26 02:52:33 WARN  RequestSendThread:93 - [Controller-1-to-broker-1-send-thread]: Controller 1's connection to broker 127.0.0.1:45151 (id: 1 rack: null) was unsuccessful
java.io.IOException: Connection to 127.0.0.1:45151 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:52:33 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:52:33 INFO  LogManager:72 - Shutting down.
2018-09-26 02:52:33 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:52:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:52:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:52:33 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:52:33 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:52:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:52:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:52:33 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:52:33 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:52:33 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:52:33 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutting down
2018-09-26 02:52:33 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Stopped
2018-09-26 02:52:33 INFO  RequestSendThread:72 - [Controller-1-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:52:33 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:52:33 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:52:33 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:52:33 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:52:33 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:52:33 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe01a2f0000
2018-09-26 02:52:33 INFO  ZooKeeper:687 - Session: 0x1016fe01a2f0000 closed
2018-09-26 02:52:33 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:51312 which had sessionid 0x1016fe01a2f0000
2018-09-26 02:52:33 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe01a2f0000
2018-09-26 02:52:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:52:34 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:52:34 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] 2 successfully elected as the controller
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Starting become controller state transition
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Incremented epoch to 2
2018-09-26 02:52:34 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Starting
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Partitions being reassigned: Map()
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Partitions already reassigned: Set()
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Resuming reassignment of partitions: Map()
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Currently active brokers in the cluster: Set(2)
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Current list of topics in the cluster: Set(MultiBrokerTest2-1537923146990)
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] List of topics to be deleted: 
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] List of topics ineligible for deletion: MultiBrokerTest2-1537923146990
2018-09-26 02:52:34 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Invoking state change to OnlineReplica for replicas [Topic=MultiBrokerTest2-1537923146990,Partition=1,Replica=2],[Topic=MultiBrokerTest2-1537923146990,Partition=0,Replica=2]
2018-09-26 02:52:34 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Controller 2 connected to 127.0.0.1:44729 (id: 2 rack: null) for sending state change requests
2018-09-26 02:52:34 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map([Topic=MultiBrokerTest2-1537923146990,Partition=1,Replica=2] -> OnlineReplica, [Topic=MultiBrokerTest2-1537923146990,Partition=0,Replica=2] -> OnlineReplica, [Topic=MultiBrokerTest2-1537923146990,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=MultiBrokerTest2-1537923146990,Partition=1,Replica=1] -> ReplicaDeletionIneligible)
2018-09-26 02:52:34 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map(MultiBrokerTest2-1537923146990-1 -> OnlinePartition, MultiBrokerTest2-1537923146990-0 -> OnlinePartition)
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Ready to serve as the new controller with epoch 2
2018-09-26 02:52:34 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 2 for partition MultiBrokerTest2-1537923146990-0 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Partitions undergoing preferred replica election: 
2018-09-26 02:52:34 WARN  logger:87 - [Broker id=2] Ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 2 for partition MultiBrokerTest2-1537923146990-1 since its associated leader epoch 1 is not higher than the current leader epoch 1
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Partitions that completed preferred replica election: 
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Resuming preferred replica election for partitions: 
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Starting preferred replica leader election for partitions 
2018-09-26 02:52:34 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:52:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0229f0000 type:delete cxid:0x43 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:52:34 INFO  KafkaController:72 - [Controller id=2] Starting the controller scheduler
2018-09-26 02:52:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:52:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:52:34 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:52:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:52:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:52:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:52:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:52:36 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:52:36 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:52:36 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:52:36 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:52:36 INFO  KafkaServer:72 - [KafkaServer id=2] shutting down
2018-09-26 02:52:36 INFO  KafkaServer:72 - [KafkaServer id=2] Starting controlled shutdown
2018-09-26 02:52:36 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:52:36 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:36 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-1 besides shutting down brokers 2
2018-09-26 02:52:36 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1537923146990-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:52:36 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:36 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-0 besides shutting down brokers 2
2018-09-26 02:52:36 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1537923146990-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:52:36 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: MultiBrokerTest2-1537923146990-0,MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:36 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 02:52:41 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:52:41 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:52:41 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:41 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-1 besides shutting down brokers 2
2018-09-26 02:52:41 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1537923146990-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:52:41 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:41 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-0 besides shutting down brokers 2
2018-09-26 02:52:41 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1537923146990-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:52:41 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: MultiBrokerTest2-1537923146990-0,MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:41 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 02:52:46 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:52:46 INFO  KafkaController:72 - [Controller id=2] Shutting down broker 2
2018-09-26 02:52:46 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:46 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-1 besides shutting down brokers 2
2018-09-26 02:52:46 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1537923146990-1 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-1 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-1 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-1 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:52:46 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Invoking state change to OnlinePartition for partitions MultiBrokerTest2-1537923146990-0
2018-09-26 02:52:46 ERROR logger:101 - [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-0 besides shutting down brokers 2
2018-09-26 02:52:46 ERROR logger:107 - [Controller id=2 epoch=2] Initiated state change for partition MultiBrokerTest2-1537923146990-0 from OnlinePartition to OnlinePartition failed
kafka.common.StateChangeFailedException: [Controller id=2 epoch=2] Encountered error while electing leader for partition MultiBrokerTest2-1537923146990-0 due to: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-0 besides shutting down brokers 2
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:324)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:165)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:110)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:109)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:109)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1489)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4$$anonfun$apply$23.apply(KafkaController.scala:1484)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1484)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown$4.apply(KafkaController.scala:1483)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:128)
	at kafka.controller.KafkaController$ControlledShutdown.kafka$controller$KafkaController$ControlledShutdown$$doControlledShutdown(KafkaController.scala:1483)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at kafka.controller.KafkaController$ControlledShutdown$$anonfun$31.apply(KafkaController.scala:1461)
	at scala.util.Try$.apply(Try.scala:192)
	at kafka.controller.KafkaController$ControlledShutdown.process(KafkaController.scala:1461)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 2 for MultiBrokerTest2-1537923146990-0 besides shutting down brokers 2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:186)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	... 22 more
2018-09-26 02:52:46 INFO  KafkaServer:72 - [KafkaServer id=2] Remaining partitions to move: MultiBrokerTest2-1537923146990-0,MultiBrokerTest2-1537923146990-1
2018-09-26 02:52:46 INFO  KafkaServer:72 - [KafkaServer id=2] Error code from controller: 0
2018-09-26 02:52:51 WARN  KafkaServer:87 - [KafkaServer id=2] Retrying controlled shutdown after the previous attempt failed...
2018-09-26 02:52:51 WARN  KafkaServer:87 - [KafkaServer id=2] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed
2018-09-26 02:52:51 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopping socket server request processors
2018-09-26 02:52:51 INFO  SocketServer:72 - [SocketServer brokerId=2] Stopped socket server request processors
2018-09-26 02:52:51 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shutting down
2018-09-26 02:52:51 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 2], shut down completely
2018-09-26 02:52:51 INFO  KafkaApis:72 - [KafkaApi-2] Shutdown complete.
2018-09-26 02:52:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutting down
2018-09-26 02:52:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Stopped
2018-09-26 02:52:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-topic]: Shutdown completed
2018-09-26 02:52:51 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutting down.
2018-09-26 02:52:51 INFO  ProducerIdManager:72 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000
2018-09-26 02:52:51 INFO  TransactionStateManager:72 - [Transaction State Manager 2]: Shutdown complete
2018-09-26 02:52:51 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutting down
2018-09-26 02:52:51 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Stopped
2018-09-26 02:52:51 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 2]: Shutdown completed
2018-09-26 02:52:51 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=2] Shutdown complete.
2018-09-26 02:52:51 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutting down.
2018-09-26 02:52:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutting down
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Stopped
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutting down
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Stopped
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2018-09-26 02:52:52 INFO  GroupCoordinator:72 - [GroupCoordinator 2]: Shutdown complete.
2018-09-26 02:52:52 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shutting down
2018-09-26 02:52:52 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:52:52 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:52:52 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:52:52 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutting down
2018-09-26 02:52:52 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 2] shutdown completed
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutting down
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Stopped
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Fetch]: Shutdown completed
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutting down
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Stopped
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-Produce]: Shutdown completed
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Stopped
2018-09-26 02:52:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2018-09-26 02:52:52 INFO  ReplicaManager:72 - [ReplicaManager broker=2] Shut down completely
2018-09-26 02:52:52 INFO  LogManager:72 - Shutting down.
2018-09-26 02:52:52 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:52:52 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:52:52 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:52:52 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:52:52 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:52:52 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:52:52 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:52:52 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:52:52 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2018-09-26 02:52:52 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2018-09-26 02:52:52 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutting down
2018-09-26 02:52:52 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Stopped
2018-09-26 02:52:52 INFO  RequestSendThread:72 - [Controller-2-to-broker-2-send-thread]: Shutdown completed
2018-09-26 02:52:52 INFO  KafkaController:72 - [Controller id=2] Resigned
2018-09-26 02:52:52 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:52:52 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe0229f0000
2018-09-26 02:52:52 INFO  ZooKeeper:687 - Session: 0x1016fe0229f0000 closed
2018-09-26 02:52:52 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:52:52 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:51310 which had sessionid 0x1016fe0229f0000
2018-09-26 02:52:52 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe0229f0000
2018-09-26 02:52:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:52:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:52:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:52:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:52:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:52:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:52:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:52:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:52:55 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutting down socket server
2018-09-26 02:52:55 INFO  SocketServer:72 - [SocketServer brokerId=2] Shutdown completed
2018-09-26 02:52:55 INFO  KafkaServer:72 - [KafkaServer id=2] shut down completed
2018-09-26 02:52:55 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:52:55 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:55 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:55 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:55 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:55 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:55 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:55 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:55 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 187.248 s - in com.salesforce.kafka.test.KafkaTestClusterTest
[INFO] testRestartingCluster  Time elapsed: 69.495 s
[INFO] testConsumingFromMultiBrokerClusterWhenBrokerIsStopped  Time elapsed: 36.826 s
[INFO] testGetKafkaConnectString  Time elapsed: 14.655 s
[INFO] testMultipleNodesInBroker  Time elapsed: 8.351 s
[INFO] testGetKafkaBrokersBeforeClusterHasStarted  Time elapsed: 0.003 s
[INFO] testGetKafkaBrokers  Time elapsed: 12.967 s
[INFO] testGetKafkaBrokerById  Time elapsed: 16.685 s
[INFO] testGetKafkaBrokerByIdBeforeClusterStarted  Time elapsed: 0.003 s
[INFO] testGetKafkaConnectStringBeforeClusterIsStarted  Time elapsed: 0.002 s
[INFO] testCreateTopicAcrossMultipleBrokers  Time elapsed: 28.244 s
[INFO] Running com.salesforce.kafka.test.KafkaBrokersTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.347 s - in com.salesforce.kafka.test.KafkaBrokersTest
[INFO] testSize  Time elapsed: 0.343 s
[INFO] testGetBrokerById  Time elapsed: 0.002 s
[INFO] testAsList  Time elapsed: 0.001 s
[INFO] Running com.salesforce.kafka.test.KafkaBrokerTest
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 s - in com.salesforce.kafka.test.KafkaBrokerTest
[INFO] testStart  Time elapsed: 0.004 s
[INFO] testStop  Time elapsed: 0.001 s
[INFO] testGetConnectString  Time elapsed: 0.001 s
[INFO] testGetBrokerId  Time elapsed: 0.001 s
[INFO] Running com.salesforce.kafka.test.ZookeeperTestServerTest
2018-09-26 02:52:55 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:52:55 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:55 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:55 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:55 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:55 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:55 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:55 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34139
2018-09-26 02:52:56 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:34139 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$204/1592601990@33d53216
2018-09-26 02:52:56 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34139. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:56 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34139, initiating session
2018-09-26 02:52:56 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59730
2018-09-26 02:52:56 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:59730
2018-09-26 02:52:56 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:52:56 INFO  ZooKeeperServer:693 - Established session 0x1016fe086290000 with negotiated timeout 6000 for client /127.0.0.1:59730
2018-09-26 02:52:56 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34139, sessionid = 0x1016fe086290000, negotiated timeout = 6000
2018-09-26 02:52:56 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe086290000
2018-09-26 02:52:56 INFO  ZooKeeper:687 - Session: 0x1016fe086290000 closed
2018-09-26 02:52:56 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe086290000
2018-09-26 02:52:56 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:56 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:59730 which had sessionid 0x1016fe086290000
2018-09-26 02:52:56 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:56 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:56 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:56 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:56 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:56 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:56 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:56 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:56 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:56 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:56 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:56 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:56 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:56 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:34139
2018-09-26 02:52:56 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:56 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:57 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:34139 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$204/1592601990@69a2b3b6
2018-09-26 02:52:57 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:34139. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:57 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:34139, initiating session
2018-09-26 02:52:57 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59732
2018-09-26 02:52:57 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:59732
2018-09-26 02:52:57 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-09-26 02:52:57 INFO  ZooKeeperServer:693 - Established session 0x1016fe08a900000 with negotiated timeout 6000 for client /127.0.0.1:59732
2018-09-26 02:52:57 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:34139, sessionid = 0x1016fe08a900000, negotiated timeout = 6000
2018-09-26 02:52:57 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe08a900000
2018-09-26 02:52:57 INFO  ZooKeeper:687 - Session: 0x1016fe08a900000 closed
2018-09-26 02:52:57 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe08a900000
2018-09-26 02:52:57 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:52:57 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:59732 which had sessionid 0x1016fe08a900000
2018-09-26 02:52:57 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:57 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:57 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:57 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:57 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:57 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:57 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:57 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:57 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:52:57 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:52:57 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:52:57 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:52:57 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:52:57 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:52:57 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:33766
2018-09-26 02:52:58 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:33766 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$204/1592601990@4f3e7344
2018-09-26 02:52:58 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:33766. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:52:58 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:33766, initiating session
2018-09-26 02:52:58 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:48020
2018-09-26 02:52:58 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:48020
2018-09-26 02:52:58 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:52:58 INFO  ZooKeeperServer:693 - Established session 0x1016fe08efd0000 with negotiated timeout 6000 for client /127.0.0.1:48020
2018-09-26 02:52:58 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:33766, sessionid = 0x1016fe08efd0000, negotiated timeout = 6000
2018-09-26 02:52:58 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe08efd0000
2018-09-26 02:52:59 INFO  ZooKeeper:687 - Session: 0x1016fe08efd0000 closed
2018-09-26 02:52:59 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:52:59 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe08efd0000
2018-09-26 02:52:59 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:48020 which had sessionid 0x1016fe08efd0000
2018-09-26 02:52:59 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:52:59 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:52:59 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:52:59 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:52:59 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:52:59 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:52:59 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:52:59 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:52:59 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:52:59 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:01 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:53:01 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:01 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:01 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:01 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:01 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:01 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:33766
2018-09-26 02:53:02 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:33766 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$204/1592601990@7808f638
2018-09-26 02:53:02 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:33766. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:02 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:33766, initiating session
2018-09-26 02:53:02 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:48024
2018-09-26 02:53:02 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:48024
2018-09-26 02:53:02 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-09-26 02:53:02 INFO  ZooKeeperServer:693 - Established session 0x1016fe09b780000 with negotiated timeout 6000 for client /127.0.0.1:48024
2018-09-26 02:53:02 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:33766, sessionid = 0x1016fe09b780000, negotiated timeout = 6000
2018-09-26 02:53:02 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe09b780000
2018-09-26 02:53:02 INFO  ZooKeeper:687 - Session: 0x1016fe09b780000 closed
2018-09-26 02:53:02 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:53:02 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe09b780000
2018-09-26 02:53:02 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:48024 which had sessionid 0x1016fe09b780000
2018-09-26 02:53:02 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:02 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:02 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:02 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:02 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:02 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:02 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:02 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:53:02 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:53:02 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:02 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:02 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:02 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:02 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:02 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:43168
2018-09-26 02:53:02 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:03 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:43168 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$204/1592601990@62d73ead
2018-09-26 02:53:03 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:43168. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:03 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:43168, initiating session
2018-09-26 02:53:03 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:46848
2018-09-26 02:53:03 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:46848
2018-09-26 02:53:03 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:53:03 INFO  ZooKeeperServer:693 - Established session 0x1016fe09fcb0000 with negotiated timeout 6000 for client /127.0.0.1:46848
2018-09-26 02:53:03 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:43168, sessionid = 0x1016fe09fcb0000, negotiated timeout = 6000
2018-09-26 02:53:03 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe09fcb0000
2018-09-26 02:53:03 INFO  ZooKeeper:687 - Session: 0x1016fe09fcb0000 closed
2018-09-26 02:53:03 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe09fcb0000
2018-09-26 02:53:03 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:46848 which had sessionid 0x1016fe09fcb0000
2018-09-26 02:53:03 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:03 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:03 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:03 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:03 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:03 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:03 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:03 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:53:03 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:03 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:03 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:03 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:03 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:03 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:43168
2018-09-26 02:53:04 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:43168 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$204/1592601990@1e141e42
2018-09-26 02:53:04 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:43168. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:04 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:43168, initiating session
2018-09-26 02:53:04 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:46850
2018-09-26 02:53:04 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:46850
2018-09-26 02:53:04 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-09-26 02:53:04 INFO  ZooKeeperServer:693 - Established session 0x1016fe0a42c0000 with negotiated timeout 6000 for client /127.0.0.1:46850
2018-09-26 02:53:04 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:43168, sessionid = 0x1016fe0a42c0000, negotiated timeout = 6000
2018-09-26 02:53:04 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe0a42c0000
2018-09-26 02:53:04 INFO  ZooKeeper:687 - Session: 0x1016fe0a42c0000 closed
2018-09-26 02:53:04 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe0a42c0000
2018-09-26 02:53:04 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:53:04 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:46850 which had sessionid 0x1016fe0a42c0000
2018-09-26 02:53:04 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:04 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:04 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:04 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:04 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:04 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:04 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:04 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:53:04 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:53:04 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:04 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:04 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:04 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:04 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:04 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42237
2018-09-26 02:53:05 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42237 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$204/1592601990@228cea97
2018-09-26 02:53:05 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42237. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:05 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42237, initiating session
2018-09-26 02:53:05 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:46752
2018-09-26 02:53:05 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:46752
2018-09-26 02:53:05 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:53:05 INFO  ZooKeeperServer:693 - Established session 0x1016fe0a8740000 with negotiated timeout 6000 for client /127.0.0.1:46752
2018-09-26 02:53:05 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42237, sessionid = 0x1016fe0a8740000, negotiated timeout = 6000
2018-09-26 02:53:05 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe0a8740000
2018-09-26 02:53:05 INFO  ZooKeeper:687 - Session: 0x1016fe0a8740000 closed
2018-09-26 02:53:05 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:46752 which had sessionid 0x1016fe0a8740000
2018-09-26 02:53:05 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:53:05 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe0a8740000
2018-09-26 02:53:05 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:05 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:05 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:05 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:05 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:05 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:05 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:05 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:53:05 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:53:05 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:05 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:05 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:05 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:05 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:05 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:43295
2018-09-26 02:53:05 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:05 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:05 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:06 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:43295 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$204/1592601990@1d0a61c8
2018-09-26 02:53:06 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:43295. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:06 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:43295, initiating session
2018-09-26 02:53:06 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:40914
2018-09-26 02:53:06 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:40914
2018-09-26 02:53:06 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:53:06 INFO  ZooKeeperServer:693 - Established session 0x1016fe0acda0000 with negotiated timeout 6000 for client /127.0.0.1:40914
2018-09-26 02:53:06 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:43295, sessionid = 0x1016fe0acda0000, negotiated timeout = 6000
2018-09-26 02:53:06 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe0acda0000
2018-09-26 02:53:06 INFO  ZooKeeper:687 - Session: 0x1016fe0acda0000 closed
2018-09-26 02:53:06 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:40914 which had sessionid 0x1016fe0acda0000
2018-09-26 02:53:06 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe0acda0000
2018-09-26 02:53:06 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:06 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:06 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:06 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:06 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:06 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:06 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:06 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:53:06 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:06 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:06 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:06 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:06 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:06 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:43295
2018-09-26 02:53:07 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:43295 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$204/1592601990@46731692
2018-09-26 02:53:07 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:43295. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:07 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:43295, initiating session
2018-09-26 02:53:07 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:40916
2018-09-26 02:53:07 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:40916
2018-09-26 02:53:07 INFO  FileTxnLog:213 - Creating new log file: log.4
2018-09-26 02:53:07 INFO  ZooKeeperServer:693 - Established session 0x1016fe0b13d0000 with negotiated timeout 6000 for client /127.0.0.1:40916
2018-09-26 02:53:07 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:43295, sessionid = 0x1016fe0b13d0000, negotiated timeout = 6000
2018-09-26 02:53:07 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe0b13d0000
2018-09-26 02:53:07 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:40916 which had sessionid 0x1016fe0b13d0000
2018-09-26 02:53:07 INFO  ZooKeeper:687 - Session: 0x1016fe0b13d0000 closed
2018-09-26 02:53:07 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:53:07 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe0b13d0000
2018-09-26 02:53:07 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:07 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:07 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:07 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:07 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:07 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:07 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:07 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:53:07 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:53:07 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:07 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:07 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:07 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:07 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:07 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:46300
2018-09-26 02:53:08 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:46300 sessionTimeout=1000 watcher=com.salesforce.kafka.test.ZookeeperTestServerTest$$Lambda$204/1592601990@782bf610
2018-09-26 02:53:08 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:46300. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:08 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:46300, initiating session
2018-09-26 02:53:08 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:37902
2018-09-26 02:53:08 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:37902
2018-09-26 02:53:08 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:53:08 INFO  ZooKeeperServer:693 - Established session 0x1016fe0b5a30000 with negotiated timeout 6000 for client /127.0.0.1:37902
2018-09-26 02:53:08 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:46300, sessionid = 0x1016fe0b5a30000, negotiated timeout = 6000
2018-09-26 02:53:08 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe0b5a30000
2018-09-26 02:53:08 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe0b5a30000
2018-09-26 02:53:08 INFO  ZooKeeper:687 - Session: 0x1016fe0b5a30000 closed
2018-09-26 02:53:08 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:53:08 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:37902 which had sessionid 0x1016fe0b5a30000
2018-09-26 02:53:08 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:08 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:08 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:08 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:08 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:08 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:08 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:08 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.285 s - in com.salesforce.kafka.test.ZookeeperTestServerTest
[INFO] testGetConnectStringBeforeStartingService  Time elapsed: 0 s
[INFO] testStart  Time elapsed: 2.259 s
[INFO] testStopAndStartPreservesData  Time elapsed: 4.299 s
[INFO] testRestartPreservesData  Time elapsed: 2.218 s
[INFO] testRestartCold  Time elapsed: 1.124 s
[INFO] testRestart  Time elapsed: 2.249 s
[INFO] testGetConnectString  Time elapsed: 1.131 s
[INFO] Running com.salesforce.kafka.test.KafkaTestServerTest
2018-09-26 02:53:08 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:53:08 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:08 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:08 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:08 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:08 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:08 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:43025
2018-09-26 02:53:08 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:08 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:08 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:09 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:37014
	advertised.port = 37014
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 22
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:37014
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923189935-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 37014
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:43025
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:53:09 INFO  KafkaServer:72 - starting
2018-09-26 02:53:09 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:43025
2018-09-26 02:53:09 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:43025 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@3db663d0
2018-09-26 02:53:09 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:53:09 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:53:09 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:43025. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:09 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:43025, initiating session
2018-09-26 02:53:09 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:32968
2018-09-26 02:53:09 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:32968
2018-09-26 02:53:09 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:53:09 INFO  ZooKeeperServer:693 - Established session 0x1016fe0ba130000 with negotiated timeout 30000 for client /127.0.0.1:32968
2018-09-26 02:53:09 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:43025, sessionid = 0x1016fe0ba130000, negotiated timeout = 30000
2018-09-26 02:53:09 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:53:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0ba130000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:53:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0ba130000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:53:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0ba130000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:53:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0ba130000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:53:10 INFO  KafkaServer:72 - Cluster ID = G2k_VRk0TdqKgndXKtTfaA
2018-09-26 02:53:10 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923189935-0/meta.properties
2018-09-26 02:53:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:53:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:53:10 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:53:10 INFO  LogManager:72 - Loading logs.
2018-09-26 02:53:10 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:53:10 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:53:10 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:53:10 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:53:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:53:10 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:37014.
2018-09-26 02:53:10 INFO  SocketServer:72 - [SocketServer brokerId=22] Started 1 acceptor threads
2018-09-26 02:53:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Starting
2018-09-26 02:53:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Starting
2018-09-26 02:53:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Starting
2018-09-26 02:53:10 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:53:10 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:53:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Starting
2018-09-26 02:53:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Starting
2018-09-26 02:53:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Starting
2018-09-26 02:53:10 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:53:10 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Starting up.
2018-09-26 02:53:10 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Startup complete.
2018-09-26 02:53:10 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=22] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:53:10 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:53:10 INFO  KafkaController:72 - [Controller id=22] 22 successfully elected as the controller
2018-09-26 02:53:10 INFO  KafkaController:72 - [Controller id=22] Starting become controller state transition
2018-09-26 02:53:10 INFO  ProducerIdManager:72 - [ProducerId Manager 22]: Acquired new producerId block (brokerId:22,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:53:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0ba130000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:53:10 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Starting up.
2018-09-26 02:53:10 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Startup complete.
2018-09-26 02:53:10 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Starting
2018-09-26 02:53:10 INFO  KafkaController:72 - [Controller id=22] Incremented epoch to 1
2018-09-26 02:53:10 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/22 (is it secure? false)
2018-09-26 02:53:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0ba130000 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:53:10 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0ba130000 type:create cxid:0x43 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:53:11 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:53:11 INFO  ZkUtils:72 - Registered broker 22 at path /brokers/ids/22 with addresses: EndPoint(127.0.0.1,37014,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:53:11 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923189935-0/meta.properties
2018-09-26 02:53:11 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Starting
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Partitions being reassigned: Map()
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Partitions already reassigned: Set()
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Resuming reassignment of partitions: Map()
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Currently active brokers in the cluster: Set(22)
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Currently shutting brokers in the cluster: Set()
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Current list of topics in the cluster: Set()
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] List of topics to be deleted: 
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] List of topics ineligible for deletion: 
2018-09-26 02:53:11 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=22] Started replica state machine with initial state -> Map()
2018-09-26 02:53:11 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=22] Started partition state machine with initial state -> Map()
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Ready to serve as the new controller with epoch 1
2018-09-26 02:53:11 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Controller 22 connected to 127.0.0.1:37014 (id: 22 rack: null) for sending state change requests
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Partitions undergoing preferred replica election: 
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Partitions that completed preferred replica election: 
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Resuming preferred replica election for partitions: 
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Starting preferred replica leader election for partitions 
2018-09-26 02:53:11 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=22] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:53:11 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0ba130000 type:delete cxid:0x4e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:53:11 INFO  SocketServer:72 - [SocketServer brokerId=22] Started processors for 1 acceptors
2018-09-26 02:53:11 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:11 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:11 INFO  KafkaServer:72 - [KafkaServer id=22] started
2018-09-26 02:53:11 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37014]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:53:11 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:11 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Starting the controller scheduler
2018-09-26 02:53:11 INFO  KafkaServer:72 - [KafkaServer id=22] shutting down
2018-09-26 02:53:11 INFO  KafkaServer:72 - [KafkaServer id=22] Starting controlled shutdown
2018-09-26 02:53:11 INFO  KafkaController:72 - [Controller id=22] Shutting down broker 22
2018-09-26 02:53:11 INFO  KafkaServer:72 - [KafkaServer id=22] Controlled shutdown succeeded
2018-09-26 02:53:11 INFO  SocketServer:72 - [SocketServer brokerId=22] Stopping socket server request processors
2018-09-26 02:53:11 INFO  SocketServer:72 - [SocketServer brokerId=22] Stopped socket server request processors
2018-09-26 02:53:11 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 22], shutting down
2018-09-26 02:53:11 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 22], shut down completely
2018-09-26 02:53:11 INFO  KafkaApis:72 - [KafkaApi-22] Shutdown complete.
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Shutting down
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Shutdown completed
2018-09-26 02:53:11 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Shutting down.
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-topic]: Stopped
2018-09-26 02:53:11 INFO  ProducerIdManager:72 - [ProducerId Manager 22]: Shutdown complete: last producerId assigned 0
2018-09-26 02:53:11 INFO  TransactionStateManager:72 - [Transaction State Manager 22]: Shutdown complete
2018-09-26 02:53:11 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Shutting down
2018-09-26 02:53:11 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Stopped
2018-09-26 02:53:11 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 22]: Shutdown completed
2018-09-26 02:53:11 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=22] Shutdown complete.
2018-09-26 02:53:11 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Shutting down.
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Shutting down
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Stopped
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Heartbeat]: Shutdown completed
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Shutting down
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Stopped
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Rebalance]: Shutdown completed
2018-09-26 02:53:11 INFO  GroupCoordinator:72 - [GroupCoordinator 22]: Shutdown complete.
2018-09-26 02:53:11 INFO  ReplicaManager:72 - [ReplicaManager broker=22] Shutting down
2018-09-26 02:53:11 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:53:11 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:53:11 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:53:11 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 22] shutting down
2018-09-26 02:53:11 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 22] shutdown completed
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Shutting down
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Shutdown completed
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Shutting down
2018-09-26 02:53:11 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Fetch]: Stopped
2018-09-26 02:53:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Shutdown completed
2018-09-26 02:53:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-Produce]: Stopped
2018-09-26 02:53:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Shutting down
2018-09-26 02:53:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Stopped
2018-09-26 02:53:12 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-22-DeleteRecords]: Shutdown completed
2018-09-26 02:53:12 INFO  ReplicaManager:72 - [ReplicaManager broker=22] Shut down completely
2018-09-26 02:53:12 INFO  LogManager:72 - Shutting down.
2018-09-26 02:53:12 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:53:12 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:53:12 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:53:12 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:53:12 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:53:12 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:53:12 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:53:12 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:53:12 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=22] Stopped partition state machine
2018-09-26 02:53:12 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=22] Stopped replica state machine
2018-09-26 02:53:12 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Shutting down
2018-09-26 02:53:12 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Stopped
2018-09-26 02:53:12 INFO  RequestSendThread:72 - [Controller-22-to-broker-22-send-thread]: Shutdown completed
2018-09-26 02:53:12 INFO  KafkaController:72 - [Controller id=22] Resigned
2018-09-26 02:53:12 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:53:12 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe0ba130000
2018-09-26 02:53:12 INFO  ZooKeeper:687 - Session: 0x1016fe0ba130000 closed
2018-09-26 02:53:12 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:32968 which had sessionid 0x1016fe0ba130000
2018-09-26 02:53:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:53:12 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe0ba130000
2018-09-26 02:53:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:53:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:53:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:53:13 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:53:13 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:53:13 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:53:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:53:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:53:14 INFO  SocketServer:72 - [SocketServer brokerId=22] Shutting down socket server
2018-09-26 02:53:14 INFO  SocketServer:72 - [SocketServer brokerId=22] Shutdown completed
2018-09-26 02:53:14 INFO  KafkaServer:72 - [KafkaServer id=22] shut down completed
2018-09-26 02:53:14 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:53:14 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:14 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:14 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:14 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:14 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:14 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:14 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:14 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:53:15 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:53:15 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:15 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:15 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:15 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:15 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:15 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:44347
2018-09-26 02:53:16 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:39094
	advertised.port = 39094
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:39094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923196005-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 39094
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:44347
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:53:16 INFO  KafkaServer:72 - starting
2018-09-26 02:53:16 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:44347
2018-09-26 02:53:16 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:44347 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@3bfc6a5e
2018-09-26 02:53:16 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:53:16 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:53:16 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:44347. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:16 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:44347, initiating session
2018-09-26 02:53:16 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:50794
2018-09-26 02:53:16 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:50794
2018-09-26 02:53:16 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:53:16 INFO  ZooKeeperServer:693 - Established session 0x1016fe0d1ca0000 with negotiated timeout 30000 for client /127.0.0.1:50794
2018-09-26 02:53:16 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:44347, sessionid = 0x1016fe0d1ca0000, negotiated timeout = 30000
2018-09-26 02:53:16 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:53:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:53:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:53:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:53:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:53:16 INFO  KafkaServer:72 - Cluster ID = 1gCzHK-tRKad-V0_e0t9CA
2018-09-26 02:53:16 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923196005-0/meta.properties
2018-09-26 02:53:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:53:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:53:16 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:53:16 INFO  LogManager:72 - Loading logs.
2018-09-26 02:53:16 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:53:16 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:53:16 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:53:16 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:53:16 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:53:16 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:39094.
2018-09-26 02:53:16 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:53:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:53:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:53:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:53:16 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:53:16 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:53:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:53:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:53:16 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:53:16 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:53:16 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:53:16 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:53:16 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:53:16 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:53:16 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:53:16 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:53:16 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:53:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:53:16 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:53:16 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:53:16 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:53:16 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:53:16 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:53:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:53:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x43 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:53:17 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:53:17 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,39094,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:53:17 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923196005-0/meta.properties
2018-09-26 02:53:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:53:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:53:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:53:17 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:39094 (id: 1 rack: null) for sending state change requests
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:53:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:53:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:delete cxid:0x4e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:53:17 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:53:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:17 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:53:17 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:39094]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:53:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:53:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:setData cxid:0x50 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/transactional-topic1537923195002 Error:KeeperErrorCode = NoNode for /config/topics/transactional-topic1537923195002
2018-09-26 02:53:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x51 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:53:17 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(transactional-topic1537923195002)], deleted topics: [Set()], new partition replica assignment [Map(transactional-topic1537923195002-0 -> Vector(1))]
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for transactional-topic1537923195002-0
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for transactional-topic1537923195002-0
2018-09-26 02:53:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions transactional-topic1537923195002-0
2018-09-26 02:53:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=transactional-topic1537923195002,Partition=0,Replica=1]
2018-09-26 02:53:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions transactional-topic1537923195002-0
2018-09-26 02:53:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x59 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/transactional-topic1537923195002/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/transactional-topic1537923195002/partitions/0
2018-09-26 02:53:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x5a zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/transactional-topic1537923195002/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/transactional-topic1537923195002/partitions
2018-09-26 02:53:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=transactional-topic1537923195002,Partition=0,Replica=1]
2018-09-26 02:53:17 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions transactional-topic1537923195002-0
2018-09-26 02:53:17 INFO  Log:72 - [Log partition=transactional-topic1537923195002-0, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:17 INFO  Log:72 - [Log partition=transactional-topic1537923195002-0, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:17 INFO  LogManager:72 - Created log for partition [transactional-topic1537923195002,0] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:17 INFO  Partition:72 - [Partition transactional-topic1537923195002-0 broker=1] No checkpointed highwatermark is found for partition transactional-topic1537923195002-0
2018-09-26 02:53:17 INFO  Replica:72 - Replica loaded for partition transactional-topic1537923195002-0 with initial high watermark 0
2018-09-26 02:53:17 INFO  Partition:72 - [Partition transactional-topic1537923195002-0 broker=1] transactional-topic1537923195002-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:17 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:39094]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-26 02:53:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:17 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:39094]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = MyRandomString1537923197634
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-26 02:53:17 INFO  KafkaProducer:336 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1537923197634] Instantiated a transactional producer.
2018-09-26 02:53:17 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1537923197634] Overriding the default acks to all since idempotence is enabled.
2018-09-26 02:53:17 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:17 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:17 INFO  TransactionManager:346 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1537923197634] ProducerId set to -1 with epoch -1
2018-09-26 02:53:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:setData cxid:0x63 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/__transaction_state Error:KeeperErrorCode = NoNode for /config/topics/__transaction_state
2018-09-26 02:53:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x64 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:53:17 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"2":[1],"1":[1],"3":[1],"0":[1]}}
2018-09-26 02:53:17 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __transaction_state with 4 partitions and replication factor 1 is successful
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__transaction_state)], deleted topics: [Set()], new partition replica assignment [Map(__transaction_state-1 -> Vector(1), __transaction_state-0 -> Vector(1), __transaction_state-2 -> Vector(1), __transaction_state-3 -> Vector(1))]
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-09-26 02:53:17 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-09-26 02:53:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-09-26 02:53:17 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__transaction_state,Partition=1,Replica=1],[Topic=__transaction_state,Partition=0,Replica=1],[Topic=__transaction_state,Partition=2,Replica=1],[Topic=__transaction_state,Partition=3,Replica=1]
2018-09-26 02:53:17 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __transaction_state-1,__transaction_state-0,__transaction_state-2,__transaction_state-3
2018-09-26 02:53:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x6f zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/1
2018-09-26 02:53:17 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:17 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x70 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions
2018-09-26 02:53:18 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x77 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/0
2018-09-26 02:53:18 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x7c zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/2
2018-09-26 02:53:18 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x80 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__transaction_state/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__transaction_state/partitions/3
2018-09-26 02:53:18 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__transaction_state,Partition=1,Replica=1],[Topic=__transaction_state,Partition=0,Replica=1],[Topic=__transaction_state,Partition=2,Replica=1],[Topic=__transaction_state,Partition=3,Replica=1]
2018-09-26 02:53:18 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __transaction_state-3,__transaction_state-0,__transaction_state-1,__transaction_state-2
2018-09-26 02:53:18 INFO  Log:72 - [Log partition=__transaction_state-3, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:18 INFO  Log:72 - [Log partition=__transaction_state-3, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:18 INFO  LogManager:72 - Created log for partition [__transaction_state,3] in /tmp/1537923196005-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:18 INFO  Partition:72 - [Partition __transaction_state-3 broker=1] No checkpointed highwatermark is found for partition __transaction_state-3
2018-09-26 02:53:18 INFO  Replica:72 - Replica loaded for partition __transaction_state-3 with initial high watermark 0
2018-09-26 02:53:18 INFO  Partition:72 - [Partition __transaction_state-3 broker=1] __transaction_state-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:18 INFO  Log:72 - [Log partition=__transaction_state-0, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:18 INFO  Log:72 - [Log partition=__transaction_state-0, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:18 INFO  LogManager:72 - Created log for partition [__transaction_state,0] in /tmp/1537923196005-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:18 INFO  Partition:72 - [Partition __transaction_state-0 broker=1] No checkpointed highwatermark is found for partition __transaction_state-0
2018-09-26 02:53:18 INFO  Replica:72 - Replica loaded for partition __transaction_state-0 with initial high watermark 0
2018-09-26 02:53:18 INFO  Partition:72 - [Partition __transaction_state-0 broker=1] __transaction_state-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:18 INFO  Log:72 - [Log partition=__transaction_state-1, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:18 INFO  Log:72 - [Log partition=__transaction_state-1, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:18 INFO  LogManager:72 - Created log for partition [__transaction_state,1] in /tmp/1537923196005-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:18 INFO  Partition:72 - [Partition __transaction_state-1 broker=1] No checkpointed highwatermark is found for partition __transaction_state-1
2018-09-26 02:53:18 INFO  Replica:72 - Replica loaded for partition __transaction_state-1 with initial high watermark 0
2018-09-26 02:53:18 INFO  Partition:72 - [Partition __transaction_state-1 broker=1] __transaction_state-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:18 INFO  Log:72 - [Log partition=__transaction_state-2, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:18 INFO  Log:72 - [Log partition=__transaction_state-2, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:18 INFO  LogManager:72 - Created log for partition [__transaction_state,2] in /tmp/1537923196005-0 with properties {compression.type -> uncompressed, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:18 INFO  Partition:72 - [Partition __transaction_state-2 broker=1] No checkpointed highwatermark is found for partition __transaction_state-2
2018-09-26 02:53:18 INFO  Replica:72 - Replica loaded for partition __transaction_state-2 with initial high watermark 0
2018-09-26 02:53:18 INFO  Partition:72 - [Partition __transaction_state-2 broker=1] __transaction_state-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:18 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-2
2018-09-26 02:53:18 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-1
2018-09-26 02:53:18 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-0
2018-09-26 02:53:18 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-3
2018-09-26 02:53:18 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __transaction_state-2. Cache now contains 0 entries.
2018-09-26 02:53:18 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Initialized transactionalId MyRandomString1537923197634 with producerId 0 and producer epoch 0 on partition __transaction_state-2
2018-09-26 02:53:18 INFO  TransactionManager:346 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1537923197634] ProducerId set to 0 with epoch 0
2018-09-26 02:53:18 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: transactional-topic1537923195002-0. Cache now contains 0 entries.
2018-09-26 02:53:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:setData cxid:0x92 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 02:53:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x93 zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:53:19 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-09-26 02:53:19 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 02:53:19 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 02:53:19 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:53:19 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:53:19 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:53:19 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:53:19 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:53:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0xcf zxid:0x3d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 02:53:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0xd0 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 02:53:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0xd7 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 02:53:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0xdd zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 02:53:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0xe5 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 02:53:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0xeb zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 02:53:19 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0xf1 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 02:53:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0xf7 zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 02:53:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0xfd zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 02:53:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x103 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 02:53:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x109 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 02:53:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x10f zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 02:53:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x115 zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 02:53:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x11b zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 02:53:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x122 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 02:53:20 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x127 zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 02:53:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x12d zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 02:53:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x133 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 02:53:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x139 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 02:53:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x13f zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 02:53:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x145 zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 02:53:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x14b zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 02:53:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x151 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 02:53:21 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x158 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 02:53:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x15e zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 02:53:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x164 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 02:53:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x16a zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 02:53:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x172 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 02:53:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x178 zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 02:53:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x17e zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 02:53:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x184 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 02:53:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x18a zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 02:53:22 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x190 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 02:53:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x196 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 02:53:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x19c zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 02:53:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1a2 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 02:53:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1a8 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 02:53:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1af zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 02:53:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1b5 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 02:53:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1bb zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 02:53:23 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1c1 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 02:53:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1c7 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 02:53:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1cd zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 02:53:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1d3 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 02:53:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1d9 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 02:53:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1df zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 02:53:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1e5 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 02:53:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1eb zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 02:53:24 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1f1 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 02:53:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1f7 zxid:0xcf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 02:53:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe0d1ca0000 type:create cxid:0x1fd zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 02:53:25 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:53:25 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923196005-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:25 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923196005-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:25 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537923196005-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 02:53:25 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 02:53:25 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 02:53:25 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 02:53:25 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Discovered group coordinator 127.0.0.1:39094 (id: 2147483646 rack: null)
2018-09-26 02:53:25 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Revoking previously assigned partitions []
2018-09-26 02:53:25 INFO  AbstractCoordinator:336 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] (Re-)joining group
2018-09-26 02:53:25 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 0 (__consumer_offsets-31)
2018-09-26 02:53:28 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Stabilized group test-consumer-group generation 1 (__consumer_offsets-31)
2018-09-26 02:53:28 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Assignment received from leader for group test-consumer-group for generation 1
2018-09-26 02:53:28 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-31. Cache now contains 0 entries.
2018-09-26 02:53:28 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Successfully joined group with generation 1
2018-09-26 02:53:28 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Setting newly assigned partitions [transactional-topic1537923195002-0]
2018-09-26 02:53:28 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer, transactionalId=MyRandomString1537923197634] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 02:53:28 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 1 (__consumer_offsets-31)
2018-09-26 02:53:28 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Group test-consumer-group with generation 2 is now empty (__consumer_offsets-31)
2018-09-26 02:53:28 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:53:28 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:53:28 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:53:28 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:53:28 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:53:28 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:53:28 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:53:28 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:53:28 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:53:28 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:53:28 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:53:28 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:53:28 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:53:28 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1
2018-09-26 02:53:28 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:53:28 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:53:28 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:53:28 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:53:28 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:53:28 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:53:28 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:53:28 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:53:28 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:53:28 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:53:28 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:53:28 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:53:28 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:53:28 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:53:28 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:53:28 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:53:28 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:53:28 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:53:28 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:53:28 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:53:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:53:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:53:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:53:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:53:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:53:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:53:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:53:29 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:53:29 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:53:29 INFO  LogManager:72 - Shutting down.
2018-09-26 02:53:29 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:53:29 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:53:29 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:53:29 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:53:29 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__transaction_state-2] Writing producer snapshot at offset 4
2018-09-26 02:53:30 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2
2018-09-26 02:53:30 INFO  ProducerStateManager:72 - [ProducerStateManager partition=transactional-topic1537923195002-0] Writing producer snapshot at offset 2
2018-09-26 02:53:31 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:53:31 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:53:31 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:53:31 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:53:31 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:53:31 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:53:31 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:53:31 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:53:31 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:53:31 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:53:31 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:53:31 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe0d1ca0000
2018-09-26 02:53:31 INFO  ZooKeeper:687 - Session: 0x1016fe0d1ca0000 closed
2018-09-26 02:53:31 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:50794 which had sessionid 0x1016fe0d1ca0000
2018-09-26 02:53:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:53:31 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe0d1ca0000
2018-09-26 02:53:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:53:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:53:31 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:53:32 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:53:32 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:53:32 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:53:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:53:33 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:53:33 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:53:33 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:53:33 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:53:33 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:53:33 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:33 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:33 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:33 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:33 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:33 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:33 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:33 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:53:33 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:53:33 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:33 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:33 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:33 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:33 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:33 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:41400
2018-09-26 02:53:34 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:45478
	advertised.port = 45478
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:45478
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923214832-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 45478
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:41400
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:53:34 INFO  KafkaServer:72 - starting
2018-09-26 02:53:34 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:41400
2018-09-26 02:53:34 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:41400 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@37af1f93
2018-09-26 02:53:34 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:53:34 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:53:34 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:41400. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:34 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:41400, initiating session
2018-09-26 02:53:34 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:34808
2018-09-26 02:53:34 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:34808
2018-09-26 02:53:34 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:53:34 INFO  ZooKeeperServer:693 - Established session 0x1016fe11b540000 with negotiated timeout 30000 for client /127.0.0.1:34808
2018-09-26 02:53:34 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:41400, sessionid = 0x1016fe11b540000, negotiated timeout = 30000
2018-09-26 02:53:34 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:53:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe11b540000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:53:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe11b540000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:53:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe11b540000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:53:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe11b540000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:53:35 INFO  KafkaServer:72 - Cluster ID = PTlWOT-LQMKYMmP1MEQS6A
2018-09-26 02:53:35 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923214832-0/meta.properties
2018-09-26 02:53:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:53:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:53:35 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:53:35 INFO  LogManager:72 - Loading logs.
2018-09-26 02:53:35 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 02:53:35 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:53:35 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:53:35 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:53:35 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:53:35 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:45478.
2018-09-26 02:53:35 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:53:35 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:53:35 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:53:35 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:53:35 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:53:35 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:53:35 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:53:35 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:53:35 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:53:35 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:53:35 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:53:35 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:53:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:53:35 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:53:35 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:53:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe11b540000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:53:35 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:53:35 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:53:35 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:53:35 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:53:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe11b540000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:53:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe11b540000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:53:35 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:53:35 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,45478,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:53:35 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923214832-0/meta.properties
2018-09-26 02:53:35 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:53:35 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:53:35 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:53:35 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:45478 (id: 1 rack: null) for sending state change requests
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:53:35 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:53:35 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:53:35 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe11b540000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:53:35 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:35 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:53:35 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:35 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:35 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:53:35 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:53:35 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:53:36 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:53:36 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-09-26 02:53:36 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:53:36 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:53:36 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:53:36 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:53:36 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:53:36 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:53:36 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:53:36 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:53:36 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:53:36 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:53:36 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:53:36 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:53:36 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:53:36 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:53:36 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:53:36 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:53:36 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:53:36 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:53:36 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:53:36 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:53:36 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:53:36 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:53:36 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:53:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:53:37 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:53:37 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:53:37 INFO  LogManager:72 - Shutting down.
2018-09-26 02:53:37 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:53:37 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:53:37 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:53:37 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:53:37 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:53:37 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:53:37 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:53:37 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:53:37 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:53:37 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:53:37 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:53:37 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:53:37 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:53:37 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:53:37 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:53:37 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe11b540000
2018-09-26 02:53:37 INFO  ZooKeeper:687 - Session: 0x1016fe11b540000 closed
2018-09-26 02:53:37 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:34808 which had sessionid 0x1016fe11b540000
2018-09-26 02:53:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:53:37 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe11b540000
2018-09-26 02:53:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:53:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:53:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:53:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:53:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:53:37 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:53:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:53:38 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:53:38 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:53:38 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:53:38 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:53:38 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:53:38 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:38 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:38 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:38 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:38 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:38 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:38 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:38 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:53:38 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:53:38 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:38 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:38 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:38 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:38 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:38 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:35373
2018-09-26 02:53:38 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:39 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:42726
	advertised.port = 42726
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:42726
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923219684-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 42726
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:35373
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:53:39 INFO  KafkaServer:72 - starting
2018-09-26 02:53:39 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:35373
2018-09-26 02:53:39 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:35373 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@7173ae5b
2018-09-26 02:53:39 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:53:39 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:53:39 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:35373. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:39 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:35373, initiating session
2018-09-26 02:53:39 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:54616
2018-09-26 02:53:39 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:54616
2018-09-26 02:53:39 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:53:39 INFO  ZooKeeperServer:693 - Established session 0x1016fe12e490000 with negotiated timeout 30000 for client /127.0.0.1:54616
2018-09-26 02:53:39 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:35373, sessionid = 0x1016fe12e490000, negotiated timeout = 30000
2018-09-26 02:53:39 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:53:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:53:39 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:53:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:53:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:53:40 INFO  KafkaServer:72 - Cluster ID = JsOIDQXeT0OSPfe-PEnF3w
2018-09-26 02:53:40 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923219684-0/meta.properties
2018-09-26 02:53:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:53:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:53:40 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:53:40 INFO  LogManager:72 - Loading logs.
2018-09-26 02:53:40 INFO  LogManager:72 - Logs loading complete in 0 ms.
2018-09-26 02:53:40 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:53:40 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:53:40 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:53:40 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:53:40 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:42726.
2018-09-26 02:53:40 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:53:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:53:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:53:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:53:40 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:53:40 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:53:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:53:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:53:40 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:53:40 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:53:40 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:53:40 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:53:40 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:53:40 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:53:40 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:53:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:53:40 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:53:40 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:53:40 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:53:40 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:53:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:53:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x43 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:53:40 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:53:40 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,42726,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:53:40 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923219684-0/meta.properties
2018-09-26 02:53:40 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:53:40 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:53:40 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:53:40 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:42726 (id: 1 rack: null) for sending state change requests
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:53:40 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:53:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:delete cxid:0x4e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:53:40 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:53:40 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:40 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:40 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:53:40 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:42726]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:53:40 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:40 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:40 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:53:40 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:setData cxid:0x50 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/subscribe-topic1537923218680 Error:KeeperErrorCode = NoNode for /config/topics/subscribe-topic1537923218680
2018-09-26 02:53:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x51 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:53:41 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-09-26 02:53:41 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(subscribe-topic1537923218680)], deleted topics: [Set()], new partition replica assignment [Map(subscribe-topic1537923218680-0 -> Vector(1))]
2018-09-26 02:53:41 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for subscribe-topic1537923218680-0
2018-09-26 02:53:41 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for subscribe-topic1537923218680-0
2018-09-26 02:53:41 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions subscribe-topic1537923218680-0
2018-09-26 02:53:41 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=subscribe-topic1537923218680,Partition=0,Replica=1]
2018-09-26 02:53:41 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions subscribe-topic1537923218680-0
2018-09-26 02:53:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x59 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/subscribe-topic1537923218680/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/subscribe-topic1537923218680/partitions/0
2018-09-26 02:53:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x5a zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/subscribe-topic1537923218680/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/subscribe-topic1537923218680/partitions
2018-09-26 02:53:41 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=subscribe-topic1537923218680,Partition=0,Replica=1]
2018-09-26 02:53:41 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions subscribe-topic1537923218680-0
2018-09-26 02:53:41 INFO  Log:72 - [Log partition=subscribe-topic1537923218680-0, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:41 INFO  Log:72 - [Log partition=subscribe-topic1537923218680-0, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:41 INFO  LogManager:72 - Created log for partition [subscribe-topic1537923218680,0] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:41 INFO  Partition:72 - [Partition subscribe-topic1537923218680-0 broker=1] No checkpointed highwatermark is found for partition subscribe-topic1537923218680-0
2018-09-26 02:53:41 INFO  Replica:72 - Replica loaded for partition subscribe-topic1537923218680-0 with initial high watermark 0
2018-09-26 02:53:41 INFO  Partition:72 - [Partition subscribe-topic1537923218680-0 broker=1] subscribe-topic1537923218680-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:41 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:42726]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-26 02:53:41 WARN  ProducerConfig:246 - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2018-09-26 02:53:41 WARN  ProducerConfig:246 - The configuration 'group.id' was supplied but isn't a known config.
2018-09-26 02:53:41 WARN  ProducerConfig:246 - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2018-09-26 02:53:41 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:41 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:41 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: subscribe-topic1537923218680-0. Cache now contains 0 entries.
2018-09-26 02:53:41 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 02:53:41 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:42726]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-26 02:53:41 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:41 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:setData cxid:0x63 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 02:53:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x64 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:53:41 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-09-26 02:53:41 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 02:53:41 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 02:53:41 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:53:41 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:53:41 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:53:41 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:53:41 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:53:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xa0 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 02:53:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xa1 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 02:53:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xa8 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 02:53:41 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xae zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 02:53:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xb4 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 02:53:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xbc zxid:0x39 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 02:53:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xc2 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 02:53:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xc8 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 02:53:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xce zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 02:53:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xd5 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 02:53:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xda zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 02:53:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xe1 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 02:53:42 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xe6 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 02:53:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xec zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 02:53:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xf2 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 02:53:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xf8 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 02:53:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0xfe zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 02:53:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x104 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 02:53:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x10a zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 02:53:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x110 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 02:53:43 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x116 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 02:53:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x11c zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 02:53:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x122 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 02:53:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x128 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 02:53:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x12e zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 02:53:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x134 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 02:53:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x13a zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 02:53:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x140 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 02:53:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x146 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 02:53:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x14c zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 02:53:44 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x152 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 02:53:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x158 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 02:53:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x15e zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 02:53:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x164 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 02:53:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x16a zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 02:53:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x170 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 02:53:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x176 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 02:53:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x17c zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 02:53:45 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x182 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 02:53:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x188 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 02:53:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x18e zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 02:53:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x194 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 02:53:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x19a zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 02:53:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x1a0 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 02:53:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x1a6 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 02:53:46 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x1ac zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 02:53:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x1b2 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 02:53:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x1b8 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 02:53:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x1be zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 02:53:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x1c4 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 02:53:47 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe12e490000 type:create cxid:0x1ca zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 02:53:47 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:53:47 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923219684-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:47 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923219684-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:47 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537923219684-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 02:53:47 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 02:53:47 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 02:53:47 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 02:53:48 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 02:53:48 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Discovered group coordinator 127.0.0.1:42726 (id: 2147483646 rack: null)
2018-09-26 02:53:48 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Revoking previously assigned partitions []
2018-09-26 02:53:48 INFO  AbstractCoordinator:336 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] (Re-)joining group
2018-09-26 02:53:48 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 0 (__consumer_offsets-31)
2018-09-26 02:53:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Stabilized group test-consumer-group generation 1 (__consumer_offsets-31)
2018-09-26 02:53:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Assignment received from leader for group test-consumer-group for generation 1
2018-09-26 02:53:51 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-31. Cache now contains 0 entries.
2018-09-26 02:53:51 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Successfully joined group with generation 1
2018-09-26 02:53:51 INFO  ConsumerCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=test-consumer-group] Setting newly assigned partitions [subscribe-topic1537923218680-0]
2018-09-26 02:53:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group test-consumer-group with old generation 1 (__consumer_offsets-31)
2018-09-26 02:53:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Group test-consumer-group with generation 2 is now empty (__consumer_offsets-31)
2018-09-26 02:53:51 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:53:51 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:53:51 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:53:51 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:53:51 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:53:51 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:53:51 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:53:51 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:53:51 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:53:51 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:53:51 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:53:51 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:53:51 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:53:51 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:53:51 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:53:51 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:53:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:53:51 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:53:51 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:53:51 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:53:51 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:53:51 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:53:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:53:51 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:53:51 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:53:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:53:52 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:53:52 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:53:52 INFO  LogManager:72 - Shutting down.
2018-09-26 02:53:52 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:53:52 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:53:52 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:53:52 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:53:52 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2
2018-09-26 02:53:52 INFO  ProducerStateManager:72 - [ProducerStateManager partition=subscribe-topic1537923218680-0] Writing producer snapshot at offset 1
2018-09-26 02:53:53 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:53:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:53:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:53:53 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:53:53 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:53:53 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:53:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:53:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:53:53 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:53:53 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:53:53 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:53:53 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe12e490000
2018-09-26 02:53:53 INFO  ZooKeeper:687 - Session: 0x1016fe12e490000 closed
2018-09-26 02:53:53 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:54616 which had sessionid 0x1016fe12e490000
2018-09-26 02:53:53 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe12e490000
2018-09-26 02:53:53 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:53:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:53:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:53:54 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:53:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:53:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:53:55 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:53:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:53:56 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:53:56 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:53:56 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:53:56 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:53:56 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:53:56 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:53:56 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:53:56 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:53:56 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:53:56 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:53:56 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:53:56 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:53:56 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:53:56 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:53:56 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:53:56 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:53:56 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:53:56 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:53:56 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:53:56 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:44856
2018-09-26 02:53:56 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:53:57 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:45078
	advertised.port = 45078
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:45078
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923237524-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 45078
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:44856
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:53:57 INFO  KafkaServer:72 - starting
2018-09-26 02:53:57 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:44856
2018-09-26 02:53:57 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:44856 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@282ffbf5
2018-09-26 02:53:57 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:53:57 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:53:57 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:44856. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:53:57 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:44856, initiating session
2018-09-26 02:53:57 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:35292
2018-09-26 02:53:57 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:35292
2018-09-26 02:53:57 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:53:57 INFO  ZooKeeperServer:693 - Established session 0x1016fe173f80000 with negotiated timeout 30000 for client /127.0.0.1:35292
2018-09-26 02:53:57 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:44856, sessionid = 0x1016fe173f80000, negotiated timeout = 30000
2018-09-26 02:53:57 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:53:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:53:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:53:57 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:53:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:53:58 INFO  KafkaServer:72 - Cluster ID = zEji36V0T1Sh3cW4izrCbQ
2018-09-26 02:53:58 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923237524-0/meta.properties
2018-09-26 02:53:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:53:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:53:58 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:53:58 INFO  LogManager:72 - Loading logs.
2018-09-26 02:53:58 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 02:53:58 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:53:58 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:53:58 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:53:58 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:53:58 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:45078.
2018-09-26 02:53:58 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:53:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:53:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:53:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:53:58 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:53:58 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:53:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:53:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:53:58 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:53:58 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:53:58 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:53:58 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:53:58 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:53:58 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:53:58 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:53:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:53:58 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:53:58 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:53:58 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:53:58 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:53:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:53:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x43 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:53:58 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:53:58 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,45078,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:53:58 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923237524-0/meta.properties
2018-09-26 02:53:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:53:58 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:53:58 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:53:58 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:45078 (id: 1 rack: null) for sending state change requests
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:53:58 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:53:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:delete cxid:0x4e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:53:58 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:53:58 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:58 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:58 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:53:58 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45078]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:53:58 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:58 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:53:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:setData cxid:0x50 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/testRestartingBroker-1537923236520 Error:KeeperErrorCode = NoNode for /config/topics/testRestartingBroker-1537923236520
2018-09-26 02:53:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x51 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:53:58 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(testRestartingBroker-1537923236520)], deleted topics: [Set()], new partition replica assignment [Map(testRestartingBroker-1537923236520-0 -> Vector(1))]
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for testRestartingBroker-1537923236520-0
2018-09-26 02:53:58 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for testRestartingBroker-1537923236520-0
2018-09-26 02:53:58 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions testRestartingBroker-1537923236520-0
2018-09-26 02:53:58 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=testRestartingBroker-1537923236520,Partition=0,Replica=1]
2018-09-26 02:53:58 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions testRestartingBroker-1537923236520-0
2018-09-26 02:53:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x59 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/testRestartingBroker-1537923236520/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/testRestartingBroker-1537923236520/partitions/0
2018-09-26 02:53:58 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x5a zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/testRestartingBroker-1537923236520/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/testRestartingBroker-1537923236520/partitions
2018-09-26 02:53:59 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=testRestartingBroker-1537923236520,Partition=0,Replica=1]
2018-09-26 02:53:59 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions testRestartingBroker-1537923236520-0
2018-09-26 02:53:59 INFO  Log:72 - [Log partition=testRestartingBroker-1537923236520-0, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:53:59 INFO  Log:72 - [Log partition=testRestartingBroker-1537923236520-0, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:53:59 INFO  LogManager:72 - Created log for partition [testRestartingBroker-1537923236520,0] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:53:59 INFO  Partition:72 - [Partition testRestartingBroker-1537923236520-0 broker=1] No checkpointed highwatermark is found for partition testRestartingBroker-1537923236520-0
2018-09-26 02:53:59 INFO  Replica:72 - Replica loaded for partition testRestartingBroker-1537923236520-0 with initial high watermark 0
2018-09-26 02:53:59 INFO  Partition:72 - [Partition testRestartingBroker-1537923236520-0 broker=1] testRestartingBroker-1537923236520-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:53:59 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:45078]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 02:53:59 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:59 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:59 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: testRestartingBroker-1537923236520-0. Cache now contains 0 entries.
2018-09-26 02:53:59 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 02:53:59 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45078]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:53:59 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:59 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:53:59 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:45078]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 02:53:59 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:53:59 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:setData cxid:0x63 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 02:54:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x64 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:54:03 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-09-26 02:54:03 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 02:54:03 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 02:54:03 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:54:03 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:54:03 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:54:03 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:54:03 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:54:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xa0 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 02:54:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xa1 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 02:54:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xaa zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 02:54:03 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xb0 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 02:54:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xb6 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 02:54:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xbc zxid:0x39 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 02:54:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xc2 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 02:54:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xc8 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 02:54:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xcf zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 02:54:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xd5 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 02:54:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xdb zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 02:54:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xe1 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 02:54:04 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xe7 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 02:54:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xed zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 02:54:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xf3 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 02:54:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xf9 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 02:54:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0xff zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 02:54:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x105 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 02:54:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x10b zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 02:54:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x111 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 02:54:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x117 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 02:54:05 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x11d zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 02:54:06 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x123 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 02:54:06 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x12b zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 02:54:06 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x131 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 02:54:06 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x137 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 02:54:06 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x13d zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 02:54:06 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x143 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 02:54:06 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x149 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 02:54:06 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x14f zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 02:54:06 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x155 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 02:54:07 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x15b zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 02:54:07 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x161 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 02:54:07 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x167 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 02:54:07 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x16d zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 02:54:07 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x173 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 02:54:07 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x179 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 02:54:07 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x180 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 02:54:07 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x186 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 02:54:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x18c zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 02:54:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x194 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 02:54:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x19a zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 02:54:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x1a0 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 02:54:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x1a6 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 02:54:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x1ad zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 02:54:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x1b3 zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 02:54:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x1b9 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 02:54:08 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x1bf zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 02:54:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x1c5 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 02:54:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x1cb zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 02:54:09 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe173f80000 type:create cxid:0x1d1 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 02:54:09 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:54:09 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:09 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:09 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537923237524-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 02:54:09 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 02:54:09 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 02:54:09 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 02:54:09 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:45078 (id: 2147483646 rack: null)
2018-09-26 02:54:09 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-09-26 02:54:09 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:54:09 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:54:09 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:54:09 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:54:09 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:54:09 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:54:09 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:54:09 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:54:09 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:54:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:54:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:54:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:54:09 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:54:09 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:54:09 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:54:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:54:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:54:09 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:54:09 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:54:09 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:54:09 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:54:10 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:54:10 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:54:10 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:54:10 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:54:10 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:54:10 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:54:10 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:54:10 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:54:10 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:54:10 INFO  LogManager:72 - Shutting down.
2018-09-26 02:54:10 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:54:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:54:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:54:10 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:54:10 INFO  ProducerStateManager:72 - [ProducerStateManager partition=testRestartingBroker-1537923236520-0] Writing producer snapshot at offset 2
2018-09-26 02:54:11 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 1
2018-09-26 02:54:12 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:54:12 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:54:12 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:54:12 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:54:12 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:54:12 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:54:12 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:54:12 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:54:12 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:54:12 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:54:12 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:54:12 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe173f80000
2018-09-26 02:54:12 INFO  ZooKeeper:687 - Session: 0x1016fe173f80000 closed
2018-09-26 02:54:12 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:35292 which had sessionid 0x1016fe173f80000
2018-09-26 02:54:12 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe173f80000
2018-09-26 02:54:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:54:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:54:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:54:12 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:54:13 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:54:13 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:54:13 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:54:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:54:14 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:54:14 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:54:14 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:54:14 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:54:14 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:54:14 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:54:14 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:54:14 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:54:14 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:54:14 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:54:14 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:54:14 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:54:14 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
2018-09-26 02:54:14 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:54:14 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:54:14 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:54:14 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:54:14 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:54:14 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:44856
2018-09-26 02:54:14 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:54:15 INFO  KafkaServer:72 - [KafkaServer id=1] starting
2018-09-26 02:54:15 INFO  KafkaServer:72 - [KafkaServer id=1] Connecting to zookeeper on 127.0.0.1:44856
2018-09-26 02:54:15 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:44856 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@6ec7bce0
2018-09-26 02:54:15 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:54:15 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:44856. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:54:15 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:54:15 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:44856, initiating session
2018-09-26 02:54:15 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:35322
2018-09-26 02:54:15 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:35322
2018-09-26 02:54:15 INFO  FileTxnLog:213 - Creating new log file: log.c4
2018-09-26 02:54:15 INFO  ZooKeeperServer:693 - Established session 0x1016fe1b9ac0000 with negotiated timeout 30000 for client /127.0.0.1:35322
2018-09-26 02:54:15 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:44856, sessionid = 0x1016fe1b9ac0000, negotiated timeout = 30000
2018-09-26 02:54:15 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:54:15 INFO  KafkaServer:72 - [KafkaServer id=1] Cluster ID = zEji36V0T1Sh3cW4izrCbQ
2018-09-26 02:54:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:54:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:54:15 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:54:15 INFO  LogManager:72 - Loading logs.
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=testRestartingBroker-1537923236520-0, dir=/tmp/1537923237524-0] Loading producer state from offset 2 with message format version 2
2018-09-26 02:54:15 INFO  ProducerStateManager:72 - [ProducerStateManager partition=testRestartingBroker-1537923236520-0] Loading producer state from snapshot file '/tmp/1537923237524-0/testRestartingBroker-1537923236520-0/00000000000000000002.snapshot'
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=testRestartingBroker-1537923236520-0, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 3 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923237524-0] Loading producer state from offset 1 with message format version 2
2018-09-26 02:54:15 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file '/tmp/1537923237524-0/__consumer_offsets-0/00000000000000000001.snapshot'
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923237524-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:15 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923237524-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms
2018-09-26 02:54:15 INFO  LogManager:72 - Logs loading complete in 100 ms.
2018-09-26 02:54:15 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:54:15 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:54:15 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:54:15 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:54:15 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:45078.
2018-09-26 02:54:15 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:54:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:54:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:54:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:54:15 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:54:15 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:54:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:54:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:54:15 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:54:15 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:54:15 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:54:15 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:54:15 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:54:15 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:54:15 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] Initialized controller epoch to 1 and zk version 0
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 2
2018-09-26 02:54:15 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:54:15 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:54:15 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:54:15 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:54:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1b9ac0000 type:create cxid:0x3d zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:54:15 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1b9ac0000 type:create cxid:0x3e zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:54:15 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:54:15 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,45078,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:54:15 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:54:15 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:15 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:15 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:54:15 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:45078]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:54:15 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:15 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set()
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set(testRestartingBroker-1537923236520, __consumer_offsets)
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:54:15 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: __consumer_offsets,testRestartingBroker-1537923236520
2018-09-26 02:54:15 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map([Topic=__consumer_offsets,Partition=48,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=11,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=10,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=21,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=6,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=13,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=34,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=26,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=44,Replica=1] -> ReplicaDeletionIneligible, [Topic=testRestartingBroker-1537923236520,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=46,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=12,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=33,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=47,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=37,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=23,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=42,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=32,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=2,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=43,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=4,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=40,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=28,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=15,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=22,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=3,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=7,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=38,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=16,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=8,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=17,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=36,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=49,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=29,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=45,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=0,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=5,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=41,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=27,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=24,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=30,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=31,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=1,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=35,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=19,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=20,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=9,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=14,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=25,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=18,Replica=1] -> ReplicaDeletionIneligible, [Topic=__consumer_offsets,Partition=39,Replica=1] -> ReplicaDeletionIneligible)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-19 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-19 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-30 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-30 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition testRestartingBroker-1537923236520-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition testRestartingBroker-1537923236520-0 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-47 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-47 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-29 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-29 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-41 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-41 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-39 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-39 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-10 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-10 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-17 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-17 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-14 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-14 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-40 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-40 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-18 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-18 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-0 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-0 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-26 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-26 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-24 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-24 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-33 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-33 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-20 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-20 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-21 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-21 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-3 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-3 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-22 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-22 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-5 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-5 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-12 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-12 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-8 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-8 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-23 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-23 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-15 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-15 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:15 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-48 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-48 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-11 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-11 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-13 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-13 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-49 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-49 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-6 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-6 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-28 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-28 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-4 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-4 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-37 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-37 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-31 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-31 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-44 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-44 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-42 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-42 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-34 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-34 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-46 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-46 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-25 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-25 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-45 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-45 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-27 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-27 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-32 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-32 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-43 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-43 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-36 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-36 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-35 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-35 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-7 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-7 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-9 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-9 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-38 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-38 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-1 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-1 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-2 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-2 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 ERROR logger:107 - [Controller id=1 epoch=2] Initiated state change for partition __consumer_offsets-16 from OfflinePartition to OnlinePartition failed
kafka.common.NoReplicaOnlineException: No replica in ISR for partition __consumer_offsets-16 is alive. Live brokers are: [Set()], ISR brokers are: [1]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:65)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:303)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:163)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:84)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:81)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:81)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:58)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:298)
	at kafka.controller.KafkaController.elect(KafkaController.scala:1681)
	at kafka.controller.KafkaController$Startup$.process(KafkaController.scala:1581)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:53)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
	at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:52)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-09-26 02:54:16 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map(__consumer_offsets-19 -> OfflinePartition, __consumer_offsets-30 -> OfflinePartition, testRestartingBroker-1537923236520-0 -> OfflinePartition, __consumer_offsets-47 -> OfflinePartition, __consumer_offsets-29 -> OfflinePartition, __consumer_offsets-41 -> OfflinePartition, __consumer_offsets-39 -> OfflinePartition, __consumer_offsets-10 -> OfflinePartition, __consumer_offsets-17 -> OfflinePartition, __consumer_offsets-14 -> OfflinePartition, __consumer_offsets-40 -> OfflinePartition, __consumer_offsets-18 -> OfflinePartition, __consumer_offsets-0 -> OfflinePartition, __consumer_offsets-26 -> OfflinePartition, __consumer_offsets-24 -> OfflinePartition, __consumer_offsets-33 -> OfflinePartition, __consumer_offsets-20 -> OfflinePartition, __consumer_offsets-21 -> OfflinePartition, __consumer_offsets-3 -> OfflinePartition, __consumer_offsets-22 -> OfflinePartition, __consumer_offsets-5 -> OfflinePartition, __consumer_offsets-12 -> OfflinePartition, __consumer_offsets-8 -> OfflinePartition, __consumer_offsets-23 -> OfflinePartition, __consumer_offsets-15 -> OfflinePartition, __consumer_offsets-48 -> OfflinePartition, __consumer_offsets-11 -> OfflinePartition, __consumer_offsets-13 -> OfflinePartition, __consumer_offsets-49 -> OfflinePartition, __consumer_offsets-6 -> OfflinePartition, __consumer_offsets-28 -> OfflinePartition, __consumer_offsets-4 -> OfflinePartition, __consumer_offsets-37 -> OfflinePartition, __consumer_offsets-31 -> OfflinePartition, __consumer_offsets-44 -> OfflinePartition, __consumer_offsets-42 -> OfflinePartition, __consumer_offsets-34 -> OfflinePartition, __consumer_offsets-46 -> OfflinePartition, __consumer_offsets-25 -> OfflinePartition, __consumer_offsets-45 -> OfflinePartition, __consumer_offsets-27 -> OfflinePartition, __consumer_offsets-32 -> OfflinePartition, __consumer_offsets-43 -> OfflinePartition, __consumer_offsets-36 -> OfflinePartition, __consumer_offsets-35 -> OfflinePartition, __consumer_offsets-7 -> OfflinePartition, __consumer_offsets-9 -> OfflinePartition, __consumer_offsets-38 -> OfflinePartition, __consumer_offsets-1 -> OfflinePartition, __consumer_offsets-2 -> OfflinePartition, __consumer_offsets-16 -> OfflinePartition)
2018-09-26 02:54:16 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 2
2018-09-26 02:54:16 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:54:16 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:54:16 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:54:16 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:54:16 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:54:16 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:54:16 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1b9ac0000 type:delete cxid:0xdb zxid:0xcb txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:54:16 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:54:16 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: 1, deleted brokers: , all live brokers: 1
2018-09-26 02:54:16 INFO  KafkaController:72 - [Controller id=1] New broker startup callback for 1
2018-09-26 02:54:16 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:54:16 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=testRestartingBroker-1537923236520,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:54:16 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:45078 (id: 1 rack: null) for sending state change requests
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-19
2018-09-26 02:54:16 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,testRestartingBroker-1537923236520-0,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 02:54:16 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:45078]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 02:54:16 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:16 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-30
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 1
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition testRestartingBroker-1537923236520-0
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-47
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-29
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-41
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-39
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-10
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-17
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-14
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-40
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-18
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-0
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-26
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-24
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:16 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 02:54:16 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-33
2018-09-26 02:54:16 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-20
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-21
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition testRestartingBroker-1537923236520-0 with initial high watermark 2
2018-09-26 02:54:17 INFO  Partition:72 - [Partition testRestartingBroker-1537923236520-0 broker=1] testRestartingBroker-1537923236520-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-3
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-22
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-5
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-12
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-8
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-23
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-15
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-48
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-11
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-13
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-49
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-6
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-28
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-4
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-37
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-31
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-44
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-42
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-34
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-46
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-25
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-45
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-27
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:17 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 02:54:17 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-32
2018-09-26 02:54:17 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:18 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 02:54:18 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-43
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:18 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 02:54:18 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-36
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:18 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 02:54:18 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-35
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:18 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 02:54:18 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-7
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:18 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 02:54:18 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-9
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:18 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-38
2018-09-26 02:54:18 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:18 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 02:54:18 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-1
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 02:54:18 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Loading group metadata for  with generation 0
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 15 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 02:54:18 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 02:54:18 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-2
2018-09-26 02:54:18 INFO  OfflinePartitionLeaderSelector:72 - [OfflinePartitionLeaderSelector]: Selected new leader and ISR {"leader":1,"leader_epoch":1,"isr":[1]} for offline partition __consumer_offsets-16
2018-09-26 02:54:18 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,testRestartingBroker-1537923236520-0,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-0 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-29 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-48 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-10 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-45 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-26 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-7 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-42 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-4 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-23 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-1 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-20 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-39 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-17 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-36 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-14 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-33 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition testRestartingBroker-1537923236520-0 broker=1] testRestartingBroker-1537923236520-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition testRestartingBroker-1537923236520-0 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-49 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-11 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-30 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-46 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-27 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-8 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-24 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-43 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-5 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-21 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-2 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-40 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-37 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-18 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-34 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-15 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-12 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-31 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-9 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-47 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-19 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-28 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-38 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-35 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-44 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-6 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-25 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-16 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-22 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-41 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-32 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-3 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:18 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0
2018-09-26 02:54:18 INFO  logger:72 - [Broker id=1] Skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 2 for partition __consumer_offsets-13 (last update controller epoch 2) since it is already the leader for the partition.
2018-09-26 02:54:21 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:45078 (id: 2147483646 rack: null)
2018-09-26 02:54:21 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:1, offset:1}, Current: {epoch:0, offset0} for Partition: __consumer_offsets-0. Cache now contains 1 entries.
2018-09-26 02:54:21 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:54:21 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:54:21 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:54:21 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:54:21 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:54:21 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:54:21 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:54:21 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:54:21 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:54:21 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:54:21 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1000
2018-09-26 02:54:21 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:54:21 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:54:21 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:54:21 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:54:21 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:54:21 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:54:21 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:54:21 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:54:21 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:54:21 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:54:21 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:54:21 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:54:21 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:54:21 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:54:22 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:54:22 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:54:22 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:54:22 INFO  LogManager:72 - Shutting down.
2018-09-26 02:54:22 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:54:22 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:54:22 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:54:22 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:54:22 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2
2018-09-26 02:54:22 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:54:22 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:54:22 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:54:22 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:54:22 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:54:22 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:54:22 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:54:22 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:54:22 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:54:22 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:54:22 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:54:22 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe1b9ac0000
2018-09-26 02:54:22 INFO  ZooKeeper:687 - Session: 0x1016fe1b9ac0000 closed
2018-09-26 02:54:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:54:22 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:35322 which had sessionid 0x1016fe1b9ac0000
2018-09-26 02:54:22 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe1b9ac0000
2018-09-26 02:54:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:54:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:54:22 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:54:23 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:54:23 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:54:23 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:54:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:54:24 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:54:24 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:54:24 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:54:24 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:54:24 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:54:24 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:54:24 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:54:24 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:54:24 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:54:24 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:54:24 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:54:24 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:54:24 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[ERROR] Tests run: 6, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 75.518 s <<< FAILURE! - in com.salesforce.kafka.test.KafkaTestServerTest
[ERROR] testOverrideBrokerProperties  Time elapsed: 6.072 s
[ERROR] testGetKafkaBrokersBeforeBrokerIsStarted  Time elapsed: 0.001 s
[ERROR] testExactlyOnceTransaction  Time elapsed: 18.825 s  <<< FAILURE!
org.opentest4j.AssertionFailedError: Should not be empty! ==> expected: <false> but was: <true>
	at com.salesforce.kafka.test.KafkaTestServerTest.testExactlyOnceTransaction(KafkaTestServerTest.java:104)

[ERROR] testGetKafkaBrokers  Time elapsed: 4.852 s
[ERROR] testProducerAndConsumerSubscribe  Time elapsed: 17.839 s
[ERROR] testRestartingBroker  Time elapsed: 27.926 s
[INFO] Running com.salesforce.kafka.test.kafka_1_0_x.StreamsBuilderSmokeTest
2018-09-26 02:54:24 INFO  ZookeeperTestServer:50 - Starting Zookeeper test server
2018-09-26 02:54:24 INFO  ZooKeeperServerMain:98 - Starting server
2018-09-26 02:54:24 INFO  ZooKeeperServer:835 - tickTime set to 3000
2018-09-26 02:54:24 INFO  ZooKeeperServer:844 - minSessionTimeout set to -1
2018-09-26 02:54:24 INFO  ZooKeeperServer:853 - maxSessionTimeout set to -1
2018-09-26 02:54:24 INFO  ServerCnxnFactory:117 - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
2018-09-26 02:54:24 INFO  NIOServerCnxnFactory:89 - binding to port 0.0.0.0/0.0.0.0:42412
2018-09-26 02:54:25 INFO  KafkaConfig:238 - KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:46663
	advertised.port = 46663
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.0-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:46663
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537923265452-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.0-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 46663
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42412
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-26 02:54:25 INFO  KafkaServer:72 - starting
2018-09-26 02:54:25 INFO  KafkaServer:72 - Connecting to zookeeper on 127.0.0.1:42412
2018-09-26 02:54:25 INFO  ZooKeeper:441 - Initiating client connection, connectString=127.0.0.1:42412 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@5f172d4a
2018-09-26 02:54:25 INFO  ZkEventThread:65 - Starting ZkClient event thread.
2018-09-26 02:54:25 INFO  ZkClient:936 - Waiting for keeper state SyncConnected
2018-09-26 02:54:25 INFO  ClientCnxn:1028 - Opening socket connection to server 127.0.0.1/127.0.0.1:42412. Will not attempt to authenticate using SASL (unknown error)
2018-09-26 02:54:25 INFO  ClientCnxn:878 - Socket connection established to 127.0.0.1/127.0.0.1:42412, initiating session
2018-09-26 02:54:25 INFO  NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:50636
2018-09-26 02:54:25 INFO  ZooKeeperServer:948 - Client attempting to establish new session at /127.0.0.1:50636
2018-09-26 02:54:25 INFO  FileTxnLog:213 - Creating new log file: log.1
2018-09-26 02:54:25 INFO  ZooKeeperServer:693 - Established session 0x1016fe1e1100000 with negotiated timeout 30000 for client /127.0.0.1:50636
2018-09-26 02:54:25 INFO  ClientCnxn:1302 - Session establishment complete on server 127.0.0.1/127.0.0.1:42412, sessionid = 0x1016fe1e1100000, negotiated timeout = 30000
2018-09-26 02:54:25 INFO  ZkClient:713 - zookeeper state changed (SyncConnected)
2018-09-26 02:54:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-26 02:54:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-26 02:54:25 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-26 02:54:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1f zxid:0x13 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-26 02:54:26 INFO  KafkaServer:72 - Cluster ID = Mr_t2kccTlubh1ZZC4OaeA
2018-09-26 02:54:26 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923265452-0/meta.properties
2018-09-26 02:54:26 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Starting
2018-09-26 02:54:26 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Starting
2018-09-26 02:54:26 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Starting
2018-09-26 02:54:26 INFO  LogManager:72 - Loading logs.
2018-09-26 02:54:26 INFO  LogManager:72 - Logs loading complete in 1 ms.
2018-09-26 02:54:26 INFO  LogManager:72 - Starting log cleanup with a period of 300000 ms.
2018-09-26 02:54:26 INFO  LogManager:72 - Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-26 02:54:26 INFO  LogCleaner:72 - Starting the log cleaner
2018-09-26 02:54:26 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Starting
2018-09-26 02:54:26 INFO  Acceptor:72 - Awaiting socket connections on 127.0.0.1:46663.
2018-09-26 02:54:26 INFO  SocketServer:72 - [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-26 02:54:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Starting
2018-09-26 02:54:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Starting
2018-09-26 02:54:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-26 02:54:26 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Starting
2018-09-26 02:54:26 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Starting
2018-09-26 02:54:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Starting
2018-09-26 02:54:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Starting
2018-09-26 02:54:26 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Starting
2018-09-26 02:54:26 INFO  ZKCheckedEphemeral:72 - Creating /controller (is it secure? false)
2018-09-26 02:54:26 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Starting up.
2018-09-26 02:54:26 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Startup complete.
2018-09-26 02:54:26 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-26 02:54:26 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] 1 successfully elected as the controller
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Starting become controller state transition
2018-09-26 02:54:26 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-26 02:54:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:setData cxid:0x2c zxid:0x18 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-26 02:54:26 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Starting up.
2018-09-26 02:54:26 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Startup complete.
2018-09-26 02:54:26 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Starting
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Incremented epoch to 1
2018-09-26 02:54:26 INFO  ZKCheckedEphemeral:72 - Creating /brokers/ids/1 (is it secure? false)
2018-09-26 02:54:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x43 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2018-09-26 02:54:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x44 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2018-09-26 02:54:26 INFO  ZKCheckedEphemeral:72 - Result of znode creation is: OK
2018-09-26 02:54:26 INFO  ZkUtils:72 - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(127.0.0.1,46663,ListenerName(PLAINTEXT),PLAINTEXT)
2018-09-26 02:54:26 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/1537923265452-0/meta.properties
2018-09-26 02:54:26 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Starting
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Partitions being reassigned: Map()
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Partitions already reassigned: Set()
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Resuming reassignment of partitions: Map()
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Current list of topics in the cluster: Set()
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] List of topics to be deleted: 
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] List of topics ineligible for deletion: 
2018-09-26 02:54:26 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-26 02:54:26 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-26 02:54:26 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to 127.0.0.1:46663 (id: 1 rack: null) for sending state change requests
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Partitions that completed preferred replica election: 
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-26 02:54:26 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
2018-09-26 02:54:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:delete cxid:0x50 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-26 02:54:26 INFO  SocketServer:72 - [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-26 02:54:26 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:26 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:26 INFO  KafkaServer:72 - [KafkaServer id=1] started
2018-09-26 02:54:26 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46663]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:54:26 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:26 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Starting the controller scheduler
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] Newly added brokers: , deleted brokers: , all live brokers: 1
2018-09-26 02:54:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:setData cxid:0x54 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/stream-input-topic1537923264448 Error:KeeperErrorCode = NoNode for /config/topics/stream-input-topic1537923264448
2018-09-26 02:54:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x55 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:54:26 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(stream-input-topic1537923264448)], deleted topics: [Set()], new partition replica assignment [Map(stream-input-topic1537923264448-0 -> Vector(1))]
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for stream-input-topic1537923264448-0
2018-09-26 02:54:26 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for stream-input-topic1537923264448-0
2018-09-26 02:54:26 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions stream-input-topic1537923264448-0
2018-09-26 02:54:26 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=stream-input-topic1537923264448,Partition=0,Replica=1]
2018-09-26 02:54:26 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions stream-input-topic1537923264448-0
2018-09-26 02:54:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x5d zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-input-topic1537923264448/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/stream-input-topic1537923264448/partitions/0
2018-09-26 02:54:26 INFO  SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2018-09-26 02:54:26 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x5e zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-input-topic1537923264448/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/stream-input-topic1537923264448/partitions
2018-09-26 02:54:27 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=stream-input-topic1537923264448,Partition=0,Replica=1]
2018-09-26 02:54:27 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions stream-input-topic1537923264448-0
2018-09-26 02:54:27 INFO  Log:72 - [Log partition=stream-input-topic1537923264448-0, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:27 INFO  Log:72 - [Log partition=stream-input-topic1537923264448-0, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:27 INFO  LogManager:72 - Created log for partition [stream-input-topic1537923264448,0] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:27 INFO  Partition:72 - [Partition stream-input-topic1537923264448-0 broker=1] No checkpointed highwatermark is found for partition stream-input-topic1537923264448-0
2018-09-26 02:54:27 INFO  Replica:72 - Replica loaded for partition stream-input-topic1537923264448-0 with initial high watermark 0
2018-09-26 02:54:27 INFO  Partition:72 - [Partition stream-input-topic1537923264448-0 broker=1] stream-input-topic1537923264448-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:27 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46663]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:54:27 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:27 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:setData cxid:0x64 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/stream-output-topic1537923264448 Error:KeeperErrorCode = NoNode for /config/topics/stream-output-topic1537923264448
2018-09-26 02:54:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x65 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:54:27 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"0":[1]}}
2018-09-26 02:54:27 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(stream-output-topic1537923264448)], deleted topics: [Set()], new partition replica assignment [Map(stream-output-topic1537923264448-0 -> Vector(1))]
2018-09-26 02:54:27 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for stream-output-topic1537923264448-0
2018-09-26 02:54:27 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for stream-output-topic1537923264448-0
2018-09-26 02:54:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions stream-output-topic1537923264448-0
2018-09-26 02:54:27 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=stream-output-topic1537923264448,Partition=0,Replica=1]
2018-09-26 02:54:27 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions stream-output-topic1537923264448-0
2018-09-26 02:54:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x6d zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-output-topic1537923264448/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/stream-output-topic1537923264448/partitions/0
2018-09-26 02:54:27 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x6e zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/stream-output-topic1537923264448/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/stream-output-topic1537923264448/partitions
2018-09-26 02:54:27 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=stream-output-topic1537923264448,Partition=0,Replica=1]
2018-09-26 02:54:27 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions stream-output-topic1537923264448-0
2018-09-26 02:54:27 INFO  Log:72 - [Log partition=stream-output-topic1537923264448-0, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:27 INFO  Log:72 - [Log partition=stream-output-topic1537923264448-0, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:27 INFO  LogManager:72 - Created log for partition [stream-output-topic1537923264448,0] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:27 INFO  Partition:72 - [Partition stream-output-topic1537923264448-0 broker=1] No checkpointed highwatermark is found for partition stream-output-topic1537923264448-0
2018-09-26 02:54:27 INFO  Replica:72 - Replica loaded for partition stream-output-topic1537923264448-0 with initial high watermark 0
2018-09-26 02:54:27 INFO  Partition:72 - [Partition stream-output-topic1537923264448-0 broker=1] stream-output-topic1537923264448-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:27 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = all
	batch.size = 0
	bootstrap.servers = [127.0.0.1:46663]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 02:54:27 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:27 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:27 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: stream-input-topic1537923264448-0. Cache now contains 0 entries.
2018-09-26 02:54:28 INFO  KafkaProducer:341 - [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 02:54:28 INFO  StreamsConfig:238 - StreamsConfig values: 
	application.id = testStreamProcessor
	application.server = 
	bootstrap.servers = [127.0.0.1:46663]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	upgrade.from = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-09-26 02:54:28 INFO  StreamThread:336 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] Creating restore consumer client
2018-09-26 02:54:28 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46663]
	check.crcs = true
	client.id = testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 02:54:28 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:28 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:28 INFO  StreamThread:336 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] Creating shared producer client
2018-09-26 02:54:28 INFO  ProducerConfig:238 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:46663]
	buffer.memory = 33554432
	client.id = testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-26 02:54:28 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:28 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:28 INFO  StreamThread:336 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] Creating consumer client
2018-09-26 02:54:28 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:46663]
	check.crcs = true
	client.id = testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testStreamProcessor
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-09-26 02:54:28 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:28 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:28 INFO  StreamThread:336 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] Starting
2018-09-26 02:54:28 INFO  StreamThread:346 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] State transition from CREATED to RUNNING
2018-09-26 02:54:28 INFO  KafkaStreams:336 - stream-client [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e]Started Streams client
2018-09-26 02:54:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:setData cxid:0x77 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-26 02:54:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x78 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2018-09-26 02:54:28 INFO  AdminUtils$:72 - Topic creation {"version":1,"partitions":{"45":[1],"34":[1],"12":[1],"8":[1],"19":[1],"23":[1],"4":[1],"40":[1],"15":[1],"11":[1],"9":[1],"44":[1],"33":[1],"22":[1],"26":[1],"37":[1],"13":[1],"46":[1],"24":[1],"35":[1],"16":[1],"5":[1],"10":[1],"48":[1],"21":[1],"43":[1],"32":[1],"49":[1],"6":[1],"36":[1],"1":[1],"39":[1],"17":[1],"25":[1],"14":[1],"47":[1],"31":[1],"42":[1],"0":[1],"20":[1],"27":[1],"2":[1],"38":[1],"18":[1],"30":[1],"7":[1],"29":[1],"41":[1],"3":[1],"28":[1]}}
2018-09-26 02:54:28 INFO  KafkaApis:72 - [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-26 02:54:28 INFO  KafkaController:72 - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-19 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-40 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-22 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-2 -> Vector(1))]
2018-09-26 02:54:28 INFO  KafkaController:72 - [Controller id=1] New topic creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:54:28 INFO  KafkaController:72 - [Controller id=1] New partition creation callback for __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:54:28 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:54:28 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:54:28 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-19,__consumer_offsets-30,__consumer_offsets-47,__consumer_offsets-29,__consumer_offsets-41,__consumer_offsets-39,__consumer_offsets-10,__consumer_offsets-17,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-18,__consumer_offsets-26,__consumer_offsets-0,__consumer_offsets-24,__consumer_offsets-33,__consumer_offsets-20,__consumer_offsets-21,__consumer_offsets-3,__consumer_offsets-5,__consumer_offsets-22,__consumer_offsets-12,__consumer_offsets-8,__consumer_offsets-23,__consumer_offsets-15,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-49,__consumer_offsets-6,__consumer_offsets-28,__consumer_offsets-4,__consumer_offsets-37,__consumer_offsets-31,__consumer_offsets-44,__consumer_offsets-42,__consumer_offsets-34,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-32,__consumer_offsets-43,__consumer_offsets-36,__consumer_offsets-35,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-16,__consumer_offsets-2
2018-09-26 02:54:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xb4 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2018-09-26 02:54:28 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xb5 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2018-09-26 02:54:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xbc zxid:0x39 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2018-09-26 02:54:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xc2 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2018-09-26 02:54:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xc8 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2018-09-26 02:54:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xce zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2018-09-26 02:54:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xd4 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2018-09-26 02:54:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xdb zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2018-09-26 02:54:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xe1 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2018-09-26 02:54:29 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xe8 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2018-09-26 02:54:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xee zxid:0x51 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2018-09-26 02:54:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xf4 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2018-09-26 02:54:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0xfa zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2018-09-26 02:54:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x100 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2018-09-26 02:54:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x106 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2018-09-26 02:54:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x10c zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2018-09-26 02:54:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x112 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2018-09-26 02:54:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x118 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2018-09-26 02:54:30 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x11e zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2018-09-26 02:54:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x124 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2018-09-26 02:54:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x12a zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2018-09-26 02:54:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x130 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2018-09-26 02:54:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x136 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2018-09-26 02:54:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x13c zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2018-09-26 02:54:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x142 zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2018-09-26 02:54:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x148 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2018-09-26 02:54:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x14e zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2018-09-26 02:54:31 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x154 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2018-09-26 02:54:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x15a zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2018-09-26 02:54:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x160 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2018-09-26 02:54:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x166 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2018-09-26 02:54:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x16c zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2018-09-26 02:54:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x172 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2018-09-26 02:54:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x178 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2018-09-26 02:54:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x17e zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2018-09-26 02:54:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x184 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2018-09-26 02:54:32 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x18a zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2018-09-26 02:54:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x190 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2018-09-26 02:54:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x196 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2018-09-26 02:54:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x19c zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2018-09-26 02:54:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1a2 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2018-09-26 02:54:33 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1a8 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2018-09-26 02:54:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1ae zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2018-09-26 02:54:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1b4 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2018-09-26 02:54:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1ba zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2018-09-26 02:54:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1c0 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2018-09-26 02:54:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1c6 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2018-09-26 02:54:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1cc zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2018-09-26 02:54:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1d2 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2018-09-26 02:54:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1d8 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2018-09-26 02:54:34 INFO  PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x1016fe1e1100000 type:create cxid:0x1de zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2018-09-26 02:54:35 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=24,Replica=1]
2018-09-26 02:54:35 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-0, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,0] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-29, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,29] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-48, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,48] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-10, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,10] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-45, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,45] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-26, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,26] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-7, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,7] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-42, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,42] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-4, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,4] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-23, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,23] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-1, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,1] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-20, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,20] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-39, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,39] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-17, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,17] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-36, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,36] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-14, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,14] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-33, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,33] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-49, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,49] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-11, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,11] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-30, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,30] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-46, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,46] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-27, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,27] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-8, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,8] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-24, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,24] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-43, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,43] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-5, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,5] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-21, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,21] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-2, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,2] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-40, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,40] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-37, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,37] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-18, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,18] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-34, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,34] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-15, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,15] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-12, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,12] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-31, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,31] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-9, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,9] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-47, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,47] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-19, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,19] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-28, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,28] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-38, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,38] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-35, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,35] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-44, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,44] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-6, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,6] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-25, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,25] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-16, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,16] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-22, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,22] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-41, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,41] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-32, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,32] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-3, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,3] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923265452-0] Loading producer state from offset 0 with message format version 2
2018-09-26 02:54:35 INFO  Log:72 - [Log partition=__consumer_offsets-13, dir=/tmp/1537923265452-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-26 02:54:35 INFO  LogManager:72 - Created log for partition [__consumer_offsets,13] in /tmp/1537923265452-0 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-26 02:54:35 INFO  Replica:72 - Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-26 02:54:35 INFO  Partition:72 - [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-26 02:54:35 INFO  GroupMetadataManager:72 - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-26 02:54:35 INFO  AbstractCoordinator:341 - [Consumer clientId=testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1-consumer, groupId=testStreamProcessor] Discovered group coordinator 127.0.0.1:46663 (id: 2147483646 rack: null)
2018-09-26 02:54:35 INFO  ConsumerCoordinator:341 - [Consumer clientId=testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1-consumer, groupId=testStreamProcessor] Revoking previously assigned partitions []
2018-09-26 02:54:35 INFO  StreamThread:346 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED
2018-09-26 02:54:35 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e]State transition from RUNNING to REBALANCING
2018-09-26 02:54:35 INFO  StreamThread:351 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-09-26 02:54:35 INFO  AbstractCoordinator:336 - [Consumer clientId=testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1-consumer, groupId=testStreamProcessor] (Re-)joining group
2018-09-26 02:54:35 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Preparing to rebalance group testStreamProcessor with old generation 0 (__consumer_offsets-8)
2018-09-26 02:54:38 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Stabilized group testStreamProcessor generation 1 (__consumer_offsets-8)
2018-09-26 02:54:38 INFO  StreamPartitionAssignor:341 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1-consumer] Assigned tasks to clients as {918be687-5ba6-4710-8bcf-c3c76f1cf18e=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-09-26 02:54:38 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Assignment received from leader for group testStreamProcessor for generation 1
2018-09-26 02:54:38 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-8. Cache now contains 0 entries.
2018-09-26 02:54:38 INFO  AbstractCoordinator:341 - [Consumer clientId=testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1-consumer, groupId=testStreamProcessor] Successfully joined group with generation 1
2018-09-26 02:54:38 INFO  ConsumerCoordinator:341 - [Consumer clientId=testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1-consumer, groupId=testStreamProcessor] Setting newly assigned partitions [stream-input-topic1537923264448-0]
2018-09-26 02:54:38 INFO  StreamThread:346 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2018-09-26 02:54:38 INFO  StreamThread:351 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] partition assignment took 19 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-09-26 02:54:38 INFO  StreamThread:346 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2018-09-26 02:54:38 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e]State transition from REBALANCING to RUNNING
2018-09-26 02:54:38 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: stream-output-topic1537923264448-0. Cache now contains 0 entries.
2018-09-26 02:54:38 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e]State transition from RUNNING to PENDING_SHUTDOWN
2018-09-26 02:54:38 INFO  StreamThread:336 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] Informed to shut down
2018-09-26 02:54:38 INFO  StreamThread:346 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
2018-09-26 02:54:38 INFO  StreamThread:336 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] Shutting down
2018-09-26 02:54:38 INFO  KafkaProducer:341 - [Producer clientId=testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-26 02:54:38 INFO  StreamThread:346 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2018-09-26 02:54:38 INFO  StreamThread:336 - stream-thread [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e-StreamThread-1] Shutdown complete
2018-09-26 02:54:38 INFO  KafkaStreams:346 - stream-client [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e]State transition from PENDING_SHUTDOWN to NOT_RUNNING
2018-09-26 02:54:38 INFO  KafkaStreams:336 - stream-client [testStreamProcessor-918be687-5ba6-4710-8bcf-c3c76f1cf18e]Streams client stopped completely
2018-09-26 02:54:38 INFO  AdminClientConfig:238 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:46663]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-26 02:54:38 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:38 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:38 INFO  ConsumerConfig:238 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:46663]
	check.crcs = true
	client.id = test-consumer-id
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RoundRobinAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-26 02:54:38 INFO  AppInfoParser:109 - Kafka version : 1.0.2
2018-09-26 02:54:38 INFO  AppInfoParser:110 - Kafka commitId : 2a121f7b1d402825
2018-09-26 02:54:43 INFO  AbstractCoordinator:341 - [Consumer clientId=test-consumer-id, groupId=] Discovered group coordinator 127.0.0.1:46663 (id: 2147483646 rack: null)
2018-09-26 02:54:43 INFO  LeaderEpochFileCache:72 - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
2018-09-26 02:54:43 INFO  KafkaServer:72 - [KafkaServer id=1] shutting down
2018-09-26 02:54:43 INFO  KafkaServer:72 - [KafkaServer id=1] Starting controlled shutdown
2018-09-26 02:54:43 INFO  KafkaController:72 - [Controller id=1] Shutting down broker 1
2018-09-26 02:54:43 INFO  KafkaServer:72 - [KafkaServer id=1] Controlled shutdown succeeded
2018-09-26 02:54:43 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopping socket server request processors
2018-09-26 02:54:43 INFO  SocketServer:72 - [SocketServer brokerId=1] Stopped socket server request processors
2018-09-26 02:54:43 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shutting down
2018-09-26 02:54:43 INFO  KafkaRequestHandlerPool:72 - [Kafka Request Handler on Broker 1], shut down completely
2018-09-26 02:54:43 INFO  KafkaApis:72 - [KafkaApi-1] Shutdown complete.
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutting down
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Shutdown completed
2018-09-26 02:54:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutting down.
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-topic]: Stopped
2018-09-26 02:54:43 INFO  ProducerIdManager:72 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-26 02:54:43 INFO  TransactionStateManager:72 - [Transaction State Manager 1]: Shutdown complete
2018-09-26 02:54:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutting down
2018-09-26 02:54:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Stopped
2018-09-26 02:54:43 INFO  TransactionMarkerChannelManager:72 - [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-26 02:54:43 INFO  TransactionCoordinator:72 - [TransactionCoordinator id=1] Shutdown complete.
2018-09-26 02:54:43 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutting down.
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Stopped
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-26 02:54:43 INFO  GroupCoordinator:72 - [GroupCoordinator 1]: Shutdown complete.
2018-09-26 02:54:43 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shutting down
2018-09-26 02:54:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutting down
2018-09-26 02:54:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Stopped
2018-09-26 02:54:43 INFO  ReplicaManager$LogDirFailureHandler:72 - [LogDirFailureHandler]: Shutdown completed
2018-09-26 02:54:43 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutting down
2018-09-26 02:54:43 INFO  ReplicaFetcherManager:72 - [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutting down
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Stopped
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutting down
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-Produce]: Stopped
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-26 02:54:43 INFO  DelayedOperationPurgatory$ExpiredOperationReaper:72 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-26 02:54:43 INFO  ReplicaManager:72 - [ReplicaManager broker=1] Shut down completely
2018-09-26 02:54:43 INFO  LogManager:72 - Shutting down.
2018-09-26 02:54:43 INFO  LogCleaner:72 - Shutting down the log cleaner.
2018-09-26 02:54:43 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutting down
2018-09-26 02:54:43 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Stopped
2018-09-26 02:54:43 INFO  LogCleaner:72 - [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-26 02:54:43 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 2
2018-09-26 02:54:44 INFO  ProducerStateManager:72 - [ProducerStateManager partition=stream-output-topic1537923264448-0] Writing producer snapshot at offset 25
2018-09-26 02:54:44 INFO  ProducerStateManager:72 - [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 1
2018-09-26 02:54:44 INFO  ProducerStateManager:72 - [ProducerStateManager partition=stream-input-topic1537923264448-0] Writing producer snapshot at offset 25
2018-09-26 02:54:45 INFO  LogManager:72 - Shutdown complete.
2018-09-26 02:54:45 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutting down
2018-09-26 02:54:45 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Stopped
2018-09-26 02:54:45 INFO  ControllerEventManager$ControllerEventThread:72 - [controller-event-thread]: Shutdown completed
2018-09-26 02:54:45 INFO  PartitionStateMachine:72 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-26 02:54:45 INFO  ReplicaStateMachine:72 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-26 02:54:45 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutting down
2018-09-26 02:54:45 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Stopped
2018-09-26 02:54:45 INFO  RequestSendThread:72 - [Controller-1-to-broker-1-send-thread]: Shutdown completed
2018-09-26 02:54:45 INFO  KafkaController:72 - [Controller id=1] Resigned
2018-09-26 02:54:45 INFO  ZkEventThread:83 - Terminate ZkClient event thread.
2018-09-26 02:54:45 INFO  PrepRequestProcessor:487 - Processed session termination for sessionid: 0x1016fe1e1100000
2018-09-26 02:54:45 INFO  ZooKeeper:687 - Session: 0x1016fe1e1100000 closed
2018-09-26 02:54:45 INFO  NIOServerCnxn:1040 - Closed socket connection for client /127.0.0.1:50636 which had sessionid 0x1016fe1e1100000
2018-09-26 02:54:45 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-26 02:54:45 INFO  ClientCnxn:521 - EventThread shut down for session: 0x1016fe1e1100000
2018-09-26 02:54:46 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Stopped
2018-09-26 02:54:46 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-26 02:54:46 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutting down
2018-09-26 02:54:47 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Stopped
2018-09-26 02:54:47 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-26 02:54:47 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutting down
2018-09-26 02:54:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-26 02:54:48 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutting down socket server
2018-09-26 02:54:48 INFO  ClientQuotaManager$ThrottledRequestReaper:72 - [ThrottledRequestReaper-Request]: Stopped
2018-09-26 02:54:48 INFO  SocketServer:72 - [SocketServer brokerId=1] Shutdown completed
2018-09-26 02:54:48 INFO  KafkaServer:72 - [KafkaServer id=1] shut down completed
2018-09-26 02:54:48 INFO  ZookeeperTestServer:99 - Shutting down zookeeper test server
2018-09-26 02:54:48 INFO  NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2018-09-26 02:54:48 INFO  ZooKeeperServer:501 - shutting down
2018-09-26 02:54:48 INFO  SessionTrackerImpl:226 - Shutting down
2018-09-26 02:54:48 INFO  PrepRequestProcessor:769 - Shutting down
2018-09-26 02:54:48 INFO  SyncRequestProcessor:208 - Shutting down
2018-09-26 02:54:48 INFO  PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2018-09-26 02:54:48 INFO  SyncRequestProcessor:186 - SyncRequestProcessor exited!
2018-09-26 02:54:48 INFO  FinalRequestProcessor:403 - shutdown of request processor complete
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.816 s - in com.salesforce.kafka.test.kafka_1_0_x.StreamsBuilderSmokeTest
[INFO] testStreamConsumer  Time elapsed: 23.816 s
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Failures: 
[ERROR]   KafkaTestServerTest.testExactlyOnceTransaction:104 Should not be empty! ==> expected: <false> but was: <true>
[INFO] 
[ERROR] Tests run: 31, Failures: 1, Errors: 0, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] kafka-junit ........................................ SUCCESS [  2.253 s]
[INFO] kafka-junit-core ................................... FAILURE [05:06 min]
[INFO] kafka-junit4 ....................................... SKIPPED
[INFO] kafka-junit5 ....................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 05:09 min
[INFO] Finished at: 2018-09-26T02:54:48+02:00
[INFO] Final Memory: 32M/497M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.22.0:test (default-test) on project kafka-junit-core: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/salesforce/kafka-junit/433224675/kafka-junit-core/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :kafka-junit-core
