[INFO] Scanning for projects...
[INFO] Inspecting build with total of 4 modules...
[INFO] Installing Nexus Staging features:
[INFO]   ... total of 4 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Kafka WebView
[INFO] Kafka WebView Plugin
[INFO] Kafka WebView UI
[INFO] Kafka Dev Cluster
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Kafka WebView 2.0.0
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:checkstyle (checkstyle-validate) @ kafka-webview ---
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:check (checkstyle-validate) @ kafka-webview ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- license-maven-plugin:3.0:check (default) @ kafka-webview ---
[INFO] Checking licenses...
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Kafka WebView Plugin 1.0.0
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:checkstyle (checkstyle-validate) @ kafka-webview-plugin ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:check (checkstyle-validate) @ kafka-webview-plugin ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- maven-resources-plugin:3.0.2:resources (default-resources) @ kafka-webview-plugin ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/src/main/resources
[INFO] skip non existing resourceDirectory /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ kafka-webview-plugin ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- license-maven-plugin:3.0:check (default) @ kafka-webview-plugin ---
[INFO] Checking licenses...
[INFO] 
[INFO] --- maven-resources-plugin:3.0.2:testResources (default-testResources) @ kafka-webview-plugin ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ kafka-webview-plugin ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ kafka-webview-plugin ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Kafka WebView UI 2.0.0
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:checkstyle (checkstyle-validate) @ kafka-webview-ui ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.0.0:check (checkstyle-validate) @ kafka-webview-ui ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- frontend-maven-plugin:1.3:install-node-and-npm (install node and npm) @ kafka-webview-ui ---
[INFO] Node v8.6.0 is already installed.
[INFO] NPM 5.5.1 is already installed.
[INFO] 
[INFO] --- frontend-maven-plugin:1.3:npm (npm install) @ kafka-webview-ui ---
[INFO] Skipping test phase.
[INFO] 
[INFO] --- frontend-maven-plugin:1.3:gulp (gulp build) @ kafka-webview-ui ---
[INFO] Skipping test phase.
[INFO] 
[INFO] --- maven-resources-plugin:3.1.0:copy-resources (copy gulp dist files to static) @ kafka-webview-ui ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/src/main/frontend/dist
[INFO] 
[INFO] --- maven-resources-plugin:3.1.0:resources (default-resources) @ kafka-webview-ui ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 0 resource
[INFO] Copying 37 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ kafka-webview-ui ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- license-maven-plugin:3.0:check (default) @ kafka-webview-ui ---
[INFO] Checking licenses...
[INFO] 
[INFO] --- maven-resources-plugin:3.1.0:testResources (default-testResources) @ kafka-webview-ui ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ kafka-webview-ui ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.21.0:test (default-test) @ kafka-webview-ui ---
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.21.0/surefire-junit4-2.21.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.21.0/surefire-junit4-2.21.0.pom (4 KB at 5.6 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.21.0/surefire-providers-2.21.0.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.21.0/surefire-providers-2.21.0.pom (3 KB at 72.2 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.21.0/surefire-junit4-2.21.0.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.21.0/surefire-junit4-2.21.0.jar (83 KB at 574.0 KB/sec)
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest
03:52:09.138 [main] DEBUG org.springframework.test.context.junit4.SpringJUnit4ClassRunner - SpringJUnit4ClassRunner constructor called with [class org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]
03:52:09.147 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating CacheAwareContextLoaderDelegate from class [org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate]
03:52:09.157 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating BootstrapContext using constructor [public org.springframework.test.context.support.DefaultBootstrapContext(java.lang.Class,org.springframework.test.context.CacheAwareContextLoaderDelegate)]
03:52:09.200 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating TestContextBootstrapper for test class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest] from class [org.springframework.boot.test.context.SpringBootTestContextBootstrapper]
03:52:09.221 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Neither @ContextConfiguration nor @ContextHierarchy found for test class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest], using SpringBootContextLoader
03:52:09.226 [main] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]: class path resource [org/sourcelab/kafka/webview/ui/controller/configuration/messageformat/MessageFormatControllerTest-context.xml] does not exist
03:52:09.227 [main] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]: class path resource [org/sourcelab/kafka/webview/ui/controller/configuration/messageformat/MessageFormatControllerTestContext.groovy] does not exist
03:52:09.228 [main] INFO org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]: no resource found for suffixes {-context.xml, Context.groovy}.
03:52:09.229 [main] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]: MessageFormatControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
03:52:09.311 [main] DEBUG org.springframework.test.context.support.ActiveProfilesUtils - Could not find an 'annotation declaring class' for annotation type [org.springframework.test.context.ActiveProfiles] and class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]
03:52:09.320 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'systemProperties' with lowest search precedence
03:52:09.321 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'systemEnvironment' with lowest search precedence
03:52:09.322 [main] DEBUG org.springframework.core.env.StandardEnvironment - Initialized StandardEnvironment with PropertySources [MapPropertySource@630074945 {name='systemProperties', properties={java.runtime.name=OpenJDK Runtime Environment, sun.boot.library.path=/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64, java.vm.version=25.121-b13, java.vm.vendor=Oracle Corporation, java.vendor.url=http://java.oracle.com/, skip.gulp=true, path.separator=:, java.vm.name=OpenJDK 64-Bit Server VM, file.encoding.pkg=sun.io, findbugs.skip=true, sun.java.launcher=SUN_STANDARD, sun.os.patch.level=unknown, java.vm.specification.name=Java Virtual Machine Specification, user.dir=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui, checkstyle.skip=true, java.runtime.version=1.8.0_121-8u121-b13-1~bpo8+1-b13, skip.npm=true, basedir=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui, java.awt.graphicsenv=sun.awt.X11GraphicsEnvironment, java.endorsed.dirs=/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed, os.arch=amd64, surefire.real.class.path=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/surefire/surefirebooter6557429458073905073.jar, gpg.skip=true, java.io.tmpdir=/tmp, line.separator=
, cobertura.skip=true, java.vm.specification.vendor=Oracle Corporation, os.name=Linux, sun.jnu.encoding=UTF-8, license.skip=true, java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib, surefire.test.class.path=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/target/classes:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka-clients/1.1.1/kafka-clients-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-thymeleaf/2.0.5.RELEASE/spring-boot-starter-thymeleaf-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter/2.0.5.RELEASE/spring-boot-starter-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-logging/2.0.5.RELEASE/spring-boot-starter-logging-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-core/1.2.3/logback-core-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-to-slf4j/2.10.0/log4j-to-slf4j-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-api/2.10.0/log4j-api-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/yaml/snakeyaml/1.19/snakeyaml-1.19.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring5/3.0.9.RELEASE/thymeleaf-spring5-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-java8time/3.0.1.RELEASE/thymeleaf-extras-java8time-3.0.1.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring4/3.0.9.RELEASE/thymeleaf-spring4-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf/3.0.9.RELEASE/thymeleaf-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ognl/ognl/3.1.12/ognl-3.1.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/javassist/javassist/3.20.0-GA/javassist-3.20.0-GA.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/attoparser/attoparser/2.0.4.RELEASE/attoparser-2.0.4.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/unbescape/unbescape/1.1.5.RELEASE/unbescape-1.1.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-layout-dialect/2.3.0/thymeleaf-layout-dialect-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-expression-processor/1.1.3/thymeleaf-expression-processor-1.1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-springsecurity4/3.0.2.RELEASE/thymeleaf-extras-springsecurity4-3.0.2.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-data-jpa/2.0.5.RELEASE/spring-boot-starter-data-jpa-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-aop/2.0.5.RELEASE/spring-boot-starter-aop-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/aspectj/aspectjweaver/1.8.13/aspectjweaver-1.8.13.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-jdbc/2.0.5.RELEASE/spring-boot-starter-jdbc-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/zaxxer/HikariCP/2.7.9/HikariCP-2.7.9.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jdbc/5.0.9.RELEASE/spring-jdbc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/hibernate-core/5.2.17.Final/hibernate-core-5.2.17.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/javax/persistence/hibernate-jpa-2.1-api/1.0.2.Final/hibernate-jpa-2.1-api-1.0.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/jandex/2.0.3.Final/jandex-2.0.3.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/classmate/1.3.4/classmate-1.3.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/common/hibernate-commons-annotations/5.0.1.Final/hibernate-commons-annotations-5.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-jpa/2.0.10.RELEASE/spring-data-jpa-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-commons/2.0.10.RELEASE/spring-data-commons-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-orm/5.0.9.RELEASE/spring-orm-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-context/5.0.9.RELEASE/spring-context-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-tx/5.0.9.RELEASE/spring-tx-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-beans/5.0.9.RELEASE/spring-beans-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aspects/5.0.9.RELEASE/spring-aspects-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/h2database/h2/1.4.197/h2-1.4.197.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-security/2.0.5.RELEASE/spring-boot-starter-security-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aop/5.0.9.RELEASE/spring-aop-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-config/5.0.8.RELEASE/spring-security-config-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-web/5.0.8.RELEASE/spring-security-web-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-expression/5.0.9.RELEASE/spring-expression-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-web/5.0.9.RELEASE/spring-web-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-websocket/2.0.5.RELEASE/spring-boot-starter-websocket-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-web/2.0.5.RELEASE/spring-boot-starter-web-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-json/2.0.5.RELEASE/spring-boot-starter-json-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.6/jackson-datatype-jdk8-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.6/jackson-module-parameter-names-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-tomcat/2.0.5.RELEASE/spring-boot-starter-tomcat-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-core/8.5.34/tomcat-embed-core-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-el/8.5.34/tomcat-embed-el-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-websocket/8.5.34/tomcat-embed-websocket-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/validator/hibernate-validator/6.0.12.Final/hibernate-validator-6.0.12.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-webmvc/5.0.9.RELEASE/spring-webmvc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-messaging/5.0.9.RELEASE/spring-messaging-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-websocket/5.0.9.RELEASE/spring-websocket-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-actuator/2.0.5.RELEASE/spring-boot-starter-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator-autoconfigure/2.0.5.RELEASE/spring-boot-actuator-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator/2.0.5.RELEASE/spring-boot-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.6/jackson-datatype-jsr310-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/io/micrometer/micrometer-core/1.0.6/micrometer-core-1.0.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hdrhistogram/HdrHistogram/2.1.10/HdrHistogram-2.1.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/interceptor/javax.interceptor-api/1.2.1/javax.interceptor-api-1.2.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-devtools/2.0.5.RELEASE/spring-boot-devtools-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot/2.0.5.RELEASE/spring-boot-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-autoconfigure/2.0.5.RELEASE/spring-boot-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-test/2.0.5.RELEASE/spring-boot-starter-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test/2.0.5.RELEASE/spring-boot-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test-autoconfigure/2.0.5.RELEASE/spring-boot-test-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/json-smart/2.3/json-smart-2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/junit/junit/4.12/junit-4.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/assertj/assertj-core/3.9.1/assertj-core-3.9.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/mockito/mockito-core/2.15.0/mockito-core-2.15.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy/1.7.11/byte-buddy-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy-agent/1.7.11/byte-buddy-agent-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-core/5.0.9.RELEASE/spring-core-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jcl/5.0.9.RELEASE/spring-jcl-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-test/5.0.9.RELEASE/spring-test-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xmlunit/xmlunit-core/2.5.1/xmlunit-core-2.5.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-test/5.0.8.RELEASE/spring-security-test-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-core/5.0.8.RELEASE/spring-security-core-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit4/3.0.1/kafka-junit4-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit-core/3.0.1/kafka-junit-core-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka_2.11/1.1.1/kafka_2.11-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/typesafe/scala-logging/scala-logging_2.11/3.8.0/scala-logging_2.11-3.8.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/zookeeper/zookeeper/3.4.10/zookeeper-3.4.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/pl/pragmatists/JUnitParams/1.1.1/JUnitParams-1.1.1.jar:, java.specification.name=Java Platform API Specification, java.class.version=52.0, skip.bower=true, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, maven.repo.local=/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2, os.version=3.10.0-862.3.2.el7.x86_64, user.home=/root, user.timezone=Europe/Paris, java.awt.printerjob=sun.print.PSPrinterJob, file.encoding=UTF-8, java.specification.version=1.8, java.class.path=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/target/classes:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka-clients/1.1.1/kafka-clients-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-thymeleaf/2.0.5.RELEASE/spring-boot-starter-thymeleaf-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter/2.0.5.RELEASE/spring-boot-starter-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-logging/2.0.5.RELEASE/spring-boot-starter-logging-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-core/1.2.3/logback-core-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-to-slf4j/2.10.0/log4j-to-slf4j-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-api/2.10.0/log4j-api-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/yaml/snakeyaml/1.19/snakeyaml-1.19.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring5/3.0.9.RELEASE/thymeleaf-spring5-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-java8time/3.0.1.RELEASE/thymeleaf-extras-java8time-3.0.1.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring4/3.0.9.RELEASE/thymeleaf-spring4-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf/3.0.9.RELEASE/thymeleaf-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ognl/ognl/3.1.12/ognl-3.1.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/javassist/javassist/3.20.0-GA/javassist-3.20.0-GA.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/attoparser/attoparser/2.0.4.RELEASE/attoparser-2.0.4.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/unbescape/unbescape/1.1.5.RELEASE/unbescape-1.1.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-layout-dialect/2.3.0/thymeleaf-layout-dialect-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-expression-processor/1.1.3/thymeleaf-expression-processor-1.1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-springsecurity4/3.0.2.RELEASE/thymeleaf-extras-springsecurity4-3.0.2.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-data-jpa/2.0.5.RELEASE/spring-boot-starter-data-jpa-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-aop/2.0.5.RELEASE/spring-boot-starter-aop-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/aspectj/aspectjweaver/1.8.13/aspectjweaver-1.8.13.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-jdbc/2.0.5.RELEASE/spring-boot-starter-jdbc-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/zaxxer/HikariCP/2.7.9/HikariCP-2.7.9.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jdbc/5.0.9.RELEASE/spring-jdbc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/hibernate-core/5.2.17.Final/hibernate-core-5.2.17.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/javax/persistence/hibernate-jpa-2.1-api/1.0.2.Final/hibernate-jpa-2.1-api-1.0.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/jandex/2.0.3.Final/jandex-2.0.3.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/classmate/1.3.4/classmate-1.3.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/common/hibernate-commons-annotations/5.0.1.Final/hibernate-commons-annotations-5.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-jpa/2.0.10.RELEASE/spring-data-jpa-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-commons/2.0.10.RELEASE/spring-data-commons-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-orm/5.0.9.RELEASE/spring-orm-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-context/5.0.9.RELEASE/spring-context-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-tx/5.0.9.RELEASE/spring-tx-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-beans/5.0.9.RELEASE/spring-beans-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aspects/5.0.9.RELEASE/spring-aspects-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/h2database/h2/1.4.197/h2-1.4.197.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-security/2.0.5.RELEASE/spring-boot-starter-security-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aop/5.0.9.RELEASE/spring-aop-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-config/5.0.8.RELEASE/spring-security-config-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-web/5.0.8.RELEASE/spring-security-web-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-expression/5.0.9.RELEASE/spring-expression-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-web/5.0.9.RELEASE/spring-web-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-websocket/2.0.5.RELEASE/spring-boot-starter-websocket-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-web/2.0.5.RELEASE/spring-boot-starter-web-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-json/2.0.5.RELEASE/spring-boot-starter-json-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.6/jackson-datatype-jdk8-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.6/jackson-module-parameter-names-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-tomcat/2.0.5.RELEASE/spring-boot-starter-tomcat-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-core/8.5.34/tomcat-embed-core-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-el/8.5.34/tomcat-embed-el-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-websocket/8.5.34/tomcat-embed-websocket-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/validator/hibernate-validator/6.0.12.Final/hibernate-validator-6.0.12.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-webmvc/5.0.9.RELEASE/spring-webmvc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-messaging/5.0.9.RELEASE/spring-messaging-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-websocket/5.0.9.RELEASE/spring-websocket-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-actuator/2.0.5.RELEASE/spring-boot-starter-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator-autoconfigure/2.0.5.RELEASE/spring-boot-actuator-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator/2.0.5.RELEASE/spring-boot-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.6/jackson-datatype-jsr310-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/io/micrometer/micrometer-core/1.0.6/micrometer-core-1.0.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hdrhistogram/HdrHistogram/2.1.10/HdrHistogram-2.1.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/interceptor/javax.interceptor-api/1.2.1/javax.interceptor-api-1.2.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-devtools/2.0.5.RELEASE/spring-boot-devtools-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot/2.0.5.RELEASE/spring-boot-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-autoconfigure/2.0.5.RELEASE/spring-boot-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-test/2.0.5.RELEASE/spring-boot-starter-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test/2.0.5.RELEASE/spring-boot-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test-autoconfigure/2.0.5.RELEASE/spring-boot-test-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/json-smart/2.3/json-smart-2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/junit/junit/4.12/junit-4.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/assertj/assertj-core/3.9.1/assertj-core-3.9.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/mockito/mockito-core/2.15.0/mockito-core-2.15.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy/1.7.11/byte-buddy-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy-agent/1.7.11/byte-buddy-agent-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-core/5.0.9.RELEASE/spring-core-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jcl/5.0.9.RELEASE/spring-jcl-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-test/5.0.9.RELEASE/spring-test-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xmlunit/xmlunit-core/2.5.1/xmlunit-core-2.5.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-test/5.0.8.RELEASE/spring-security-test-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-core/5.0.8.RELEASE/spring-security-core-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit4/3.0.1/kafka-junit4-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit-core/3.0.1/kafka-junit-core-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka_2.11/1.1.1/kafka_2.11-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/typesafe/scala-logging/scala-logging_2.11/3.8.0/scala-logging_2.11-3.8.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/zookeeper/zookeeper/3.4.10/zookeeper-3.4.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/pl/pragmatists/JUnitParams/1.1.1/JUnitParams-1.1.1.jar:, user.name=root, skipITs=true, java.vm.specification.version=1.8, sun.java.command=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/surefire/surefirebooter6557429458073905073.jar /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/surefire 2018-09-24T03-52-03_876-jvmRun1 surefire5579905461119079460tmp surefire_01248498674082760979tmp, java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre, sun.arch.data.model=64, user.language=en, java.specification.vendor=Oracle Corporation, dependency-check.skip=true, awt.toolkit=sun.awt.X11.XToolkit, java.vm.info=mixed mode, java.version=1.8.0_121, java.ext.dirs=/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext, sun.boot.class.path=/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes, rat.skip=true, enforcer.skip=true, java.vendor=Oracle Corporation, localRepository=/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2, file.separator=/, java.vendor.url.bug=http://bugreport.sun.com/bugreport/, sun.io.unicode.encoding=UnicodeLittle, sun.cpu.endian=little, sun.cpu.isalist=}}, SystemEnvironmentPropertySource@64133603 {name='systemEnvironment', properties={PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin, JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64, NOTIFY_TO=, CA_CERTIFICATES_JAVA_VERSION=20161107~bpo8+1, MONGODB_HOST=, BUILD_ID=, LANG=C.UTF-8, MAVEN_HOME=/usr/share/maven, SMTP_SERVER=, MONGODB_NAME=, REPAIR_MODE=repair, PWD=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui, JAVA_VERSION=8u121, GITHUB_OAUTH=, MAVEN_CMD_LINE_ARGS=/root/.m2 -B -D enforcer.skip=true -D dependency-check.skip=true -D skipITs=true -D cobertura.skip=true -D maven.repo.local=/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2 -D rat.skip=true -D findbugs.skip=true -D skip.bower=true -D gpg.skip=true -D checkstyle.skip=true -D skip.gulp=true -D license.skip=true -D skip.npm=true test, _=/usr/bin/java, OUTPUT=, MAVEN_TERMINATE_CMD=on, MAVEN_CONFIG=/root/.m2, MAVEN_PROJECTBASEDIR=/root/workspace/SourceLabOrg/kafka-webview/432293183, OLDPWD=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui, LOG_FILENAME=repairnator-pipeline_2018-09-24_0349_432293183_6927fb33-1ea7-4003-9018-b027a8f8f5e3, RUN_ID=, HOSTNAME=cyclone1, JAVA_DEBIAN_VERSION=8u121-b13-1~bpo8+1, M2_HOME=/usr/share/maven, REPAIR_TOOLS=AssertFixer, HOME=/root, SHLVL=1, PUSH_URL=}}]
03:52:09.339 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved classpath location [org/sourcelab/kafka/webview/ui/controller/configuration/messageformat/] to resources [URL [file:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/configuration/messageformat/], URL [file:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/configuration/messageformat/]]
03:52:09.340 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/configuration/messageformat]
03:52:09.340 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/configuration/messageformat] for files matching pattern [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/configuration/messageformat/*.class]
03:52:09.344 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/configuration/messageformat]
03:52:09.344 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/configuration/messageformat] for files matching pattern [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/configuration/messageformat/*.class]
03:52:09.345 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved location pattern [classpath*:org/sourcelab/kafka/webview/ui/controller/configuration/messageformat/*.class] to resources [file [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/configuration/messageformat/MessageFormatControllerTest.class], file [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/configuration/messageformat/MessageFormatController.class]]
03:52:09.397 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved classpath location [org/sourcelab/kafka/webview/ui/controller/configuration/] to resources [URL [file:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/configuration/], URL [file:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/configuration/]]
03:52:09.397 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/configuration]
03:52:09.397 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/configuration] for files matching pattern [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/configuration/*.class]
03:52:09.399 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/configuration]
03:52:09.400 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/configuration] for files matching pattern [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/configuration/*.class]
03:52:09.402 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved location pattern [classpath*:org/sourcelab/kafka/webview/ui/controller/configuration/*.class] to resources [file [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/configuration/ConfigurationController.class]]
03:52:09.403 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved classpath location [org/sourcelab/kafka/webview/ui/controller/] to resources [URL [file:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/], URL [file:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/]]
03:52:09.404 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller]
03:52:09.404 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller] for files matching pattern [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/*.class]
03:52:09.405 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller]
03:52:09.405 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller] for files matching pattern [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/*.class]
03:52:09.407 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved location pattern [classpath*:org/sourcelab/kafka/webview/ui/controller/*.class] to resources [file [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/controller/AbstractMvcTest.class], file [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/controller/BaseController.class]]
03:52:09.409 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved classpath location [org/sourcelab/kafka/webview/ui/] to resources [URL [file:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/], URL [file:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/], URL [file:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/target/classes/org/sourcelab/kafka/webview/ui/]]
03:52:09.410 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui]
03:52:09.410 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui] for files matching pattern [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/*.class]
03:52:09.411 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui]
03:52:09.412 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui] for files matching pattern [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/*.class]
03:52:09.413 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Looking for matching resources in directory tree [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/target/classes/org/sourcelab/kafka/webview/ui]
03:52:09.413 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Searching directory [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/target/classes/org/sourcelab/kafka/webview/ui] for files matching pattern [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/target/classes/org/sourcelab/kafka/webview/ui/*.class]
03:52:09.414 [main] DEBUG org.springframework.core.io.support.PathMatchingResourcePatternResolver - Resolved location pattern [classpath*:org/sourcelab/kafka/webview/ui/*.class] to resources [file [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes/org/sourcelab/kafka/webview/ui/ApplicationTest.class], file [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/Application.class]]
03:52:09.447 [main] DEBUG org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider - Identified candidate component class: file [/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes/org/sourcelab/kafka/webview/ui/Application.class]
03:52:09.449 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration org.sourcelab.kafka.webview.ui.Application for test class org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest
03:52:09.610 [main] DEBUG org.springframework.boot.test.context.SpringBootTestContextBootstrapper - @TestExecutionListeners is not present for class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]: using defaults.
03:52:09.611 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener]
03:52:09.634 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@865dd6, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4da4253, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@3972a855, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@62e7f11d, org.springframework.test.context.support.DirtiesContextTestExecutionListener@503d687a, org.springframework.test.context.transaction.TransactionalTestExecutionListener@6a370f4, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@2abf4075, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@770d3326, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@4cc8eb05, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@51f116b8, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@19d481b, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@1f97cf0d, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@140c9f39, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@4d910fd6]
03:52:09.636 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]
03:52:09.636 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]
03:52:09.639 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]
03:52:09.639 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]
03:52:09.640 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]
03:52:09.640 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]
03:52:09.645 [main] DEBUG org.springframework.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test class: context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = [null], testMethod = [null], testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true]], class annotated with @DirtiesContext [false] with mode [null].
03:52:09.645 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]
03:52:09.646 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest]
03:52:09.671 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'systemProperties' with lowest search precedence
03:52:09.671 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'systemEnvironment' with lowest search precedence
03:52:09.671 [main] DEBUG org.springframework.core.env.StandardEnvironment - Initialized StandardEnvironment with PropertySources [MapPropertySource@621300254 {name='systemProperties', properties={java.runtime.name=OpenJDK Runtime Environment, sun.boot.library.path=/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64, java.vm.version=25.121-b13, java.vm.vendor=Oracle Corporation, java.vendor.url=http://java.oracle.com/, skip.gulp=true, path.separator=:, java.vm.name=OpenJDK 64-Bit Server VM, file.encoding.pkg=sun.io, findbugs.skip=true, sun.java.launcher=SUN_STANDARD, sun.os.patch.level=unknown, java.vm.specification.name=Java Virtual Machine Specification, user.dir=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui, checkstyle.skip=true, java.runtime.version=1.8.0_121-8u121-b13-1~bpo8+1-b13, skip.npm=true, basedir=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui, java.awt.graphicsenv=sun.awt.X11GraphicsEnvironment, java.endorsed.dirs=/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed, os.arch=amd64, surefire.real.class.path=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/surefire/surefirebooter6557429458073905073.jar, gpg.skip=true, java.io.tmpdir=/tmp, line.separator=
, cobertura.skip=true, java.vm.specification.vendor=Oracle Corporation, os.name=Linux, sun.jnu.encoding=UTF-8, license.skip=true, java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib, surefire.test.class.path=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/target/classes:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka-clients/1.1.1/kafka-clients-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-thymeleaf/2.0.5.RELEASE/spring-boot-starter-thymeleaf-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter/2.0.5.RELEASE/spring-boot-starter-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-logging/2.0.5.RELEASE/spring-boot-starter-logging-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-core/1.2.3/logback-core-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-to-slf4j/2.10.0/log4j-to-slf4j-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-api/2.10.0/log4j-api-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/yaml/snakeyaml/1.19/snakeyaml-1.19.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring5/3.0.9.RELEASE/thymeleaf-spring5-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-java8time/3.0.1.RELEASE/thymeleaf-extras-java8time-3.0.1.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring4/3.0.9.RELEASE/thymeleaf-spring4-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf/3.0.9.RELEASE/thymeleaf-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ognl/ognl/3.1.12/ognl-3.1.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/javassist/javassist/3.20.0-GA/javassist-3.20.0-GA.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/attoparser/attoparser/2.0.4.RELEASE/attoparser-2.0.4.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/unbescape/unbescape/1.1.5.RELEASE/unbescape-1.1.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-layout-dialect/2.3.0/thymeleaf-layout-dialect-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-expression-processor/1.1.3/thymeleaf-expression-processor-1.1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-springsecurity4/3.0.2.RELEASE/thymeleaf-extras-springsecurity4-3.0.2.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-data-jpa/2.0.5.RELEASE/spring-boot-starter-data-jpa-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-aop/2.0.5.RELEASE/spring-boot-starter-aop-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/aspectj/aspectjweaver/1.8.13/aspectjweaver-1.8.13.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-jdbc/2.0.5.RELEASE/spring-boot-starter-jdbc-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/zaxxer/HikariCP/2.7.9/HikariCP-2.7.9.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jdbc/5.0.9.RELEASE/spring-jdbc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/hibernate-core/5.2.17.Final/hibernate-core-5.2.17.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/javax/persistence/hibernate-jpa-2.1-api/1.0.2.Final/hibernate-jpa-2.1-api-1.0.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/jandex/2.0.3.Final/jandex-2.0.3.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/classmate/1.3.4/classmate-1.3.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/common/hibernate-commons-annotations/5.0.1.Final/hibernate-commons-annotations-5.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-jpa/2.0.10.RELEASE/spring-data-jpa-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-commons/2.0.10.RELEASE/spring-data-commons-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-orm/5.0.9.RELEASE/spring-orm-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-context/5.0.9.RELEASE/spring-context-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-tx/5.0.9.RELEASE/spring-tx-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-beans/5.0.9.RELEASE/spring-beans-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aspects/5.0.9.RELEASE/spring-aspects-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/h2database/h2/1.4.197/h2-1.4.197.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-security/2.0.5.RELEASE/spring-boot-starter-security-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aop/5.0.9.RELEASE/spring-aop-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-config/5.0.8.RELEASE/spring-security-config-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-web/5.0.8.RELEASE/spring-security-web-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-expression/5.0.9.RELEASE/spring-expression-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-web/5.0.9.RELEASE/spring-web-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-websocket/2.0.5.RELEASE/spring-boot-starter-websocket-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-web/2.0.5.RELEASE/spring-boot-starter-web-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-json/2.0.5.RELEASE/spring-boot-starter-json-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.6/jackson-datatype-jdk8-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.6/jackson-module-parameter-names-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-tomcat/2.0.5.RELEASE/spring-boot-starter-tomcat-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-core/8.5.34/tomcat-embed-core-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-el/8.5.34/tomcat-embed-el-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-websocket/8.5.34/tomcat-embed-websocket-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/validator/hibernate-validator/6.0.12.Final/hibernate-validator-6.0.12.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-webmvc/5.0.9.RELEASE/spring-webmvc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-messaging/5.0.9.RELEASE/spring-messaging-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-websocket/5.0.9.RELEASE/spring-websocket-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-actuator/2.0.5.RELEASE/spring-boot-starter-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator-autoconfigure/2.0.5.RELEASE/spring-boot-actuator-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator/2.0.5.RELEASE/spring-boot-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.6/jackson-datatype-jsr310-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/io/micrometer/micrometer-core/1.0.6/micrometer-core-1.0.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hdrhistogram/HdrHistogram/2.1.10/HdrHistogram-2.1.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/interceptor/javax.interceptor-api/1.2.1/javax.interceptor-api-1.2.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-devtools/2.0.5.RELEASE/spring-boot-devtools-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot/2.0.5.RELEASE/spring-boot-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-autoconfigure/2.0.5.RELEASE/spring-boot-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-test/2.0.5.RELEASE/spring-boot-starter-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test/2.0.5.RELEASE/spring-boot-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test-autoconfigure/2.0.5.RELEASE/spring-boot-test-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/json-smart/2.3/json-smart-2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/junit/junit/4.12/junit-4.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/assertj/assertj-core/3.9.1/assertj-core-3.9.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/mockito/mockito-core/2.15.0/mockito-core-2.15.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy/1.7.11/byte-buddy-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy-agent/1.7.11/byte-buddy-agent-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-core/5.0.9.RELEASE/spring-core-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jcl/5.0.9.RELEASE/spring-jcl-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-test/5.0.9.RELEASE/spring-test-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xmlunit/xmlunit-core/2.5.1/xmlunit-core-2.5.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-test/5.0.8.RELEASE/spring-security-test-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-core/5.0.8.RELEASE/spring-security-core-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit4/3.0.1/kafka-junit4-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit-core/3.0.1/kafka-junit-core-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka_2.11/1.1.1/kafka_2.11-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/typesafe/scala-logging/scala-logging_2.11/3.8.0/scala-logging_2.11-3.8.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/zookeeper/zookeeper/3.4.10/zookeeper-3.4.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/pl/pragmatists/JUnitParams/1.1.1/JUnitParams-1.1.1.jar:, java.specification.name=Java Platform API Specification, java.class.version=52.0, skip.bower=true, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, maven.repo.local=/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2, os.version=3.10.0-862.3.2.el7.x86_64, user.home=/root, user.timezone=Europe/Paris, java.awt.printerjob=sun.print.PSPrinterJob, file.encoding=UTF-8, java.specification.version=1.8, java.class.path=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/target/classes:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka-clients/1.1.1/kafka-clients-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-thymeleaf/2.0.5.RELEASE/spring-boot-starter-thymeleaf-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter/2.0.5.RELEASE/spring-boot-starter-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-logging/2.0.5.RELEASE/spring-boot-starter-logging-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-core/1.2.3/logback-core-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-to-slf4j/2.10.0/log4j-to-slf4j-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-api/2.10.0/log4j-api-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/yaml/snakeyaml/1.19/snakeyaml-1.19.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring5/3.0.9.RELEASE/thymeleaf-spring5-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-java8time/3.0.1.RELEASE/thymeleaf-extras-java8time-3.0.1.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring4/3.0.9.RELEASE/thymeleaf-spring4-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf/3.0.9.RELEASE/thymeleaf-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ognl/ognl/3.1.12/ognl-3.1.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/javassist/javassist/3.20.0-GA/javassist-3.20.0-GA.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/attoparser/attoparser/2.0.4.RELEASE/attoparser-2.0.4.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/unbescape/unbescape/1.1.5.RELEASE/unbescape-1.1.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-layout-dialect/2.3.0/thymeleaf-layout-dialect-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-expression-processor/1.1.3/thymeleaf-expression-processor-1.1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-springsecurity4/3.0.2.RELEASE/thymeleaf-extras-springsecurity4-3.0.2.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-data-jpa/2.0.5.RELEASE/spring-boot-starter-data-jpa-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-aop/2.0.5.RELEASE/spring-boot-starter-aop-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/aspectj/aspectjweaver/1.8.13/aspectjweaver-1.8.13.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-jdbc/2.0.5.RELEASE/spring-boot-starter-jdbc-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/zaxxer/HikariCP/2.7.9/HikariCP-2.7.9.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jdbc/5.0.9.RELEASE/spring-jdbc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/hibernate-core/5.2.17.Final/hibernate-core-5.2.17.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/javax/persistence/hibernate-jpa-2.1-api/1.0.2.Final/hibernate-jpa-2.1-api-1.0.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/jandex/2.0.3.Final/jandex-2.0.3.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/classmate/1.3.4/classmate-1.3.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/common/hibernate-commons-annotations/5.0.1.Final/hibernate-commons-annotations-5.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-jpa/2.0.10.RELEASE/spring-data-jpa-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-commons/2.0.10.RELEASE/spring-data-commons-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-orm/5.0.9.RELEASE/spring-orm-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-context/5.0.9.RELEASE/spring-context-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-tx/5.0.9.RELEASE/spring-tx-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-beans/5.0.9.RELEASE/spring-beans-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aspects/5.0.9.RELEASE/spring-aspects-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/h2database/h2/1.4.197/h2-1.4.197.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-security/2.0.5.RELEASE/spring-boot-starter-security-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aop/5.0.9.RELEASE/spring-aop-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-config/5.0.8.RELEASE/spring-security-config-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-web/5.0.8.RELEASE/spring-security-web-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-expression/5.0.9.RELEASE/spring-expression-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-web/5.0.9.RELEASE/spring-web-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-websocket/2.0.5.RELEASE/spring-boot-starter-websocket-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-web/2.0.5.RELEASE/spring-boot-starter-web-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-json/2.0.5.RELEASE/spring-boot-starter-json-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.6/jackson-datatype-jdk8-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.6/jackson-module-parameter-names-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-tomcat/2.0.5.RELEASE/spring-boot-starter-tomcat-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-core/8.5.34/tomcat-embed-core-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-el/8.5.34/tomcat-embed-el-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-websocket/8.5.34/tomcat-embed-websocket-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/validator/hibernate-validator/6.0.12.Final/hibernate-validator-6.0.12.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-webmvc/5.0.9.RELEASE/spring-webmvc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-messaging/5.0.9.RELEASE/spring-messaging-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-websocket/5.0.9.RELEASE/spring-websocket-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-actuator/2.0.5.RELEASE/spring-boot-starter-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator-autoconfigure/2.0.5.RELEASE/spring-boot-actuator-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator/2.0.5.RELEASE/spring-boot-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.6/jackson-datatype-jsr310-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/io/micrometer/micrometer-core/1.0.6/micrometer-core-1.0.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hdrhistogram/HdrHistogram/2.1.10/HdrHistogram-2.1.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/interceptor/javax.interceptor-api/1.2.1/javax.interceptor-api-1.2.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-devtools/2.0.5.RELEASE/spring-boot-devtools-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot/2.0.5.RELEASE/spring-boot-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-autoconfigure/2.0.5.RELEASE/spring-boot-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-test/2.0.5.RELEASE/spring-boot-starter-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test/2.0.5.RELEASE/spring-boot-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test-autoconfigure/2.0.5.RELEASE/spring-boot-test-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/json-smart/2.3/json-smart-2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/junit/junit/4.12/junit-4.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/assertj/assertj-core/3.9.1/assertj-core-3.9.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/mockito/mockito-core/2.15.0/mockito-core-2.15.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy/1.7.11/byte-buddy-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy-agent/1.7.11/byte-buddy-agent-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-core/5.0.9.RELEASE/spring-core-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jcl/5.0.9.RELEASE/spring-jcl-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-test/5.0.9.RELEASE/spring-test-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xmlunit/xmlunit-core/2.5.1/xmlunit-core-2.5.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-test/5.0.8.RELEASE/spring-security-test-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-core/5.0.8.RELEASE/spring-security-core-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit4/3.0.1/kafka-junit4-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit-core/3.0.1/kafka-junit-core-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka_2.11/1.1.1/kafka_2.11-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/typesafe/scala-logging/scala-logging_2.11/3.8.0/scala-logging_2.11-3.8.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/zookeeper/zookeeper/3.4.10/zookeeper-3.4.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/pl/pragmatists/JUnitParams/1.1.1/JUnitParams-1.1.1.jar:, user.name=root, skipITs=true, java.vm.specification.version=1.8, sun.java.command=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/surefire/surefirebooter6557429458073905073.jar /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/surefire 2018-09-24T03-52-03_876-jvmRun1 surefire5579905461119079460tmp surefire_01248498674082760979tmp, java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre, sun.arch.data.model=64, user.language=en, java.specification.vendor=Oracle Corporation, dependency-check.skip=true, awt.toolkit=sun.awt.X11.XToolkit, java.vm.info=mixed mode, java.version=1.8.0_121, java.ext.dirs=/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext, sun.boot.class.path=/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes, rat.skip=true, enforcer.skip=true, java.vendor=Oracle Corporation, localRepository=/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2, file.separator=/, java.vendor.url.bug=http://bugreport.sun.com/bugreport/, sun.io.unicode.encoding=UnicodeLittle, sun.cpu.endian=little, sun.cpu.isalist=}}, SystemEnvironmentPropertySource@359368949 {name='systemEnvironment', properties={PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin, JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64, NOTIFY_TO=, CA_CERTIFICATES_JAVA_VERSION=20161107~bpo8+1, MONGODB_HOST=, BUILD_ID=, LANG=C.UTF-8, MAVEN_HOME=/usr/share/maven, SMTP_SERVER=, MONGODB_NAME=, REPAIR_MODE=repair, PWD=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui, JAVA_VERSION=8u121, GITHUB_OAUTH=, MAVEN_CMD_LINE_ARGS=/root/.m2 -B -D enforcer.skip=true -D dependency-check.skip=true -D skipITs=true -D cobertura.skip=true -D maven.repo.local=/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2 -D rat.skip=true -D findbugs.skip=true -D skip.bower=true -D gpg.skip=true -D checkstyle.skip=true -D skip.gulp=true -D license.skip=true -D skip.npm=true test, _=/usr/bin/java, OUTPUT=, MAVEN_TERMINATE_CMD=on, MAVEN_CONFIG=/root/.m2, MAVEN_PROJECTBASEDIR=/root/workspace/SourceLabOrg/kafka-webview/432293183, OLDPWD=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui, LOG_FILENAME=repairnator-pipeline_2018-09-24_0349_432293183_6927fb33-1ea7-4003-9018-b027a8f8f5e3, RUN_ID=, HOSTNAME=cyclone1, JAVA_DEBIAN_VERSION=8u121-b13-1~bpo8+1, M2_HOME=/usr/share/maven, REPAIR_TOOLS=AssertFixer, HOME=/root, SHLVL=1, PUSH_URL=}}]
03:52:09.675 [main] DEBUG org.springframework.test.context.support.TestPropertySourceUtils - Adding inlined properties to environment: {spring.jmx.enabled=false, org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true, server.port=-1}
03:52:09.675 [main] DEBUG org.springframework.core.env.StandardEnvironment - Adding PropertySource 'Inlined Test Properties' with highest search precedence

  _  __      __ _          __          __  _      __      ___
 | |/ /     / _| |         \ \        / / | |     \ \    / (_)
 | ' / __ _| |_| | ____ _   \ \  /\  / /__| |__    \ \  / / _  _____      __
 |  < / _` |  _| |/ / _` |   \ \/  \/ / _ \ '_ \    \ \/ / | |/ _ \ \ /\ / /
 | . \ (_| | | |   < (_| |    \  /\  /  __/ |_) |    \  /  | |  __/\ V  V /
 |_|\_\__,_|_| |_|\_\__,_|     \/  \/ \___|_.__/      \/   |_|\___| \_/\_/



2018-09-24 03:52:10.313  INFO 323 --- [           main] .k.w.u.c.c.m.MessageFormatControllerTest : Starting MessageFormatControllerTest on cyclone1 with PID 323 (started by root in /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui)
2018-09-24 03:52:10.316  INFO 323 --- [           main] .k.w.u.c.c.m.MessageFormatControllerTest : No active profile set, falling back to default profiles: default
2018-09-24 03:52:10.657  INFO 323 --- [           main] o.s.w.c.s.GenericWebApplicationContext   : Refreshing org.springframework.web.context.support.GenericWebApplicationContext@5b7a8434: startup date [Mon Sep 24 03:52:10 CEST 2018]; root of context hierarchy
2018-09-24 03:52:14.096  INFO 323 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c84796a2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-09-24 03:52:14.516  INFO 323 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2018-09-24 03:52:14.713  INFO 323 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2018-09-24 03:52:14.731  INFO 323 --- [           main] o.s.jdbc.datasource.init.ScriptUtils     : Executing SQL script from class path resource [schema/schema.sql]
2018-09-24 03:52:14.798  INFO 323 --- [           main] o.s.jdbc.datasource.init.ScriptUtils     : Executed SQL script from class path resource [schema/schema.sql] in 67 ms.
2018-09-24 03:52:15.003  INFO 323 --- [           main] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-09-24 03:52:15.031  INFO 323 --- [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-09-24 03:52:15.130  INFO 323 --- [           main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.2.17.Final}
2018-09-24 03:52:15.132  INFO 323 --- [           main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2018-09-24 03:52:15.234  INFO 323 --- [           main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.1.Final}
2018-09-24 03:52:15.470  INFO 323 --- [           main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-09-24 03:52:16.315  INFO 323 --- [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-09-24 03:52:17.464  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'clientInboundChannelExecutor'
2018-09-24 03:52:17.482  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'clientOutboundChannelExecutor'
2018-09-24 03:52:17.511  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 
2018-09-24 03:52:17.512  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'backgroundConsumerExecutor'
2018-09-24 03:52:18.796  INFO 323 --- [           main] o.s.s.web.DefaultSecurityFilterChain     : Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@30bd39d5, org.springframework.security.web.context.SecurityContextPersistenceFilter@1a66be41, org.springframework.security.web.header.HeaderWriterFilter@23a78c77, org.springframework.security.web.csrf.CsrfFilter@5d22604e, org.springframework.security.web.authentication.logout.LogoutFilter@68479e8b, org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter@45ad3cd8, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@fd14789, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@7bbd76b8, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@3c87e851, org.springframework.security.web.session.SessionManagementFilter@61d09475, org.springframework.security.web.access.ExceptionTranslationFilter@26d8908e, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@4e756867]
2018-09-24 03:52:18.872  WARN 323 --- [           main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2018-09-24 03:52:19.029  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topics/list],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicListing> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getTopics(java.lang.Long)
2018-09-24 03:52:19.031  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/create/topic],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.controller.api.responses.ResultResponse org.sourcelab.kafka.webview.ui.controller.api.ApiController.createTopic(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.CreateTopicRequest)
2018-09-24 03:52:19.032  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topic/{topic}/details],methods=[GET],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicDetails org.sourcelab.kafka.webview.ui.controller.api.ApiController.getTopicDetails(java.lang.Long,java.lang.String)
2018-09-24 03:52:19.033  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topic/{topic}/config],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConfigItem> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getTopicConfig(java.lang.Long,java.lang.String)
2018-09-24 03:52:19.034  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/broker/{brokerId}/config],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConfigItem> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getBrokerConfig(java.lang.Long,java.lang.String)
2018-09-24 03:52:19.034  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/nodes],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.NodeDetails> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getClusterNodes(java.lang.Long)
2018-09-24 03:52:19.034  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/consumer/view/{id}],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.KafkaResults org.sourcelab.kafka.webview.ui.controller.api.ApiController.consume(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.ConsumeRequest)
2018-09-24 03:52:19.035  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/consumer/view/{id}/offsets],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConsumerState org.sourcelab.kafka.webview.ui.controller.api.ApiController.setConsumerOffsets(java.lang.Long,java.util.Map<java.lang.Integer, java.lang.Long>)
2018-09-24 03:52:19.035  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/consumer/view/{id}/timestamp/{timestamp}],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConsumerState org.sourcelab.kafka.webview.ui.controller.api.ApiController.setConsumerOffsetsByTimestamp(java.lang.Long,java.lang.Long)
2018-09-24 03:52:19.036  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/view/{id}/partitions],methods=[GET],produces=[application/json]}" onto public java.util.Collection<java.lang.Integer> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getPartitionsForView(java.lang.Long)
2018-09-24 03:52:19.036  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topics/details],methods=[GET],produces=[application/json]}" onto public java.util.Collection<org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicDetails> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getAllTopicsDetails(java.lang.Long)
2018-09-24 03:52:19.038  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/modify/topic],methods=[POST],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConfigItem> org.sourcelab.kafka.webview.ui.controller.api.ApiController.modifyTopicConfig(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.ModifyTopicConfigRequest)
2018-09-24 03:52:19.040  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/filter/{id}/options],methods=[GET],produces=[application/json]}" onto public java.lang.String[] org.sourcelab.kafka.webview.ui.controller.api.ApiController.getFilterOptions(java.lang.Long)
2018-09-24 03:52:19.045  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.clusterIndex(org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.051  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster/{clusterId}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readCluster(java.lang.Long,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.052  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster/{clusterId}/broker/{brokerId}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readBroker(java.lang.Long,java.lang.Integer,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.052  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster/{clusterId}/topic/{topic:.+}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readTopic(java.lang.Long,java.lang.String,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.053  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.ConfigurationController.index(org.springframework.ui.Model)
2018-09-24 03:52:19.056  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.createClusterForm(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.ui.Model)
2018-09-24 03:52:19.056  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.editClusterForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:19.057  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.clusterUpdate(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.057  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.deleteCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.058  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/test/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.testCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.058  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.index(org.springframework.ui.Model)
2018-09-24 03:52:19.060  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.createFilter(org.sourcelab.kafka.webview.ui.controller.configuration.filter.forms.FilterForm,org.springframework.ui.Model)
2018-09-24 03:52:19.061  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.editFilter(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.filter.forms.FilterForm,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.061  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.index(org.springframework.ui.Model)
2018-09-24 03:52:19.062  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.update(org.sourcelab.kafka.webview.ui.controller.configuration.filter.forms.FilterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.062  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.delete(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.064  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.createMessageFormat(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.ui.Model)
2018-09-24 03:52:19.065  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.deleteCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.065  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.editMessageFormat(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.066  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.index(org.springframework.ui.Model)
2018-09-24 03:52:19.066  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.create(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:52:19.067  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/stream/close/{hash}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController.closeConsumer(java.lang.String,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.068  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/stream],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController.index(org.springframework.ui.Model)
2018-09-24 03:52:19.070  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.createUser(org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.ui.Model)
2018-09-24 03:52:19.070  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.editUserForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:19.071  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.index(org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.ui.Model)
2018-09-24 03:52:19.071  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.update(org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:19.072  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.delete(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.074  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.createViewForm(org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.ui.Model)
2018-09-24 03:52:19.074  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.editViewForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:19.075  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.updateView(org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:52:19.075  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.deleteView(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.076  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.index(org.springframework.ui.Model)
2018-09-24 03:52:19.077  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.home.HomeController.home(org.springframework.ui.Model)
2018-09-24 03:52:19.077  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/help],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.home.HomeController.help(org.springframework.ui.Model)
2018-09-24 03:52:19.078  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/me],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.me(org.springframework.security.core.Authentication)
2018-09-24 03:52:19.079  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.loginForm(org.springframework.ui.Model,java.lang.String)
2018-09-24 03:52:19.079  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/lostPassword],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.lostPasswordForm(org.sourcelab.kafka.webview.ui.controller.login.forms.LostPasswordForm)
2018-09-24 03:52:19.080  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/lostPassword],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.lostPasswordFormSubmit(org.sourcelab.kafka.webview.ui.controller.login.forms.LostPasswordForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:19.080  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/resetPassword],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.resetPasswordForm(org.sourcelab.kafka.webview.ui.controller.login.forms.ResetPasswordForm)
2018-09-24 03:52:19.080  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/resetPassword],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.resetPasswordFormSubmit(org.sourcelab.kafka.webview.ui.controller.login.forms.ResetPasswordForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:19.082  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/stream],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.index(org.springframework.ui.Model)
2018-09-24 03:52:19.082  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/stream/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.stream(java.lang.Long,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:19.083  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/view/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.view.ViewController.index(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:19.084  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/view],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.view.ViewController.index(org.springframework.ui.Model,java.lang.Long)
2018-09-24 03:52:19.093  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-09-24 03:52:19.093  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-09-24 03:52:19.162  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/css/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:52:19.162  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/js/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:52:19.163  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/vendors/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:52:19.163  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/img/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:52:19.312  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@5b7a8434: startup date [Mon Sep 24 03:52:10 CEST 2018]; root of context hierarchy
2018-09-24 03:52:19.442  INFO 323 --- [           main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService  'messageBrokerTaskScheduler'
2018-09-24 03:52:19.514  INFO 323 --- [           main] o.s.w.s.s.s.WebSocketHandlerMapping      : Mapped URL path [/websocket/**] onto handler of type [class org.springframework.web.socket.sockjs.support.SockJsHttpRequestHandler]
2018-09-24 03:52:19.536  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'brokerChannelExecutor'
2018-09-24 03:52:19.599  INFO 323 --- [           main] .WebSocketAnnotationMethodMessageHandler : Mapped "{[/pause/{viewId}],messageType=[MESSAGE]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.pauseConsumer(java.lang.Long,org.springframework.messaging.simp.SimpMessageHeaderAccessor)
2018-09-24 03:52:19.600  INFO 323 --- [           main] .WebSocketAnnotationMethodMessageHandler : Mapped "{[/resume/{viewId}],messageType=[MESSAGE]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.resumeConsumer(java.lang.Long,org.springframework.messaging.simp.SimpMessageHeaderAccessor)
2018-09-24 03:52:19.600  INFO 323 --- [           main] .WebSocketAnnotationMethodMessageHandler : Mapped "{[/consume/{viewId}],messageType=[MESSAGE]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.newConsumer(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.ConsumeRequest,org.springframework.messaging.simp.SimpMessageHeaderAccessor)
2018-09-24 03:52:21.054  INFO 323 --- [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'
2018-09-24 03:52:21.079  INFO 323 --- [           main] s.b.a.e.w.s.WebMvcEndpointHandlerMapping : Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:52:21.080  INFO 323 --- [           main] s.b.a.e.w.s.WebMvcEndpointHandlerMapping : Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:52:21.081  INFO 323 --- [           main] s.b.a.e.w.s.WebMvcEndpointHandlerMapping : Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-09-24 03:52:21.699  INFO 323 --- [           main] o.s.b.t.m.w.SpringBootMockServletContext : Initializing Spring FrameworkServlet ''
2018-09-24 03:52:21.699  INFO 323 --- [           main] o.s.t.web.servlet.TestDispatcherServlet  : FrameworkServlet '': initialization started
2018-09-24 03:52:21.718  INFO 323 --- [           main] o.s.t.web.servlet.TestDispatcherServlet  : FrameworkServlet '': initialization completed in 19 ms
2018-09-24 03:52:21.796  INFO 323 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-09-24 03:52:21.797  INFO 323 --- [           main] o.s.m.s.b.SimpleBrokerMessageHandler     : Starting...
2018-09-24 03:52:21.798  INFO 323 --- [           main] o.s.m.s.b.SimpleBrokerMessageHandler     : BrokerAvailabilityEvent[available=true, SimpleBrokerMessageHandler [DefaultSubscriptionRegistry[cache[0 destination(s)], registry[0 sessions]]]]
2018-09-24 03:52:21.799  INFO 323 --- [           main] o.s.m.s.b.SimpleBrokerMessageHandler     : Started.
2018-09-24 03:52:21.817  INFO 323 --- [           main] .k.w.u.c.c.m.MessageFormatControllerTest : Started MessageFormatControllerTest in 12.129 seconds (JVM running for 13.523)
2018-09-24 03:52:21.852  INFO 323 --- [           main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
Hibernate: select count(*) as col_0_0_ from user user0_
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
2018-09-24 03:52:22.473  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@1cfb7450, testMethod = testPostUpdate_createNewMessageFormatMissingFile@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/update
       Parameters = {name=[MyMessageFormat1537753942901], classpath=[examples.deserializer.ExampleDeserializer], _csrf=[5733fdef-da39-4be5-a4d3-705aeb3b9146]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@fe33371f: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@fe33371f: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@20276412; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.create(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,java.util.Map<java.lang.String, java.lang.String>)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/messageFormat/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 2
        Attribute = messageFormatForm
            value = MessageFormatForm{id=null, name='MyMessageFormat1537753942901', classpath='examples.deserializer.ExampleDeserializer', file=org.springframework.mock.web.MockMultipartFile@43c20142, customOptionNames=[], customOptionValues=[]}
           errors = [Field error in object 'messageFormatForm' on field 'file': rejected value []; codes []; arguments []; default message [Select a jar to upload]]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Message Format Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="5733fdef-da39-4be5-a4d3-705aeb3b9146"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753942598@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/2">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Create</strong>
                        <span>New Message Format</span>
                    </div>
                    <form
                        action="/configuration/messageFormat/update"
                        method="post" class="form-horizontal" enctype="multipart/form-data"><input type="hidden" name="_csrf" value="5733fdef-da39-4be5-a4d3-705aeb3b9146"/>
                        <div class="card-body">
                            <!-- Name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="name">
                                    Message Format Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="name" name="name" class="form-control" type="text"
                                        placeholder="A unique name to identify this message format"
                                        value="MyMessageFormat1537753942901">
                                    
                                </div>
                            </div>

                            <!-- Jar Upload -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="file">
                                    Jar upload
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="file" name="file" class="form-control is-invalid" type="file"
                                        placeholder="Select a jar to upload"
                                        value="org.springframework.mock.web.MockMultipartFile@43c20142">
                                    <div class="invalid-feedback">Select a jar to upload</div>
                                </div>
                            </div>

                            <!-- Fully qualified class name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="classpath">
                                    Fully qualified class name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="classpath" name="classpath" class="form-control" type="text"
                                        placeholder="Fully qualified class name for deserializer implementation"
                                        value="examples.deserializer.ExampleDeserializer">
                                    
                                </div>
                            </div>

                            <!-- Custom Settings -->
                            <h6>
                                Configuration Properties
                                <small class="form-text text-muted">
                                    If your Deserializer requires additional settings define them here.
                                </small>
                            </h6>
                            <hr>

                            <!-- Defined Options -->
                            <div id="optionsContainer">
                                <!-- Loop over each option -->
                                
                            </div>

                            <hr>

                            <!-- Dynamic Fields -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="newOption">
                                    Add new property
                                </label>
                                <div class="col-md-8">
                                    <input
                                        autocomplete="off" class="form-control" id="newOption" name="newOption" type="text"
                                        placeholder="Enter property name"/>
                                </div>
                                <div class="col-md-1">
                                    <button id="addOption" class="btn add-more" type="button">+</button>
                                </div>
                            </div>
                        </div>
                        <div class="card-footer">
                            
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/configuration/messageFormat" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>

    <script type="application/javascript">
        jQuery().ready(function() {
            jQuery('#addOption').click(function(e) {
                e.preventDefault();

                // Get and compile template
                var source   = jQuery('#options-template').html();
                var template = Handlebars.compile(source);

                // Get name from input
                var optionName = jQuery('#newOption').val();
                if (optionName == null || optionName.trim().length == 0) {
                    alert('Must enter a name for property');
                    return;
                }

                // Generate html from template
                var properties = {
                    optionName: optionName,
                    optionValueFieldName: "",
                    optionNameFieldName: "customOptionNames"
                };
                var optionsHtml = template(properties);

                // Append it to our div
                jQuery('#optionsContainer').append(optionsHtml);

                // Clear input
                jQuery('#newOption').val("");
            });
        });

        // Handle removing custom options
        function removeOption(element) {
            if (confirm('Are you sure you want to remove this property?')) {
                jQuery(element).closest('.custom-option').remove();
            }
        }
    </script>

    <!-- Options Template -->
    <script id="options-template" type="text/x-handlebars-template">
        <!-- User Defined Option -->
        <div class="form-group row custom-option">
            <label class="col-md-3 form-control-label" for="classpath">
                <i>{{optionName}}</i>
            </label>
            <div class="col-md-8">
                <input
                    type="text" name="customOptionValues" class="form-control"
                    placeholder="Set property value">
                <input
                    type="hidden" name="customOptionNames" value="{{optionName}}">
            </div>
            <div class="col-md-1">
                <button class="btn removeOption" type="button" onclick="removeOption(this);">-</button>
            </div>
        </div>
    </script>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
2018-09-24 03:52:24.476  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@1cfb7450, testMethod = testPostUpdate_createNewMessageFormatMissingFile@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:24.481  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@32b8992e, testMethod = testPostUpdate_newMessageFormat@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/update
       Parameters = {name=[MyMessageFormat1537753944798], classpath=[examples.deserializer.ExampleDeserializer], customOptionNames=[option1, option2], customOptionValues=[value1, value2], _csrf=[4e8c4a05-c91a-42f7-b876-055e65735c59]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Successfully created message format!'}}, targetRequestPath=/configuration/messageFormat, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@561ead00: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@561ead00: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5325674a; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.create(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,java.util.Map<java.lang.String, java.lang.String>)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/messageFormat
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Successfully created message format!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/messageFormat]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/messageFormat
          Cookies = []
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
2018-09-24 03:52:24.870  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@32b8992e, testMethod = testPostUpdate_newMessageFormat@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:24.873  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@18ab513d, testMethod = testIndex@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.is_default_format=? order by messagefor0_.name asc
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.is_default_format=? order by messagefor0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/messageFormat
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@7ec75228, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@566b8c2c: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@566b8c2c: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@55cf5626; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.index(org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/messageFormat/index
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 6
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@8de8b07
           errors = []
        Attribute = defaultMessageFormats
            value = [MessageFormat{id=5, name='ByteArray', classpath='org.apache.kafka.common.serialization.ByteArrayDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=2, name='Bytes', classpath='org.apache.kafka.common.serialization.BytesDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=7, name='Double', classpath='org.apache.kafka.common.serialization.DoubleDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=3, name='Float', classpath='org.apache.kafka.common.serialization.FloatDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=1, name='Integer', classpath='org.apache.kafka.common.serialization.IntegerDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=4, name='Long', classpath='org.apache.kafka.common.serialization.LongDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=8, name='Short', classpath='org.apache.kafka.common.serialization.ShortDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=6, name='String', classpath='org.apache.kafka.common.serialization.StringDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}]
        Attribute = customMessageFormats
            value = [MessageFormat{id=10, name='Format 1', classpath='com.example.Format 1', jar='Format 1.jar', isDefaultFormat=false, optionParameters='{"key": "value"}'}, MessageFormat{id=11, name='Format 2', classpath='com.example.Format 2', jar='Format 2.jar', isDefaultFormat=false, optionParameters='{"key": "value"}'}]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Message Format Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="75d6a6f6-a56a-4c8c-a199-0c5a911df508"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753944875@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/6">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Message Formats</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">

        <!-- Custom Message Formats -->
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Custom Message Formats
                        <div class="btn-group float-right" role="group" aria-label="Button group">
                            <a class="btn" href="/help#deserializers" style="padding-bottom: 0;">
                                <i class="icon-question"></i>
                                &nbsp; Help
                            </a>

                            <a class="btn" href="/configuration/messageFormat/create" style="padding-bottom: 0;">
                                <i class="icon-settings"></i>
                                &nbsp;Create new
                            </a>
                        </div>
                    </div>
                    <div class="card-body">
                        <table class="table table-bordered table-striped table-sm">
                            <thead>
                            <tr>
                                <th>Name</th>
                                <th>Class</th>
                                <th>Type</th>
                                <th class="text-right">Action</th>
                            </tr>
                            </thead>
                            <tbody>
                            
                            <tr>
                                <td>Format 1</td>
                                <td>com.example.Format 1</td>
                                <td>Custom</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <a class="dropdown-item" href="/configuration/messageFormat/edit/10">
                                                <i class="fa fa-edit"></i>
                                                Edit
                                            </a>
                                            <form action="/configuration/messageFormat/delete/10" method="post"><input type="hidden" name="_csrf" value="75d6a6f6-a56a-4c8c-a199-0c5a911df508"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Delete
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>Format 2</td>
                                <td>com.example.Format 2</td>
                                <td>Custom</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <a class="dropdown-item" href="/configuration/messageFormat/edit/11">
                                                <i class="fa fa-edit"></i>
                                                Edit
                                            </a>
                                            <form action="/configuration/messageFormat/delete/11" method="post"><input type="hidden" name="_csrf" value="75d6a6f6-a56a-4c8c-a199-0c5a911df508"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Delete
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
            <!--/.col-->
        </div>

        <!-- Default Message Formats -->
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Default Message Formats
                    </div>
                    <div class="card-body">
                        <table class="table table-bordered table-striped table-sm">
                            <thead>
                            <tr>
                                <th>Name</th>
                                <th>Class</th>
                                <th>Type</th>
                            </tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td>ByteArray</td>
                                <td>org.apache.kafka.common.serialization.ByteArrayDeserializer</td>
                                <td>Default</td>
                            </tr>
                            <tr>
                                <td>Bytes</td>
                                <td>org.apache.kafka.common.serialization.BytesDeserializer</td>
                                <td>Default</td>
                            </tr>
                            <tr>
                                <td>Double</td>
                                <td>org.apache.kafka.common.serialization.DoubleDeserializer</td>
                                <td>Default</td>
                            </tr>
                            <tr>
                                <td>Float</td>
                                <td>org.apache.kafka.common.serialization.FloatDeserializer</td>
                                <td>Default</td>
                            </tr>
                            <tr>
                                <td>Integer</td>
                                <td>org.apache.kafka.common.serialization.IntegerDeserializer</td>
                                <td>Default</td>
                            </tr>
                            <tr>
                                <td>Long</td>
                                <td>org.apache.kafka.common.serialization.LongDeserializer</td>
                                <td>Default</td>
                            </tr>
                            <tr>
                                <td>Short</td>
                                <td>org.apache.kafka.common.serialization.ShortDeserializer</td>
                                <td>Default</td>
                            </tr>
                            <tr>
                                <td>String</td>
                                <td>org.apache.kafka.common.serialization.StringDeserializer</td>
                                <td>Default</td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
            <!--/.col-->
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:25.268  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@18ab513d, testMethod = testIndex@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:25.275  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@677274e7, testMethod = testPostUpdate_createNewMessageFormatInvalidJar@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/update
       Parameters = {name=[MyMessageFormat1537753945490], classpath=[examples.deserializer.ExampleDeserializer], _csrf=[c8118c19-9bb7-4272-89a8-475d0a60307b]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@ee8f2282: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@ee8f2282: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@3ec52163; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.create(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,java.util.Map<java.lang.String, java.lang.String>)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/messageFormat/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 8
        Attribute = messageFormatForm
            value = MessageFormatForm{id=null, name='MyMessageFormat1537753945490', classpath='examples.deserializer.ExampleDeserializer', file=org.springframework.mock.web.MockMultipartFile@208b8425, customOptionNames=[], customOptionValues=[]}
           errors = [Field error in object 'messageFormatForm' on field 'file': rejected value []; codes []; arguments []; default message [Unable to find class examples.deserializer.ExampleDeserializer]]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Message Format Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="c8118c19-9bb7-4272-89a8-475d0a60307b"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753945277@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/8">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Create</strong>
                        <span>New Message Format</span>
                    </div>
                    <form
                        action="/configuration/messageFormat/update"
                        method="post" class="form-horizontal" enctype="multipart/form-data"><input type="hidden" name="_csrf" value="c8118c19-9bb7-4272-89a8-475d0a60307b"/>
                        <div class="card-body">
                            <!-- Name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="name">
                                    Message Format Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="name" name="name" class="form-control" type="text"
                                        placeholder="A unique name to identify this message format"
                                        value="MyMessageFormat1537753945490">
                                    
                                </div>
                            </div>

                            <!-- Jar Upload -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="file">
                                    Jar upload
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="file" name="file" class="form-control is-invalid" type="file"
                                        placeholder="Select a jar to upload"
                                        value="org.springframework.mock.web.MockMultipartFile@208b8425">
                                    <div class="invalid-feedback">Unable to find class examples.deserializer.ExampleDeserializer</div>
                                </div>
                            </div>

                            <!-- Fully qualified class name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="classpath">
                                    Fully qualified class name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="classpath" name="classpath" class="form-control" type="text"
                                        placeholder="Fully qualified class name for deserializer implementation"
                                        value="examples.deserializer.ExampleDeserializer">
                                    
                                </div>
                            </div>

                            <!-- Custom Settings -->
                            <h6>
                                Configuration Properties
                                <small class="form-text text-muted">
                                    If your Deserializer requires additional settings define them here.
                                </small>
                            </h6>
                            <hr>

                            <!-- Defined Options -->
                            <div id="optionsContainer">
                                <!-- Loop over each option -->
                                
                            </div>

                            <hr>

                            <!-- Dynamic Fields -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="newOption">
                                    Add new property
                                </label>
                                <div class="col-md-8">
                                    <input
                                        autocomplete="off" class="form-control" id="newOption" name="newOption" type="text"
                                        placeholder="Enter property name"/>
                                </div>
                                <div class="col-md-1">
                                    <button id="addOption" class="btn add-more" type="button">+</button>
                                </div>
                            </div>
                        </div>
                        <div class="card-footer">
                            
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/configuration/messageFormat" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>

    <script type="application/javascript">
        jQuery().ready(function() {
            jQuery('#addOption').click(function(e) {
                e.preventDefault();

                // Get and compile template
                var source   = jQuery('#options-template').html();
                var template = Handlebars.compile(source);

                // Get name from input
                var optionName = jQuery('#newOption').val();
                if (optionName == null || optionName.trim().length == 0) {
                    alert('Must enter a name for property');
                    return;
                }

                // Generate html from template
                var properties = {
                    optionName: optionName,
                    optionValueFieldName: "",
                    optionNameFieldName: "customOptionNames"
                };
                var optionsHtml = template(properties);

                // Append it to our div
                jQuery('#optionsContainer').append(optionsHtml);

                // Clear input
                jQuery('#newOption').val("");
            });
        });

        // Handle removing custom options
        function removeOption(element) {
            if (confirm('Are you sure you want to remove this property?')) {
                jQuery(element).closest('.custom-option').remove();
            }
        }
    </script>

    <!-- Options Template -->
    <script id="options-template" type="text/x-handlebars-template">
        <!-- User Defined Option -->
        <div class="form-group row custom-option">
            <label class="col-md-3 form-control-label" for="classpath">
                <i>{{optionName}}</i>
            </label>
            <div class="col-md-8">
                <input
                    type="text" name="customOptionValues" class="form-control"
                    placeholder="Set property value">
                <input
                    type="hidden" name="customOptionNames" value="{{optionName}}">
            </div>
            <div class="col-md-1">
                <button class="btn removeOption" type="button" onclick="removeOption(this);">-</button>
            </div>
        </div>
    </script>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
2018-09-24 03:52:25.539  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@677274e7, testMethod = testPostUpdate_createNewMessageFormatInvalidJar@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:25.542  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@6334c0d8, testMethod = testPostDelete_inUse@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into view (id, cluster_id, created_at, key_message_format_id, name, partitions, results_per_partition, topic, updated_at, value_message_format_id) values (null, ?, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ left outer join message_format messagefor1_ on view0_.key_message_format_id=messagefor1_.id left outer join message_format messagefor2_ on view0_.value_message_format_id=messagefor2_.id where messagefor1_.id=? or messagefor2_.id=? order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/delete/12
       Parameters = {_csrf=[6f5cac9e-3f64-4f13-8463-b5d0f31e7fdf]}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='warning', message='Message format in use by views: [My Name]'}}, targetRequestPath=/configuration/messageFormat, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@d370e35e: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@d370e35e: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@17e4beda; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.deleteCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/messageFormat
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='warning', message='Message format in use by views: [My Name]'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/messageFormat]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/messageFormat
          Cookies = []
2018-09-24 03:52:25.844  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@6334c0d8, testMethod = testPostDelete_inUse@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:25.848  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@61627c9d, testMethod = testPostUpdate_updatingExistingButWithInvalidJar@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/update
       Parameters = {id=[13], name=[Updated Name], classpath=[made.up.classpath], customOptionNames=[option1, option2], customOptionValues=[value1, value2], _csrf=[68fed4a5-7141-4ce2-b919-d1d8eaaed6d9]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@484dd0f: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@484dd0f: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@3b39bee2; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.create(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,java.util.Map<java.lang.String, java.lang.String>)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/messageFormat/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 12
        Attribute = messageFormatForm
            value = MessageFormatForm{id=13, name='Updated Name', classpath='made.up.classpath', file=org.springframework.mock.web.MockMultipartFile@26f7b114, customOptionNames=[option1, option2], customOptionValues=[value1, value2]}
           errors = [Field error in object 'messageFormatForm' on field 'file': rejected value []; codes []; arguments []; default message [Unable to find class made.up.classpath]]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Message Format Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="68fed4a5-7141-4ce2-b919-d1d8eaaed6d9"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753945850@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/12">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Edit</strong>
                        <span>Updated Name</span>
                    </div>
                    <form
                        action="/configuration/messageFormat/update"
                        method="post" class="form-horizontal" enctype="multipart/form-data"><input type="hidden" name="_csrf" value="68fed4a5-7141-4ce2-b919-d1d8eaaed6d9"/>
                        <div class="card-body">
                            <!-- Name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="name">
                                    Message Format Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="name" name="name" class="form-control" type="text"
                                        placeholder="A unique name to identify this message format"
                                        value="Updated Name">
                                    
                                </div>
                            </div>

                            <!-- Jar Upload -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="file">
                                    Jar upload
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="file" name="file" class="form-control is-invalid" type="file"
                                        placeholder="Select a jar to upload"
                                        value="org.springframework.mock.web.MockMultipartFile@26f7b114">
                                    <div class="invalid-feedback">Unable to find class made.up.classpath</div>
                                </div>
                            </div>

                            <!-- Fully qualified class name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="classpath">
                                    Fully qualified class name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="classpath" name="classpath" class="form-control" type="text"
                                        placeholder="Fully qualified class name for deserializer implementation"
                                        value="made.up.classpath">
                                    
                                </div>
                            </div>

                            <!-- Custom Settings -->
                            <h6>
                                Configuration Properties
                                <small class="form-text text-muted">
                                    If your Deserializer requires additional settings define them here.
                                </small>
                            </h6>
                            <hr>

                            <!-- Defined Options -->
                            <div id="optionsContainer">
                                <!-- Loop over each option -->
                                <div class="form-group row custom-option">
                                    <label class="col-md-3 form-control-label" for="classpath">
                                        <i>option1</i>
                                    </label>
                                    <div class="col-md-8">
                                        <input
                                            value="value1"
                                            type="text" name="customOptionValues" class="form-control"
                                            placeholder="Set property value">
                                        <input
                                            value="option1"
                                            type="hidden" name="customOptionNames">
                                    </div>
                                    <div class="col-md-1">
                                        <button class="btn removeOption" type="button" onclick="removeOption(this);">-</button>
                                    </div>
                                </div>
                                <div class="form-group row custom-option">
                                    <label class="col-md-3 form-control-label" for="classpath">
                                        <i>option2</i>
                                    </label>
                                    <div class="col-md-8">
                                        <input
                                            value="value2"
                                            type="text" name="customOptionValues" class="form-control"
                                            placeholder="Set property value">
                                        <input
                                            value="option2"
                                            type="hidden" name="customOptionNames">
                                    </div>
                                    <div class="col-md-1">
                                        <button class="btn removeOption" type="button" onclick="removeOption(this);">-</button>
                                    </div>
                                </div>
                            </div>

                            <hr>

                            <!-- Dynamic Fields -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="newOption">
                                    Add new property
                                </label>
                                <div class="col-md-8">
                                    <input
                                        autocomplete="off" class="form-control" id="newOption" name="newOption" type="text"
                                        placeholder="Enter property name"/>
                                </div>
                                <div class="col-md-1">
                                    <button id="addOption" class="btn add-more" type="button">+</button>
                                </div>
                            </div>
                        </div>
                        <div class="card-footer">
                            <input type="hidden" name="id" id="id" value="13">
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/configuration/messageFormat" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>

    <script type="application/javascript">
        jQuery().ready(function() {
            jQuery('#addOption').click(function(e) {
                e.preventDefault();

                // Get and compile template
                var source   = jQuery('#options-template').html();
                var template = Handlebars.compile(source);

                // Get name from input
                var optionName = jQuery('#newOption').val();
                if (optionName == null || optionName.trim().length == 0) {
                    alert('Must enter a name for property');
                    return;
                }

                // Generate html from template
                var properties = {
                    optionName: optionName,
                    optionValueFieldName: "",
                    optionNameFieldName: "customOptionNames"
                };
                var optionsHtml = template(properties);

                // Append it to our div
                jQuery('#optionsContainer').append(optionsHtml);

                // Clear input
                jQuery('#newOption').val("");
            });
        });

        // Handle removing custom options
        function removeOption(element) {
            if (confirm('Are you sure you want to remove this property?')) {
                jQuery(element).closest('.custom-option').remove();
            }
        }
    </script>

    <!-- Options Template -->
    <script id="options-template" type="text/x-handlebars-template">
        <!-- User Defined Option -->
        <div class="form-group row custom-option">
            <label class="col-md-3 form-control-label" for="classpath">
                <i>{{optionName}}</i>
            </label>
            <div class="col-md-8">
                <input
                    type="text" name="customOptionValues" class="form-control"
                    placeholder="Set property value">
                <input
                    type="hidden" name="customOptionNames" value="{{optionName}}">
            </div>
            <div class="col-md-1">
                <button class="btn removeOption" type="button" onclick="removeOption(this);">-</button>
            </div>
        </div>
    </script>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:26.175  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@61627c9d, testMethod = testPostUpdate_updatingExistingButWithInvalidJar@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:26.179  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@20ddc780, testMethod = testPostDelete_notUsed@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ left outer join message_format messagefor1_ on view0_.key_message_format_id=messagefor1_.id left outer join message_format messagefor2_ on view0_.value_message_format_id=messagefor2_.id where messagefor1_.id=? or messagefor2_.id=? order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/delete/14
       Parameters = {_csrf=[36edbdcc-6d4d-4446-b41d-155b5ca8c37a]}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Deleted message format!'}}, targetRequestPath=/configuration/messageFormat, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@61e10d7: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@61e10d7: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@4d2f8ee7; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.deleteCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/messageFormat
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Deleted message format!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/messageFormat]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/messageFormat
          Cookies = []
Hibernate: delete from message_format where id=?
Hibernate: select count(*) as col_0_0_ from message_format messagefor0_ where messagefor0_.id=?
2018-09-24 03:52:26.424  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@20ddc780, testMethod = testPostDelete_notUsed@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:26.426  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@2f97e3de, testMethod = testPostUpdate_updatingExistingNoJarUploaded@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/update
       Parameters = {id=[15], name=[MyUpdatedName1537753946633], classpath=[my new class path], customOptionNames=[option1, option2], customOptionValues=[value1, value2], _csrf=[e9c6400f-a231-4716-9424-3682b55f99df]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Successfully created message format!'}}, targetRequestPath=/configuration/messageFormat, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@900f66d: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@900f66d: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5eed2edf; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.create(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,java.util.Map<java.lang.String, java.lang.String>)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/messageFormat
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Successfully created message format!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/messageFormat]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/messageFormat
          Cookies = []
2018-09-24 03:52:26.647  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@2f97e3de, testMethod = testPostUpdate_updatingExistingNoJarUploaded@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:26.649  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@5c648e38, testMethod = test_withoutAdminRole@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/messageFormat
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@ae5d544, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@da17884: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@da17884: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5aec151b; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/messageFormat/create
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@74cf2d5f, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@da17884: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@da17884: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5aec151b; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/messageFormat/edit/1
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@14b9817b, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@da17884: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@da17884: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5aec151b; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/create
       Parameters = {_csrf=[5adf826c-a3d8-4420-bbfe-764f27cecfdb]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@da17884: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@da17884: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5aec151b; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/delete/1
       Parameters = {_csrf=[f660ad34-517c-4f19-9eb1-c8f3030439e9]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@da17884: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@da17884: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5aec151b; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:26.891  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@5c648e38, testMethod = test_withoutAdminRole@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:26.894  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@5fee3c9c, testMethod = testPostUpdate_updatingExistingButWithBadMessageFormatId@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/update
       Parameters = {id=[-1000], name=[MyMessageFormat1537753947149], classpath=[examples.deserializer.ExampleDeserializer], _csrf=[1be86de9-7f58-4962-a68d-fc40d85134cf]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='warning', message='Unable to find message format!'}}, targetRequestPath=/configuration/messageFormat, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@936d39ce: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@936d39ce: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@2db82155; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.create(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,java.util.Map<java.lang.String, java.lang.String>)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/messageFormat
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='warning', message='Unable to find message format!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/messageFormat]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/messageFormat
          Cookies = []
2018-09-24 03:52:27.170  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@5fee3c9c, testMethod = testPostUpdate_updatingExistingButWithBadMessageFormatId@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:27.173  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@2eb91767, testMethod = testPostUpdate_updatingExistingWithValidJarSameName@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/messageFormat/update
       Parameters = {id=[16], name=[MyUpdatedName1537753947396], classpath=[examples.deserializer.ExampleDeserializer], _csrf=[988c13a2-59d0-4206-b907-c74a4074d1d6]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Successfully created message format!'}}, targetRequestPath=/configuration/messageFormat, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@ce48210f: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@ce48210f: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@28d1b2f; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.create(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,java.util.Map<java.lang.String, java.lang.String>)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/messageFormat
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Successfully created message format!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/messageFormat]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/messageFormat
          Cookies = []
2018-09-24 03:52:27.412  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@2eb91767, testMethod = testPostUpdate_updatingExistingWithValidJarSameName@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:27.415  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@5f32de90, testMethod = testGetCreate@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/messageFormat/create
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@72ad577b, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@bc0188a: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@bc0188a: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@99948fe; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.createMessageFormat(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/messageFormat/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 24
        Attribute = messageFormatForm
            value = MessageFormatForm{id=null, name='null', classpath='null', file=null, customOptionNames=[], customOptionValues=[]}
           errors = []
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@4c31b6c2
           errors = []

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Message Format Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="b088ad9c-4c8d-476d-aa4b-f15c60f4091e"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753947416@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/24">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration/messageFormat">Message Formats</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Create</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Create</strong>
                        <span>New Message Format</span>
                    </div>
                    <form
                        action="/configuration/messageFormat/update"
                        method="post" class="form-horizontal" enctype="multipart/form-data"><input type="hidden" name="_csrf" value="b088ad9c-4c8d-476d-aa4b-f15c60f4091e"/>
                        <div class="card-body">
                            <!-- Name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="name">
                                    Message Format Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="name" name="name" class="form-control" type="text"
                                        placeholder="A unique name to identify this message format"
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Jar Upload -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="file">
                                    Jar upload
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="file" name="file" class="form-control" type="file"
                                        placeholder="Select a jar to upload"
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Fully qualified class name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="classpath">
                                    Fully qualified class name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="classpath" name="classpath" class="form-control" type="text"
                                        placeholder="Fully qualified class name for deserializer implementation"
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Custom Settings -->
                            <h6>
                                Configuration Properties
                                <small class="form-text text-muted">
                                    If your Deserializer requires additional settings define them here.
                                </small>
                            </h6>
                            <hr>

                            <!-- Defined Options -->
                            <div id="optionsContainer">
                                <!-- Loop over each option -->
                                
                            </div>

                            <hr>

                            <!-- Dynamic Fields -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="newOption">
                                    Add new property
                                </label>
                                <div class="col-md-8">
                                    <input
                                        autocomplete="off" class="form-control" id="newOption" name="newOption" type="text"
                                        placeholder="Enter property name"/>
                                </div>
                                <div class="col-md-1">
                                    <button id="addOption" class="btn add-more" type="button">+</button>
                                </div>
                            </div>
                        </div>
                        <div class="card-footer">
                            
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/configuration/messageFormat" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>

    <script type="application/javascript">
        jQuery().ready(function() {
            jQuery('#addOption').click(function(e) {
                e.preventDefault();

                // Get and compile template
                var source   = jQuery('#options-template').html();
                var template = Handlebars.compile(source);

                // Get name from input
                var optionName = jQuery('#newOption').val();
                if (optionName == null || optionName.trim().length == 0) {
                    alert('Must enter a name for property');
                    return;
                }

                // Generate html from template
                var properties = {
                    optionName: optionName,
                    optionValueFieldName: "",
                    optionNameFieldName: "customOptionNames"
                };
                var optionsHtml = template(properties);

                // Append it to our div
                jQuery('#optionsContainer').append(optionsHtml);

                // Clear input
                jQuery('#newOption').val("");
            });
        });

        // Handle removing custom options
        function removeOption(element) {
            if (confirm('Are you sure you want to remove this property?')) {
                jQuery(element).closest('.custom-option').remove();
            }
        }
    </script>

    <!-- Options Template -->
    <script id="options-template" type="text/x-handlebars-template">
        <!-- User Defined Option -->
        <div class="form-group row custom-option">
            <label class="col-md-3 form-control-label" for="classpath">
                <i>{{optionName}}</i>
            </label>
            <div class="col-md-8">
                <input
                    type="text" name="customOptionValues" class="form-control"
                    placeholder="Set property value">
                <input
                    type="hidden" name="customOptionNames" value="{{optionName}}">
            </div>
            <div class="col-md-1">
                <button class="btn removeOption" type="button" onclick="removeOption(this);">-</button>
            </div>
        </div>
    </script>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:27.681  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@5f32de90, testMethod = testGetCreate@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:27.684  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@5605a59b, testMethod = testGetEdit_existingMessageFormat@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/messageFormat/edit/17
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@687d31a9, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@74db4e7d: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@74db4e7d: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@6ce24203; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.editMessageFormat(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/messageFormat/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 26
        Attribute = messageFormatForm
            value = MessageFormatForm{id=17, name='MyMessageFormat1537753947897', classpath='com.example.MyMessageFormat1537753947897', file=null, customOptionNames=[myOption1, myOption2], customOptionValues=[myValue1, myValue2]}
           errors = []
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@4cc28ad0
           errors = []

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Message Format Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="ece8daf8-43b1-4d2a-9652-cbb49ac86084"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753947686@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/26">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration/messageFormat">Message Formats</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Edit MyMessageFormat1537753947897</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Edit</strong>
                        <span>MyMessageFormat1537753947897</span>
                    </div>
                    <form
                        action="/configuration/messageFormat/update"
                        method="post" class="form-horizontal" enctype="multipart/form-data"><input type="hidden" name="_csrf" value="ece8daf8-43b1-4d2a-9652-cbb49ac86084"/>
                        <div class="card-body">
                            <!-- Name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="name">
                                    Message Format Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="name" name="name" class="form-control" type="text"
                                        placeholder="A unique name to identify this message format"
                                        value="MyMessageFormat1537753947897">
                                    
                                </div>
                            </div>

                            <!-- Jar Upload -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="file">
                                    Jar upload
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="file" name="file" class="form-control" type="file"
                                        placeholder="Select a jar to upload"
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Fully qualified class name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="classpath">
                                    Fully qualified class name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="classpath" name="classpath" class="form-control" type="text"
                                        placeholder="Fully qualified class name for deserializer implementation"
                                        value="com.example.MyMessageFormat1537753947897">
                                    
                                </div>
                            </div>

                            <!-- Custom Settings -->
                            <h6>
                                Configuration Properties
                                <small class="form-text text-muted">
                                    If your Deserializer requires additional settings define them here.
                                </small>
                            </h6>
                            <hr>

                            <!-- Defined Options -->
                            <div id="optionsContainer">
                                <!-- Loop over each option -->
                                <div class="form-group row custom-option">
                                    <label class="col-md-3 form-control-label" for="classpath">
                                        <i>myOption1</i>
                                    </label>
                                    <div class="col-md-8">
                                        <input
                                            value="myValue1"
                                            type="text" name="customOptionValues" class="form-control"
                                            placeholder="Set property value">
                                        <input
                                            value="myOption1"
                                            type="hidden" name="customOptionNames">
                                    </div>
                                    <div class="col-md-1">
                                        <button class="btn removeOption" type="button" onclick="removeOption(this);">-</button>
                                    </div>
                                </div>
                                <div class="form-group row custom-option">
                                    <label class="col-md-3 form-control-label" for="classpath">
                                        <i>myOption2</i>
                                    </label>
                                    <div class="col-md-8">
                                        <input
                                            value="myValue2"
                                            type="text" name="customOptionValues" class="form-control"
                                            placeholder="Set property value">
                                        <input
                                            value="myOption2"
                                            type="hidden" name="customOptionNames">
                                    </div>
                                    <div class="col-md-1">
                                        <button class="btn removeOption" type="button" onclick="removeOption(this);">-</button>
                                    </div>
                                </div>
                            </div>

                            <hr>

                            <!-- Dynamic Fields -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="newOption">
                                    Add new property
                                </label>
                                <div class="col-md-8">
                                    <input
                                        autocomplete="off" class="form-control" id="newOption" name="newOption" type="text"
                                        placeholder="Enter property name"/>
                                </div>
                                <div class="col-md-1">
                                    <button id="addOption" class="btn add-more" type="button">+</button>
                                </div>
                            </div>
                        </div>
                        <div class="card-footer">
                            <input type="hidden" name="id" id="id" value="17">
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/configuration/messageFormat" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>

    <script type="application/javascript">
        jQuery().ready(function() {
            jQuery('#addOption').click(function(e) {
                e.preventDefault();

                // Get and compile template
                var source   = jQuery('#options-template').html();
                var template = Handlebars.compile(source);

                // Get name from input
                var optionName = jQuery('#newOption').val();
                if (optionName == null || optionName.trim().length == 0) {
                    alert('Must enter a name for property');
                    return;
                }

                // Generate html from template
                var properties = {
                    optionName: optionName,
                    optionValueFieldName: "",
                    optionNameFieldName: "customOptionNames"
                };
                var optionsHtml = template(properties);

                // Append it to our div
                jQuery('#optionsContainer').append(optionsHtml);

                // Clear input
                jQuery('#newOption').val("");
            });
        });

        // Handle removing custom options
        function removeOption(element) {
            if (confirm('Are you sure you want to remove this property?')) {
                jQuery(element).closest('.custom-option').remove();
            }
        }
    </script>

    <!-- Options Template -->
    <script id="options-template" type="text/x-handlebars-template">
        <!-- User Defined Option -->
        <div class="form-group row custom-option">
            <label class="col-md-3 form-control-label" for="classpath">
                <i>{{optionName}}</i>
            </label>
            <div class="col-md-8">
                <input
                    type="text" name="customOptionValues" class="form-control"
                    placeholder="Set property value">
                <input
                    type="hidden" name="customOptionNames" value="{{optionName}}">
            </div>
            <div class="col-md-1">
                <button class="btn removeOption" type="button" onclick="removeOption(this);">-</button>
            </div>
        </div>
    </script>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:27.988  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@4e7912d8 testClass = MessageFormatControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest@5605a59b, testMethod = testGetEdit_existingMessageFormat@MessageFormatControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@53976f5c testClass = MessageFormatControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@2bfc268b key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.066 s - in org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatControllerTest
[INFO] Running org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest
2018-09-24 03:52:27.991  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Neither @ContextConfiguration nor @ContextHierarchy found for test class [org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest], using SpringBootContextLoader
2018-09-24 03:52:27.992  INFO 323 --- [           main] o.s.t.c.support.AbstractContextLoader    : Could not detect default resource locations for test class [org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-09-24 03:52:27.992  INFO 323 --- [           main] t.c.s.AnnotationConfigContextLoaderUtils : Could not detect default configuration classes for test class [org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest]: UserControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2018-09-24 03:52:28.007  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Found @SpringBootConfiguration org.sourcelab.kafka.webview.ui.Application for test class org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest
2018-09-24 03:52:28.010  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener]
2018-09-24 03:52:28.011  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@13d1653, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3533d790, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@23e1f610, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@73dc7db0, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1a3a6216, org.springframework.test.context.transaction.TransactionalTestExecutionListener@319ea996, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1de398c3, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@dc24732, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@44a1ae4e, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@377d55, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@193c810, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@1ef7e4c7, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@57edfa89, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@6c0bf8f4]
2018-09-24 03:52:28.029  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@37fc7e3c, testMethod = testLoadEditForOtherUserAsAdminUser@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/user/edit/29
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@6f076c53, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@3c9b5092: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@3c9b5092: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@3c39c739; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.editUserForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/user/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 28
        Attribute = userForm
            value = UserForm{id=29, email='test1537753948137@example.com', displayName='Test User', password='XXXXX', password2='XXXXX', userRole=ROLE_USER}
           errors = []
        Attribute = isAdmin
            value = true
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@4b3b2a4f
           errors = []
        Attribute = userRoles
            value = [ROLE_USER, ROLE_ADMIN]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>User Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="3288b6c4-9a23-4605-8e3c-929c8d142923"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753948030@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/28">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration/user">Users</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Edit: Test User</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Edit</strong>
                        <span>Test User</span>
                    </div>
                    <form
                        action="/configuration/user/update"
                        method="post" class="form-horizontal" autocomplete="off"><input type="hidden" name="_csrf" value="3288b6c4-9a23-4605-8e3c-929c8d142923"/>
                        <div class="card-body">

                            <!-- Email Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="email">
                                    Email Address
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="email" name="email" class="form-control" type="text"
                                        placeholder="User's email address"
                                        value="test1537753948137@example.com">
                                    
                                </div>
                            </div>

                            <!-- Name Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="displayName">
                                    Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="displayName" name="displayName" class="form-control" type="text"
                                        placeholder="User's name"
                                        value="Test User">
                                    
                                </div>
                            </div>

                            <!-- Password Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="password">
                                    Password
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="password" name="password" class="form-control" type="password"
                                        placeholder=""
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Password Validation Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="password2">
                                    Verify Password
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="password2" name="password2" class="form-control" type="password"
                                        placeholder=""
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- User role -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="userRole">
                                    User Role
                                </label>
                                <div class="col-md-9">
                                    <select
                                        id="userRole" name="userRole" class="form-control">
                                    <option value="">Please select a user role</option>
                                    <option value="ROLE_USER" selected="selected">ROLE_USER</option>
                                    <option value="ROLE_ADMIN">ROLE_ADMIN</option>
                                    </select>
                                    
                                </div>
                            </div>
                        </div>
                        <div class="card-footer">
                            <input type="hidden" name="id" id="id" value="29">
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/configuration/user" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:28.303  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@37fc7e3c, testMethod = testLoadEditForOtherUserAsAdminUser@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:28.306  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@2e8eafb2, testMethod = testIndex@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.is_active=? order by user0_.email asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/user
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@306c8e09, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@8e2c8368: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@8e2c8368: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@87df88d; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.index(org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/user/index
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 30
        Attribute = userForm
            value = UserForm{id=null, email='null', displayName='null', password='XXXXX', password2='XXXXX', userRole=ROLE_USER}
           errors = []
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@4f3b11e6
           errors = []
        Attribute = users
            value = [org.sourcelab.kafka.webview.ui.model.User@1516f497, org.sourcelab.kafka.webview.ui.model.User@7a3f3bc4, org.sourcelab.kafka.webview.ui.model.User@57859e2c]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>User Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="7f95a1df-a9d1-4fb4-a0c4-6a5f76ceb82d"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753948308@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/30">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Users</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Users
                        <div class="btn-group float-right" role="group" aria-label="Button group">
                            <a class="btn" href="/configuration/user/create" style="padding-bottom: 0;">
                                <i class="icon-settings"></i>
                                &nbsp;Create new
                            </a>
                        </div>
                    </div>
                    <div class="card-body">
                        <table class="table table-bordered table-striped table-sm">
                            <thead>
                            <tr>
                                <th>Email</th>
                                <th>Name</th>
                                <th>Role</th>
                                <th class="text-right">Action</th>
                            </tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td>admin@example.com</td>
                                <td>Default Admin User</td>
                                <td>ROLE_ADMIN</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <a class="dropdown-item" href="/configuration/user/edit/1">
                                                <i class="fa fa-edit"></i>
                                                Edit
                                            </a>
                                            <form action="/configuration/user/delete/1" method="post"><input type="hidden" name="_csrf" value="7f95a1df-a9d1-4fb4-a0c4-6a5f76ceb82d"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Delete
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>test1537753948308@example.com</td>
                                <td>Test User</td>
                                <td>ROLE_ADMIN</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <a class="dropdown-item" href="/configuration/user/edit/30">
                                                <i class="fa fa-edit"></i>
                                                Edit
                                            </a>
                                            <form action="/configuration/user/delete/30" method="post"><input type="hidden" name="_csrf" value="7f95a1df-a9d1-4fb4-a0c4-6a5f76ceb82d"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Delete
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>test1537753948418@example.com</td>
                                <td>Test User</td>
                                <td>ROLE_USER</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <a class="dropdown-item" href="/configuration/user/edit/31">
                                                <i class="fa fa-edit"></i>
                                                Edit
                                            </a>
                                            <form action="/configuration/user/delete/31" method="post"><input type="hidden" name="_csrf" value="7f95a1df-a9d1-4fb4-a0c4-6a5f76ceb82d"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Delete
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
            <!--/.col-->
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:28.593  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@2e8eafb2, testMethod = testIndex@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:28.596  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@7c928399, testMethod = testLoadEditSelfAsNonAdminUser@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/user/edit/33
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@5fb0a09e, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@75e6b410: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@75e6b410: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@732bb49d; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.editUserForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/user/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 33
        Attribute = userForm
            value = UserForm{id=33, email='test1537753948699@example.com', displayName='Test User', password='XXXXX', password2='XXXXX', userRole=ROLE_USER}
           errors = []
        Attribute = isAdmin
            value = false
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@684eb4a0
           errors = []
        Attribute = userRoles
            value = [ROLE_USER, ROLE_ADMIN]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>User Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="51c09b65-2370-4a4e-82e4-e1f3cb591424"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753948699@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/33">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration/user">Users</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Edit: Test User</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Edit</strong>
                        <span>Test User</span>
                    </div>
                    <form
                        action="/configuration/user/update"
                        method="post" class="form-horizontal" autocomplete="off"><input type="hidden" name="_csrf" value="51c09b65-2370-4a4e-82e4-e1f3cb591424"/>
                        <div class="card-body">

                            <!-- Email Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="email">
                                    Email Address
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="email" name="email" class="form-control" type="text"
                                        placeholder="User's email address"
                                        value="test1537753948699@example.com">
                                    
                                </div>
                            </div>

                            <!-- Name Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="displayName">
                                    Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="displayName" name="displayName" class="form-control" type="text"
                                        placeholder="User's name"
                                        value="Test User">
                                    
                                </div>
                            </div>

                            <!-- Password Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="password">
                                    Password
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="password" name="password" class="form-control" type="password"
                                        placeholder=""
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Password Validation Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="password2">
                                    Verify Password
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="password2" name="password2" class="form-control" type="password"
                                        placeholder=""
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- User role -->
                            
                        </div>
                        <div class="card-footer">
                            <input type="hidden" name="id" id="id" value="33">
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:28.856  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@7c928399, testMethod = testLoadEditSelfAsNonAdminUser@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:28.859  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@19a4cdea, testMethod = test_withoutAdminRole@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/user
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@1b84d03d, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@93d94209: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@93d94209: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@41d8ac75; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/user/create
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@1e1d813a, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@93d94209: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@93d94209: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@41d8ac75; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/filter/delete/1
       Parameters = {_csrf=[e230f3ba-acff-48b8-9e63-e04b0b41169b]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@93d94209: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@93d94209: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@41d8ac75; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:29.145  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@19a4cdea, testMethod = test_withoutAdminRole@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:29.148  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@1964ef9, testMethod = testLoadEditAnotherUserAsNonAdminUserIsBlocked@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/user/edit/36
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@6c120b00, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@2648e4: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@2648e4: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@d8a2b1b; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.editUserForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /
          Cookies = []
2018-09-24 03:52:29.454  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@1964ef9, testMethod = testLoadEditAnotherUserAsNonAdminUserIsBlocked@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:29.456  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@2709e075, testMethod = testLoadEditSelfAsAdminUser@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/user/edit/38
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@21b3d356, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@fa3079c4: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@fa3079c4: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@294b045b; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.editUserForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/user/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 38
        Attribute = userForm
            value = UserForm{id=38, email='test1537753949458@example.com', displayName='Test User', password='XXXXX', password2='XXXXX', userRole=ROLE_ADMIN}
           errors = []
        Attribute = isAdmin
            value = true
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@285ac29
           errors = []
        Attribute = userRoles
            value = [ROLE_USER, ROLE_ADMIN]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>User Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="9e44b015-a23c-4a44-b84a-090abbd76c24"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753949458@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/38">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration/user">Users</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Edit: Test User</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Edit</strong>
                        <span>Test User</span>
                    </div>
                    <form
                        action="/configuration/user/update"
                        method="post" class="form-horizontal" autocomplete="off"><input type="hidden" name="_csrf" value="9e44b015-a23c-4a44-b84a-090abbd76c24"/>
                        <div class="card-body">

                            <!-- Email Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="email">
                                    Email Address
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="email" name="email" class="form-control" type="text"
                                        placeholder="User's email address"
                                        value="test1537753949458@example.com">
                                    
                                </div>
                            </div>

                            <!-- Name Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="displayName">
                                    Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="displayName" name="displayName" class="form-control" type="text"
                                        placeholder="User's name"
                                        value="Test User">
                                    
                                </div>
                            </div>

                            <!-- Password Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="password">
                                    Password
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="password" name="password" class="form-control" type="password"
                                        placeholder=""
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Password Validation Input -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="password2">
                                    Verify Password
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="password2" name="password2" class="form-control" type="password"
                                        placeholder=""
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- User role -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="userRole">
                                    User Role
                                </label>
                                <div class="col-md-9">
                                    <select
                                        id="userRole" name="userRole" class="form-control">
                                    <option value="">Please select a user role</option>
                                    <option value="ROLE_USER">ROLE_USER</option>
                                    <option value="ROLE_ADMIN" selected="selected">ROLE_ADMIN</option>
                                    </select>
                                    
                                </div>
                            </div>
                        </div>
                        <div class="card-footer">
                            <input type="hidden" name="id" id="id" value="38">
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/configuration/user" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:29.743  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@25093079 testClass = UserControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest@2709e075, testMethod = testLoadEditSelfAsAdminUser@UserControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1c96bf1e testClass = UserControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7890324e key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.701 s - in org.sourcelab.kafka.webview.ui.controller.configuration.user.UserControllerTest
[INFO] Running org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserFormTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserFormTest
[INFO] Running org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest
2018-09-24 03:52:29.756  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Neither @ContextConfiguration nor @ContextHierarchy found for test class [org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest], using SpringBootContextLoader
2018-09-24 03:52:29.758  INFO 323 --- [           main] o.s.t.c.support.AbstractContextLoader    : Could not detect default resource locations for test class [org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-09-24 03:52:29.758  INFO 323 --- [           main] t.c.s.AnnotationConfigContextLoaderUtils : Could not detect default configuration classes for test class [org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest]: ClusterConfigControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2018-09-24 03:52:29.773  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Found @SpringBootConfiguration org.sourcelab.kafka.webview.ui.Application for test class org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest
2018-09-24 03:52:29.774  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener]
2018-09-24 03:52:29.775  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@5de6c7d7, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@69f55ea, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@2b370ca9, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@3203a4ae, org.springframework.test.context.support.DirtiesContextTestExecutionListener@59301546, org.springframework.test.context.transaction.TransactionalTestExecutionListener@25fc2b8f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@363d29dd, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@19b4dd60, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@40f77135, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@4138af7, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@5bbf3869, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@64dfa1a3, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@1f5a1ad4, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@7866ffa]
2018-09-24 03:52:29.806  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@68aa1164, testMethod = testPostUpdate_existingNonSslCluster@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ where cluster0_.name=?

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/cluster/update
       Parameters = {id=[2], name=[My New Cluster Name1537753950081], brokerHosts=[newHost:9092], _csrf=[f11c8ca9-f45d-4394-998d-49a4971f0047]}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Updated cluster successfully!'}}, targetRequestPath=/configuration/cluster, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@cce4c8a5: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@cce4c8a5: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@a5df98c; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.clusterUpdate(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/cluster
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Updated cluster successfully!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/cluster]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/cluster
          Cookies = []
2018-09-24 03:52:30.108  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@68aa1164, testMethod = testPostUpdate_existingNonSslCluster@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:30.111  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@d15f031, testMethod = testIndex@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/cluster
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@5d50e7f6, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@c6725ed6: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@c6725ed6: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@54fbaa65; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.index(org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/cluster/index
             View = null
        Attribute = MenuClusters
            value = [Cluster{+ id=3, + name='My Test Cluster 1 2 3', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}, Cluster{+ id=4, + name='Some other Cluster', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}]
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 42
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@48e3017a
           errors = []
        Attribute = clusterList
            value = [Cluster{+ id=3, + name='My Test Cluster 1 2 3', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}, Cluster{+ id=4, + name='Some other Cluster', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Cluster Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="d07f15e9-ec3f-45e3-bf86-85a5101ac7ed"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753950112@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/42">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item" title="My Test Cluster 1 2 3">
                            <a class="nav-link" href="/cluster/3">
                                <i class="icon-layers"></i>
                                My Test Cluster 1 2 3
                            </a>
                        </li>
                        <li class="nav-item" title="Some other Cluster">
                            <a class="nav-link" href="/cluster/4">
                                <i class="icon-layers"></i>
                                Some other Cluster
                            </a>
                        </li>
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Clusters</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Kafka Clusters
                        <div class="btn-group float-right" role="group" aria-label="Button group">
                            <a class="btn" href="/configuration/cluster/create" style="padding-bottom: 0;">
                                <i class="icon-settings"></i>
                                &nbsp;Create new
                            </a>
                        </div>
                    </div>
                    <div class="card-body">
                        <table class="table table-bordered table-striped table-sm">
                            <thead>
                            <tr>
                                <th>Cluster Name</th>
                                <th>Brokers</th>
                                <th>SSL Enabled</th>
                                <th>Status</th>
                                <th class="text-right">Action</th>
                            </tr>
                            </thead>
                            <tbody>
                                
                                <tr>
                                    <td>My Test Cluster 1 2 3</td>
                                    <td>localhost:9092</td>
                                    <td>
                                        
                                        <span
                                            class="badge badge-danger">No
                                        </span>
                                    </td>
                                    <td>
                                        <span
                                            class="badge badge-success">Validated
                                        </span>
                                        
                                    </td>
                                    <td class="text-right">
                                        <div class="dropdown">
                                            <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                                Actions
                                            </button>
                                            <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                                <a class="dropdown-item" href="/configuration/cluster/test/3">
                                                    <i class="fa fa-edit"></i>
                                                    Test
                                                </a>
                                                <a class="dropdown-item" href="/configuration/cluster/edit/3">
                                                    <i class="fa fa-edit"></i>
                                                    Edit
                                                </a>
                                                <form action="/configuration/cluster/delete/3" method="post"><input type="hidden" name="_csrf" value="d07f15e9-ec3f-45e3-bf86-85a5101ac7ed"/>
                                                    <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                        <i class="fa fa-remove"></i>
                                                        Delete
                                                    </button>
                                                </form>
                                            </div>
                                        </div>
                                    </td>
                                </tr>
                                <tr>
                                    <td>Some other Cluster</td>
                                    <td>localhost:9092</td>
                                    <td>
                                        
                                        <span
                                            class="badge badge-danger">No
                                        </span>
                                    </td>
                                    <td>
                                        <span
                                            class="badge badge-success">Validated
                                        </span>
                                        
                                    </td>
                                    <td class="text-right">
                                        <div class="dropdown">
                                            <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                                Actions
                                            </button>
                                            <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                                <a class="dropdown-item" href="/configuration/cluster/test/4">
                                                    <i class="fa fa-edit"></i>
                                                    Test
                                                </a>
                                                <a class="dropdown-item" href="/configuration/cluster/edit/4">
                                                    <i class="fa fa-edit"></i>
                                                    Edit
                                                </a>
                                                <form action="/configuration/cluster/delete/4" method="post"><input type="hidden" name="_csrf" value="d07f15e9-ec3f-45e3-bf86-85a5101ac7ed"/>
                                                    <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                        <i class="fa fa-remove"></i>
                                                        Delete
                                                    </button>
                                                </form>
                                            </div>
                                        </div>
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
            <!--/.col-->
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:30.357  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@d15f031, testMethod = testIndex@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:30.360  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@4a937d43, testMethod = testPostUpdate_existingSslCluster@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: update cluster set broker_hosts=?, is_ssl_enabled=?, is_valid=?, key_store_file=?, key_store_password=?, name=?, trust_store_file=?, trust_store_password=? where id=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ where cluster0_.name=?

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/cluster/update
       Parameters = {id=[5], name=[My Updated Cluster Name1537753950566], brokerHosts=[updatedHost:9092], ssl=[true], _csrf=[d3576184-9872-42ad-ac37-e1de74392e01]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Updated cluster successfully!'}}, targetRequestPath=/configuration/cluster, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@9c485092: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@9c485092: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@514c6ca0; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.clusterUpdate(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/cluster
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Updated cluster successfully!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/cluster]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/cluster
          Cookies = []
2018-09-24 03:52:30.581  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@4a937d43, testMethod = testPostUpdate_existingSslCluster@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:30.582  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@6cb2b947, testMethod = testPostUpdate_existingSslClusterUpdateKeyStore@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: update cluster set broker_hosts=?, is_ssl_enabled=?, is_valid=?, key_store_file=?, key_store_password=?, name=?, trust_store_file=?, trust_store_password=? where id=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ where cluster0_.name=?

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/cluster/update
       Parameters = {id=[6], name=[UpdatedClusterName1537753950789], brokerHosts=[updatedHost:9092], ssl=[true], keyStorePassword=[NewPassword], _csrf=[a85e51d6-ea1c-4263-8068-4fa077e0cafd]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Updated cluster successfully!'}}, targetRequestPath=/configuration/cluster, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@c94a5f6e: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@c94a5f6e: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@3687b83c; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.clusterUpdate(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/cluster
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Updated cluster successfully!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/cluster]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/cluster
          Cookies = []
2018-09-24 03:52:31.072  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@6cb2b947, testMethod = testPostUpdate_existingSslClusterUpdateKeyStore@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:31.074  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@4cbd17b3, testMethod = test_withoutAdminRole@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/cluster
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@349686e8, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@26b6ad33: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@26b6ad33: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5c3e7128; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/filter/create
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@5ce03a9d, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@26b6ad33: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@26b6ad33: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5c3e7128; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/filter/edit/1
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@10c67c1c, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@26b6ad33: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@26b6ad33: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5c3e7128; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/filter/update
       Parameters = {_csrf=[ea39c65c-e824-4ab4-978c-25f782988889]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@26b6ad33: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@26b6ad33: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5c3e7128; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/filter/delete/1
       Parameters = {_csrf=[3955f57d-f253-4166-bb06-ff73ec531377]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@26b6ad33: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@26b6ad33: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5c3e7128; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:31.302  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@4cbd17b3, testMethod = test_withoutAdminRole@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:31.304  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@1067192a, testMethod = testPostUpdate_existingSslClusterUpdateTrustStore@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: update cluster set broker_hosts=?, is_ssl_enabled=?, is_valid=?, key_store_file=?, key_store_password=?, name=?, trust_store_file=?, trust_store_password=? where id=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ where cluster0_.name=?

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/cluster/update
       Parameters = {id=[7], name=[UpdatedClusterName1537753951549], brokerHosts=[updatedHost:9092], ssl=[true], trustStorePassword=[NewPassword], _csrf=[04f60543-9f57-4945-95e8-170332175d12]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Updated cluster successfully!'}}, targetRequestPath=/configuration/cluster, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@bf19aa53: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@bf19aa53: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@785477e5; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.clusterUpdate(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/cluster
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Updated cluster successfully!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/cluster]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/cluster
          Cookies = []
2018-09-24 03:52:31.674  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@1067192a, testMethod = testPostUpdate_existingSslClusterUpdateTrustStore@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:31.676  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@c950fd, testMethod = testPostUpdate_newSslCluster@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ where cluster0_.name=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/cluster/update
       Parameters = {name=[My New Cluster Name1537753951881], brokerHosts=[localhost:9092], ssl=[true], trustStorePassword=[TrustStorePassword], keyStorePassword=[KeyStorePassword], _csrf=[47f04232-6dd5-4b54-be5c-a358759c6d20]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Created new cluster!'}}, targetRequestPath=/configuration/cluster, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@30d6f841: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@30d6f841: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@76ccde41; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.clusterUpdate(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/cluster
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Created new cluster!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/cluster]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/cluster
          Cookies = []
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ where cluster0_.name=?
2018-09-24 03:52:32.117  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@c950fd, testMethod = testPostUpdate_newSslCluster@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:32.119  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@1fb379e4, testMethod = testGetCreate@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/cluster/create
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@773cc551, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@ea02089a: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@ea02089a: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5cbaafbd; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.createClusterForm(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/cluster/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 54
        Attribute = clusterForm
            value = ClusterForm{id=null, name='null', brokerHosts='null', ssl=false, trustStoreFile=null, trustStoreFilename='null', keyStoreFile=null, keyStoreFilename='null'}
           errors = []
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@4f0f56f5
           errors = []

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Cluster Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="7226c24b-7946-4396-be52-bf3195795835"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753952121@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/54">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration/cluster">Clusters</a>
                
            </li>
            <li class="breadcrumb-item active">
                <a href="/configuration/cluster/create">Create</a>
                
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <script type="application/javascript">
        // On ready register handlers
        jQuery(document).ready(function() {
            jQuery('#ssl').click(function() {
                var isChecked = jQuery('#ssl').is(':checked');
                jQuery('#ssl-options').toggle(isChecked);
            });
        });
    </script>

    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Create</strong>
                        <span>New Cluster</span>
                    </div>
                    <form
                        enctype="multipart/form-data" method="post" class="form-horizontal"
                        action="/configuration/cluster/update"><input type="hidden" name="_csrf" value="7226c24b-7946-4396-be52-bf3195795835"/>
                        <div class="card-body">
                            <!-- Name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="name">
                                    Cluster Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="name" name="name" class="form-control" type="text"
                                        placeholder="A unique name to identify this cluster"
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Brokers -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="brokers">
                                    Brokers
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="brokers" name="brokerHosts" class="form-control" type="text"
                                        placeholder="Comma separated list of brokers.  hostname1:9092,hostname2:9092"
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Use SSL -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="ssl">
                                    Use SSL authentication?
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="ssl" name="ssl" class="" type="checkbox"
                                        value="true"><input type="hidden" name="_ssl" value="on"/>
                                    
                                </div>
                            </div>

                            <!-- SSL Options -->
                            <div id="ssl-options" style="display: none;">
                                <h6>SSL Settings</h6>
                                <hr>

                                <!-- Trust Store file -->
                                <div class="form-group row">
                                    <label class="col-md-3 form-control-label" for="trustStoreFile">
                                        Trust Store
                                        
                                    </label>
                                    <div class="col-md-9">
                                        <input
                                            id="trustStoreFile" name="trustStoreFile" class="form-control" type="file"
                                            placeholder="Select TrustStore JKS"
                                            value="">
                                        
                                    </div>
                                </div>

                                <!-- Trust Store Password -->
                                <div class="form-group row">
                                    <label class="col-md-3 form-control-label" for="trustStorePassword">
                                        Trust Store Password
                                    </label>
                                    <div class="col-md-9">
                                        <input
                                            id="trustStorePassword" name="trustStorePassword" class="form-control" type="password"
                                            placeholder="TrustStore password"
                                            value="">
                                        
                                    </div>
                                </div>

                                <!-- Client KeyStore file -->
                                <div class="form-group row">
                                    <label class="col-md-3 form-control-label" for="keyStoreFile">
                                        Key Store JKS
                                        
                                    </label>
                                    <div class="col-md-9">
                                        <input
                                            id="keyStoreFile" name="keyStoreFile" class="form-control" type="file"
                                            placeholder="Select KeyStore JKS"
                                            value="">
                                        
                                    </div>
                                </div>

                                <!-- Client KeyStore Password -->
                                <div class="form-group row">
                                    <label class="col-md-3 form-control-label" for="keyStorePassword">
                                        Key Store Password
                                    </label>
                                    <div class="col-md-9">
                                        <input
                                            id="keyStorePassword" name="keyStorePassword" class="form-control" type="password"
                                            placeholder="Key Store password"
                                            value="">
                                        
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="card-footer">
                            </input>
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/configuration/cluster" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:32.408  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@1fb379e4, testMethod = testGetCreate@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:32.411  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@6edb093f, testMethod = testPostUpdate_newCluster@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ where cluster0_.name=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/cluster/update
       Parameters = {name=[My New Cluster Name], brokerHosts=[localhost:9092], _csrf=[722d52ab-bd31-4d38-b787-acda73083e9a]}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Created new cluster!'}}, targetRequestPath=/configuration/cluster, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@3a8286e9: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@3a8286e9: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5f93ec02; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.clusterUpdate(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/cluster
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Created new cluster!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/cluster]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/cluster
          Cookies = []
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ where cluster0_.name=?
2018-09-24 03:52:32.672  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@6edb093f, testMethod = testPostUpdate_newCluster@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:32.674  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@5aa2758a, testMethod = testPostUpdate_existingSslClusterUpdateToNonSsl@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: update cluster set broker_hosts=?, is_ssl_enabled=?, is_valid=?, key_store_file=?, key_store_password=?, name=?, trust_store_file=?, trust_store_password=? where id=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ where cluster0_.name=?

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/cluster/update
       Parameters = {id=[10], name=[UpdatedClusterName1537753952924], brokerHosts=[updatedHost:9092], _csrf=[34650399-c879-450b-bd34-8181cd2305e9]}
          Headers = {Content-Type=[multipart/form-data;charset=UTF-8]}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Updated cluster successfully!'}}, targetRequestPath=/configuration/cluster, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@79bd1053: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@79bd1053: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@58fb5b8f; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.clusterUpdate(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/cluster
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Updated cluster successfully!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/cluster]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/cluster
          Cookies = []
2018-09-24 03:52:32.939  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@244c0fbe testClass = ClusterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest@5aa2758a, testMethod = testPostUpdate_existingSslClusterUpdateToNonSsl@ClusterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@1188e08b testClass = ClusterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@12e13abd key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.179 s - in org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigControllerTest
[INFO] Running org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest
2018-09-24 03:52:32.941  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Neither @ContextConfiguration nor @ContextHierarchy found for test class [org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest], using SpringBootContextLoader
2018-09-24 03:52:32.942  INFO 323 --- [           main] o.s.t.c.support.AbstractContextLoader    : Could not detect default resource locations for test class [org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-09-24 03:52:32.943  INFO 323 --- [           main] t.c.s.AnnotationConfigContextLoaderUtils : Could not detect default configuration classes for test class [org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest]: ViewConfigControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2018-09-24 03:52:32.957  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Found @SpringBootConfiguration org.sourcelab.kafka.webview.ui.Application for test class org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest
2018-09-24 03:52:32.960  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener]
2018-09-24 03:52:32.961  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@19439ec4, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@6f53f5a4, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@21ebf9be, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@7d50b4c4, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7860a014, org.springframework.test.context.transaction.TransactionalTestExecutionListener@86e8469, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@76b6bad3, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@e38d655, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@7325b786, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@f943847, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@4c376b44, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@47596e9, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@5ab29866, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@74cad577]
2018-09-24 03:52:32.979  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@29612ee2 testClass = ViewConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest@20524816, testMethod = testIndex@ViewConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@6a7cbeed testClass = ViewConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@3d96b8fb key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: insert into view (id, cluster_id, created_at, key_message_format_id, name, partitions, results_per_partition, topic, updated_at, value_message_format_id) values (null, ?, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: insert into view (id, cluster_id, created_at, key_message_format_id, name, partitions, results_per_partition, topic, updated_at, value_message_format_id) values (null, ?, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/view
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@464017f5, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@97f5d87b: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@97f5d87b: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@3c4231e5; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.index(org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/view/index
             View = null
        Attribute = MenuClusters
            value = [Cluster{+ id=11, + name='View 1', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}, Cluster{+ id=12, + name='View 2', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}]
        Attribute = MenuViews
            value = [org.sourcelab.kafka.webview.ui.model.View@3c1ef806, org.sourcelab.kafka.webview.ui.model.View@5ce1ec7]
        Attribute = UserId
            value = 60
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@397f9672
           errors = []
        Attribute = views
            value = [org.sourcelab.kafka.webview.ui.model.View@3c1ef806, org.sourcelab.kafka.webview.ui.model.View@5ce1ec7]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>View Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="bbcc92b1-98f8-4264-b99b-bc2406c44675"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753952981@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/60">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item" title="View 1">
                            <a class="nav-link" href="/cluster/11">
                                <i class="icon-layers"></i>
                                View 1
                            </a>
                        </li>
                        <li class="nav-item" title="View 2">
                            <a class="nav-link" href="/cluster/12">
                                <i class="icon-layers"></i>
                                View 2
                            </a>
                        </li>
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item" title="View 1">
                            <a class="nav-link" href="/view/2">
                                <i class="icon-eye"></i>
                                View 1
                            </a>
                        </li>
                        <li class="nav-item" title="View 2">
                            <a class="nav-link" href="/view/3">
                                <i class="icon-eye"></i>
                                View 2
                            </a>
                        </li>
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Views</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Views
                        <div class="btn-group float-right" role="group" aria-label="Button group">
                            <a class="btn" href="/configuration/view/create" style="padding-bottom: 0;">
                                <i class="icon-settings"></i>
                                &nbsp;Create new
                            </a>
                        </div>
                    </div>
                    <div class="card-body">
                        <table class="table table-bordered table-striped table-sm">
                            <thead>
                            <tr>
                                <th>Name</th>
                                <th>Cluster</th>
                                <th>Topic</th>
                                <th>Partitions</th>
                                <th>Key Format</th>
                                <th>Value Format</th>
                                <th class="text-right">Action</th>
                            </tr>
                            </thead>
                            <tbody>
                            
                            <tr>
                                <td>
                                    <a href="/view/2">View 1</a>
                                </td>
                                <td>View 1</td>
                                <td>MyTopic</td>
                                <td></td>
                                <td>View 1</td>
                                <td>View 1</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <a class="dropdown-item" href="/configuration/view/edit/2">
                                                <i class="fa fa-edit"></i>
                                                Edit
                                            </a>
                                            <form action="/configuration/view/delete/2" method="post"><input type="hidden" name="_csrf" value="bbcc92b1-98f8-4264-b99b-bc2406c44675"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Delete
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <a href="/view/3">View 2</a>
                                </td>
                                <td>View 2</td>
                                <td>MyTopic</td>
                                <td></td>
                                <td>View 2</td>
                                <td>View 2</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <a class="dropdown-item" href="/configuration/view/edit/3">
                                                <i class="fa fa-edit"></i>
                                                Edit
                                            </a>
                                            <form action="/configuration/view/delete/3" method="post"><input type="hidden" name="_csrf" value="bbcc92b1-98f8-4264-b99b-bc2406c44675"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Delete
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
            <!--/.col-->
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:33.319  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@29612ee2 testClass = ViewConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest@20524816, testMethod = testIndex@ViewConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@6a7cbeed testClass = ViewConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@3d96b8fb key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:33.321  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@29612ee2 testClass = ViewConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest@72e4ffa2, testMethod = test_withoutAdminRole@ViewConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@6a7cbeed testClass = ViewConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@3d96b8fb key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/view
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@539f2fec, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@abe82348: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@abe82348: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@a4e1ca7; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/view/create
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@7d466ef9, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@abe82348: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@abe82348: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@a4e1ca7; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/view/edit/1
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@4a561f7d, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@abe82348: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@abe82348: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@a4e1ca7; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/view/update
       Parameters = {_csrf=[de108e9b-ec42-4008-8c95-750af1a647d3]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@abe82348: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@abe82348: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@a4e1ca7; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/view/delete/1
       Parameters = {_csrf=[ad8a5910-67fe-4b6d-a39a-003e4b7ff555]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@abe82348: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@abe82348: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@a4e1ca7; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:33.546  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@29612ee2 testClass = ViewConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest@72e4ffa2, testMethod = test_withoutAdminRole@ViewConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@6a7cbeed testClass = ViewConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@3d96b8fb key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:33.548  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@29612ee2 testClass = ViewConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest@601ca994, testMethod = testRegressionCreateViewWhenFilterExistsWithOptions@ViewConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@6a7cbeed testClass = ViewConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@3d96b8fb key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into filter (id, classpath, jar, name, options) values (null, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.is_default_format=? order by messagefor0_.name asc
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.is_default_format=? order by messagefor0_.name asc
Hibernate: select filter0_.id as id1_1_, filter0_.classpath as classpat2_1_, filter0_.jar as jar3_1_, filter0_.name as name4_1_, filter0_.options as options5_1_ from filter filter0_ order by filter0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/view/create
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@443b9ebb, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@dc20b92d: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@dc20b92d: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@4830c979; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.createViewForm(org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/view/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 64
        Attribute = viewForm
            value = ViewForm{id=null, name='null', clusterId=null, keyMessageFormatId=null, valueMessageFormatId=null, topic='null', partitions=[], enforcedFilters=[], optionalFilters=[], resultsPerPartition=10}
           errors = []
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@d98ce13
           errors = []
        Attribute = clusters
            value = []
        Attribute = defaultMessageFormats
            value = [MessageFormat{id=5, name='ByteArray', classpath='org.apache.kafka.common.serialization.ByteArrayDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=2, name='Bytes', classpath='org.apache.kafka.common.serialization.BytesDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=7, name='Double', classpath='org.apache.kafka.common.serialization.DoubleDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=3, name='Float', classpath='org.apache.kafka.common.serialization.FloatDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=1, name='Integer', classpath='org.apache.kafka.common.serialization.IntegerDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=4, name='Long', classpath='org.apache.kafka.common.serialization.LongDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=8, name='Short', classpath='org.apache.kafka.common.serialization.ShortDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=6, name='String', classpath='org.apache.kafka.common.serialization.StringDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}]
        Attribute = customMessageFormats
            value = []
        Attribute = topics
            value = []
        Attribute = partitions
            value = []
        Attribute = filterList
            value = [Filter{id=1, name='SearchStringFilter1537753953752', classpath='examples.filter.StringSearchFilter', jar='SearchStringFilter1537753953752.jar', options='{}'}]
        Attribute = filterParameters
            value = {}

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>View Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="c70a0960-8b57-4ed7-a1d0-8d9a5edaecbe"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753953549@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/64">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration/view">Views</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Create</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <script type="application/javascript">
            // On ready register handlers
            jQuery(document).ready(function() {

                // Enable fancy multi-select
                jQuery('#enforced_filters_available')
                    .multiselect({
                        right: '#enforced_filters',
                        sort: false,
                        submitAllLeft: false,
                        submitAllRight: true,
                        afterMoveToRight: function(t,e,o) {
                            // grab filterId
                            var filterId = o.val();

                            // Define parent container
                            var parentContainerId = '#filterOptions' + filterId;

                            // Toggle display on
                            jQuery('#filterOptions' + filterId).toggle(true);

                            // Mark all inputs as enabled
                            jQuery(parentContainerId + ' input').removeAttr("disabled");
                        },
                        afterMoveToLeft: function(t,e,o) {
                            // grab filterId
                            var filterId = o.val();

                            // Define parent container
                            var parentContainerId = '#filterOptions' + filterId;

                            // Toggle display off
                            jQuery(parentContainerId).toggle(false);

                            // Mark all inputs as disabled
                            jQuery(parentContainerId + ' input').attr("disabled", true);
                        }
                    }
                );

                jQuery('#optional_filters_available')
                    .multiselect({
                        right: '#optional_filters',
                        sort: false,
                        submitAllLeft: false,
                        submitAllRight: true
                    }
                );

                // Handle selecting a cluster.
                jQuery('#clusterId').change(function() {
                    var clusterId = jQuery('#clusterId').val();
                    ApiClient.getTopics(clusterId, function(topicList) {
                        var topicSelector = jQuery('#topic');
                        jQuery(topicSelector).empty();
                        jQuery(topicSelector).removeAttr('disabled');
                        jQuery(topicSelector).append(jQuery('<option></option>')
                            .attr('value', '!')
                            .text('Please select a topic')
                        );
                        jQuery.each(topicList, function (index, topic) {
                            jQuery(topicSelector)
                                .append(
                                    jQuery('<option></option>')
                                        .attr('value', topic.name)
                                        .text(topic.name)
                                );
                        });
                    });
                });

                // Handle selecting a topic
                jQuery('#topic').change(function() {
                    var topic = jQuery(this).val();
                    if (topic === '!') {
                        // Clear partitions
                        return
                    }
                    var clusterId = jQuery('#clusterId').val();
                    var topic = jQuery('#topic').val();

                    ApiClient.getTopicDetails(clusterId, topic, function(results) {
                        var partitionSelector = jQuery('#partitions');
                        jQuery(partitionSelector).empty();
                        jQuery(partitionSelector).removeAttr('disabled');
                        jQuery(partitionSelector).append(jQuery('<option></option>')
                            .attr('value', '')
                            .text('View all partitions')
                            .attr('selected', 'selected')
                        );

                        jQuery.each(results.partitions, function(index, result) {
                            jQuery(partitionSelector)
                                .append(
                                    jQuery('<option></option>')
                                        .attr('value', result.partition)
                                        .text(result.partition)
                                );
                        });
                    });
                });
            });
        </script>

        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Create</strong>
                        <span>New View</span>
                    </div>
                    <form method="post" class="form-horizontal"
                        action="/configuration/view/update"><input type="hidden" name="_csrf" value="c70a0960-8b57-4ed7-a1d0-8d9a5edaecbe"/>

                        <div class="card-body">
                            <!-- Topic Options -->
                            <h6>Topic Selection</h6>
                            <hr>

                            <!-- Name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="name">
                                    View Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="name" name="name" class="form-control" type="text"
                                        placeholder="A unique name to identify this view"
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Cluster -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="clusterId">
                                    Cluster
                                </label>
                                <div class="col-md-9">
                                    <select
                                        id="clusterId" name="clusterId" class="form-control">
                                        <option value="">Please select a cluster</option>
                                        
                                    </select>
                                    
                                </div>
                            </div>

                            <!-- Topic -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="topic">
                                    Topic
                                </label>
                                <div class="col-md-9">
                                    <select
                                        id="topic" name="topic" class="form-control"
                                        disabled="disabled">
                                        <option value="!">Please select a topic</option>
                                        
                                    </select>
                                    
                                </div>
                            </div>

                            <!-- Key Message Formats -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="keyMessageFormatId">
                                    Message Format for Keys
                                </label>
                                <div class="col-md-9">
                                    <select
                                            id="keyMessageFormatId" name="keyMessageFormatId" class="form-control">
                                        <option value="">Please select a message format</option>
                                        <optgroup label="Default Formats">
                                            <option value="5">ByteArray</option>
                                            <option value="2">Bytes</option>
                                            <option value="7">Double</option>
                                            <option value="3">Float</option>
                                            <option value="1">Integer</option>
                                            <option value="4">Long</option>
                                            <option value="8">Short</option>
                                            <option value="6">String</option>
                                        </optgroup>
                                        <optgroup label="Custom Formats">
                                            
                                        </optgroup>
                                    </select>
                                    
                                </div>
                            </div>

                            <!-- Key Message Formats -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="valueMessageFormatId">
                                    Message Format for Values
                                </label>
                                <div class="col-md-9">
                                    <select
                                            id="valueMessageFormatId" name="valueMessageFormatId" class="form-control">
                                        <option value="">Please select a message format</option>
                                        <optgroup label="Default Formats">
                                            <option value="5">ByteArray</option>
                                            <option value="2">Bytes</option>
                                            <option value="7">Double</option>
                                            <option value="3">Float</option>
                                            <option value="1">Integer</option>
                                            <option value="4">Long</option>
                                            <option value="8">Short</option>
                                            <option value="6">String</option>
                                        </optgroup>
                                        <optgroup label="Custom Formats">
                                            
                                        </optgroup>
                                    </select>
                                    
                                </div>
                            </div>

                            <!-- View Options -->
                            <h6>View Options</h6>
                            <hr>

                            <!-- Results Per Partition -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="resultsPerPartition">
                                    Results per Partition
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="resultsPerPartition" name="resultsPerPartition" class="form-control" type="text"
                                        placeholder="How many results to display per partition"
                                        value="10">
                                    
                                </div>
                            </div>

                            <!-- Optional Record Filters  -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="optional_filters_available">
                                    Optional Record Filters
                                </label>
                                <div class="col-md-4">
                                    Available:
                                    <select
                                        id="optional_filters_available" name="optional_filters_available" class="form-control" multiple="multiple">
                                        <option value="1">SearchStringFilter1537753953752</option>
                                    </select>
                                </div>
                                <div class="col-md-1 text-center my-auto"></div>
                                <div class="col-md-4">
                                    Enabled:
                                    <input type="hidden" name="_optionalFilters" value="1"/><select
                                        id="optional_filters" name="optionalFilters" class="form-control" multiple="multiple">>
                                        
                                    </select>
                                </div>
                                
                            </div>

                            <!-- Enforced Filtering Options -->
                            <h6>Enforced Filtering</h6>
                            <hr>

                            <!-- Partition Selector -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="partitions">
                                    Partition Filtering
                                </label>
                                <div class="col-md-9">
                                    <select
                                        id="partitions" name="partitions" class="form-control" multiple="multiple"
                                        disabled="disabled">>
                                        <option value="" selected="selected">View all partitions</option>
                                        
                                    </select>
                                    
                                </div>
                            </div>

                            <!-- Enforced Record Filter  -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="enforced_filters">
                                    Record Filtering
                                </label>
                                <div class="col-md-4">
                                    Available:
                                    <select
                                        id="enforced_filters_available" name="enforced_filters_available" class="form-control" multiple="multiple">
                                        <option value="1">SearchStringFilter1537753953752</option>
                                    </select>
                                </div>
                                <div class="col-md-1 text-center my-auto">

                                </div>
                                <div class="col-md-4">
                                    Enforced:
                                    <input type="hidden" name="_enforcedFilters" value="1"/><select
                                        id="enforced_filters" name="enforcedFilters" class="form-control" multiple="multiple">>
                                        
                                    </select>
                                </div>
                                
                            </div>

                            <!-- Start and filter options -->
                            <div id="filterOptions1" style="display: none;">
                                <h8><strong>SearchStringFilter1537753953752</strong> Options</h8>
                                <hr>

                                <!-- Loop over each option -->
                                <div class="form-group row">
                                    <label
                                        class="col-md-3 form-control-label"
                                        for="1-{}">{}</label>
                                    <div class="col-md-9">
                                        <input
                                            class="form-control" type="text"
                                            name="1-{}"
                                            value="">
                                    </div>
                                </div>

                            </div>
                        </div>

                        <!-- Footer -->
                        <div class="card-footer">
                            </input>
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/configuration/view" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:33.847  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@29612ee2 testClass = ViewConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest@601ca994, testMethod = testRegressionCreateViewWhenFilterExistsWithOptions@ViewConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@6a7cbeed testClass = ViewConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@3d96b8fb key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:33.849  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@29612ee2 testClass = ViewConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest@1e86b2d1, testMethod = testCreate@ViewConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@6a7cbeed testClass = ViewConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@3d96b8fb key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.is_default_format=? order by messagefor0_.name asc
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.is_default_format=? order by messagefor0_.name asc
Hibernate: select filter0_.id as id1_1_, filter0_.classpath as classpat2_1_, filter0_.jar as jar3_1_, filter0_.name as name4_1_, filter0_.options as options5_1_ from filter filter0_ order by filter0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/view/create
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@7bb888b7, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@b9e729ea: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@b9e729ea: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@5825932c; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.createViewForm(org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/view/create
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 66
        Attribute = viewForm
            value = ViewForm{id=null, name='null', clusterId=null, keyMessageFormatId=null, valueMessageFormatId=null, topic='null', partitions=[], enforcedFilters=[], optionalFilters=[], resultsPerPartition=10}
           errors = []
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@277dddcf
           errors = []
        Attribute = clusters
            value = []
        Attribute = defaultMessageFormats
            value = [MessageFormat{id=5, name='ByteArray', classpath='org.apache.kafka.common.serialization.ByteArrayDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=2, name='Bytes', classpath='org.apache.kafka.common.serialization.BytesDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=7, name='Double', classpath='org.apache.kafka.common.serialization.DoubleDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=3, name='Float', classpath='org.apache.kafka.common.serialization.FloatDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=1, name='Integer', classpath='org.apache.kafka.common.serialization.IntegerDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=4, name='Long', classpath='org.apache.kafka.common.serialization.LongDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=8, name='Short', classpath='org.apache.kafka.common.serialization.ShortDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}, MessageFormat{id=6, name='String', classpath='org.apache.kafka.common.serialization.StringDeserializer', jar='n/a', isDefaultFormat=true, optionParameters='{}'}]
        Attribute = customMessageFormats
            value = []
        Attribute = topics
            value = []
        Attribute = partitions
            value = []
        Attribute = filterList
            value = []
        Attribute = filterParameters
            value = {}

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>View Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="2d0f8edf-eb76-4c05-83b5-d8f6d9b65707"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753953851@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/66">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration/view">Views</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Create</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <script type="application/javascript">
            // On ready register handlers
            jQuery(document).ready(function() {

                // Enable fancy multi-select
                jQuery('#enforced_filters_available')
                    .multiselect({
                        right: '#enforced_filters',
                        sort: false,
                        submitAllLeft: false,
                        submitAllRight: true,
                        afterMoveToRight: function(t,e,o) {
                            // grab filterId
                            var filterId = o.val();

                            // Define parent container
                            var parentContainerId = '#filterOptions' + filterId;

                            // Toggle display on
                            jQuery('#filterOptions' + filterId).toggle(true);

                            // Mark all inputs as enabled
                            jQuery(parentContainerId + ' input').removeAttr("disabled");
                        },
                        afterMoveToLeft: function(t,e,o) {
                            // grab filterId
                            var filterId = o.val();

                            // Define parent container
                            var parentContainerId = '#filterOptions' + filterId;

                            // Toggle display off
                            jQuery(parentContainerId).toggle(false);

                            // Mark all inputs as disabled
                            jQuery(parentContainerId + ' input').attr("disabled", true);
                        }
                    }
                );

                jQuery('#optional_filters_available')
                    .multiselect({
                        right: '#optional_filters',
                        sort: false,
                        submitAllLeft: false,
                        submitAllRight: true
                    }
                );

                // Handle selecting a cluster.
                jQuery('#clusterId').change(function() {
                    var clusterId = jQuery('#clusterId').val();
                    ApiClient.getTopics(clusterId, function(topicList) {
                        var topicSelector = jQuery('#topic');
                        jQuery(topicSelector).empty();
                        jQuery(topicSelector).removeAttr('disabled');
                        jQuery(topicSelector).append(jQuery('<option></option>')
                            .attr('value', '!')
                            .text('Please select a topic')
                        );
                        jQuery.each(topicList, function (index, topic) {
                            jQuery(topicSelector)
                                .append(
                                    jQuery('<option></option>')
                                        .attr('value', topic.name)
                                        .text(topic.name)
                                );
                        });
                    });
                });

                // Handle selecting a topic
                jQuery('#topic').change(function() {
                    var topic = jQuery(this).val();
                    if (topic === '!') {
                        // Clear partitions
                        return
                    }
                    var clusterId = jQuery('#clusterId').val();
                    var topic = jQuery('#topic').val();

                    ApiClient.getTopicDetails(clusterId, topic, function(results) {
                        var partitionSelector = jQuery('#partitions');
                        jQuery(partitionSelector).empty();
                        jQuery(partitionSelector).removeAttr('disabled');
                        jQuery(partitionSelector).append(jQuery('<option></option>')
                            .attr('value', '')
                            .text('View all partitions')
                            .attr('selected', 'selected')
                        );

                        jQuery.each(results.partitions, function(index, result) {
                            jQuery(partitionSelector)
                                .append(
                                    jQuery('<option></option>')
                                        .attr('value', result.partition)
                                        .text(result.partition)
                                );
                        });
                    });
                });
            });
        </script>

        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <strong>Create</strong>
                        <span>New View</span>
                    </div>
                    <form method="post" class="form-horizontal"
                        action="/configuration/view/update"><input type="hidden" name="_csrf" value="2d0f8edf-eb76-4c05-83b5-d8f6d9b65707"/>

                        <div class="card-body">
                            <!-- Topic Options -->
                            <h6>Topic Selection</h6>
                            <hr>

                            <!-- Name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="name">
                                    View Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="name" name="name" class="form-control" type="text"
                                        placeholder="A unique name to identify this view"
                                        value="">
                                    
                                </div>
                            </div>

                            <!-- Cluster -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="clusterId">
                                    Cluster
                                </label>
                                <div class="col-md-9">
                                    <select
                                        id="clusterId" name="clusterId" class="form-control">
                                        <option value="">Please select a cluster</option>
                                        
                                    </select>
                                    
                                </div>
                            </div>

                            <!-- Topic -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="topic">
                                    Topic
                                </label>
                                <div class="col-md-9">
                                    <select
                                        id="topic" name="topic" class="form-control"
                                        disabled="disabled">
                                        <option value="!">Please select a topic</option>
                                        
                                    </select>
                                    
                                </div>
                            </div>

                            <!-- Key Message Formats -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="keyMessageFormatId">
                                    Message Format for Keys
                                </label>
                                <div class="col-md-9">
                                    <select
                                            id="keyMessageFormatId" name="keyMessageFormatId" class="form-control">
                                        <option value="">Please select a message format</option>
                                        <optgroup label="Default Formats">
                                            <option value="5">ByteArray</option>
                                            <option value="2">Bytes</option>
                                            <option value="7">Double</option>
                                            <option value="3">Float</option>
                                            <option value="1">Integer</option>
                                            <option value="4">Long</option>
                                            <option value="8">Short</option>
                                            <option value="6">String</option>
                                        </optgroup>
                                        <optgroup label="Custom Formats">
                                            
                                        </optgroup>
                                    </select>
                                    
                                </div>
                            </div>

                            <!-- Key Message Formats -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="valueMessageFormatId">
                                    Message Format for Values
                                </label>
                                <div class="col-md-9">
                                    <select
                                            id="valueMessageFormatId" name="valueMessageFormatId" class="form-control">
                                        <option value="">Please select a message format</option>
                                        <optgroup label="Default Formats">
                                            <option value="5">ByteArray</option>
                                            <option value="2">Bytes</option>
                                            <option value="7">Double</option>
                                            <option value="3">Float</option>
                                            <option value="1">Integer</option>
                                            <option value="4">Long</option>
                                            <option value="8">Short</option>
                                            <option value="6">String</option>
                                        </optgroup>
                                        <optgroup label="Custom Formats">
                                            
                                        </optgroup>
                                    </select>
                                    
                                </div>
                            </div>

                            <!-- View Options -->
                            <h6>View Options</h6>
                            <hr>

                            <!-- Results Per Partition -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="resultsPerPartition">
                                    Results per Partition
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="resultsPerPartition" name="resultsPerPartition" class="form-control" type="text"
                                        placeholder="How many results to display per partition"
                                        value="10">
                                    
                                </div>
                            </div>

                            <!-- Optional Record Filters  -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="optional_filters_available">
                                    Optional Record Filters
                                </label>
                                <div class="col-md-4">
                                    Available:
                                    <select
                                        id="optional_filters_available" name="optional_filters_available" class="form-control" multiple="multiple" disabled="disabled">
                                        
                                    </select>
                                </div>
                                <div class="col-md-1 text-center my-auto"></div>
                                <div class="col-md-4">
                                    Enabled:
                                    <select
                                        id="optional_filters" name="optionalFilters" class="form-control" multiple="multiple"
                                        disabled="disabled">>
                                        
                                    </select>
                                </div>
                                
                            </div>

                            <!-- Enforced Filtering Options -->
                            <h6>Enforced Filtering</h6>
                            <hr>

                            <!-- Partition Selector -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="partitions">
                                    Partition Filtering
                                </label>
                                <div class="col-md-9">
                                    <select
                                        id="partitions" name="partitions" class="form-control" multiple="multiple"
                                        disabled="disabled">>
                                        <option value="" selected="selected">View all partitions</option>
                                        
                                    </select>
                                    
                                </div>
                            </div>

                            <!-- Enforced Record Filter  -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="enforced_filters">
                                    Record Filtering
                                </label>
                                <div class="col-md-4">
                                    Available:
                                    <select
                                        id="enforced_filters_available" name="enforced_filters_available" class="form-control" multiple="multiple" disabled="disabled">
                                        
                                    </select>
                                </div>
                                <div class="col-md-1 text-center my-auto">

                                </div>
                                <div class="col-md-4">
                                    Enforced:
                                    <select
                                        id="enforced_filters" name="enforcedFilters" class="form-control" multiple="multiple"
                                        disabled="disabled">>
                                        
                                    </select>
                                </div>
                                
                            </div>

                            <!-- Start and filter options -->
                            
                        </div>

                        <!-- Footer -->
                        <div class="card-footer">
                            </input>
                            <button type="submit" class="btn btn-sm btn-primary">
                                <i class="fa fa-dot-circle-o"></i>
                                Submit
                            </button>
                            <a class="btn btn-sm btn-danger" href="/configuration/view" role="button">
                                <i class="fa fa-ban"></i>
                                Cancel
                            </a>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:34.123  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@29612ee2 testClass = ViewConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest@1e86b2d1, testMethod = testCreate@ViewConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@6a7cbeed testClass = ViewConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@3d96b8fb key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.171 s - in org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigControllerTest
[INFO] Running org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigControllerTest
2018-09-24 03:52:34.126  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Neither @ContextConfiguration nor @ContextHierarchy found for test class [org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigControllerTest], using SpringBootContextLoader
2018-09-24 03:52:34.127  INFO 323 --- [           main] o.s.t.c.support.AbstractContextLoader    : Could not detect default resource locations for test class [org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigControllerTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-09-24 03:52:34.127  INFO 323 --- [           main] t.c.s.AnnotationConfigContextLoaderUtils : Could not detect default configuration classes for test class [org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigControllerTest]: FilterConfigControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2018-09-24 03:52:34.137  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Found @SpringBootConfiguration org.sourcelab.kafka.webview.ui.Application for test class org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigControllerTest
2018-09-24 03:52:34.139  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener]
2018-09-24 03:52:34.140  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@7fb28ed, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@536f389, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@2b33f7a0, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@71b6edfb, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2f541f60, org.springframework.test.context.transaction.TransactionalTestExecutionListener@1dcc0bb8, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@29767156, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@6f6998b6, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@60493524, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@1da5635e, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@7c35d7d, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@24ccc91b, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@d0538b3, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@3b8c15de]
2018-09-24 03:52:34.149  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@78c91d2a testClass = FilterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigControllerTest@5b7d5eca, testMethod = testIndex@FilterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@52a3eba3 testClass = FilterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@4ed74d03 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into filter (id, classpath, jar, name, options) values (null, ?, ?, ?, ?)
Hibernate: insert into filter (id, classpath, jar, name, options) values (null, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select filter0_.id as id1_1_, filter0_.classpath as classpat2_1_, filter0_.jar as jar3_1_, filter0_.name as name4_1_, filter0_.options as options5_1_ from filter filter0_ order by filter0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/filter
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@4ed492df, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@7f99c604: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@7f99c604: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@1ae2028d; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.index(org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/filter/index
             View = null
        Attribute = MenuClusters
            value = []
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 68
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@259ae1a9
           errors = []
        Attribute = filters
            value = [Filter{id=2, name='Filter1', classpath='Filter1', jar='Filter1.jar', options='{"key": "value"}'}, Filter{id=3, name='Filter2', classpath='Filter2', jar='Filter2.jar', options='{"key": "value"}'}]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Filter Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="523c45d8-3e08-45d4-b029-1c3dc7595c87"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753954151@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/68">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Filters</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Filters

                        <div class="btn-group float-right" role="group" aria-label="Button group">
                            <a class="btn" href="/help#filters" style="padding-bottom: 0;">
                                <i class="icon-question"></i>
                                &nbsp; Help
                            </a>

                            <a class="btn" href="/configuration/filter/create" style="padding-bottom: 0;">
                                <i class="icon-settings"></i>
                                &nbsp;Create new
                            </a>
                        </div>
                    </div>
                    <div class="card-body">
                        <table class="table table-bordered table-striped table-sm">
                            <thead>
                            <tr>
                                <th>Name</th>
                                <th>Class</th>
                                <th>Options</th>
                                <th class="text-right">Action</th>
                            </tr>
                            </thead>
                            <tbody>
                            
                            <tr>
                                <td>Filter1</td>
                                <td>Filter1</td>
                                <td>{&quot;key&quot;: &quot;value&quot;}</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <a class="dropdown-item" href="/configuration/filter/edit/2">
                                                <i class="fa fa-edit"></i>
                                                Edit
                                            </a>
                                            <form action="/configuration/filter/delete/2" method="post"><input type="hidden" name="_csrf" value="523c45d8-3e08-45d4-b029-1c3dc7595c87"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Delete
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>Filter2</td>
                                <td>Filter2</td>
                                <td>{&quot;key&quot;: &quot;value&quot;}</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <a class="dropdown-item" href="/configuration/filter/edit/3">
                                                <i class="fa fa-edit"></i>
                                                Edit
                                            </a>
                                            <form action="/configuration/filter/delete/3" method="post"><input type="hidden" name="_csrf" value="523c45d8-3e08-45d4-b029-1c3dc7595c87"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Delete
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
            <!--/.col-->
        </div>
    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:34.388  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@78c91d2a testClass = FilterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigControllerTest@5b7d5eca, testMethod = testIndex@FilterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@52a3eba3 testClass = FilterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@4ed74d03 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:34.390  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@78c91d2a testClass = FilterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigControllerTest@d082916, testMethod = test_withoutAdminRole@FilterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@52a3eba3 testClass = FilterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@4ed74d03 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/filter
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@66ad7167, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@7a0699f8: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@7a0699f8: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@14aa2123; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/filter/create
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@7def62d0, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@7a0699f8: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@7a0699f8: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@14aa2123; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/filter/edit/1
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@736eb2a2, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@7a0699f8: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@7a0699f8: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@14aa2123; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/filter/update
       Parameters = {_csrf=[0e1ecaad-5416-455f-8f55-1fac8e76be42]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@7a0699f8: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@7a0699f8: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@14aa2123; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/filter/delete/1
       Parameters = {_csrf=[7cd576b5-eb57-4074-a1c6-0de34527f607]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@7a0699f8: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@7a0699f8: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@14aa2123; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:34.616  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@78c91d2a testClass = FilterConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigControllerTest@d082916, testMethod = test_withoutAdminRole@FilterConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@52a3eba3 testClass = FilterConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@4ed74d03 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.484 s - in org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigControllerTest
[INFO] Running org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest
2018-09-24 03:52:34.621  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Neither @ContextConfiguration nor @ContextHierarchy found for test class [org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest], using SpringBootContextLoader
2018-09-24 03:52:34.622  INFO 323 --- [           main] o.s.t.c.support.AbstractContextLoader    : Could not detect default resource locations for test class [org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-09-24 03:52:34.622  INFO 323 --- [           main] t.c.s.AnnotationConfigContextLoaderUtils : Could not detect default configuration classes for test class [org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest]: StreamConfigControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2018-09-24 03:52:34.640  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Found @SpringBootConfiguration org.sourcelab.kafka.webview.ui.Application for test class org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest
2018-09-24 03:52:34.642  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener]
2018-09-24 03:52:34.643  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@c7aac7c, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ab8f93, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@6037748a, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@4d87e7f3, org.springframework.test.context.support.DirtiesContextTestExecutionListener@14c7ab73, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4fcb796f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@1483c738, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@66c91224, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@4ffcb1bd, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@5be8a92c, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@51d80f6e, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@7fae6f43, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@55f54852, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@4bca2a09]

  _  __      __ _          __          __  _      __      ___
 | |/ /     / _| |         \ \        / / | |     \ \    / (_)
 | ' / __ _| |_| | ____ _   \ \  /\  / /__| |__    \ \  / / _  _____      __
 |  < / _` |  _| |/ / _` |   \ \/  \/ / _ \ '_ \    \ \/ / | |/ _ \ \ /\ / /
 | . \ (_| | | |   < (_| |    \  /\  /  __/ |_) |    \  /  | |  __/\ V  V /
 |_|\_\__,_|_| |_|\_\__,_|     \/  \/ \___|_.__/      \/   |_|\___| \_/\_/



2018-09-24 03:52:34.694  INFO 323 --- [           main] s.k.w.u.c.c.s.StreamConfigControllerTest : Starting StreamConfigControllerTest on cyclone1 with PID 323 (started by root in /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui)
2018-09-24 03:52:34.695  INFO 323 --- [           main] s.k.w.u.c.c.s.StreamConfigControllerTest : No active profile set, falling back to default profiles: default
2018-09-24 03:52:34.697  INFO 323 --- [           main] o.s.w.c.s.GenericWebApplicationContext   : Refreshing org.springframework.web.context.support.GenericWebApplicationContext@57d0c779: startup date [Mon Sep 24 03:52:34 CEST 2018]; root of context hierarchy
2018-09-24 03:52:36.200  INFO 323 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c84796a2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-09-24 03:52:36.422  INFO 323 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-2 - Starting...
2018-09-24 03:52:36.449  INFO 323 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-2 - Start completed.
2018-09-24 03:52:36.449  INFO 323 --- [           main] o.s.jdbc.datasource.init.ScriptUtils     : Executing SQL script from class path resource [schema/schema.sql]
2018-09-24 03:52:36.460  INFO 323 --- [           main] o.s.jdbc.datasource.init.ScriptUtils     : Executed SQL script from class path resource [schema/schema.sql] in 11 ms.
2018-09-24 03:52:36.606  INFO 323 --- [           main] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-09-24 03:52:36.606  INFO 323 --- [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-09-24 03:52:36.638  INFO 323 --- [           main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-09-24 03:52:36.844  INFO 323 --- [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-09-24 03:52:37.450  INFO 323 --- [           main] o.s.s.web.DefaultSecurityFilterChain     : Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@23938caa, org.springframework.security.web.context.SecurityContextPersistenceFilter@70ba01be, org.springframework.security.web.header.HeaderWriterFilter@514f2b5c, org.springframework.security.web.csrf.CsrfFilter@76a13b12, org.springframework.security.web.authentication.logout.LogoutFilter@6a40e660, org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter@465a121d, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@2b3fd4d2, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@3020f22, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@643bef2a, org.springframework.security.web.session.SessionManagementFilter@f3cc2e0, org.springframework.security.web.access.ExceptionTranslationFilter@7475f57e, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@443819d5]
2018-09-24 03:52:37.465  WARN 323 --- [           main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2018-09-24 03:52:37.509  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topics/list],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicListing> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getTopics(java.lang.Long)
2018-09-24 03:52:37.509  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/create/topic],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.controller.api.responses.ResultResponse org.sourcelab.kafka.webview.ui.controller.api.ApiController.createTopic(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.CreateTopicRequest)
2018-09-24 03:52:37.509  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topic/{topic}/details],methods=[GET],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicDetails org.sourcelab.kafka.webview.ui.controller.api.ApiController.getTopicDetails(java.lang.Long,java.lang.String)
2018-09-24 03:52:37.510  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topic/{topic}/config],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConfigItem> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getTopicConfig(java.lang.Long,java.lang.String)
2018-09-24 03:52:37.510  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/broker/{brokerId}/config],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConfigItem> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getBrokerConfig(java.lang.Long,java.lang.String)
2018-09-24 03:52:37.510  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/nodes],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.NodeDetails> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getClusterNodes(java.lang.Long)
2018-09-24 03:52:37.510  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/consumer/view/{id}],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.KafkaResults org.sourcelab.kafka.webview.ui.controller.api.ApiController.consume(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.ConsumeRequest)
2018-09-24 03:52:37.511  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/consumer/view/{id}/offsets],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConsumerState org.sourcelab.kafka.webview.ui.controller.api.ApiController.setConsumerOffsets(java.lang.Long,java.util.Map<java.lang.Integer, java.lang.Long>)
2018-09-24 03:52:37.511  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/consumer/view/{id}/timestamp/{timestamp}],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConsumerState org.sourcelab.kafka.webview.ui.controller.api.ApiController.setConsumerOffsetsByTimestamp(java.lang.Long,java.lang.Long)
2018-09-24 03:52:37.511  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/view/{id}/partitions],methods=[GET],produces=[application/json]}" onto public java.util.Collection<java.lang.Integer> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getPartitionsForView(java.lang.Long)
2018-09-24 03:52:37.511  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topics/details],methods=[GET],produces=[application/json]}" onto public java.util.Collection<org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicDetails> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getAllTopicsDetails(java.lang.Long)
2018-09-24 03:52:37.512  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/modify/topic],methods=[POST],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConfigItem> org.sourcelab.kafka.webview.ui.controller.api.ApiController.modifyTopicConfig(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.ModifyTopicConfigRequest)
2018-09-24 03:52:37.512  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/filter/{id}/options],methods=[GET],produces=[application/json]}" onto public java.lang.String[] org.sourcelab.kafka.webview.ui.controller.api.ApiController.getFilterOptions(java.lang.Long)
2018-09-24 03:52:37.517  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.clusterIndex(org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.517  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster/{clusterId}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readCluster(java.lang.Long,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.518  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster/{clusterId}/broker/{brokerId}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readBroker(java.lang.Long,java.lang.Integer,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.518  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster/{clusterId}/topic/{topic:.+}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readTopic(java.lang.Long,java.lang.String,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.518  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.ConfigurationController.index(org.springframework.ui.Model)
2018-09-24 03:52:37.520  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.createClusterForm(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.ui.Model)
2018-09-24 03:52:37.520  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.editClusterForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:37.520  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.clusterUpdate(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.521  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.deleteCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.521  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/test/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.testCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.521  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.index(org.springframework.ui.Model)
2018-09-24 03:52:37.522  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.createFilter(org.sourcelab.kafka.webview.ui.controller.configuration.filter.forms.FilterForm,org.springframework.ui.Model)
2018-09-24 03:52:37.523  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.editFilter(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.filter.forms.FilterForm,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.523  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.index(org.springframework.ui.Model)
2018-09-24 03:52:37.523  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.update(org.sourcelab.kafka.webview.ui.controller.configuration.filter.forms.FilterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.523  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.delete(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.525  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.createMessageFormat(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.ui.Model)
2018-09-24 03:52:37.525  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.deleteCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.525  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.editMessageFormat(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.525  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.index(org.springframework.ui.Model)
2018-09-24 03:52:37.526  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.create(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:52:37.526  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/stream/close/{hash}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController.closeConsumer(java.lang.String,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.527  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/stream],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController.index(org.springframework.ui.Model)
2018-09-24 03:52:37.528  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.createUser(org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.ui.Model)
2018-09-24 03:52:37.528  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.editUserForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:37.528  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.index(org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.ui.Model)
2018-09-24 03:52:37.529  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.update(org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:37.529  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.delete(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.530  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.createViewForm(org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.ui.Model)
2018-09-24 03:52:37.531  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.editViewForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:37.531  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.updateView(org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:52:37.531  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.deleteView(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.531  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.index(org.springframework.ui.Model)
2018-09-24 03:52:37.532  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.home.HomeController.home(org.springframework.ui.Model)
2018-09-24 03:52:37.532  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/help],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.home.HomeController.help(org.springframework.ui.Model)
2018-09-24 03:52:37.533  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/me],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.me(org.springframework.security.core.Authentication)
2018-09-24 03:52:37.533  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.loginForm(org.springframework.ui.Model,java.lang.String)
2018-09-24 03:52:37.534  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/lostPassword],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.lostPasswordForm(org.sourcelab.kafka.webview.ui.controller.login.forms.LostPasswordForm)
2018-09-24 03:52:37.534  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/lostPassword],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.lostPasswordFormSubmit(org.sourcelab.kafka.webview.ui.controller.login.forms.LostPasswordForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:37.534  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/resetPassword],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.resetPasswordForm(org.sourcelab.kafka.webview.ui.controller.login.forms.ResetPasswordForm)
2018-09-24 03:52:37.534  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/resetPassword],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.resetPasswordFormSubmit(org.sourcelab.kafka.webview.ui.controller.login.forms.ResetPasswordForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:37.535  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/stream],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.index(org.springframework.ui.Model)
2018-09-24 03:52:37.535  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/stream/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.stream(java.lang.Long,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:52:37.536  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/view/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.view.ViewController.index(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:52:37.536  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/view],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.view.ViewController.index(org.springframework.ui.Model,java.lang.Long)
2018-09-24 03:52:37.539  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-09-24 03:52:37.539  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-09-24 03:52:37.580  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/css/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:52:37.580  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/js/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:52:37.580  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/vendors/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:52:37.580  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/img/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:52:37.692  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@57d0c779: startup date [Mon Sep 24 03:52:34 CEST 2018]; root of context hierarchy
2018-09-24 03:52:37.738  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'clientInboundChannelExecutor'
2018-09-24 03:52:37.744  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'clientOutboundChannelExecutor'
2018-09-24 03:52:37.755  INFO 323 --- [           main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService  'messageBrokerTaskScheduler'
2018-09-24 03:52:37.765  INFO 323 --- [           main] o.s.w.s.s.s.WebSocketHandlerMapping      : Mapped URL path [/websocket/**] onto handler of type [class org.springframework.web.socket.sockjs.support.SockJsHttpRequestHandler]
2018-09-24 03:52:37.773  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'brokerChannelExecutor'
2018-09-24 03:52:37.790  INFO 323 --- [           main] .WebSocketAnnotationMethodMessageHandler : Mapped "{[/pause/{viewId}],messageType=[MESSAGE]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.pauseConsumer(java.lang.Long,org.springframework.messaging.simp.SimpMessageHeaderAccessor)
2018-09-24 03:52:37.790  INFO 323 --- [           main] .WebSocketAnnotationMethodMessageHandler : Mapped "{[/resume/{viewId}],messageType=[MESSAGE]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.resumeConsumer(java.lang.Long,org.springframework.messaging.simp.SimpMessageHeaderAccessor)
2018-09-24 03:52:37.790  INFO 323 --- [           main] .WebSocketAnnotationMethodMessageHandler : Mapped "{[/consume/{viewId}],messageType=[MESSAGE]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.newConsumer(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.ConsumeRequest,org.springframework.messaging.simp.SimpMessageHeaderAccessor)
2018-09-24 03:52:37.807  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 
2018-09-24 03:52:37.807  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'backgroundConsumerExecutor'
2018-09-24 03:52:38.617  INFO 323 --- [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'
2018-09-24 03:52:38.633  INFO 323 --- [           main] s.b.a.e.w.s.WebMvcEndpointHandlerMapping : Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:52:38.633  INFO 323 --- [           main] s.b.a.e.w.s.WebMvcEndpointHandlerMapping : Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:52:38.633  INFO 323 --- [           main] s.b.a.e.w.s.WebMvcEndpointHandlerMapping : Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-09-24 03:52:38.820  INFO 323 --- [           main] o.s.b.t.m.w.SpringBootMockServletContext : Initializing Spring FrameworkServlet ''
2018-09-24 03:52:38.820  INFO 323 --- [           main] o.s.t.web.servlet.TestDispatcherServlet  : FrameworkServlet '': initialization started
2018-09-24 03:52:38.837  INFO 323 --- [           main] o.s.t.web.servlet.TestDispatcherServlet  : FrameworkServlet '': initialization completed in 17 ms
2018-09-24 03:52:38.872  INFO 323 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-09-24 03:52:38.872  INFO 323 --- [           main] o.s.m.s.b.SimpleBrokerMessageHandler     : Starting...
2018-09-24 03:52:38.872  INFO 323 --- [           main] o.s.m.s.b.SimpleBrokerMessageHandler     : BrokerAvailabilityEvent[available=true, SimpleBrokerMessageHandler [DefaultSubscriptionRegistry[cache[0 destination(s)], registry[0 sessions]]]]
2018-09-24 03:52:38.873  INFO 323 --- [           main] o.s.m.s.b.SimpleBrokerMessageHandler     : Started.
2018-09-24 03:52:38.880  INFO 323 --- [           main] s.k.w.u.c.c.s.StreamConfigControllerTest : Started StreamConfigControllerTest in 4.234 seconds (JVM running for 30.586)
2018-09-24 03:52:38.885  INFO 323 --- [           main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
Hibernate: select count(*) as col_0_0_ from user user0_
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
2018-09-24 03:52:38.931  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@1b61a646 testClass = StreamConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest@38c840fb, testMethod = test_closeInvalidHash@StreamConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@fbc1de9 testClass = StreamConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@295e9aef key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@d0c78340, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@7ec63b9a]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/stream/close/SessionHash1
       Parameters = {_csrf=[046e19bc-a681-4bee-9ef7-d0b34afbc370]}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='warning', message='Unable to find consumer!'}}, targetRequestPath=/configuration/stream, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@83a65b66: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@83a65b66: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@71d2bc34; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController.closeConsumer(java.lang.String,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/stream
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='warning', message='Unable to find consumer!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/stream]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/stream
          Cookies = []
2018-09-24 03:52:39.216  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@1b61a646 testClass = StreamConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest@38c840fb, testMethod = test_closeInvalidHash@StreamConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@fbc1de9 testClass = StreamConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@295e9aef key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@d0c78340, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:39.219  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@1b61a646 testClass = StreamConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest@6d86d1ad, testMethod = test_withoutAdminRole@StreamConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@fbc1de9 testClass = StreamConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@295e9aef key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@d0c78340, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@7ec63b9a]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/stream
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@b9750f0, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@4b5e8dea: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@4b5e8dea: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@2d854c13; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/stream/close/SomeHashHere
       Parameters = {_csrf=[a000e26f-e924-407c-a0fb-53cb93897f63]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@4b5e8dea: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@4b5e8dea: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@2d854c13; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:39.456  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@1b61a646 testClass = StreamConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest@6d86d1ad, testMethod = test_withoutAdminRole@StreamConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@fbc1de9 testClass = StreamConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@295e9aef key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@d0c78340, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:39.458  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@1b61a646 testClass = StreamConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest@3577fd9b, testMethod = test_closeValidHash@StreamConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@fbc1de9 testClass = StreamConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@295e9aef key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@d0c78340, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@7ec63b9a]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /configuration/stream/close/SessionHash1
       Parameters = {_csrf=[43a41ff8-3e44-41bb-9730-293ab1edfcdf]}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.web.servlet.support.SessionFlashMapManager.FLASH_MAPS=[FlashMap [attributes={FlashMessage=FlashMessage{type='success', message='Closed consumer!'}}, targetRequestPath=/configuration/stream, targetRequestParams={}]], SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@fcb6fd55: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@fcb6fd55: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@42b6acc2; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController.closeConsumer(java.lang.String,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = redirect:/configuration/stream
             View = null
            Model = null

FlashMap:
        Attribute = FlashMessage
            value = FlashMessage{type='success', message='Closed consumer!'}

MockHttpServletResponse:
           Status = 302
    Error message = null
          Headers = {Content-Language=[en], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Location=[/configuration/stream]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = /configuration/stream
          Cookies = []
2018-09-24 03:52:39.677  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@1b61a646 testClass = StreamConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest@3577fd9b, testMethod = test_closeValidHash@StreamConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@fbc1de9 testClass = StreamConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@295e9aef key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@d0c78340, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:39.679  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@1b61a646 testClass = StreamConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest@3de8e614, testMethod = test_index@StreamConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@fbc1de9 testClass = StreamConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@295e9aef key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@d0c78340, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@7ec63b9a]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: insert into view (id, cluster_id, created_at, key_message_format_id, name, partitions, results_per_partition, topic, updated_at, value_message_format_id) values (null, ?, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: insert into view (id, cluster_id, created_at, key_message_format_id, name, partitions, results_per_partition, topic, updated_at, value_message_format_id) values (null, ?, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: update cluster set broker_hosts=?, is_ssl_enabled=?, is_valid=?, key_store_file=?, key_store_password=?, name=?, trust_store_file=?, trust_store_password=? where id=?
Hibernate: update cluster set broker_hosts=?, is_ssl_enabled=?, is_valid=?, key_store_file=?, key_store_password=?, name=?, trust_store_file=?, trust_store_password=? where id=?
Hibernate: update user set display_name=?, email=?, has_password=?, is_active=?, password=?, reset_password_hash=?, role=? where id=?
Hibernate: update user set display_name=?, email=?, has_password=?, is_active=?, password=?, reset_password_hash=?, role=? where id=?
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.id in (? , ?)
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ where view0_.id in (? , ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ where cluster0_.id in (? , ?)

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /configuration/stream
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@446dbf7b, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@8db2648: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@8db2648: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@1cb09347; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController.index(org.springframework.ui.Model)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = configuration/stream/index
             View = null
        Attribute = MenuClusters
            value = [Cluster{+ id=13, + name='ClusterA', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}, Cluster{+ id=14, + name='ClusterB', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}]
        Attribute = MenuViews
            value = [org.sourcelab.kafka.webview.ui.model.View@4c3c1963, org.sourcelab.kafka.webview.ui.model.View@2c3f47ba]
        Attribute = UserId
            value = 78
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@673218b2
           errors = []
        Attribute = viewMap
            value = {4=org.sourcelab.kafka.webview.ui.model.View@4c3c1963, 5=org.sourcelab.kafka.webview.ui.model.View@2c3f47ba}
        Attribute = userMap
            value = {80=org.sourcelab.kafka.webview.ui.model.User@7225f871, 81=org.sourcelab.kafka.webview.ui.model.User@5a4a8a33}
        Attribute = clusterMap
            value = {13=Cluster{+ id=13, + name='ClusterA', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}, 14=Cluster{+ id=14, + name='ClusterB', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}}
        Attribute = consumers
            value = [StreamConsumerDetails{userId=80, viewId=4, startedAtTimestamp=1529841610, recordCount=234243, isPaused=false}, StreamConsumerDetails{userId=81, viewId=5, startedAtTimestamp=977702112, recordCount=2334, isPaused=true}]

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Stream Configuration</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="bec5751e-7b22-4e1a-b630-57ed15e69b2e"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753959680@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/78">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item" title="ClusterA">
                            <a class="nav-link" href="/cluster/13">
                                <i class="icon-layers"></i>
                                ClusterA
                            </a>
                        </li>
                        <li class="nav-item" title="ClusterB">
                            <a class="nav-link" href="/cluster/14">
                                <i class="icon-layers"></i>
                                ClusterB
                            </a>
                        </li>
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item" title="My first view">
                            <a class="nav-link" href="/view/4">
                                <i class="icon-eye"></i>
                                My first view
                            </a>
                        </li>
                        <li class="nav-item" title="My second view">
                            <a class="nav-link" href="/view/5">
                                <i class="icon-eye"></i>
                                My second view
                            </a>
                        </li>
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/configuration">Configuration</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Streams</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Active Stream Consumers
                    </div>
                    <div class="card-body">
                        <table class="table table-bordered table-striped table-sm">
                            <thead>
                            <tr>
                                <th>User</th>
                                <th>View</th>
                                <th>Cluster</th>
                                <th>Active Since</th>
                                <th>Records Consumed</th>
                                <th class="text-right">Action</th>
                            </tr>
                            </thead>
                            <tbody>
                            
                            <tr>
                                <td>First User Display Name</td>
                                <td>
                                    <a
                                        href="/view/4">My first view</a>
                                </td>
                                <td>
                                    <a
                                        href="/cluster/13">ClusterA</a>
                                </td>
                                <td
                                    class="relativeUnixTimestamp"
                                    >1529841610</td>
                                <td>234243</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <form action="/configuration/stream/close/SessionHash1" method="post"><input type="hidden" name="_csrf" value="bec5751e-7b22-4e1a-b630-57ed15e69b2e"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Close Consumer
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            <tr>
                                <td>Second User Display Name</td>
                                <td>
                                    <a
                                        href="/view/5">My second view</a>
                                </td>
                                <td>
                                    <a
                                        href="/cluster/14">ClusterB</a>
                                </td>
                                <td
                                    class="relativeUnixTimestamp"
                                    >977702112</td>
                                <td>2334</td>
                                <td class="text-right">
                                    <div class="dropdown">
                                        <button class="btn btn-secondary btn-sm dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                            Actions
                                        </button>
                                        <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
                                            <form action="/configuration/stream/close/SessionHash2" method="post"><input type="hidden" name="_csrf" value="bec5751e-7b22-4e1a-b630-57ed15e69b2e"/>
                                                <button class="dropdown-item" onclick="return confirm('Are you sure?');" type="submit">
                                                    <i class="fa fa-remove"></i>
                                                    Close Consumer
                                                </button>
                                            </form>
                                        </div>
                                    </div>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
            <!--/.col-->
        </div>
    </div>

    <!-- Javascript -->
    <script type="application/javascript">
        jQuery(document).ready(function() {
            // Convert timestamps to relative times on load.
            jQuery('.relativeUnixTimestamp').each(
                function( index, tdEl ) {
                    var unixTimestamp = jQuery(tdEl).text();
                    var momentInstance = moment(unixTimestamp, "x");

                    jQuery(tdEl)
                        .text(momentInstance.fromNow());

                    jQuery(tdEl)
                        .attr("title", momentInstance.utc().format())
                }
            );
        });
    </script>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:40.191  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@1b61a646 testClass = StreamConfigControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest@3de8e614, testMethod = test_index@StreamConfigControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@fbc1de9 testClass = StreamConfigControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@295e9aef key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@d0c78340, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.57 s - in org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigControllerTest
[INFO] Running org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest
2018-09-24 03:52:40.197  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Neither @ContextConfiguration nor @ContextHierarchy found for test class [org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest], using SpringBootContextLoader
2018-09-24 03:52:40.198  INFO 323 --- [           main] o.s.t.c.support.AbstractContextLoader    : Could not detect default resource locations for test class [org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-09-24 03:52:40.198  INFO 323 --- [           main] t.c.s.AnnotationConfigContextLoaderUtils : Could not detect default configuration classes for test class [org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest]: ApiControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2018-09-24 03:52:40.210  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Found @SpringBootConfiguration org.sourcelab.kafka.webview.ui.Application for test class org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest
2018-09-24 03:52:40.212  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener]
2018-09-24 03:52:40.213  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@2fb006dc, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1285ec6, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@2abe5132, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@12fbc568, org.springframework.test.context.support.DirtiesContextTestExecutionListener@3dd2a70d, org.springframework.test.context.transaction.TransactionalTestExecutionListener@7ecf001f, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@2620f935, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@6a3cb81c, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@42fe9099, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@4437af21, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@657f1fc3, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@6a0ca728, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@5cc088a8, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@25777ab6]
2018-09-24 03:52:40.215  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Starting kafka test server
2018-09-24 03:52:40.218  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:52:40.329  INFO 323 --- [      Thread-13] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:52:40.334  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-09-24 03:52:40.335  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:host.name=cyclone1
2018-09-24 03:52:40.335  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.version=1.8.0_121
2018-09-24 03:52:40.335  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.vendor=Oracle Corporation
2018-09-24 03:52:40.336  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2018-09-24 03:52:40.336  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.class.path=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/target/classes:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka-clients/1.1.1/kafka-clients-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-thymeleaf/2.0.5.RELEASE/spring-boot-starter-thymeleaf-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter/2.0.5.RELEASE/spring-boot-starter-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-logging/2.0.5.RELEASE/spring-boot-starter-logging-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-core/1.2.3/logback-core-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-to-slf4j/2.10.0/log4j-to-slf4j-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-api/2.10.0/log4j-api-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/yaml/snakeyaml/1.19/snakeyaml-1.19.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring5/3.0.9.RELEASE/thymeleaf-spring5-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-java8time/3.0.1.RELEASE/thymeleaf-extras-java8time-3.0.1.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring4/3.0.9.RELEASE/thymeleaf-spring4-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf/3.0.9.RELEASE/thymeleaf-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ognl/ognl/3.1.12/ognl-3.1.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/javassist/javassist/3.20.0-GA/javassist-3.20.0-GA.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/attoparser/attoparser/2.0.4.RELEASE/attoparser-2.0.4.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/unbescape/unbescape/1.1.5.RELEASE/unbescape-1.1.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-layout-dialect/2.3.0/thymeleaf-layout-dialect-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-expression-processor/1.1.3/thymeleaf-expression-processor-1.1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-springsecurity4/3.0.2.RELEASE/thymeleaf-extras-springsecurity4-3.0.2.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-data-jpa/2.0.5.RELEASE/spring-boot-starter-data-jpa-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-aop/2.0.5.RELEASE/spring-boot-starter-aop-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/aspectj/aspectjweaver/1.8.13/aspectjweaver-1.8.13.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-jdbc/2.0.5.RELEASE/spring-boot-starter-jdbc-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/zaxxer/HikariCP/2.7.9/HikariCP-2.7.9.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jdbc/5.0.9.RELEASE/spring-jdbc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/hibernate-core/5.2.17.Final/hibernate-core-5.2.17.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/javax/persistence/hibernate-jpa-2.1-api/1.0.2.Final/hibernate-jpa-2.1-api-1.0.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/jandex/2.0.3.Final/jandex-2.0.3.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/classmate/1.3.4/classmate-1.3.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/common/hibernate-commons-annotations/5.0.1.Final/hibernate-commons-annotations-5.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-jpa/2.0.10.RELEASE/spring-data-jpa-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-commons/2.0.10.RELEASE/spring-data-commons-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-orm/5.0.9.RELEASE/spring-orm-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-context/5.0.9.RELEASE/spring-context-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-tx/5.0.9.RELEASE/spring-tx-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-beans/5.0.9.RELEASE/spring-beans-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aspects/5.0.9.RELEASE/spring-aspects-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/h2database/h2/1.4.197/h2-1.4.197.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-security/2.0.5.RELEASE/spring-boot-starter-security-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aop/5.0.9.RELEASE/spring-aop-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-config/5.0.8.RELEASE/spring-security-config-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-web/5.0.8.RELEASE/spring-security-web-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-expression/5.0.9.RELEASE/spring-expression-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-web/5.0.9.RELEASE/spring-web-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-websocket/2.0.5.RELEASE/spring-boot-starter-websocket-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-web/2.0.5.RELEASE/spring-boot-starter-web-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-json/2.0.5.RELEASE/spring-boot-starter-json-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.6/jackson-datatype-jdk8-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.6/jackson-module-parameter-names-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-tomcat/2.0.5.RELEASE/spring-boot-starter-tomcat-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-core/8.5.34/tomcat-embed-core-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-el/8.5.34/tomcat-embed-el-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-websocket/8.5.34/tomcat-embed-websocket-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/validator/hibernate-validator/6.0.12.Final/hibernate-validator-6.0.12.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-webmvc/5.0.9.RELEASE/spring-webmvc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-messaging/5.0.9.RELEASE/spring-messaging-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-websocket/5.0.9.RELEASE/spring-websocket-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-actuator/2.0.5.RELEASE/spring-boot-starter-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator-autoconfigure/2.0.5.RELEASE/spring-boot-actuator-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator/2.0.5.RELEASE/spring-boot-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.6/jackson-datatype-jsr310-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/io/micrometer/micrometer-core/1.0.6/micrometer-core-1.0.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hdrhistogram/HdrHistogram/2.1.10/HdrHistogram-2.1.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/interceptor/javax.interceptor-api/1.2.1/javax.interceptor-api-1.2.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-devtools/2.0.5.RELEASE/spring-boot-devtools-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot/2.0.5.RELEASE/spring-boot-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-autoconfigure/2.0.5.RELEASE/spring-boot-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-test/2.0.5.RELEASE/spring-boot-starter-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test/2.0.5.RELEASE/spring-boot-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test-autoconfigure/2.0.5.RELEASE/spring-boot-test-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/json-smart/2.3/json-smart-2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/junit/junit/4.12/junit-4.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/assertj/assertj-core/3.9.1/assertj-core-3.9.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/mockito/mockito-core/2.15.0/mockito-core-2.15.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy/1.7.11/byte-buddy-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy-agent/1.7.11/byte-buddy-agent-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-core/5.0.9.RELEASE/spring-core-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jcl/5.0.9.RELEASE/spring-jcl-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-test/5.0.9.RELEASE/spring-test-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xmlunit/xmlunit-core/2.5.1/xmlunit-core-2.5.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-test/5.0.8.RELEASE/spring-security-test-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-core/5.0.8.RELEASE/spring-security-core-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit4/3.0.1/kafka-junit4-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit-core/3.0.1/kafka-junit-core-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka_2.11/1.1.1/kafka_2.11-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/typesafe/scala-logging/scala-logging_2.11/3.8.0/scala-logging_2.11-3.8.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/zookeeper/zookeeper/3.4.10/zookeeper-3.4.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/pl/pragmatists/JUnitParams/1.1.1/JUnitParams-1.1.1.jar:
2018-09-24 03:52:40.336  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2018-09-24 03:52:40.336  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.io.tmpdir=/tmp
2018-09-24 03:52:40.336  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:java.compiler=<NA>
2018-09-24 03:52:40.336  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:os.name=Linux
2018-09-24 03:52:40.337  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:os.arch=amd64
2018-09-24 03:52:40.337  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:os.version=3.10.0-862.3.2.el7.x86_64
2018-09-24 03:52:40.337  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:user.name=root
2018-09-24 03:52:40.337  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:user.home=/root
2018-09-24 03:52:40.337  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : Server environment:user.dir=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui
2018-09-24 03:52:40.346  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:52:40.347  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:52:40.347  INFO 323 --- [      Thread-13] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:52:40.360  INFO 323 --- [      Thread-13] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:44240
2018-09-24 03:52:41.392  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:52:41.393  INFO 323 --- [0/0.0.0.0:44240] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:52:41.394  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:52:41.394  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:52:41.394  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:52:41.394  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:52:41.394  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:52:41.394  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:52:41.395  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2018-09-24 03:52:41.395  INFO 323 --- [      Thread-14] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:52:41.396  INFO 323 --- [      Thread-14] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:52:41.396  INFO 323 --- [      Thread-14] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:52:41.396  INFO 323 --- [      Thread-14] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:52:41.396  INFO 323 --- [      Thread-14] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:44240
2018-09-24 03:52:42.000  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:52:42.573  INFO 323 --- [           main] k.utils.Log4jControllerRegistration$     : Registered kafka:type=kafka.Log4jController MBean
2018-09-24 03:52:42.664  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:37631
	advertised.port = 37631
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:37631
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753962399-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 37631
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:44240
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:52:42.751  INFO 323 --- [           main] kafka.server.KafkaServer                 : starting
2018-09-24 03:52:42.752  INFO 323 --- [           main] kafka.server.KafkaServer                 : Connecting to zookeeper on 127.0.0.1:44240
2018-09-24 03:52:42.770  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Initializing a new session to 127.0.0.1:44240.
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:host.name=cyclone1
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.version=1.8.0_121
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.vendor=Oracle Corporation
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.class.path=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/test-classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/classes:/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-plugin/target/classes:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka-clients/1.1.1/kafka-clients-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-thymeleaf/2.0.5.RELEASE/spring-boot-starter-thymeleaf-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter/2.0.5.RELEASE/spring-boot-starter-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-logging/2.0.5.RELEASE/spring-boot-starter-logging-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ch/qos/logback/logback-core/1.2.3/logback-core-1.2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-to-slf4j/2.10.0/log4j-to-slf4j-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/logging/log4j/log4j-api/2.10.0/log4j-api-2.10.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/yaml/snakeyaml/1.19/snakeyaml-1.19.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring5/3.0.9.RELEASE/thymeleaf-spring5-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-java8time/3.0.1.RELEASE/thymeleaf-extras-java8time-3.0.1.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf-spring4/3.0.9.RELEASE/thymeleaf-spring4-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/thymeleaf/3.0.9.RELEASE/thymeleaf-3.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/ognl/ognl/3.1.12/ognl-3.1.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/javassist/javassist/3.20.0-GA/javassist-3.20.0-GA.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/attoparser/attoparser/2.0.4.RELEASE/attoparser-2.0.4.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/unbescape/unbescape/1.1.5.RELEASE/unbescape-1.1.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-layout-dialect/2.3.0/thymeleaf-layout-dialect-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/nz/net/ultraq/thymeleaf/thymeleaf-expression-processor/1.1.3/thymeleaf-expression-processor-1.1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/codehaus/groovy/groovy/2.4.15/groovy-2.4.15.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/thymeleaf/extras/thymeleaf-extras-springsecurity4/3.0.2.RELEASE/thymeleaf-extras-springsecurity4-3.0.2.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-data-jpa/2.0.5.RELEASE/spring-boot-starter-data-jpa-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-aop/2.0.5.RELEASE/spring-boot-starter-aop-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/aspectj/aspectjweaver/1.8.13/aspectjweaver-1.8.13.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-jdbc/2.0.5.RELEASE/spring-boot-starter-jdbc-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/zaxxer/HikariCP/2.7.9/HikariCP-2.7.9.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jdbc/5.0.9.RELEASE/spring-jdbc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/transaction/javax.transaction-api/1.2/javax.transaction-api-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/hibernate-core/5.2.17.Final/hibernate-core-5.2.17.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/javax/persistence/hibernate-jpa-2.1-api/1.0.2.Final/hibernate-jpa-2.1-api-1.0.2.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/jboss/jandex/2.0.3.Final/jandex-2.0.3.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/classmate/1.3.4/classmate-1.3.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/common/hibernate-commons-annotations/5.0.1.Final/hibernate-commons-annotations-5.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-jpa/2.0.10.RELEASE/spring-data-jpa-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/data/spring-data-commons/2.0.10.RELEASE/spring-data-commons-2.0.10.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-orm/5.0.9.RELEASE/spring-orm-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-context/5.0.9.RELEASE/spring-context-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-tx/5.0.9.RELEASE/spring-tx-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-beans/5.0.9.RELEASE/spring-beans-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aspects/5.0.9.RELEASE/spring-aspects-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/h2database/h2/1.4.197/h2-1.4.197.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-security/2.0.5.RELEASE/spring-boot-starter-security-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-aop/5.0.9.RELEASE/spring-aop-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-config/5.0.8.RELEASE/spring-security-config-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-web/5.0.8.RELEASE/spring-security-web-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-expression/5.0.9.RELEASE/spring-expression-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-web/5.0.9.RELEASE/spring-web-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-websocket/2.0.5.RELEASE/spring-boot-starter-websocket-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-web/2.0.5.RELEASE/spring-boot-starter-web-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-json/2.0.5.RELEASE/spring-boot-starter-json-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.6/jackson-datatype-jdk8-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.6/jackson-module-parameter-names-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-tomcat/2.0.5.RELEASE/spring-boot-starter-tomcat-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-core/8.5.34/tomcat-embed-core-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-el/8.5.34/tomcat-embed-el-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/tomcat/embed/tomcat-embed-websocket/8.5.34/tomcat-embed-websocket-8.5.34.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hibernate/validator/hibernate-validator/6.0.12.Final/hibernate-validator-6.0.12.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-webmvc/5.0.9.RELEASE/spring-webmvc-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-messaging/5.0.9.RELEASE/spring-messaging-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-websocket/5.0.9.RELEASE/spring-websocket-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-actuator/2.0.5.RELEASE/spring-boot-starter-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator-autoconfigure/2.0.5.RELEASE/spring-boot-actuator-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-actuator/2.0.5.RELEASE/spring-boot-actuator-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.6/jackson-datatype-jsr310-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/io/micrometer/micrometer-core/1.0.6/micrometer-core-1.0.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hdrhistogram/HdrHistogram/2.1.10/HdrHistogram-2.1.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/interceptor/javax.interceptor-api/1.2.1/javax.interceptor-api-1.2.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-devtools/2.0.5.RELEASE/spring-boot-devtools-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot/2.0.5.RELEASE/spring-boot-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-autoconfigure/2.0.5.RELEASE/spring-boot-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-starter-test/2.0.5.RELEASE/spring-boot-starter-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test/2.0.5.RELEASE/spring-boot-test-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/boot/spring-boot-test-autoconfigure/2.0.5.RELEASE/spring-boot-test-autoconfigure-2.0.5.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/json-smart/2.3/json-smart-2.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/junit/junit/4.12/junit-4.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/assertj/assertj-core/3.9.1/assertj-core-3.9.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/mockito/mockito-core/2.15.0/mockito-core-2.15.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy/1.7.11/byte-buddy-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/bytebuddy/byte-buddy-agent/1.7.11/byte-buddy-agent-1.7.11.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-core/5.0.9.RELEASE/spring-core-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-jcl/5.0.9.RELEASE/spring-jcl-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/spring-test/5.0.9.RELEASE/spring-test-5.0.9.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/xmlunit/xmlunit-core/2.5.1/xmlunit-core-2.5.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-test/5.0.8.RELEASE/spring-security-test-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/springframework/security/spring-security-core/5.0.8.RELEASE/spring-security-core-5.0.8.RELEASE.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit4/3.0.1/kafka-junit4-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/salesforce/kafka/test/kafka-junit-core/3.0.1/kafka-junit-core-3.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/curator/curator-test/2.12.0/curator-test-2.12.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/kafka/kafka_2.11/1.1.1/kafka_2.11-1.1.1.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/fasterxml/jackson/core/jackson-core/2.9.6/jackson-core-2.9.6.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/typesafe/scala-logging/scala-logging_2.11/3.8.0/scala-logging_2.11-3.8.0.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/org/apache/zookeeper/zookeeper/3.4.10/zookeeper-3.4.10.jar:/root/./workspace/SourceLabOrg/kafka-webview/432293183/.m2/pl/pragmatists/JUnitParams/1.1.1/JUnitParams-1.1.1.jar:
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.io.tmpdir=/tmp
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.compiler=<NA>
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.name=Linux
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.arch=amd64
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.version=3.10.0-862.3.2.el7.x86_64
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:user.name=root
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:user.home=/root
2018-09-24 03:52:42.775  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:user.dir=/root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui
2018-09-24 03:52:42.777  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Initiating client connection, connectString=127.0.0.1:44240 sessionTimeout=30000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4a35aed6
2018-09-24 03:52:42.789  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Waiting until connected.
2018-09-24 03:52:42.790  INFO 323 --- [27.0.0.1:44240)] org.apache.zookeeper.ClientCnxn          : Opening socket connection to server 127.0.0.1/127.0.0.1:44240. Will not attempt to authenticate using SASL (unknown error)
2018-09-24 03:52:42.793  INFO 323 --- [0/0.0.0.0:44240] o.a.z.server.NIOServerCnxnFactory        : Accepted socket connection from /127.0.0.1:56904
2018-09-24 03:52:42.794  INFO 323 --- [27.0.0.1:44240)] org.apache.zookeeper.ClientCnxn          : Socket connection established to 127.0.0.1/127.0.0.1:44240, initiating session
2018-09-24 03:52:42.801  INFO 323 --- [0/0.0.0.0:44240] o.a.zookeeper.server.ZooKeeperServer     : Client attempting to establish new session at /127.0.0.1:56904
2018-09-24 03:52:42.806  INFO 323 --- [   SyncThread:0] o.a.z.server.persistence.FileTxnLog      : Creating new log file: log.1
2018-09-24 03:52:42.854  INFO 323 --- [   SyncThread:0] o.a.zookeeper.server.ZooKeeperServer     : Established session 0x166094753b60000 with negotiated timeout 30000 for client /127.0.0.1:56904
2018-09-24 03:52:42.855  INFO 323 --- [27.0.0.1:44240)] org.apache.zookeeper.ClientCnxn          : Session establishment complete on server 127.0.0.1/127.0.0.1:44240, sessionid = 0x166094753b60000, negotiated timeout = 30000
2018-09-24 03:52:42.859  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Connected.
2018-09-24 03:52:42.944  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094753b60000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-24 03:52:43.252  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094753b60000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-24 03:52:43.352  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094753b60000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-24 03:52:43.871  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094753b60000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-24 03:52:43.994  INFO 323 --- [           main] kafka.server.KafkaServer                 : Cluster ID = XWP0HG87SNClCED3mmNuPQ
2018-09-24 03:52:43.999  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537753962399-0/meta.properties
2018-09-24 03:52:44.085  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:37631
	advertised.port = 37631
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:37631
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753962399-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 37631
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:44240
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:52:44.094  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:37631
	advertised.port = 37631
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:37631
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753962399-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 37631
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:44240
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:52:44.164  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Starting
2018-09-24 03:52:44.167  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Starting
2018-09-24 03:52:44.173  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Starting
2018-09-24 03:52:44.221  INFO 323 --- [           main] kafka.log.LogManager                     : Loading logs.
2018-09-24 03:52:44.239  INFO 323 --- [           main] kafka.log.LogManager                     : Logs loading complete in 17 ms.
2018-09-24 03:52:44.254  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log cleanup with a period of 300000 ms.
2018-09-24 03:52:44.261  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-24 03:52:44.276  INFO 323 --- [           main] kafka.log.LogCleaner                     : Starting the log cleaner
2018-09-24 03:52:44.340  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Starting
2018-09-24 03:52:44.718  INFO 323 --- [           main] kafka.network.Acceptor                   : Awaiting socket connections on 127.0.0.1:37631.
2018-09-24 03:52:44.759  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-24 03:52:44.787  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Starting
2018-09-24 03:52:44.792  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-24 03:52:44.792  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Starting
2018-09-24 03:52:44.823  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Starting
2018-09-24 03:52:44.846  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Creating /brokers/ids/1 (is it secure? false)
2018-09-24 03:52:44.885  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Result of znode creation at /brokers/ids/1 is: OK
2018-09-24 03:52:44.887  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(127.0.0.1,37631,ListenerName(PLAINTEXT),PLAINTEXT))
2018-09-24 03:52:44.889  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537753962399-0/meta.properties
2018-09-24 03:52:44.972  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Starting
2018-09-24 03:52:44.984  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Creating /controller (is it secure? false)
2018-09-24 03:52:44.984  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Starting
2018-09-24 03:52:44.989  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Starting
2018-09-24 03:52:44.990  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Starting
2018-09-24 03:52:45.029  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Result of znode creation at /controller is: OK
2018-09-24 03:52:45.030  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] 1 successfully elected as the controller
2018-09-24 03:52:45.030  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Reading controller epoch from ZooKeeper
2018-09-24 03:52:45.032  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Incrementing controller epoch in ZooKeeper
2018-09-24 03:52:45.037  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094753b60000 type:setData cxid:0x21 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-24 03:52:45.042  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Starting up.
2018-09-24 03:52:45.043  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Startup complete.
2018-09-24 03:52:45.047  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 4 milliseconds.
2018-09-24 03:52:45.110  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Epoch incremented to 1
2018-09-24 03:52:45.111  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Registering handlers
2018-09-24 03:52:45.145  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting log dir event notifications
2018-09-24 03:52:45.145  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-24 03:52:45.147  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting isr change notifications
2018-09-24 03:52:45.150  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing controller context
2018-09-24 03:52:45.171  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Starting up.
2018-09-24 03:52:45.179  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Starting
2018-09-24 03:52:45.182  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Startup complete.
2018-09-24 03:52:45.241  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Starting
2018-09-24 03:52:45.242  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions being reassigned: Map()
2018-09-24 03:52:45.244  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-24 03:52:45.245  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-24 03:52:45.245  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Current list of topics in the cluster: Set()
2018-09-24 03:52:45.246  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Fetching topic deletions in progress
2018-09-24 03:52:45.248  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Starting
2018-09-24 03:52:45.251  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics to be deleted: 
2018-09-24 03:52:45.252  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics ineligible for deletion: 
2018-09-24 03:52:45.253  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing topic deletion manager
2018-09-24 03:52:45.254  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Sending update metadata request
2018-09-24 03:52:45.261  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-24 03:52:45.264  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:52:45.264  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:52:45.266  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] started
2018-09-24 03:52:45.278  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Controller 1 connected to 127.0.0.1:37631 (id: 1 rack: null) for sending state change requests
2018-09-24 03:52:45.278  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37631]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:52:45.283  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Initializing replica state
2018-09-24 03:52:45.285  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Triggering online replica state changes
2018-09-24 03:52:45.297  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-24 03:52:45.298  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Initializing partition state
2018-09-24 03:52:45.302  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:52:45.302  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:52:45.305  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Triggering online partition state changes
2018-09-24 03:52:45.311  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-24 03:52:45.312  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-24 03:52:45.316  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-24 03:52:45.316  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions that completed preferred replica election: 
2018-09-24 03:52:45.317  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-24 03:52:45.318  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-24 03:52:45.318  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-24 03:52:45.323  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094753b60000 type:delete cxid:0x37 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-24 03:52:45.361  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting the controller scheduler
2018-09-24 03:52:45.416  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: XWP0HG87SNClCED3mmNuPQ
2018-09-24 03:52:45.426  INFO 323 --- [           main] c.s.kafka.test.KafkaTestCluster          : Found 1 brokers on-line, cluster is ready.
2018-09-24 03:52:45.440  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@1fba15d7 testClass = ApiControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest@c8dc1ef, testMethod = test_modifyTopic@ApiControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@21f4f5d4 testClass = ApiControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@45488836 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
2018-09-24 03:52:45.684  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37631]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:52:45.687  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:52:45.687  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:52:45.793  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: XWP0HG87SNClCED3mmNuPQ
2018-09-24 03:52:45.811  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094753b60000 type:setData cxid:0x3c zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/TestTopic-1537753965683 Error:KeeperErrorCode = NoNode for /config/topics/TestTopic-1537753965683
2018-09-24 03:52:45.894  INFO 323 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(TestTopic-1537753965683-0 -> ArrayBuffer(1))
2018-09-24 03:52:45.943  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(TestTopic-1537753965683)], deleted topics: [Set()], new partition replica assignment [Map(TestTopic-1537753965683-0 -> Vector(1))]
2018-09-24 03:52:45.945  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for TestTopic-1537753965683-0
2018-09-24 03:52:46.502  INFO 323 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions TestTopic-1537753965683-0
2018-09-24 03:52:46.541  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=TestTopic-1537753965683-0, dir=/tmp/1537753962399-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:52:46.549  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=TestTopic-1537753965683-0, dir=/tmp/1537753962399-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms
2018-09-24 03:52:46.551  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition TestTopic-1537753965683-0 in /tmp/1537753962399-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:52:46.552  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition TestTopic-1537753965683-0 broker=1] No checkpointed highwatermark is found for partition TestTopic-1537753965683-0
2018-09-24 03:52:46.555  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition TestTopic-1537753965683-0 with initial high watermark 0
2018-09-24 03:52:46.557  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition TestTopic-1537753965683-0 broker=1] TestTopic-1537753965683-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:52:46.572  INFO 323 --- [quest-handler-1] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:52:46.619  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37631]
	client.id = KafkaWebView-Operation-UserId82
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:52:46.621  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:52:46.622  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:52:46.726  INFO 323 --- [ration-UserId82] org.apache.kafka.clients.Metadata        : Cluster ID: XWP0HG87SNClCED3mmNuPQ
2018-09-24 03:52:46.766  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094753b60000 type:create cxid:0x48 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2018-09-24 03:52:47.123  INFO 323 --- [-process-thread] k.c.ZkNodeChangeNotificationListener     : Processing notification(s) to /config/changes
2018-09-24 03:52:47.134  INFO 323 --- [-process-thread] kafka.server.DynamicConfigManager        : Processing override for entityPath: topics/TestTopic-1537753965683 with config: Map(max.message.bytes -> 1024, flush.messages -> 0)

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/cluster/15/modify/topic
       Parameters = {_csrf=[b4e1c0e2-bf37-456d-afab-235a52ad0d31]}
          Headers = {Content-Type=[application/json;charset=UTF-8]}
             Body = { "topic": "TestTopic-1537753965683", "config": {"flush.messages": "0", "max.message.bytes": "1024"}}
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@6c7d118a: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@6c7d118a: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@1e1c1634; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.api.ApiController
           Method = public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConfigItem> org.sourcelab.kafka.webview.ui.controller.api.ApiController.modifyTopicConfig(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.ModifyTopicConfigRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Type=[application/json;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = application/json;charset=UTF-8
             Body = [{"name":"cleanup.policy","value":"delete","default":true},{"name":"compression.type","value":"producer","default":true},{"name":"delete.retention.ms","value":"86400000","default":true},{"name":"file.delete.delay.ms","value":"60000","default":true},{"name":"flush.messages","value":"0","default":false},{"name":"flush.ms","value":"9223372036854775807","default":true},{"name":"follower.replication.throttled.replicas","value":"","default":true},{"name":"index.interval.bytes","value":"4096","default":true},{"name":"leader.replication.throttled.replicas","value":"","default":true},{"name":"max.message.bytes","value":"1024","default":false},{"name":"message.format.version","value":"1.1-IV0","default":true},{"name":"message.timestamp.difference.max.ms","value":"9223372036854775807","default":true},{"name":"message.timestamp.type","value":"CreateTime","default":true},{"name":"min.cleanable.dirty.ratio","value":"0.5","default":true},{"name":"min.compaction.lag.ms","value":"0","default":true},{"name":"min.insync.replicas","value":"1","default":true},{"name":"preallocate","value":"false","default":true},{"name":"retention.bytes","value":"-1","default":true},{"name":"retention.ms","value":"604800000","default":true},{"name":"segment.bytes","value":"1073741824","default":true},{"name":"segment.index.bytes","value":"10485760","default":true},{"name":"segment.jitter.ms","value":"0","default":true},{"name":"segment.ms","value":"604800000","default":true},{"name":"unclean.leader.election.enable","value":"false","default":true}]
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:47.194  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@1fba15d7 testClass = ApiControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest@c8dc1ef, testMethod = test_modifyTopic@ApiControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@21f4f5d4 testClass = ApiControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@45488836 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:47.196  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@1fba15d7 testClass = ApiControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest@4ca3e806, testMethod = test_createTopic@ApiControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@21f4f5d4 testClass = ApiControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@45488836 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
2018-09-24 03:52:47.403  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37631]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:52:47.405  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:52:47.405  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:52:47.510  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: XWP0HG87SNClCED3mmNuPQ
2018-09-24 03:52:47.532  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37631]
	client.id = KafkaWebView-Operation-UserId84
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:52:47.534  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:52:47.534  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:52:47.638  INFO 323 --- [ration-UserId84] org.apache.kafka.clients.Metadata        : Cluster ID: XWP0HG87SNClCED3mmNuPQ
2018-09-24 03:52:47.643  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094753b60000 type:setData cxid:0x50 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/TestTopic-1537753967403 Error:KeeperErrorCode = NoNode for /config/topics/TestTopic-1537753967403
2018-09-24 03:52:47.726  INFO 323 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Topic creation Map(TestTopic-1537753967403-0 -> ArrayBuffer(1))
2018-09-24 03:52:47.770  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(TestTopic-1537753967403)], deleted topics: [Set()], new partition replica assignment [Map(TestTopic-1537753967403-0 -> Vector(1))]
2018-09-24 03:52:47.770  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for TestTopic-1537753967403-0
2018-09-24 03:52:47.887  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions TestTopic-1537753967403-0
2018-09-24 03:52:47.891  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=TestTopic-1537753967403-0, dir=/tmp/1537753962399-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:52:47.892  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=TestTopic-1537753967403-0, dir=/tmp/1537753962399-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-24 03:52:47.893  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition TestTopic-1537753967403-0 in /tmp/1537753962399-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:52:47.894  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition TestTopic-1537753967403-0 broker=1] No checkpointed highwatermark is found for partition TestTopic-1537753967403-0
2018-09-24 03:52:47.894  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition TestTopic-1537753967403-0 with initial high watermark 0
2018-09-24 03:52:47.894  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition TestTopic-1537753967403-0 broker=1] TestTopic-1537753967403-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:52:47.895  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/cluster/16/create/topic
       Parameters = {_csrf=[19ad447f-ceea-4655-ad7b-1eaa296f1a15]}
          Headers = {Content-Type=[application/json;charset=UTF-8]}
             Body = { "name": "TestTopic-1537753967403", "partitions": 1, "replicas": 1}
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@9daa9d5f: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@9daa9d5f: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@6375af2a; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.api.ApiController
           Method = public org.sourcelab.kafka.webview.ui.controller.api.responses.ResultResponse org.sourcelab.kafka.webview.ui.controller.api.ApiController.createTopic(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.CreateTopicRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Type=[application/json;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = application/json;charset=UTF-8
             Body = {"operation":"CreateTopic","result":true,"message":""}
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:47.903  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:37631]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:52:47.905  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:52:47.905  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:52:48.009  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: XWP0HG87SNClCED3mmNuPQ
2018-09-24 03:52:48.018  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@1fba15d7 testClass = ApiControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest@4ca3e806, testMethod = test_createTopic@ApiControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@21f4f5d4 testClass = ApiControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@45488836 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:48.020  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@1fba15d7 testClass = ApiControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest@4ce2f4d6, testMethod = test_withoutAdminRole@ApiControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@21f4f5d4 testClass = ApiControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@45488836 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/cluster/1/create/topic
       Parameters = {_csrf=[9b930a59-c2e6-4315-b172-42944653fe41]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@c32768c4: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@c32768c4: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@6f14ce3; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/cluster/1/modify/topic
       Parameters = {_csrf=[06391202-a296-4706-9aff-b0ddd8473baf]}
          Headers = {}
             Body = null
    Session Attrs = {SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@c32768c4: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@c32768c4: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@6f14ce3; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = null

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 403
    Error message = Forbidden
          Headers = {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = null
             Body = 
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:48.246  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@1fba15d7 testClass = ApiControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest@4ce2f4d6, testMethod = test_withoutAdminRole@ApiControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@21f4f5d4 testClass = ApiControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@45488836 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:48.247  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Shutting down kafka test server
2018-09-24 03:52:48.247  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shutting down
2018-09-24 03:52:48.248  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Starting controlled shutdown
2018-09-24 03:52:48.259  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Shutting down broker 1
2018-09-24 03:52:48.268  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Controlled shutdown succeeded
2018-09-24 03:52:48.272  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2018-09-24 03:52:48.273  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2018-09-24 03:52:48.273  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2018-09-24 03:52:48.274  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopping socket server request processors
2018-09-24 03:52:48.284  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopped socket server request processors
2018-09-24 03:52:48.285  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shutting down
2018-09-24 03:52:48.287  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shut down completely
2018-09-24 03:52:48.291  INFO 323 --- [           main] kafka.server.KafkaApis                   : [KafkaApi-1] Shutdown complete.
2018-09-24 03:52:48.292  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutting down
2018-09-24 03:52:48.357  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Stopped
2018-09-24 03:52:48.357  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutdown completed
2018-09-24 03:52:48.359  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutting down.
2018-09-24 03:52:48.360  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-24 03:52:48.361  INFO 323 --- [           main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 1]: Shutdown complete
2018-09-24 03:52:48.361  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutting down
2018-09-24 03:52:48.362  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Stopped
2018-09-24 03:52:48.362  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-24 03:52:48.363  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutdown complete.
2018-09-24 03:52:48.364  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutting down.
2018-09-24 03:52:48.364  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-24 03:52:48.557  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-24 03:52:48.557  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-24 03:52:48.557  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-24 03:52:48.757  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-24 03:52:48.757  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Stopped
2018-09-24 03:52:48.759  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutdown complete.
2018-09-24 03:52:48.760  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shutting down
2018-09-24 03:52:48.761  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2018-09-24 03:52:48.761  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2018-09-24 03:52:48.761  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2018-09-24 03:52:48.762  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutting down
2018-09-24 03:52:48.765  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-24 03:52:48.766  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutting down
2018-09-24 03:52:48.767  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2018-09-24 03:52:48.767  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutting down
2018-09-24 03:52:48.958  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Stopped
2018-09-24 03:52:48.958  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-24 03:52:48.958  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutting down
2018-09-24 03:52:49.157  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Stopped
2018-09-24 03:52:49.157  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-24 03:52:49.158  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-24 03:52:49.357  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-24 03:52:49.357  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-24 03:52:49.399  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shut down completely
2018-09-24 03:52:49.399  INFO 323 --- [           main] kafka.log.LogManager                     : Shutting down.
2018-09-24 03:52:49.401  INFO 323 --- [           main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2018-09-24 03:52:49.401  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2018-09-24 03:52:49.402  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2018-09-24 03:52:49.402  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-24 03:52:49.534  INFO 323 --- [           main] kafka.log.LogManager                     : Shutdown complete.
2018-09-24 03:52:49.535  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutting down
2018-09-24 03:52:49.535  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Stopped
2018-09-24 03:52:49.535  INFO 323 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutdown completed
2018-09-24 03:52:49.538  INFO 323 --- [           main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-24 03:52:49.539  INFO 323 --- [           main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-24 03:52:49.540  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutting down
2018-09-24 03:52:49.540  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Stopped
2018-09-24 03:52:49.540  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutdown completed
2018-09-24 03:52:49.543  INFO 323 --- [           main] kafka.controller.KafkaController         : [Controller id=1] Resigned
2018-09-24 03:52:49.544  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2018-09-24 03:52:49.545  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x166094753b60000
2018-09-24 03:52:49.584  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x166094753b60000 closed
2018-09-24 03:52:49.584  INFO 323 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x166094753b60000
2018-09-24 03:52:49.585  INFO 323 --- [0/0.0.0.0:44240] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:56904 which had sessionid 0x166094753b60000
2018-09-24 03:52:49.586  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2018-09-24 03:52:49.586  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-24 03:52:50.355  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-24 03:52:50.355  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutting down
2018-09-24 03:52:50.355  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Stopped
2018-09-24 03:52:51.355  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-24 03:52:51.355  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Stopped
2018-09-24 03:52:51.355  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutting down
2018-09-24 03:52:52.355  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Stopped
2018-09-24 03:52:52.355  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-24 03:52:52.356  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutting down socket server
2018-09-24 03:52:52.406  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutdown completed
2018-09-24 03:52:52.409  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shut down completed
2018-09-24 03:52:52.409  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Shutting down zookeeper test server
2018-09-24 03:52:52.410  INFO 323 --- [0/0.0.0.0:44240] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:52:52.410  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:52:52.410  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:52:52.410  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:52:52.410  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:52:52.410  INFO 323 --- [0 cport:44240):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:52:52.410  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:52:52.411  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.215 s - in org.sourcelab.kafka.webview.ui.controller.api.ApiControllerTest
[INFO] Running org.sourcelab.kafka.webview.ui.controller.cluster.ClusterControllerTest
2018-09-24 03:52:52.413  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Neither @ContextConfiguration nor @ContextHierarchy found for test class [org.sourcelab.kafka.webview.ui.controller.cluster.ClusterControllerTest], using SpringBootContextLoader
2018-09-24 03:52:52.414  INFO 323 --- [           main] o.s.t.c.support.AbstractContextLoader    : Could not detect default resource locations for test class [org.sourcelab.kafka.webview.ui.controller.cluster.ClusterControllerTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-09-24 03:52:52.414  INFO 323 --- [           main] t.c.s.AnnotationConfigContextLoaderUtils : Could not detect default configuration classes for test class [org.sourcelab.kafka.webview.ui.controller.cluster.ClusterControllerTest]: ClusterControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2018-09-24 03:52:52.424  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Found @SpringBootConfiguration org.sourcelab.kafka.webview.ui.Application for test class org.sourcelab.kafka.webview.ui.controller.cluster.ClusterControllerTest
2018-09-24 03:52:52.425  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener]
2018-09-24 03:52:52.426  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@264e0b8e, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@294c1b45, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@53ed0519, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@45070db0, org.springframework.test.context.support.DirtiesContextTestExecutionListener@13437ce5, org.springframework.test.context.transaction.TransactionalTestExecutionListener@5a9ccbfb, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@6162d87c, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@1cf5236d, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@14d9d042, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@28261231, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@5f709e71, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@6a2b30b9, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@302ab67e, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@28058dd0]
2018-09-24 03:52:52.439  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@7d5e165 testClass = ClusterControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.cluster.ClusterControllerTest@7adf0ff9, testMethod = test_readIndexShowsCreateTopicLink_withAdminRole@ClusterControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@3778cd05 testClass = ClusterControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7d5238b4 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /cluster/17
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@432e61f1, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@1028a9bf: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@1028a9bf: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@4a3b0387; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER, ROLE_ADMIN}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readCluster(java.lang.Long,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = cluster/read
             View = null
        Attribute = MenuClusters
            value = [Cluster{+ id=17, + name='Test Cluster', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}]
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 88
        Attribute = cluster
            value = Cluster{+ id=17, + name='Test Cluster', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}
           errors = []
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@6967cdee
           errors = []

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Cluster Explorer</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="9c6e3f00-1255-492a-b1e7-b0d734d6a54a"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753972441@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/88">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item" title="Test Cluster">
                            <a class="nav-link" href="/cluster/17">
                                <i class="icon-layers"></i>
                                Test Cluster
                            </a>
                        </li>
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/configuration">
                        <i class="icon-settings"></i>
                        Configuration
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/user" target="_top">
                                <i class="icon-people"></i>
                                Users
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/cluster" target="_top">
                                <i class="icon-layers"></i>
                                Clusters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/messageFormat" target="_top">
                                <i class="icon-envelope-letter"></i>
                                Message Formats
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/filter" target="_top">
                                <i class="icon-magnifier"></i>
                                Filters
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/view" target="_top">
                                <i class="icon-eye"></i>
                                Views
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="/configuration/stream" target="_top">
                                <i class="icon-eye"></i>
                                Streams
                            </a>
                        </li>
                    </ul>
                </li>
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/cluster">Cluster Explorer</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Test Cluster</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <script type="application/javascript">
            // Maintains state of our consumer
            var ClusterInfo = {
                clusterId: '17',

                // Handle cluster node results ajax result
                handleClusterNodeResults: function(results) {
                    // Clear nodes table
                    var table = jQuery('#nodes-tbody');
                    jQuery(table).empty();

                    // Get and compile template
                    var source   = jQuery('#nodes-template').html();
                    var template = Handlebars.compile(source);

                    jQuery.each(results, function(index, result) {
                        // Generate html from template
                        var properties = {
                            clusterId: ClusterInfo.clusterId,
                            id: result.id,
                            host: result.host,
                            port: result.port,
                            rack: result.rack
                        };
                        var resultHtml = template(properties);

                        // Append it to our table
                        jQuery(table).append(resultHtml);
                    });

                    // Hide loader
                    jQuery('#nodes-loader').toggle(false);

                    if (results.length == 0) {
                        jQuery('#nodes-no-results').toggle(true);
                    } else {
                        jQuery('#nodes-no-results').toggle(false);
                        jQuery('#nodes-table').toggle(true);
                    }
                },

                // Handle all topics details results ajax result
                handleAllTopicsDetails: function(results) {
                    // Clear topics table
                    var table = jQuery('#topics-tbody');
                    jQuery(table).empty();

                    // Get and compile template
                    var source   = jQuery('#topics-template').html();
                    var template = Handlebars.compile(source);

                    jQuery.each(results, function(index, result) {
                        // Generate html from template
                        var properties = {
                            topic: result.name,
                            encodedTopic: encodeURIComponent(result.name),
                            clusterId: ClusterInfo.clusterId,
                            internal: result.internal,
                            partitions_count: result.partitions.length,
                            isUnderReplicated: result.underReplicated
                        };
                        var resultHtml = template(properties);

                        // Append it to our table
                        jQuery(table).append(resultHtml);
                    });

                    // Hide loader
                    jQuery('#topics-loader').toggle(false);

                    if (results.length == 0) {
                        jQuery('#topics-no-results').toggle(true);
                    } else {
                        jQuery('#topics-no-results').toggle(false);
                        jQuery('#topics-table').toggle(true);
                    }
                },
                loadTopics: function() {
                    // Fire off request to get topic details
                    ApiClient.getAllTopicsDetails(ClusterInfo.clusterId, function(results) {
                        // Handle results
                        ClusterInfo.handleAllTopicsDetails(results);
                    });
                },
                // Handle submitting new topic form.
                createNewTopic: function() {
                    ApiClient.createTopic(
                        ClusterInfo.clusterId,
                        jQuery('#topicName').val(),
                        jQuery('#topicPartitions').val(),
                        jQuery('#topicReplicas').val(),

                        // Handle results
                        function(results) {
                            // Hide modal
                            jQuery('#createTopicModal').modal('hide');

                            // Reset form
                            jQuery('#topicName').val("");
                            jQuery('#topicPartitions').val(1);
                            jQuery('#topicReplicas').val(1);

                            // Reload topic listing
                            UITools.showSuccess("Created topic successfully.");

                            // show notification
                            ClusterInfo.loadTopics();
                        }
                    )
                }
            };

            // On load, fire off ajax request to load results.
            jQuery(document).ready(function() {
                // Chain initial ajax requests.
                // Request Cluster Information
                ApiClient.getClusterNodes(ClusterInfo.clusterId, function(results) {
                    // Handle results
                    ClusterInfo.handleClusterNodeResults(results);

                    // Fire off request to get topic details
                    ClusterInfo.loadTopics();
                });
            });
        </script>

        <!-- Brokers -->
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Cluster <strong>Test Cluster</strong> Brokers
                    </div>
                    <div class="card-body">
                        <!-- Display Loader First -->
                        <div class="alert alert-light" role="alert" id="nodes-loader" style="display: block;">
                            <div class="progress">
                                <div
                                    class="progress-bar progress-bar-striped progress-bar-animated"
                                    role="progressbar" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"
                                    style="width: 100%">
                                </div>
                            </div>
                        </div>

                        <!-- No Results Found -->
                        <div class="alert alert-light" role="alert" id="nodes-no-results" style="display: none;">
                            <h4 class="alert-heading">No Brokers Found</h4>
                            <p>Looks like we couldn't find any brokers!</p>
                        </div>

                        <!-- Hide Results Table -->
                        <table class="table table-bordered table-striped table-sm" id="nodes-table" style="display: none;">
                            <thead>
                            <tr>
                                <th>Broker Id</th>
                                <th>Hostname</th>
                                <th>Rack</th>
                            </tr>
                            </thead>
                            <tbody id="nodes-tbody">
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>

        <!-- Topics -->
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Cluster <strong>Test Cluster</strong> Topics

                        <div class="btn-group float-right" role="group" aria-label="Button group">
                            <a class="btn" href="#" style="padding-bottom: 0;" data-toggle="modal" data-target="#createTopicModal">
                                <i class="icon-settings"></i>
                                &nbsp;Create new
                            </a>
                        </div>
                    </div>
                    <div class="card-body">
                        <!-- Display Loader First -->
                        <div class="alert alert-light" role="alert" id="topics-loader" style="display: block;">
                            <div class="progress">
                                <div
                                    class="progress-bar progress-bar-striped progress-bar-animated"
                                    role="progressbar" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"
                                    style="width: 100%">
                                </div>
                            </div>
                        </div>

                        <!-- No Results Found -->
                        <div class="alert alert-light" role="alert" id="topics-no-results" style="display: none;">
                            <h4 class="alert-heading">No Topics Found</h4>
                            <p>Looks like we couldn't find any topics!</p>
                        </div>

                        <!-- Hide Results Table -->
                        <table class="table table-bordered table-striped table-sm" id="topics-table" style="display: none;">
                            <thead>
                            <tr>
                                <th>Topic</th>
                                <th>Partitions</th>
                                <th>Status</th>
                            </tr>
                            </thead>
                            <tbody id="topics-tbody">
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>

        <!-- Nodes Template -->
        <script id="nodes-template" type="text/x-handlebars-template">
            <tr>
                <td>
                    <a href="/cluster/{{clusterId}}/broker/{{id}}">{{id}}</a>
                </td>
                <td>{{host}}:{{port}}</td>
                <td>
                    {{#if rack}}
                        {{rack}}
                    {{else}}
                        <i>none</i>
                    {{/if}}
                </td>
            </tr>
        </script>

        <!-- Topics Details Template -->
        <script id="topics-template" type="text/x-handlebars-template">
            <tr>
                <td>
                    <a href="/cluster/{{clusterId}}/topic/{{encodedTopic}}">
                        {{topic}}
                    </a>
                </td>
                <td>{{partitions_count}}</td>
                <td>
                    {{#if isUnderReplicated}}
                        <span class="badge badge-warning">Under Replicated</span>
                    {{else}}
                        <span class="badge badge-success">Fully Replicated</span>
                    {{/if}}
                    {{#if internal}}
                        <span class="badge badge-info">Internal topic</span>
                    {{/if}}
                </td>
            </tr>
        </script>

        <!-- Create topic modal -->
        <div class="modal fade show" id="createTopicModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" style="display: none;">
            <div class="modal-dialog" role="document">
                <div class="modal-content">
                    <div class="modal-header">
                        <h4 class="modal-title">Create new topic on Test Cluster</h4>
                        <button class="close" type="button" data-dismiss="modal" aria-label="Close">
                            <span aria-hidden="true">×</span>
                        </button>
                    </div>
                    <div class="modal-body">
                        <form method="post" class="form-horizontal">

                            <!-- Name -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="topicName">
                                    Topic Name
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="topicName" name="name" class="form-control" type="text"
                                        placeholder="A unique name to identify this topic">
                                    <div class="invalid-feedback"></div>
                                </div>
                            </div>

                            <!-- Partition Count -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="topicPartitions">
                                    Partitions
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="topicPartitions" name="partitions" class="form-control" type="text"
                                        placeholder="How many partitions on this topic"
                                        value="1">
                                    <div class="invalid-feedback"></div>
                                </div>
                            </div>

                            <!-- Partition Count -->
                            <div class="form-group row">
                                <label class="col-md-3 form-control-label" for="topicReplicas">
                                    Replication factor
                                </label>
                                <div class="col-md-9">
                                    <input
                                        id="topicReplicas" name="resultsPerPartition" class="form-control" type="text"
                                        placeholder="Number of replicas"
                                        value="1">
                                    <div class="invalid-feedback"></div>
                                </div>
                            </div>
                        </form>
                    </div>
                    <div class="modal-footer">
                        <button class="btn btn-secondary" type="button" data-dismiss="modal">Close</button>
                        <button class="btn btn-primary" type="button" onclick="ClusterInfo.createNewTopic();">Create topic</button>
                    </div>
                </div>
            </div>
        </div>

    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:52.682  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@7d5e165 testClass = ClusterControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.cluster.ClusterControllerTest@7adf0ff9, testMethod = test_readIndexShowsCreateTopicLink_withAdminRole@ClusterControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@3778cd05 testClass = ClusterControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7d5238b4 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
2018-09-24 03:52:52.684  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@7d5e165 testClass = ClusterControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.cluster.ClusterControllerTest@4c33450c, testMethod = test_readIndexShowsCreateTopicLink_withoutAdminRole@ClusterControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@3778cd05 testClass = ClusterControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7d5238b4 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@55a055cc]; rollback [true]
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into user (id, display_name, email, has_password, is_active, password, reset_password_hash, role) values (null, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select user0_.id as id1_3_, user0_.display_name as display_2_3_, user0_.email as email3_3_, user0_.has_password as has_pass4_3_, user0_.is_active as is_activ5_3_, user0_.password as password6_3_, user0_.reset_password_hash as reset_pa7_3_, user0_.role as role8_3_ from user user0_ where user0_.email=?
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: select cluster0_.id as id1_0_, cluster0_.broker_hosts as broker_h2_0_, cluster0_.is_ssl_enabled as is_ssl_e3_0_, cluster0_.is_valid as is_valid4_0_, cluster0_.key_store_file as key_stor5_0_, cluster0_.key_store_password as key_stor6_0_, cluster0_.name as name7_0_, cluster0_.trust_store_file as trust_st8_0_, cluster0_.trust_store_password as trust_st9_0_ from cluster cluster0_ order by cluster0_.name asc
Hibernate: select view0_.id as id1_4_, view0_.cluster_id as cluster_8_4_, view0_.created_at as created_2_4_, view0_.key_message_format_id as key_mess9_4_, view0_.name as name3_4_, view0_.partitions as partitio4_4_, view0_.results_per_partition as results_5_4_, view0_.topic as topic6_4_, view0_.updated_at as updated_7_4_, view0_.value_message_format_id as value_m10_4_ from view view0_ order by view0_.name asc

MockHttpServletRequest:
      HTTP Method = GET
      Request URI = /cluster/18
       Parameters = {}
          Headers = {}
             Body = null
    Session Attrs = {org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.CSRF_TOKEN=org.springframework.security.web.csrf.DefaultCsrfToken@4e2bed0f, SPRING_SECURITY_CONTEXT=org.springframework.security.core.context.SecurityContextImpl@3c83b86f: Authentication: org.springframework.security.authentication.UsernamePasswordAuthenticationToken@3c83b86f: Principal: org.sourcelab.kafka.webview.ui.manager.user.CustomUserDetails@507c33cc; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_USER}

Handler:
             Type = org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController
           Method = public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readCluster(java.lang.Long,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = cluster/read
             View = null
        Attribute = MenuClusters
            value = [Cluster{+ id=18, + name='Test Cluster', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}]
        Attribute = MenuViews
            value = []
        Attribute = UserId
            value = 91
        Attribute = cluster
            value = Cluster{+ id=18, + name='Test Cluster', + brokerHosts='localhost:9092', + isSslEnabled=false, + trustStoreFile='null', + keyStoreFile='null', + isValid=true}
           errors = []
        Attribute = BreadCrumbs
            value = org.sourcelab.kafka.webview.ui.manager.ui.BreadCrumbManager@48d68740
           errors = []

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 200
    Error message = null
          Headers = {Content-Language=[en], Content-Type=[text/html;charset=UTF-8], X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY]}
     Content type = text/html;charset=UTF-8
             Body = <!DOCTYPE html>
<!--
 * CoreUI - Open Source Bootstrap Admin Template
 * @version v1.0.0
 * @link http://coreui.io
 * Copyright (c) 2017 creativeLabs Łukasz Holeczek
 * @license MIT
 -->
<html
    lang="en">

<head>
    <title>Cluster Explorer</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Kafka Webview">
    <meta name="keyword" content="Kafka WebView">
    <meta name="_csrf" content="fdc5c8e8-eefd-43a8-8987-b1c18a721daf"/>
    <meta name="_csrf_header" content="X-CSRF-TOKEN"/>
    <link rel="shortcut icon" href="/img/favicon.png">

    <!-- Icons -->
    <link href="/vendors/css/font-awesome.min.css" rel="stylesheet">
    <link href="/vendors/css/simple-line-icons.min.css" rel="stylesheet">

    <!-- Main styles for this application -->
    <link href="/css/style.css" rel="stylesheet">
    <link href="/css/app.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui.min.css" rel="stylesheet">
    <link href="/vendors/css/jquery-ui-timepicker-addon.min.css" rel="stylesheet">

    <!-- Bootstrap and necessary plugins -->
    <script src="/vendors/js/jquery.min.js"></script>
    <script src="/vendors/js/popper.min.js"></script>
    <script src="/vendors/js/bootstrap.min.js"></script>
    <script src="/vendors/js/pace.min.js"></script>

    <!-- Plugins and scripts required by all views -->
    <script src="/vendors/js/Chart.min.js"></script>

    <!-- Handlebars -->
    <script src="/vendors/js/handlebars.min.js"></script>

    <!-- Fancy Multi-select -->
    <script src="/vendors/js/multiselect.min.js"></script>

    <!-- Fancy DateTime -->
    <script src="/vendors/js/jquery-ui.min.js"></script>
    <script src="/vendors/js/jquery-ui-timepicker-addon.min.js"></script>

    <!-- Websocket -->
    <script src="/vendors/js/sockjs.min.js"></script>
    <script src="/vendors/js/stomp.min.js"></script>

    <!-- moment / time -->
    <script src="/vendors/js/moment.min.js"></script>

    <!-- main scripts -->
    <script src="/js/app.js"></script>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
</head>

<body class="app header-fixed breadcrumb-fixed sidebar-minimized aside-menu-fixed aside-menu-hidden">
<header class="app-header navbar">
    <a class="navbar-brand" href="/"></a>

    <!-- User Settings Nav -->
    <ul class="nav navbar-nav ml-auto">
        <li class="nav-item dropdown" style="padding-right: 50px;">
            <a class="nav-link dropdown-toggle nav-link" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">
                <i class="icon-user"></i>
                <span class="d-md-down-none">test1537753972788@example.com</span>
            </a>
            <div class="dropdown-menu dropdown-menu-right">
                <div class="dropdown-header text-center">
                    <strong>Settings</strong>
                </div>
                <a class="dropdown-item" href="/configuration/user/edit/91">
                    <i class="fa fa-user"></i> Profile
                </a>
                <div class="divider"></div>
                <a class="dropdown-item" href="/logout">
                    <i class="fa fa-lock"></i> Logout
                </a>
            </div>
        </li>
    </ul>
</header>

<div class="app-body">
    <!-- Left Sidebar -->
    <div class="sidebar">
        <nav class="sidebar-nav">
            <ul class="nav">
                <!-- Home? -->
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="icon-speedometer"></i>
                        Home
                    </a>
                </li>
                <li class="divider"></li>

                <!-- Clusters -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/cluster">
                        <i class="icon-layers"></i> Clusters
                    </a>
                    <ul class="nav-dropdown-items">
                        <li class="nav-item" title="Test Cluster">
                            <a class="nav-link" href="/cluster/18">
                                <i class="icon-layers"></i>
                                Test Cluster
                            </a>
                        </li>
                    </ul>
                </li>

                <!-- Views -->
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/view">
                        <i class="icon-eye"></i> Views
                    </a>
                    <ul class="nav-dropdown-items">
                        
                    </ul>
                </li>

                <!-- Setup -->
                <li class="divider"></li>
                
                <!-- Help -->
                <li class="divider"></li>
                <li class="nav-item nav-dropdown">
                    <a class="nav-link nav-dropdown-toggle" href="/help">
                        <i class="icon-support"></i>
                        Help
                    </a>
                </li>
            </ul>
        </nav>
        <button class="sidebar-minimizer brand-minimizer" type="button"></button>
    </div>

    <!-- Main content -->
    <main class="main">

        <!-- Breadcrumb -->
        <!-- Handles showing breadcrumbs -->
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/">Home</a>
                
            </li>
            <li class="breadcrumb-item">
                <a href="/cluster">Cluster Explorer</a>
                
            </li>
            <li class="breadcrumb-item active">
                
                <span>Test Cluster</span>
            </li>

            <!-- Breadcrumb Menu-->
            <section>
                <!-- empty by default -->
            </section>

        </ol>

        <div class="container-fluid">
            <div class="animated fadeIn">
                <!-- Include Flash Attribute Messages -->
                

                <!-- Container for Dynamic Alerts -->
                <div id="AlertContainer"></div>

                <!-- Start main content -->
                <section>
    <div class="container">
        <script type="application/javascript">
            // Maintains state of our consumer
            var ClusterInfo = {
                clusterId: '18',

                // Handle cluster node results ajax result
                handleClusterNodeResults: function(results) {
                    // Clear nodes table
                    var table = jQuery('#nodes-tbody');
                    jQuery(table).empty();

                    // Get and compile template
                    var source   = jQuery('#nodes-template').html();
                    var template = Handlebars.compile(source);

                    jQuery.each(results, function(index, result) {
                        // Generate html from template
                        var properties = {
                            clusterId: ClusterInfo.clusterId,
                            id: result.id,
                            host: result.host,
                            port: result.port,
                            rack: result.rack
                        };
                        var resultHtml = template(properties);

                        // Append it to our table
                        jQuery(table).append(resultHtml);
                    });

                    // Hide loader
                    jQuery('#nodes-loader').toggle(false);

                    if (results.length == 0) {
                        jQuery('#nodes-no-results').toggle(true);
                    } else {
                        jQuery('#nodes-no-results').toggle(false);
                        jQuery('#nodes-table').toggle(true);
                    }
                },

                // Handle all topics details results ajax result
                handleAllTopicsDetails: function(results) {
                    // Clear topics table
                    var table = jQuery('#topics-tbody');
                    jQuery(table).empty();

                    // Get and compile template
                    var source   = jQuery('#topics-template').html();
                    var template = Handlebars.compile(source);

                    jQuery.each(results, function(index, result) {
                        // Generate html from template
                        var properties = {
                            topic: result.name,
                            encodedTopic: encodeURIComponent(result.name),
                            clusterId: ClusterInfo.clusterId,
                            internal: result.internal,
                            partitions_count: result.partitions.length,
                            isUnderReplicated: result.underReplicated
                        };
                        var resultHtml = template(properties);

                        // Append it to our table
                        jQuery(table).append(resultHtml);
                    });

                    // Hide loader
                    jQuery('#topics-loader').toggle(false);

                    if (results.length == 0) {
                        jQuery('#topics-no-results').toggle(true);
                    } else {
                        jQuery('#topics-no-results').toggle(false);
                        jQuery('#topics-table').toggle(true);
                    }
                },
                loadTopics: function() {
                    // Fire off request to get topic details
                    ApiClient.getAllTopicsDetails(ClusterInfo.clusterId, function(results) {
                        // Handle results
                        ClusterInfo.handleAllTopicsDetails(results);
                    });
                },
                // Handle submitting new topic form.
                createNewTopic: function() {
                    ApiClient.createTopic(
                        ClusterInfo.clusterId,
                        jQuery('#topicName').val(),
                        jQuery('#topicPartitions').val(),
                        jQuery('#topicReplicas').val(),

                        // Handle results
                        function(results) {
                            // Hide modal
                            jQuery('#createTopicModal').modal('hide');

                            // Reset form
                            jQuery('#topicName').val("");
                            jQuery('#topicPartitions').val(1);
                            jQuery('#topicReplicas').val(1);

                            // Reload topic listing
                            UITools.showSuccess("Created topic successfully.");

                            // show notification
                            ClusterInfo.loadTopics();
                        }
                    )
                }
            };

            // On load, fire off ajax request to load results.
            jQuery(document).ready(function() {
                // Chain initial ajax requests.
                // Request Cluster Information
                ApiClient.getClusterNodes(ClusterInfo.clusterId, function(results) {
                    // Handle results
                    ClusterInfo.handleClusterNodeResults(results);

                    // Fire off request to get topic details
                    ClusterInfo.loadTopics();
                });
            });
        </script>

        <!-- Brokers -->
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Cluster <strong>Test Cluster</strong> Brokers
                    </div>
                    <div class="card-body">
                        <!-- Display Loader First -->
                        <div class="alert alert-light" role="alert" id="nodes-loader" style="display: block;">
                            <div class="progress">
                                <div
                                    class="progress-bar progress-bar-striped progress-bar-animated"
                                    role="progressbar" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"
                                    style="width: 100%">
                                </div>
                            </div>
                        </div>

                        <!-- No Results Found -->
                        <div class="alert alert-light" role="alert" id="nodes-no-results" style="display: none;">
                            <h4 class="alert-heading">No Brokers Found</h4>
                            <p>Looks like we couldn't find any brokers!</p>
                        </div>

                        <!-- Hide Results Table -->
                        <table class="table table-bordered table-striped table-sm" id="nodes-table" style="display: none;">
                            <thead>
                            <tr>
                                <th>Broker Id</th>
                                <th>Hostname</th>
                                <th>Rack</th>
                            </tr>
                            </thead>
                            <tbody id="nodes-tbody">
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>

        <!-- Topics -->
        <div class="row">
            <div class="col-lg-12">
                <div class="card">
                    <div class="card-header">
                        <i class="fa fa-align-justify"></i>
                        Cluster <strong>Test Cluster</strong> Topics

                        
                    </div>
                    <div class="card-body">
                        <!-- Display Loader First -->
                        <div class="alert alert-light" role="alert" id="topics-loader" style="display: block;">
                            <div class="progress">
                                <div
                                    class="progress-bar progress-bar-striped progress-bar-animated"
                                    role="progressbar" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"
                                    style="width: 100%">
                                </div>
                            </div>
                        </div>

                        <!-- No Results Found -->
                        <div class="alert alert-light" role="alert" id="topics-no-results" style="display: none;">
                            <h4 class="alert-heading">No Topics Found</h4>
                            <p>Looks like we couldn't find any topics!</p>
                        </div>

                        <!-- Hide Results Table -->
                        <table class="table table-bordered table-striped table-sm" id="topics-table" style="display: none;">
                            <thead>
                            <tr>
                                <th>Topic</th>
                                <th>Partitions</th>
                                <th>Status</th>
                            </tr>
                            </thead>
                            <tbody id="topics-tbody">
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>

        <!-- Nodes Template -->
        <script id="nodes-template" type="text/x-handlebars-template">
            <tr>
                <td>
                    <a href="/cluster/{{clusterId}}/broker/{{id}}">{{id}}</a>
                </td>
                <td>{{host}}:{{port}}</td>
                <td>
                    {{#if rack}}
                        {{rack}}
                    {{else}}
                        <i>none</i>
                    {{/if}}
                </td>
            </tr>
        </script>

        <!-- Topics Details Template -->
        <script id="topics-template" type="text/x-handlebars-template">
            <tr>
                <td>
                    <a href="/cluster/{{clusterId}}/topic/{{encodedTopic}}">
                        {{topic}}
                    </a>
                </td>
                <td>{{partitions_count}}</td>
                <td>
                    {{#if isUnderReplicated}}
                        <span class="badge badge-warning">Under Replicated</span>
                    {{else}}
                        <span class="badge badge-success">Fully Replicated</span>
                    {{/if}}
                    {{#if internal}}
                        <span class="badge badge-info">Internal topic</span>
                    {{/if}}
                </td>
            </tr>
        </script>

        <!-- Create topic modal -->
        

    </div>
</section>
            </div>

        </div>
        <!-- /.container-fluid -->
    </main>

    <!-- Right Side Menu -->
    <aside class="aside-menu">
    </aside>


</div>

<!-- Start footer -->
<footer class="app-footer">
    <a href="https://www.github.com/sourcelaborg/kafka-webview">Kafka WebView</a>
    <span class="float-right">
        UI by <a href="http://coreui.io">CoreUI</a>
    </span>
</footer>

</body>
</html>
    Forwarded URL = null
   Redirected URL = null
          Cookies = []
2018-09-24 03:52:52.921  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@7d5e165 testClass = ClusterControllerTest, testInstance = org.sourcelab.kafka.webview.ui.controller.cluster.ClusterControllerTest@4c33450c, testMethod = test_readIndexShowsCreateTopicLink_withoutAdminRole@ClusterControllerTest, testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@3778cd05 testClass = ClusterControllerTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@7d5238b4 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@6ee12bac, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@e7e8512, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.populatedRequestContextHolder' -> true, 'org.springframework.test.context.web.ServletTestExecutionListener.resetRequestContextHolder' -> true]]
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.506 s - in org.sourcelab.kafka.webview.ui.controller.cluster.ClusterControllerTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.kafka.filter.RecordFilterInterceptorTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.063 s - in org.sourcelab.kafka.webview.ui.manager.kafka.filter.RecordFilterInterceptorTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.kafka.ViewCustomizerTest
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.022 s - in org.sourcelab.kafka.webview.ui.manager.kafka.ViewCustomizerTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicListTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 s - in org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicListTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.kafka.dto.KafkaResultTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.013 s - in org.sourcelab.kafka.webview.ui.manager.kafka.dto.KafkaResultTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.kafka.KafkaOperationsFactoryTest
2018-09-24 03:52:53.042  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Starting kafka test server
2018-09-24 03:52:53.042  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:52:53.043  INFO 323 --- [      Thread-16] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:52:53.043  INFO 323 --- [      Thread-16] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:52:53.044  INFO 323 --- [      Thread-16] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:52:53.044  INFO 323 --- [      Thread-16] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:52:53.044  INFO 323 --- [      Thread-16] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:37142
2018-09-24 03:52:54.000  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:52:54.052  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:52:54.053  INFO 323 --- [0/0.0.0.0:37142] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:52:54.053  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:52:54.053  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:52:54.054  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:52:54.054  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:52:54.054  INFO 323 --- [0 cport:37142):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:52:54.055  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:52:54.055  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2018-09-24 03:52:54.056  INFO 323 --- [      Thread-17] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:52:54.056  INFO 323 --- [      Thread-17] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:52:54.056  INFO 323 --- [      Thread-17] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:52:54.056  INFO 323 --- [      Thread-17] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:52:54.056  INFO 323 --- [      Thread-17] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:37142
2018-09-24 03:52:55.060  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:42438
	advertised.port = 42438
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:42438
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753975059-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 42438
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:37142
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:52:55.062  INFO 323 --- [           main] kafka.server.KafkaServer                 : starting
2018-09-24 03:52:55.063  INFO 323 --- [           main] kafka.server.KafkaServer                 : Connecting to zookeeper on 127.0.0.1:37142
2018-09-24 03:52:55.063  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Initializing a new session to 127.0.0.1:37142.
2018-09-24 03:52:55.063  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Initiating client connection, connectString=127.0.0.1:37142 sessionTimeout=30000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2eaaef66
2018-09-24 03:52:55.064  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Waiting until connected.
2018-09-24 03:52:55.064  INFO 323 --- [27.0.0.1:37142)] org.apache.zookeeper.ClientCnxn          : Opening socket connection to server 127.0.0.1/127.0.0.1:37142. Will not attempt to authenticate using SASL (unknown error)
2018-09-24 03:52:55.065  INFO 323 --- [0/0.0.0.0:37142] o.a.z.server.NIOServerCnxnFactory        : Accepted socket connection from /127.0.0.1:58326
2018-09-24 03:52:55.065  INFO 323 --- [27.0.0.1:37142)] org.apache.zookeeper.ClientCnxn          : Socket connection established to 127.0.0.1/127.0.0.1:37142, initiating session
2018-09-24 03:52:55.065  INFO 323 --- [0/0.0.0.0:37142] o.a.zookeeper.server.ZooKeeperServer     : Client attempting to establish new session at /127.0.0.1:58326
2018-09-24 03:52:55.066  INFO 323 --- [   SyncThread:0] o.a.z.server.persistence.FileTxnLog      : Creating new log file: log.1
2018-09-24 03:52:55.117  INFO 323 --- [   SyncThread:0] o.a.zookeeper.server.ZooKeeperServer     : Established session 0x166094785290000 with negotiated timeout 30000 for client /127.0.0.1:58326
2018-09-24 03:52:55.117  INFO 323 --- [27.0.0.1:37142)] org.apache.zookeeper.ClientCnxn          : Session establishment complete on server 127.0.0.1/127.0.0.1:37142, sessionid = 0x166094785290000, negotiated timeout = 30000
2018-09-24 03:52:55.118  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Connected.
2018-09-24 03:52:55.151  INFO 323 --- [0 cport:37142):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094785290000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-24 03:52:55.307  INFO 323 --- [0 cport:37142):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094785290000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-24 03:52:55.435  INFO 323 --- [0 cport:37142):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094785290000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-24 03:52:55.891  INFO 323 --- [0 cport:37142):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094785290000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-24 03:52:56.009  INFO 323 --- [           main] kafka.server.KafkaServer                 : Cluster ID = BV_ZQTMpQCaCRjtE40J4XQ
2018-09-24 03:52:56.010  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537753975059-0/meta.properties
2018-09-24 03:52:56.015  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:42438
	advertised.port = 42438
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:42438
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753975059-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 42438
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:37142
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:52:56.047  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:42438
	advertised.port = 42438
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:42438
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753975059-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 42438
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:37142
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:52:56.068  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Starting
2018-09-24 03:52:56.070  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Starting
2018-09-24 03:52:56.071  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Starting
2018-09-24 03:52:56.073  INFO 323 --- [           main] kafka.log.LogManager                     : Loading logs.
2018-09-24 03:52:56.074  INFO 323 --- [           main] kafka.log.LogManager                     : Logs loading complete in 1 ms.
2018-09-24 03:52:56.075  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log cleanup with a period of 300000 ms.
2018-09-24 03:52:56.076  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-24 03:52:56.089  INFO 323 --- [           main] kafka.log.LogCleaner                     : Starting the log cleaner
2018-09-24 03:52:56.137  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Starting
2018-09-24 03:52:56.237  INFO 323 --- [           main] kafka.network.Acceptor                   : Awaiting socket connections on 127.0.0.1:42438.
2018-09-24 03:52:56.257  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-24 03:52:56.305  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Starting
2018-09-24 03:52:56.312  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Starting
2018-09-24 03:52:56.312  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-24 03:52:56.314  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Creating /brokers/ids/1 (is it secure? false)
2018-09-24 03:52:56.315  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Starting
2018-09-24 03:52:56.365  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Result of znode creation at /brokers/ids/1 is: OK
2018-09-24 03:52:56.365  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(127.0.0.1,42438,ListenerName(PLAINTEXT),PLAINTEXT))
2018-09-24 03:52:56.365  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537753975059-0/meta.properties
2018-09-24 03:52:56.853  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Starting
2018-09-24 03:52:56.855  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Starting
2018-09-24 03:52:56.860  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Starting
2018-09-24 03:52:56.869  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Starting
2018-09-24 03:52:56.870  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Creating /controller (is it secure? false)
2018-09-24 03:52:56.870  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Starting up.
2018-09-24 03:52:56.870  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Startup complete.
2018-09-24 03:52:56.870  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-24 03:52:56.909  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Result of znode creation at /controller is: OK
2018-09-24 03:52:56.909  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] 1 successfully elected as the controller
2018-09-24 03:52:56.909  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Reading controller epoch from ZooKeeper
2018-09-24 03:52:56.910  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Incrementing controller epoch in ZooKeeper
2018-09-24 03:52:56.911  INFO 323 --- [0 cport:37142):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094785290000 type:setData cxid:0x23 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-24 03:52:56.948  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-24 03:52:56.986  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Starting up.
2018-09-24 03:52:56.998  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Startup complete.
2018-09-24 03:52:56.999  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Starting
2018-09-24 03:52:57.016  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Starting
2018-09-24 03:52:57.000  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:52:57.017  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Epoch incremented to 1
2018-09-24 03:52:57.017  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Registering handlers
2018-09-24 03:52:57.029  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting log dir event notifications
2018-09-24 03:52:57.036  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting isr change notifications
2018-09-24 03:52:57.044  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing controller context
2018-09-24 03:52:57.050  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-24 03:52:57.050  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:52:57.050  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:52:57.050  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] started
2018-09-24 03:52:57.051  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:42438]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:52:57.052  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:52:57.052  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:52:57.085  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Starting
2018-09-24 03:52:57.090  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions being reassigned: Map()
2018-09-24 03:52:57.090  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-24 03:52:57.090  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-24 03:52:57.090  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Current list of topics in the cluster: Set()
2018-09-24 03:52:57.090  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Fetching topic deletions in progress
2018-09-24 03:52:57.093  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics to be deleted: 
2018-09-24 03:52:57.094  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics ineligible for deletion: 
2018-09-24 03:52:57.094  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing topic deletion manager
2018-09-24 03:52:57.094  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Sending update metadata request
2018-09-24 03:52:57.094  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Initializing replica state
2018-09-24 03:52:57.094  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Triggering online replica state changes
2018-09-24 03:52:57.094  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-24 03:52:57.094  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Initializing partition state
2018-09-24 03:52:57.094  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Triggering online partition state changes
2018-09-24 03:52:57.094  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-24 03:52:57.094  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-24 03:52:57.096  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Controller 1 connected to 127.0.0.1:42438 (id: 1 rack: null) for sending state change requests
2018-09-24 03:52:57.101  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-24 03:52:57.101  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions that completed preferred replica election: 
2018-09-24 03:52:57.101  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-24 03:52:57.101  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-24 03:52:57.101  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-24 03:52:57.103  INFO 323 --- [0 cport:37142):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094785290000 type:delete cxid:0x37 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-24 03:52:57.142  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting the controller scheduler
2018-09-24 03:52:57.165  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: BV_ZQTMpQCaCRjtE40J4XQ
2018-09-24 03:52:57.193  INFO 323 --- [           main] c.s.kafka.test.KafkaTestCluster          : Found 1 brokers on-line, cluster is ready.
2018-09-24 03:52:57.194  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:42438]
	client.id = KafkaWebView-Operation-UserId1
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:52:57.196  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:52:57.196  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:52:57.299  INFO 323 --- [eration-UserId1] org.apache.kafka.clients.Metadata        : Cluster ID: BV_ZQTMpQCaCRjtE40J4XQ
2018-09-24 03:52:57.312  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Shutting down kafka test server
2018-09-24 03:52:57.313  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shutting down
2018-09-24 03:52:57.313  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Starting controlled shutdown
2018-09-24 03:52:57.319  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Shutting down broker 1
2018-09-24 03:52:57.321  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Controlled shutdown succeeded
2018-09-24 03:52:57.322  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2018-09-24 03:52:57.323  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2018-09-24 03:52:57.325  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2018-09-24 03:52:57.325  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopping socket server request processors
2018-09-24 03:52:57.338  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopped socket server request processors
2018-09-24 03:52:57.338  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shutting down
2018-09-24 03:52:57.338  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shut down completely
2018-09-24 03:52:57.346  INFO 323 --- [           main] kafka.server.KafkaApis                   : [KafkaApi-1] Shutdown complete.
2018-09-24 03:52:57.346  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutting down
2018-09-24 03:52:57.456  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutdown completed
2018-09-24 03:52:57.456  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Stopped
2018-09-24 03:52:57.456  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutting down.
2018-09-24 03:52:57.457  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-24 03:52:57.457  INFO 323 --- [           main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 1]: Shutdown complete
2018-09-24 03:52:57.457  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutting down
2018-09-24 03:52:57.457  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Stopped
2018-09-24 03:52:57.457  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-24 03:52:57.457  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutdown complete.
2018-09-24 03:52:57.457  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutting down.
2018-09-24 03:52:57.458  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-24 03:52:57.461  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-24 03:52:57.461  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-24 03:52:57.461  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-24 03:52:57.469  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-24 03:52:57.469  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Stopped
2018-09-24 03:52:57.470  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutdown complete.
2018-09-24 03:52:57.470  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shutting down
2018-09-24 03:52:57.470  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2018-09-24 03:52:57.470  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2018-09-24 03:52:57.470  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2018-09-24 03:52:57.470  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutting down
2018-09-24 03:52:57.470  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-24 03:52:57.470  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutting down
2018-09-24 03:52:57.470  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2018-09-24 03:52:57.470  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutting down
2018-09-24 03:52:57.516  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Stopped
2018-09-24 03:52:57.516  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-24 03:52:57.516  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutting down
2018-09-24 03:52:57.709  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Stopped
2018-09-24 03:52:57.709  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-24 03:52:57.710  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-24 03:52:57.716  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-24 03:52:57.716  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-24 03:52:57.716  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shut down completely
2018-09-24 03:52:57.716  INFO 323 --- [           main] kafka.log.LogManager                     : Shutting down.
2018-09-24 03:52:57.717  INFO 323 --- [           main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2018-09-24 03:52:57.717  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2018-09-24 03:52:57.717  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2018-09-24 03:52:57.717  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-24 03:52:57.718  INFO 323 --- [           main] kafka.log.LogManager                     : Shutdown complete.
2018-09-24 03:52:57.718  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutting down
2018-09-24 03:52:57.718  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Stopped
2018-09-24 03:52:57.718  INFO 323 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutdown completed
2018-09-24 03:52:57.718  INFO 323 --- [           main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-24 03:52:57.719  INFO 323 --- [           main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-24 03:52:57.719  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutting down
2018-09-24 03:52:57.719  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Stopped
2018-09-24 03:52:57.719  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutdown completed
2018-09-24 03:52:57.721  INFO 323 --- [           main] kafka.controller.KafkaController         : [Controller id=1] Resigned
2018-09-24 03:52:57.721  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2018-09-24 03:52:57.722  INFO 323 --- [0 cport:37142):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x166094785290000
2018-09-24 03:52:57.750  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x166094785290000 closed
2018-09-24 03:52:57.750  INFO 323 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x166094785290000
2018-09-24 03:52:57.751  INFO 323 --- [0/0.0.0.0:37142] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:58326 which had sessionid 0x166094785290000
2018-09-24 03:52:57.751  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2018-09-24 03:52:57.751  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-24 03:52:58.069  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-24 03:52:58.069  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Stopped
2018-09-24 03:52:58.069  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutting down
2018-09-24 03:52:58.073  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Stopped
2018-09-24 03:52:58.073  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-24 03:52:58.073  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutting down
2018-09-24 03:52:59.073  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Stopped
2018-09-24 03:52:59.073  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-24 03:52:59.073  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutting down socket server
2018-09-24 03:52:59.107  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutdown completed
2018-09-24 03:52:59.108  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shut down completed
2018-09-24 03:52:59.108  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Shutting down zookeeper test server
2018-09-24 03:52:59.108  INFO 323 --- [0/0.0.0.0:37142] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:52:59.109  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:52:59.109  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:52:59.109  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:52:59.109  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:52:59.109  INFO 323 --- [0 cport:37142):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:52:59.109  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:52:59.109  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.064 s - in org.sourcelab.kafka.webview.ui.manager.kafka.KafkaOperationsFactoryTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.kafka.KafkaOperationsTest
2018-09-24 03:52:59.111  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Starting kafka test server
2018-09-24 03:52:59.111  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:52:59.114  INFO 323 --- [      Thread-18] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:52:59.122  INFO 323 --- [      Thread-18] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:52:59.122  INFO 323 --- [      Thread-18] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:52:59.122  INFO 323 --- [      Thread-18] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:52:59.122  INFO 323 --- [      Thread-18] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:42181
2018-09-24 03:53:00.000  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:53:00.148  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:53:00.149  INFO 323 --- [0/0.0.0.0:42181] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:53:00.150  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:53:00.150  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:53:00.150  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:53:00.150  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:53:00.150  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:53:00.150  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:53:00.150  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2018-09-24 03:53:00.151  INFO 323 --- [      Thread-19] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:53:00.151  INFO 323 --- [      Thread-19] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:53:00.152  INFO 323 --- [      Thread-19] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:53:00.152  INFO 323 --- [      Thread-19] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:53:00.152  INFO 323 --- [      Thread-19] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:42181
2018-09-24 03:53:01.157  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:44468
	advertised.port = 44468
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:44468
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753981156-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 44468
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42181
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:01.159  INFO 323 --- [           main] kafka.server.KafkaServer                 : starting
2018-09-24 03:53:01.159  INFO 323 --- [           main] kafka.server.KafkaServer                 : Connecting to zookeeper on 127.0.0.1:42181
2018-09-24 03:53:01.160  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Initializing a new session to 127.0.0.1:42181.
2018-09-24 03:53:01.160  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Initiating client connection, connectString=127.0.0.1:42181 sessionTimeout=30000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@287d9e0c
2018-09-24 03:53:01.161  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Waiting until connected.
2018-09-24 03:53:01.162  INFO 323 --- [27.0.0.1:42181)] org.apache.zookeeper.ClientCnxn          : Opening socket connection to server 127.0.0.1/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2018-09-24 03:53:01.162  INFO 323 --- [27.0.0.1:42181)] org.apache.zookeeper.ClientCnxn          : Socket connection established to 127.0.0.1/127.0.0.1:42181, initiating session
2018-09-24 03:53:01.162  INFO 323 --- [0/0.0.0.0:42181] o.a.z.server.NIOServerCnxnFactory        : Accepted socket connection from /127.0.0.1:39846
2018-09-24 03:53:01.162  INFO 323 --- [0/0.0.0.0:42181] o.a.zookeeper.server.ZooKeeperServer     : Client attempting to establish new session at /127.0.0.1:39846
2018-09-24 03:53:01.163  INFO 323 --- [   SyncThread:0] o.a.z.server.persistence.FileTxnLog      : Creating new log file: log.1
2018-09-24 03:53:01.224  INFO 323 --- [   SyncThread:0] o.a.zookeeper.server.ZooKeeperServer     : Established session 0x16609479cfb0000 with negotiated timeout 30000 for client /127.0.0.1:39846
2018-09-24 03:53:01.224  INFO 323 --- [27.0.0.1:42181)] org.apache.zookeeper.ClientCnxn          : Session establishment complete on server 127.0.0.1/127.0.0.1:42181, sessionid = 0x16609479cfb0000, negotiated timeout = 30000
2018-09-24 03:53:01.224  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Connected.
2018-09-24 03:53:01.267  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-24 03:53:01.415  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-24 03:53:01.532  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-24 03:53:01.959  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-24 03:53:02.075  INFO 323 --- [           main] kafka.server.KafkaServer                 : Cluster ID = hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:02.076  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537753981156-0/meta.properties
2018-09-24 03:53:02.079  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:44468
	advertised.port = 44468
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:44468
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753981156-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 44468
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42181
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:02.083  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:44468
	advertised.port = 44468
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:44468
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753981156-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 44468
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:42181
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:02.086  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Starting
2018-09-24 03:53:02.087  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Starting
2018-09-24 03:53:02.087  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Starting
2018-09-24 03:53:02.095  INFO 323 --- [           main] kafka.log.LogManager                     : Loading logs.
2018-09-24 03:53:02.095  INFO 323 --- [           main] kafka.log.LogManager                     : Logs loading complete in 0 ms.
2018-09-24 03:53:02.096  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log cleanup with a period of 300000 ms.
2018-09-24 03:53:02.096  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-24 03:53:02.097  INFO 323 --- [           main] kafka.log.LogCleaner                     : Starting the log cleaner
2018-09-24 03:53:02.122  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Starting
2018-09-24 03:53:02.159  INFO 323 --- [           main] kafka.network.Acceptor                   : Awaiting socket connections on 127.0.0.1:44468.
2018-09-24 03:53:02.163  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-24 03:53:02.173  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Starting
2018-09-24 03:53:02.176  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Creating /brokers/ids/1 (is it secure? false)
2018-09-24 03:53:02.177  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Starting
2018-09-24 03:53:02.177  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-24 03:53:02.179  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Starting
2018-09-24 03:53:02.209  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Result of znode creation at /brokers/ids/1 is: OK
2018-09-24 03:53:02.209  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(127.0.0.1,44468,ListenerName(PLAINTEXT),PLAINTEXT))
2018-09-24 03:53:02.209  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537753981156-0/meta.properties
2018-09-24 03:53:02.243  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Starting
2018-09-24 03:53:02.244  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Starting
2018-09-24 03:53:02.245  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Starting
2018-09-24 03:53:02.246  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Creating /controller (is it secure? false)
2018-09-24 03:53:02.247  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Starting
2018-09-24 03:53:02.248  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Starting up.
2018-09-24 03:53:02.248  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Startup complete.
2018-09-24 03:53:02.248  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-24 03:53:02.284  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Result of znode creation at /controller is: OK
2018-09-24 03:53:02.284  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] 1 successfully elected as the controller
2018-09-24 03:53:02.284  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Reading controller epoch from ZooKeeper
2018-09-24 03:53:02.323  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Incrementing controller epoch in ZooKeeper
2018-09-24 03:53:02.323  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-24 03:53:02.323  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:setData cxid:0x23 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-24 03:53:02.361  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Starting up.
2018-09-24 03:53:02.361  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Startup complete.
2018-09-24 03:53:02.362  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Starting
2018-09-24 03:53:02.364  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Starting
2018-09-24 03:53:02.392  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Epoch incremented to 1
2018-09-24 03:53:02.392  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Registering handlers
2018-09-24 03:53:02.393  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting log dir event notifications
2018-09-24 03:53:02.394  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting isr change notifications
2018-09-24 03:53:02.394  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing controller context
2018-09-24 03:53:02.395  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-24 03:53:02.395  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:02.395  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:02.395  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] started
2018-09-24 03:53:02.396  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:02.397  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:02.397  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:02.408  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Starting
2018-09-24 03:53:02.409  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions being reassigned: Map()
2018-09-24 03:53:02.409  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-24 03:53:02.409  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-24 03:53:02.409  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Current list of topics in the cluster: Set()
2018-09-24 03:53:02.409  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Fetching topic deletions in progress
2018-09-24 03:53:02.410  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics to be deleted: 
2018-09-24 03:53:02.410  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics ineligible for deletion: 
2018-09-24 03:53:02.410  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing topic deletion manager
2018-09-24 03:53:02.410  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Sending update metadata request
2018-09-24 03:53:02.410  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Initializing replica state
2018-09-24 03:53:02.410  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Triggering online replica state changes
2018-09-24 03:53:02.411  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-24 03:53:02.411  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Initializing partition state
2018-09-24 03:53:02.411  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Triggering online partition state changes
2018-09-24 03:53:02.411  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-24 03:53:02.411  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-24 03:53:02.411  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Controller 1 connected to 127.0.0.1:44468 (id: 1 rack: null) for sending state change requests
2018-09-24 03:53:02.412  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-24 03:53:02.412  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions that completed preferred replica election: 
2018-09-24 03:53:02.413  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-24 03:53:02.413  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-24 03:53:02.413  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-24 03:53:02.413  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:delete cxid:0x37 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-24 03:53:02.450  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting the controller scheduler
2018-09-24 03:53:02.502  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:02.509  INFO 323 --- [           main] c.s.kafka.test.KafkaTestCluster          : Found 1 brokers on-line, cluster is ready.
2018-09-24 03:53:02.510  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:02.512  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:02.512  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:02.615  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:02.620  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:setData cxid:0x3c zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/MyTopic11537753982509 Error:KeeperErrorCode = NoNode for /config/topics/MyTopic11537753982509
2018-09-24 03:53:02.700  INFO 323 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(MyTopic11537753982509-1 -> ArrayBuffer(1), MyTopic11537753982509-0 -> ArrayBuffer(1))
2018-09-24 03:53:02.735  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(MyTopic11537753982509)], deleted topics: [Set()], new partition replica assignment [Map(MyTopic11537753982509-1 -> Vector(1), MyTopic11537753982509-0 -> Vector(1))]
2018-09-24 03:53:02.735  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for MyTopic11537753982509-1,MyTopic11537753982509-0
2018-09-24 03:53:02.901  INFO 323 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MyTopic11537753982509-1,MyTopic11537753982509-0
2018-09-24 03:53:02.904  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=MyTopic11537753982509-1, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:02.905  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=MyTopic11537753982509-1, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:02.906  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition MyTopic11537753982509-1 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:02.906  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition MyTopic11537753982509-1 broker=1] No checkpointed highwatermark is found for partition MyTopic11537753982509-1
2018-09-24 03:53:02.906  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition MyTopic11537753982509-1 with initial high watermark 0
2018-09-24 03:53:02.907  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition MyTopic11537753982509-1 broker=1] MyTopic11537753982509-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:02.910  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=MyTopic11537753982509-0, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:02.910  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=MyTopic11537753982509-0, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:02.911  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition MyTopic11537753982509-0 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:02.911  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition MyTopic11537753982509-0 broker=1] No checkpointed highwatermark is found for partition MyTopic11537753982509-0
2018-09-24 03:53:02.911  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition MyTopic11537753982509-0 with initial high watermark 0
2018-09-24 03:53:02.912  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition MyTopic11537753982509-0 broker=1] MyTopic11537753982509-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:02.913  INFO 323 --- [quest-handler-1] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:02.918  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:02.920  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:02.920  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:03.000  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:53:03.025  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:03.029  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:setData cxid:0x49 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/config/topics/MyTopic21537753982509 Error:KeeperErrorCode = NoNode for /config/topics/MyTopic21537753982509
2018-09-24 03:53:03.117  INFO 323 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(MyTopic21537753982509-0 -> ArrayBuffer(1))
2018-09-24 03:53:03.158  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(MyTopic21537753982509)], deleted topics: [Set()], new partition replica assignment [Map(MyTopic21537753982509-0 -> Vector(1))]
2018-09-24 03:53:03.158  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for MyTopic21537753982509-0
2018-09-24 03:53:03.277  INFO 323 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MyTopic21537753982509-0
2018-09-24 03:53:03.280  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=MyTopic21537753982509-0, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:03.280  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=MyTopic21537753982509-0, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:03.281  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition MyTopic21537753982509-0 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:03.282  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition MyTopic21537753982509-0 broker=1] No checkpointed highwatermark is found for partition MyTopic21537753982509-0
2018-09-24 03:53:03.282  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition MyTopic21537753982509-0 with initial high watermark 0
2018-09-24 03:53:03.282  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition MyTopic21537753982509-0 broker=1] MyTopic21537753982509-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:03.282  INFO 323 --- [quest-handler-1] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:03.287  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = BobsYerAunty
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:03.288  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:03.288  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:03.391  INFO 323 --- [ | BobsYerAunty] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:03.397  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = BobsYerAunty
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:03.398  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:03.399  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:03.502  INFO 323 --- [ | BobsYerAunty] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:03.508  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:setData cxid:0x53 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/topics/TestTopic-1537753983397 Error:KeeperErrorCode = NoNode for /config/topics/TestTopic-1537753983397
2018-09-24 03:53:03.592  INFO 323 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Topic creation Map(TestTopic-1537753983397-0 -> ArrayBuffer(1))
2018-09-24 03:53:03.635  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(TestTopic-1537753983397)], deleted topics: [Set()], new partition replica assignment [Map(TestTopic-1537753983397-0 -> Vector(1))]
2018-09-24 03:53:03.635  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for TestTopic-1537753983397-0
2018-09-24 03:53:03.760  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions TestTopic-1537753983397-0
2018-09-24 03:53:03.764  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=TestTopic-1537753983397-0, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:03.764  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=TestTopic-1537753983397-0, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:03.765  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition TestTopic-1537753983397-0 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:03.765  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition TestTopic-1537753983397-0 broker=1] No checkpointed highwatermark is found for partition TestTopic-1537753983397-0
2018-09-24 03:53:03.765  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition TestTopic-1537753983397-0 with initial high watermark 0
2018-09-24 03:53:03.765  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition TestTopic-1537753983397-0 broker=1] TestTopic-1537753983397-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:03.765  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:03.771  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:03.772  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:03.772  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:03.875  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:03.880  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:setData cxid:0x5d zxid:0x32 txntype:-1 reqpath:n/a Error Path:/config/topics/MyTopic11537753983771 Error:KeeperErrorCode = NoNode for /config/topics/MyTopic11537753983771
2018-09-24 03:53:03.950  INFO 323 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(MyTopic11537753983771-1 -> ArrayBuffer(1), MyTopic11537753983771-0 -> ArrayBuffer(1))
2018-09-24 03:53:03.985  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(MyTopic11537753983771)], deleted topics: [Set()], new partition replica assignment [Map(MyTopic11537753983771-1 -> Vector(1), MyTopic11537753983771-0 -> Vector(1))]
2018-09-24 03:53:03.985  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for MyTopic11537753983771-1,MyTopic11537753983771-0
2018-09-24 03:53:04.094  INFO 323 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MyTopic11537753983771-0,MyTopic11537753983771-1
2018-09-24 03:53:04.097  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=MyTopic11537753983771-0, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:04.097  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=MyTopic11537753983771-0, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:04.099  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition MyTopic11537753983771-0 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:04.099  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition MyTopic11537753983771-0 broker=1] No checkpointed highwatermark is found for partition MyTopic11537753983771-0
2018-09-24 03:53:04.100  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition MyTopic11537753983771-0 with initial high watermark 0
2018-09-24 03:53:04.100  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition MyTopic11537753983771-0 broker=1] MyTopic11537753983771-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:04.102  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=MyTopic11537753983771-1, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:04.103  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=MyTopic11537753983771-1, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:04.104  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition MyTopic11537753983771-1 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:04.104  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition MyTopic11537753983771-1 broker=1] No checkpointed highwatermark is found for partition MyTopic11537753983771-1
2018-09-24 03:53:04.104  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition MyTopic11537753983771-1 with initial high watermark 0
2018-09-24 03:53:04.104  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition MyTopic11537753983771-1 broker=1] MyTopic11537753983771-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:04.104  INFO 323 --- [quest-handler-1] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:04.109  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:04.110  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:04.110  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:04.215  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:04.220  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:setData cxid:0x6a zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics/MyTopic21537753983771 Error:KeeperErrorCode = NoNode for /config/topics/MyTopic21537753983771
2018-09-24 03:53:04.292  INFO 323 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Topic creation Map(MyTopic21537753983771-0 -> ArrayBuffer(1))
2018-09-24 03:53:04.327  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(MyTopic21537753983771)], deleted topics: [Set()], new partition replica assignment [Map(MyTopic21537753983771-0 -> Vector(1))]
2018-09-24 03:53:04.327  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for MyTopic21537753983771-0
2018-09-24 03:53:04.450  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MyTopic21537753983771-0
2018-09-24 03:53:04.452  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=MyTopic21537753983771-0, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:04.453  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=MyTopic21537753983771-0, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:04.453  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition MyTopic21537753983771-0 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:04.453  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition MyTopic21537753983771-0 broker=1] No checkpointed highwatermark is found for partition MyTopic21537753983771-0
2018-09-24 03:53:04.453  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition MyTopic21537753983771-0 with initial high watermark 0
2018-09-24 03:53:04.454  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition MyTopic21537753983771-0 broker=1] MyTopic21537753983771-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:04.454  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:04.457  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = BobsYerAunty
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:04.459  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:04.459  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:04.561  INFO 323 --- [ | BobsYerAunty] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:04.569  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = BobsYerAunty
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:04.571  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:04.571  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:04.674  INFO 323 --- [ | BobsYerAunty] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:04.678  INFO 323 --- [           main] o.s.k.w.u.m.kafka.KafkaOperationsTest    : NodeList{nodes=[NodeDetails{id=1, host='127.0.0.1', port=44468, rack='null'}]}
2018-09-24 03:53:04.681  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:04.682  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:04.682  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:04.785  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:04.789  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:setData cxid:0x74 zxid:0x40 txntype:-1 reqpath:n/a Error Path:/config/topics/MyTopic11537753984680 Error:KeeperErrorCode = NoNode for /config/topics/MyTopic11537753984680
2018-09-24 03:53:04.873  INFO 323 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Topic creation Map(MyTopic11537753984680-1 -> ArrayBuffer(1), MyTopic11537753984680-0 -> ArrayBuffer(1))
2018-09-24 03:53:04.916  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(MyTopic11537753984680)], deleted topics: [Set()], new partition replica assignment [Map(MyTopic11537753984680-1 -> Vector(1), MyTopic11537753984680-0 -> Vector(1))]
2018-09-24 03:53:04.916  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for MyTopic11537753984680-1,MyTopic11537753984680-0
2018-09-24 03:53:05.076  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MyTopic11537753984680-0,MyTopic11537753984680-1
2018-09-24 03:53:05.078  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=MyTopic11537753984680-0, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:05.079  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=MyTopic11537753984680-0, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:05.080  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition MyTopic11537753984680-0 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:05.080  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition MyTopic11537753984680-0 broker=1] No checkpointed highwatermark is found for partition MyTopic11537753984680-0
2018-09-24 03:53:05.080  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition MyTopic11537753984680-0 with initial high watermark 0
2018-09-24 03:53:05.080  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition MyTopic11537753984680-0 broker=1] MyTopic11537753984680-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:05.084  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=MyTopic11537753984680-1, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:05.085  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=MyTopic11537753984680-1, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:05.086  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition MyTopic11537753984680-1 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:05.086  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition MyTopic11537753984680-1 broker=1] No checkpointed highwatermark is found for partition MyTopic11537753984680-1
2018-09-24 03:53:05.087  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition MyTopic11537753984680-1 with initial high watermark 0
2018-09-24 03:53:05.087  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition MyTopic11537753984680-1 broker=1] MyTopic11537753984680-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:05.087  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:05.093  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:05.095  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:05.095  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:05.199  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:05.202  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:setData cxid:0x81 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/config/topics/MyTopic21537753984680 Error:KeeperErrorCode = NoNode for /config/topics/MyTopic21537753984680
2018-09-24 03:53:05.281  INFO 323 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Topic creation Map(MyTopic21537753984680-0 -> ArrayBuffer(1))
2018-09-24 03:53:05.324  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(MyTopic21537753984680)], deleted topics: [Set()], new partition replica assignment [Map(MyTopic21537753984680-0 -> Vector(1))]
2018-09-24 03:53:05.324  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for MyTopic21537753984680-0
2018-09-24 03:53:05.452  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions MyTopic21537753984680-0
2018-09-24 03:53:05.455  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=MyTopic21537753984680-0, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:05.455  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=MyTopic21537753984680-0, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:05.456  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition MyTopic21537753984680-0 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:05.456  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition MyTopic21537753984680-0 broker=1] No checkpointed highwatermark is found for partition MyTopic21537753984680-0
2018-09-24 03:53:05.456  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition MyTopic21537753984680-0 with initial high watermark 0
2018-09-24 03:53:05.457  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition MyTopic21537753984680-0 broker=1] MyTopic21537753984680-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:05.457  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:05.461  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = BobsYerAunty
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:05.463  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:05.463  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:05.565  INFO 323 --- [ | BobsYerAunty] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:05.574  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = BobsYerAunty
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:05.576  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:05.576  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:05.681  INFO 323 --- [ | BobsYerAunty] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:05.686  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x16609479cfb0000 type:setData cxid:0x8c zxid:0x4e txntype:-1 reqpath:n/a Error Path:/config/topics/TestTopic-1537753985574 Error:KeeperErrorCode = NoNode for /config/topics/TestTopic-1537753985574
2018-09-24 03:53:05.766  INFO 323 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Topic creation Map(TestTopic-1537753985574-0 -> ArrayBuffer(1))
2018-09-24 03:53:05.810  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(TestTopic-1537753985574)], deleted topics: [Set()], new partition replica assignment [Map(TestTopic-1537753985574-0 -> Vector(1))]
2018-09-24 03:53:05.810  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for TestTopic-1537753985574-0
2018-09-24 03:53:05.935  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions TestTopic-1537753985574-0
2018-09-24 03:53:05.938  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=TestTopic-1537753985574-0, dir=/tmp/1537753981156-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:05.938  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=TestTopic-1537753985574-0, dir=/tmp/1537753981156-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:05.939  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition TestTopic-1537753985574-0 in /tmp/1537753981156-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:05.939  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition TestTopic-1537753985574-0 broker=1] No checkpointed highwatermark is found for partition TestTopic-1537753985574-0
2018-09-24 03:53:05.939  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition TestTopic-1537753985574-0 with initial high watermark 0
2018-09-24 03:53:05.940  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition TestTopic-1537753985574-0 broker=1] TestTopic-1537753985574-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:05.940  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:05.960  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44468]
	client.id = BobsYerAunty
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:05.962  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:05.962  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:06.066  INFO 323 --- [ | BobsYerAunty] org.apache.kafka.clients.Metadata        : Cluster ID: hbHL61pXT8a9sR-cNfF_hA
2018-09-24 03:53:06.088  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Shutting down kafka test server
2018-09-24 03:53:06.088  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shutting down
2018-09-24 03:53:06.088  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Starting controlled shutdown
2018-09-24 03:53:06.092  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Shutting down broker 1
2018-09-24 03:53:06.093  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Controlled shutdown succeeded
2018-09-24 03:53:06.094  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2018-09-24 03:53:06.094  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2018-09-24 03:53:06.094  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2018-09-24 03:53:06.094  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopping socket server request processors
2018-09-24 03:53:06.097  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopped socket server request processors
2018-09-24 03:53:06.097  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shutting down
2018-09-24 03:53:06.097  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shut down completely
2018-09-24 03:53:06.099  INFO 323 --- [           main] kafka.server.KafkaApis                   : [KafkaApi-1] Shutdown complete.
2018-09-24 03:53:06.099  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutting down
2018-09-24 03:53:06.247  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Stopped
2018-09-24 03:53:06.247  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutdown completed
2018-09-24 03:53:06.247  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutting down.
2018-09-24 03:53:06.247  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-24 03:53:06.247  INFO 323 --- [           main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 1]: Shutdown complete
2018-09-24 03:53:06.247  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutting down
2018-09-24 03:53:06.247  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Stopped
2018-09-24 03:53:06.247  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-24 03:53:06.247  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutdown complete.
2018-09-24 03:53:06.247  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutting down.
2018-09-24 03:53:06.247  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-24 03:53:06.447  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-24 03:53:06.447  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-24 03:53:06.447  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-24 03:53:06.450  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-24 03:53:06.450  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Stopped
2018-09-24 03:53:06.450  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutdown complete.
2018-09-24 03:53:06.450  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shutting down
2018-09-24 03:53:06.450  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2018-09-24 03:53:06.451  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2018-09-24 03:53:06.451  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutting down
2018-09-24 03:53:06.451  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-24 03:53:06.451  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutting down
2018-09-24 03:53:06.451  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2018-09-24 03:53:06.451  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutting down
2018-09-24 03:53:06.451  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2018-09-24 03:53:06.579  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-24 03:53:06.579  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutting down
2018-09-24 03:53:06.579  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Stopped
2018-09-24 03:53:06.775  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-24 03:53:06.775  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Stopped
2018-09-24 03:53:06.775  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-24 03:53:06.780  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-24 03:53:06.780  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-24 03:53:06.831  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shut down completely
2018-09-24 03:53:06.831  INFO 323 --- [           main] kafka.log.LogManager                     : Shutting down.
2018-09-24 03:53:06.831  INFO 323 --- [           main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2018-09-24 03:53:06.831  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2018-09-24 03:53:06.831  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2018-09-24 03:53:06.831  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-24 03:53:07.748  INFO 323 --- [           main] kafka.log.LogManager                     : Shutdown complete.
2018-09-24 03:53:07.748  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutting down
2018-09-24 03:53:07.748  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Stopped
2018-09-24 03:53:07.748  INFO 323 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutdown completed
2018-09-24 03:53:07.748  INFO 323 --- [           main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-24 03:53:07.749  INFO 323 --- [           main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-24 03:53:07.749  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutting down
2018-09-24 03:53:07.749  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Stopped
2018-09-24 03:53:07.749  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutdown completed
2018-09-24 03:53:07.750  INFO 323 --- [           main] kafka.controller.KafkaController         : [Controller id=1] Resigned
2018-09-24 03:53:07.750  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2018-09-24 03:53:07.751  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x16609479cfb0000
2018-09-24 03:53:07.789  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x16609479cfb0000 closed
2018-09-24 03:53:07.790  INFO 323 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x16609479cfb0000
2018-09-24 03:53:07.790  INFO 323 --- [0/0.0.0.0:42181] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:39846 which had sessionid 0x16609479cfb0000
2018-09-24 03:53:07.790  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2018-09-24 03:53:07.791  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-24 03:53:08.088  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Stopped
2018-09-24 03:53:08.088  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-24 03:53:08.088  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutting down
2018-09-24 03:53:09.087  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Stopped
2018-09-24 03:53:09.087  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-24 03:53:09.087  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutting down
2018-09-24 03:53:09.088  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Stopped
2018-09-24 03:53:09.088  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-24 03:53:09.088  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutting down socket server
2018-09-24 03:53:09.111  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutdown completed
2018-09-24 03:53:09.112  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shut down completed
2018-09-24 03:53:09.112  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Shutting down zookeeper test server
2018-09-24 03:53:09.112  INFO 323 --- [0/0.0.0.0:42181] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:53:09.113  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:53:09.113  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:53:09.113  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:53:09.113  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:53:09.113  INFO 323 --- [0 cport:42181):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:53:09.113  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:53:09.113  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
[ERROR] Tests run: 7, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 10 s <<< FAILURE! - in org.sourcelab.kafka.webview.ui.manager.kafka.KafkaOperationsTest
[ERROR] testModifyingATopic(org.sourcelab.kafka.webview.ui.manager.kafka.KafkaOperationsTest)  Time elapsed: 0.384 s  <<< FAILURE!
java.lang.AssertionError: Should be set to default
	at org.sourcelab.kafka.webview.ui.manager.kafka.KafkaOperationsTest.testModifyingATopic(KafkaOperationsTest.java:314)

[INFO] Running org.sourcelab.kafka.webview.ui.manager.kafka.KafkaConsumerFactoryTest
2018-09-24 03:53:09.115  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Starting kafka test server
2018-09-24 03:53:09.115  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:53:09.116  INFO 323 --- [      Thread-20] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:53:09.116  INFO 323 --- [      Thread-20] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:53:09.116  INFO 323 --- [      Thread-20] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:53:09.116  INFO 323 --- [      Thread-20] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:53:09.116  INFO 323 --- [      Thread-20] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:41166
2018-09-24 03:53:10.125  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:53:10.126  INFO 323 --- [0/0.0.0.0:41166] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:53:10.126  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:53:10.126  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:53:10.126  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:53:10.126  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:53:10.127  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:53:10.127  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:53:10.127  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2018-09-24 03:53:10.128  INFO 323 --- [      Thread-21] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:53:10.128  INFO 323 --- [      Thread-21] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:53:10.128  INFO 323 --- [      Thread-21] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:53:10.128  INFO 323 --- [      Thread-21] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:53:10.128  INFO 323 --- [      Thread-21] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:41166
2018-09-24 03:53:11.131  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:40615
	advertised.port = 40615
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:40615
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753991130-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 40615
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:41166
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:11.132  INFO 323 --- [           main] kafka.server.KafkaServer                 : starting
2018-09-24 03:53:11.132  INFO 323 --- [           main] kafka.server.KafkaServer                 : Connecting to zookeeper on 127.0.0.1:41166
2018-09-24 03:53:11.133  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Initializing a new session to 127.0.0.1:41166.
2018-09-24 03:53:11.133  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Initiating client connection, connectString=127.0.0.1:41166 sessionTimeout=30000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@48c63936
2018-09-24 03:53:11.134  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Waiting until connected.
2018-09-24 03:53:11.134  INFO 323 --- [27.0.0.1:41166)] org.apache.zookeeper.ClientCnxn          : Opening socket connection to server 127.0.0.1/127.0.0.1:41166. Will not attempt to authenticate using SASL (unknown error)
2018-09-24 03:53:11.134  INFO 323 --- [27.0.0.1:41166)] org.apache.zookeeper.ClientCnxn          : Socket connection established to 127.0.0.1/127.0.0.1:41166, initiating session
2018-09-24 03:53:11.134  INFO 323 --- [0/0.0.0.0:41166] o.a.z.server.NIOServerCnxnFactory        : Accepted socket connection from /127.0.0.1:49926
2018-09-24 03:53:11.135  INFO 323 --- [0/0.0.0.0:41166] o.a.zookeeper.server.ZooKeeperServer     : Client attempting to establish new session at /127.0.0.1:49926
2018-09-24 03:53:11.135  INFO 323 --- [   SyncThread:0] o.a.z.server.persistence.FileTxnLog      : Creating new log file: log.1
2018-09-24 03:53:11.175  INFO 323 --- [   SyncThread:0] o.a.zookeeper.server.ZooKeeperServer     : Established session 0x1660947c3f10000 with negotiated timeout 30000 for client /127.0.0.1:49926
2018-09-24 03:53:11.175  INFO 323 --- [27.0.0.1:41166)] org.apache.zookeeper.ClientCnxn          : Session establishment complete on server 127.0.0.1/127.0.0.1:41166, sessionid = 0x1660947c3f10000, negotiated timeout = 30000
2018-09-24 03:53:11.175  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Connected.
2018-09-24 03:53:11.217  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660947c3f10000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-24 03:53:11.375  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660947c3f10000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-24 03:53:11.475  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660947c3f10000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-24 03:53:11.882  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660947c3f10000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-24 03:53:12.000  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:53:12.000  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:53:12.006  INFO 323 --- [           main] kafka.server.KafkaServer                 : Cluster ID = _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:12.006  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537753991130-0/meta.properties
2018-09-24 03:53:12.009  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:40615
	advertised.port = 40615
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:40615
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753991130-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 40615
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:41166
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:12.011  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:40615
	advertised.port = 40615
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:40615
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537753991130-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 40615
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:41166
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:12.016  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Starting
2018-09-24 03:53:12.016  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Starting
2018-09-24 03:53:12.017  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Starting
2018-09-24 03:53:12.020  INFO 323 --- [           main] kafka.log.LogManager                     : Loading logs.
2018-09-24 03:53:12.020  INFO 323 --- [           main] kafka.log.LogManager                     : Logs loading complete in 0 ms.
2018-09-24 03:53:12.021  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log cleanup with a period of 300000 ms.
2018-09-24 03:53:12.021  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-24 03:53:12.022  INFO 323 --- [           main] kafka.log.LogCleaner                     : Starting the log cleaner
2018-09-24 03:53:12.056  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Starting
2018-09-24 03:53:12.081  INFO 323 --- [           main] kafka.network.Acceptor                   : Awaiting socket connections on 127.0.0.1:40615.
2018-09-24 03:53:12.084  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-24 03:53:12.085  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Starting
2018-09-24 03:53:12.085  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Starting
2018-09-24 03:53:12.086  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-24 03:53:12.088  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Starting
2018-09-24 03:53:12.088  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Creating /brokers/ids/1 (is it secure? false)
2018-09-24 03:53:12.124  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Result of znode creation at /brokers/ids/1 is: OK
2018-09-24 03:53:12.125  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(127.0.0.1,40615,ListenerName(PLAINTEXT),PLAINTEXT))
2018-09-24 03:53:12.125  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537753991130-0/meta.properties
2018-09-24 03:53:12.159  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Starting
2018-09-24 03:53:12.159  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Starting
2018-09-24 03:53:12.160  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Starting
2018-09-24 03:53:12.160  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Starting
2018-09-24 03:53:12.161  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Creating /controller (is it secure? false)
2018-09-24 03:53:12.161  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Starting up.
2018-09-24 03:53:12.162  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Startup complete.
2018-09-24 03:53:12.162  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-24 03:53:12.200  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Result of znode creation at /controller is: OK
2018-09-24 03:53:12.200  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] 1 successfully elected as the controller
2018-09-24 03:53:12.200  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Reading controller epoch from ZooKeeper
2018-09-24 03:53:12.200  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Incrementing controller epoch in ZooKeeper
2018-09-24 03:53:12.201  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660947c3f10000 type:setData cxid:0x22 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-24 03:53:12.274  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-24 03:53:12.308  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Epoch incremented to 1
2018-09-24 03:53:12.308  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Registering handlers
2018-09-24 03:53:12.309  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Starting up.
2018-09-24 03:53:12.309  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting log dir event notifications
2018-09-24 03:53:12.309  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Startup complete.
2018-09-24 03:53:12.309  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Starting
2018-09-24 03:53:12.310  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting isr change notifications
2018-09-24 03:53:12.310  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing controller context
2018-09-24 03:53:12.310  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Starting
2018-09-24 03:53:12.313  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-24 03:53:12.314  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:12.314  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:12.314  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] started
2018-09-24 03:53:12.314  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:40615]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:12.315  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:12.316  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:12.318  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Starting
2018-09-24 03:53:12.319  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions being reassigned: Map()
2018-09-24 03:53:12.319  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-24 03:53:12.319  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-24 03:53:12.319  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Current list of topics in the cluster: Set()
2018-09-24 03:53:12.319  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Fetching topic deletions in progress
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics to be deleted: 
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics ineligible for deletion: 
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing topic deletion manager
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Sending update metadata request
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Initializing replica state
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Triggering online replica state changes
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Initializing partition state
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Triggering online partition state changes
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-24 03:53:12.320  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-24 03:53:12.321  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-24 03:53:12.321  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions that completed preferred replica election: 
2018-09-24 03:53:12.321  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-24 03:53:12.321  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Controller 1 connected to 127.0.0.1:40615 (id: 1 rack: null) for sending state change requests
2018-09-24 03:53:12.321  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-24 03:53:12.321  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-24 03:53:12.321  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660947c3f10000 type:delete cxid:0x37 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-24 03:53:12.356  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting the controller scheduler
2018-09-24 03:53:12.419  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:12.422  INFO 323 --- [           main] c.s.kafka.test.KafkaTestCluster          : Found 1 brokers on-line, cluster is ready.
2018-09-24 03:53:12.423  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:40615]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:12.424  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:12.424  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:12.528  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:12.531  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660947c3f10000 type:setData cxid:0x3c zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/TestTopic Error:KeeperErrorCode = NoNode for /config/topics/TestTopic
2018-09-24 03:53:12.599  INFO 323 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(TestTopic-1 -> ArrayBuffer(1), TestTopic-0 -> ArrayBuffer(1))
2018-09-24 03:53:12.634  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(TestTopic)], deleted topics: [Set()], new partition replica assignment [Map(TestTopic-1 -> Vector(1), TestTopic-0 -> Vector(1))]
2018-09-24 03:53:12.634  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for TestTopic-1,TestTopic-0
2018-09-24 03:53:12.799  INFO 323 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions TestTopic-1,TestTopic-0
2018-09-24 03:53:12.802  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=TestTopic-1, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:12.803  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=TestTopic-1, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:12.803  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition TestTopic-1 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:12.803  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition TestTopic-1 broker=1] No checkpointed highwatermark is found for partition TestTopic-1
2018-09-24 03:53:12.804  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition TestTopic-1 with initial high watermark 0
2018-09-24 03:53:12.804  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition TestTopic-1 broker=1] TestTopic-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:12.806  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=TestTopic-0, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:12.807  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=TestTopic-0, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:12.808  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition TestTopic-0 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:12.808  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition TestTopic-0 broker=1] No checkpointed highwatermark is found for partition TestTopic-0
2018-09-24 03:53:12.808  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition TestTopic-0 with initial high watermark 0
2018-09-24 03:53:12.808  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition TestTopic-0 broker=1] TestTopic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:12.808  INFO 323 --- [quest-handler-1] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:12.822  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:40615]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:12.843  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:12.844  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:12.850  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:12.892  INFO 323 --- [quest-handler-0] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: TestTopic-0. Cache now contains 0 entries.
2018-09-24 03:53:13.339  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:13.340  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:13.342  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:40615]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:13.344  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:13.344  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:13.347  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:13.351  INFO 323 --- [quest-handler-1] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: TestTopic-1. Cache now contains 0 entries.
2018-09-24 03:53:13.775  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:13.775  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:13.782  INFO 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:40615]
	check.crcs = true
	client.id = TestPrefix-MyConsumerId
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TestPrefix-MyConsumerId
	heartbeat.interval.ms = 3000
	interceptor.classes = [org.sourcelab.kafka.webview.ui.manager.kafka.filter.RecordFilterInterceptor]
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-24 03:53:13.808  WARN 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'RecordFilterInterceptor.recordFilterDefinitions' was supplied but isn't a known config.
2018-09-24 03:53:13.808  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:13.808  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:13.812  INFO 323 --- [           main] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:13.827  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660947c3f10000 type:setData cxid:0x4c zxid:0x26 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-24 03:53:13.908  INFO 323 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(__consumer_offsets-22 -> ArrayBuffer(1), __consumer_offsets-30 -> ArrayBuffer(1), __consumer_offsets-8 -> ArrayBuffer(1), __consumer_offsets-21 -> ArrayBuffer(1), __consumer_offsets-4 -> ArrayBuffer(1), __consumer_offsets-27 -> ArrayBuffer(1), __consumer_offsets-7 -> ArrayBuffer(1), __consumer_offsets-9 -> ArrayBuffer(1), __consumer_offsets-46 -> ArrayBuffer(1), __consumer_offsets-25 -> ArrayBuffer(1), __consumer_offsets-35 -> ArrayBuffer(1), __consumer_offsets-41 -> ArrayBuffer(1), __consumer_offsets-33 -> ArrayBuffer(1), __consumer_offsets-23 -> ArrayBuffer(1), __consumer_offsets-49 -> ArrayBuffer(1), __consumer_offsets-47 -> ArrayBuffer(1), __consumer_offsets-16 -> ArrayBuffer(1), __consumer_offsets-28 -> ArrayBuffer(1), __consumer_offsets-31 -> ArrayBuffer(1), __consumer_offsets-36 -> ArrayBuffer(1), __consumer_offsets-42 -> ArrayBuffer(1), __consumer_offsets-3 -> ArrayBuffer(1), __consumer_offsets-18 -> ArrayBuffer(1), __consumer_offsets-37 -> ArrayBuffer(1), __consumer_offsets-15 -> ArrayBuffer(1), __consumer_offsets-24 -> ArrayBuffer(1), __consumer_offsets-38 -> ArrayBuffer(1), __consumer_offsets-17 -> ArrayBuffer(1), __consumer_offsets-48 -> ArrayBuffer(1), __consumer_offsets-19 -> ArrayBuffer(1), __consumer_offsets-11 -> ArrayBuffer(1), __consumer_offsets-13 -> ArrayBuffer(1), __consumer_offsets-2 -> ArrayBuffer(1), __consumer_offsets-43 -> ArrayBuffer(1), __consumer_offsets-6 -> ArrayBuffer(1), __consumer_offsets-14 -> ArrayBuffer(1), __consumer_offsets-20 -> ArrayBuffer(1), __consumer_offsets-0 -> ArrayBuffer(1), __consumer_offsets-44 -> ArrayBuffer(1), __consumer_offsets-39 -> ArrayBuffer(1), __consumer_offsets-12 -> ArrayBuffer(1), __consumer_offsets-45 -> ArrayBuffer(1), __consumer_offsets-1 -> ArrayBuffer(1), __consumer_offsets-5 -> ArrayBuffer(1), __consumer_offsets-26 -> ArrayBuffer(1), __consumer_offsets-29 -> ArrayBuffer(1), __consumer_offsets-34 -> ArrayBuffer(1), __consumer_offsets-10 -> ArrayBuffer(1), __consumer_offsets-32 -> ArrayBuffer(1), __consumer_offsets-40 -> ArrayBuffer(1))
2018-09-24 03:53:13.950  INFO 323 --- [quest-handler-0] kafka.server.KafkaApis                   : [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-24 03:53:13.954  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-22 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-19 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-2 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-40 -> Vector(1))]
2018-09-24 03:53:13.955  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-24 03:53:14.868  INFO 323 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-24 03:53:14.871  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.872  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.873  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.873  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-24 03:53:14.873  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-24 03:53:14.873  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.876  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-29, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.877  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-29, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.878  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-29 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.878  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-24 03:53:14.878  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-24 03:53:14.878  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.881  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-48, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.882  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-48, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.882  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-48 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.883  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-24 03:53:14.883  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-24 03:53:14.883  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.886  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-10, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.887  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-10, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.887  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-10 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.887  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-24 03:53:14.888  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-24 03:53:14.888  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.891  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-45, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.892  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-45, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.892  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-45 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.893  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-24 03:53:14.893  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-24 03:53:14.893  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.897  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-26, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.898  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-26, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-24 03:53:14.898  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-26 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.899  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-24 03:53:14.899  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-24 03:53:14.899  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.903  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-7, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.904  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-7, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-24 03:53:14.904  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-7 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.905  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-24 03:53:14.905  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-24 03:53:14.905  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.908  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-42, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.909  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-42, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.910  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-42 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.910  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-24 03:53:14.910  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-24 03:53:14.911  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.914  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.915  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.916  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.916  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-24 03:53:14.916  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-24 03:53:14.916  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.920  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-23, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.921  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-23, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.921  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-23 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.922  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-24 03:53:14.922  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-24 03:53:14.922  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.925  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.926  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.927  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.927  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-24 03:53:14.927  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-24 03:53:14.927  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.931  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-20, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.932  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-20, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.933  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-20 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.933  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-24 03:53:14.933  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-24 03:53:14.933  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.937  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-39, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.937  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-39, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.938  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-39 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.938  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-24 03:53:14.938  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-24 03:53:14.939  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.942  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-17, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.943  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-17, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.943  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-17 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.944  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-24 03:53:14.944  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-24 03:53:14.944  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.950  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-36, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.951  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-36, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.952  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-36 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.952  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-24 03:53:14.952  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-24 03:53:14.952  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.955  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-14, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.956  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-14, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.956  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-14 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.956  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-24 03:53:14.956  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-24 03:53:14.957  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.959  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-33, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.960  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-33, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.960  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-33 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.961  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-24 03:53:14.961  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-24 03:53:14.961  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.963  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-49, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.964  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-49, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:14.964  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-49 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.965  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-24 03:53:14.965  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-24 03:53:14.965  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.967  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-11, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.968  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-11, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.968  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-11 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.968  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-24 03:53:14.968  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-24 03:53:14.968  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.971  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-30, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.971  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-30, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:14.972  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-30 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.972  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-24 03:53:14.972  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-24 03:53:14.972  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.975  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-46, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.975  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-46, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:14.976  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-46 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.976  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-24 03:53:14.976  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-24 03:53:14.976  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.979  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-27, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.979  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-27, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:14.980  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-27 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.980  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-24 03:53:14.980  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-24 03:53:14.980  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.983  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-8, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.984  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-8, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.984  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-8 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.984  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-24 03:53:14.984  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-24 03:53:14.984  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.987  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-24, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.988  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-24, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.988  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-24 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.988  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-24 03:53:14.988  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-24 03:53:14.989  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.991  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-43, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.992  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-43, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.992  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-43 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.992  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-24 03:53:14.992  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-24 03:53:14.993  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.995  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-5, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:14.996  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-5, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:14.997  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-5 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:14.997  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-24 03:53:14.997  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-24 03:53:14.997  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:14.999  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-21, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.000  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-21, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.000  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-21 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.001  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-24 03:53:15.001  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-24 03:53:15.001  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.003  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.004  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.005  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.005  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-24 03:53:15.005  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-24 03:53:15.005  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.008  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-40, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.008  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-40, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.009  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-40 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.009  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-24 03:53:15.009  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-24 03:53:15.009  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.012  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-37, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.012  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-37, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.013  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-37 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.013  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-24 03:53:15.013  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-24 03:53:15.013  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.015  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-18, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.016  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-18, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.016  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-18 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.017  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-24 03:53:15.017  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-24 03:53:15.017  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.019  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-34, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.020  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-34, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.020  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-34 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.021  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-24 03:53:15.021  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-24 03:53:15.021  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.024  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-15, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.024  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-15, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.025  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-15 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.025  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-24 03:53:15.025  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-24 03:53:15.025  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.028  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-12, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.028  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-12, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.029  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-12 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.029  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-24 03:53:15.029  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-24 03:53:15.029  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.032  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-31, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.033  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-31, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.033  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-31 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.034  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-24 03:53:15.034  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-24 03:53:15.034  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.036  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-9, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.037  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-9, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.037  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-9 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.037  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-24 03:53:15.037  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-24 03:53:15.038  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.040  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-47, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.040  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-47, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.041  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-47 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.041  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-24 03:53:15.041  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-24 03:53:15.041  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.044  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-19, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.045  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-19, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.045  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-19 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.046  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-24 03:53:15.046  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-24 03:53:15.046  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.049  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-28, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.050  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-28, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.050  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-28 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.050  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-24 03:53:15.050  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-24 03:53:15.051  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.053  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-38, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.054  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-38, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.054  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-38 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.054  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-24 03:53:15.054  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-24 03:53:15.055  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.057  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-35, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.058  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-35, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.058  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-35 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.058  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-24 03:53:15.058  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-24 03:53:15.059  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.062  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-44, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.063  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-44, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.063  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-44 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.064  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-24 03:53:15.064  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-24 03:53:15.064  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.067  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-6, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.067  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-6, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.068  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-6 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.068  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-24 03:53:15.068  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-24 03:53:15.068  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.071  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-25, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.071  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-25, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.071  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-25 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.072  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-24 03:53:15.072  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-24 03:53:15.072  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.074  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-16, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.075  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-16, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.075  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-16 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.075  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-24 03:53:15.075  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-24 03:53:15.076  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.078  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-22, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.079  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-22, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.079  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-22 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.079  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-24 03:53:15.079  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-24 03:53:15.079  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.082  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-41, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.082  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-41, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.083  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-41 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.083  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-24 03:53:15.083  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-24 03:53:15.083  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.086  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-32, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.086  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-32, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:15.087  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-32 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.087  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-24 03:53:15.087  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-24 03:53:15.087  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.089  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.090  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.090  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.091  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-24 03:53:15.091  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-24 03:53:15.091  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.093  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-13, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:15.094  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=__consumer_offsets-13, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:15.094  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition __consumer_offsets-13 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:15.094  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-24 03:53:15.094  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-24 03:53:15.095  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:15.096  INFO 323 --- [quest-handler-1] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:15.097  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-24 03:53:15.098  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-24 03:53:15.099  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-24 03:53:15.100  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-24 03:53:15.101  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-24 03:53:15.101  INFO 323 --- [quest-handler-1] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-24 03:53:15.105  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 7 milliseconds.
2018-09-24 03:53:15.106  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-24 03:53:15.106  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-24 03:53:15.106  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-24 03:53:15.106  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-24 03:53:15.106  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-24 03:53:15.106  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-24 03:53:15.107  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-24 03:53:15.107  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-24 03:53:15.107  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-24 03:53:15.107  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-24 03:53:15.107  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-24 03:53:15.107  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-24 03:53:15.107  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-24 03:53:15.108  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-24 03:53:15.108  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-24 03:53:15.108  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-24 03:53:15.108  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-24 03:53:15.108  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-24 03:53:15.108  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-24 03:53:15.108  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-24 03:53:15.109  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds.
2018-09-24 03:53:15.109  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-24 03:53:15.109  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-24 03:53:15.109  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-24 03:53:15.109  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-24 03:53:15.109  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-24 03:53:15.109  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-24 03:53:15.110  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-24 03:53:15.110  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-24 03:53:15.110  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-24 03:53:15.110  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-24 03:53:15.110  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-24 03:53:15.110  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-24 03:53:15.110  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-24 03:53:15.111  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds.
2018-09-24 03:53:15.111  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-24 03:53:15.111  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds.
2018-09-24 03:53:15.111  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-24 03:53:15.111  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-24 03:53:15.111  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-24 03:53:15.111  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-24 03:53:15.112  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds.
2018-09-24 03:53:15.112  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-24 03:53:15.112  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-24 03:53:15.112  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-24 03:53:15.112  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-24 03:53:15.112  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-24 03:53:15.112  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-24 03:53:15.112  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-24 03:53:15.150  INFO 323 --- [           main] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=TestPrefix-MyConsumerId, groupId=TestPrefix-MyConsumerId] Discovered group coordinator 127.0.0.1:40615 (id: 2147483646 rack: null)
2018-09-24 03:53:15.165  INFO 323 --- [           main] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=TestPrefix-MyConsumerId, groupId=TestPrefix-MyConsumerId] Resetting offset for partition TestTopic-1 to offset 0.
2018-09-24 03:53:15.166  INFO 323 --- [           main] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=TestPrefix-MyConsumerId, groupId=TestPrefix-MyConsumerId] Resetting offset for partition TestTopic-0 to offset 0.
2018-09-24 03:53:17.227  INFO 323 --- [quest-handler-1] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: __consumer_offsets-42. Cache now contains 0 entries.
2018-09-24 03:53:17.375  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:40615]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:17.376  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:17.376  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:17.480  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:17.487  INFO 323 --- [quest-handler-1] kafka.server.AdminManager                : [Admin Manager on Broker 1]: Error processing create topic request for topic TestTopic with arguments (numPartitions=2, replicationFactor=1, replicasAssignments={}, configs={})

org.apache.kafka.common.errors.TopicExistsException: Topic 'TestTopic' already exists.

2018-09-24 03:53:17.492  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:40615]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:17.495  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:17.495  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:17.501  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:17.833  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:17.833  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:17.835  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:40615]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:17.836  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:17.836  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:17.839  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:18.200  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:18.200  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:18.201  INFO 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:40615]
	check.crcs = true
	client.id = TestPrefix-MyConsumerId
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TestPrefix-MyConsumerId
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-24 03:53:18.204  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:18.204  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:18.206  INFO 323 --- [           main] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:18.212  INFO 323 --- [           main] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=TestPrefix-MyConsumerId, groupId=TestPrefix-MyConsumerId] Discovered group coordinator 127.0.0.1:40615 (id: 2147483646 rack: null)
2018-09-24 03:53:18.508  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:40615]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:18.509  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:18.509  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:18.614  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:18.618  INFO 323 --- [quest-handler-1] kafka.server.AdminManager                : [Admin Manager on Broker 1]: Error processing create topic request for topic TestTopic with arguments (numPartitions=2, replicationFactor=1, replicasAssignments={}, configs={})

org.apache.kafka.common.errors.TopicExistsException: Topic 'TestTopic' already exists.

2018-09-24 03:53:18.621  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:40615]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:18.625  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:18.625  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:18.640  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:19.050  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:19.050  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:19.051  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:40615]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:19.053  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:19.053  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:19.057  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:19.532  INFO 323 --- [MessageBroker-1] o.s.w.s.c.WebSocketMessageBrokerStats    : WebSocketSession[0 current WS(0)-HttpStream(0)-HttpPoll(0), 0 total, 0 closed abnormally (0 connect failure, 0 send limit, 0 transport error)], stompSubProtocol[processed CONNECT(0)-CONNECTED(0)-DISCONNECT(0)], stompBrokerRelay[null], inboundChannel[pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0], outboundChannelpool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0], sockJsScheduler[pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
2018-09-24 03:53:19.624  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:19.625  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:19.626  INFO 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:40615]
	check.crcs = true
	client.id = TestPrefix-MyConsumerId
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TestPrefix-MyConsumerId
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 10
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-24 03:53:19.627  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:19.627  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:19.630  INFO 323 --- [           main] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:19.634  INFO 323 --- [           main] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=TestPrefix-MyConsumerId, groupId=TestPrefix-MyConsumerId] Discovered group coordinator 127.0.0.1:40615 (id: 2147483646 rack: null)
2018-09-24 03:53:21.668  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:40615]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:21.669  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:21.669  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:21.772  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:21.775  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660947c3f10000 type:setData cxid:0x103 zxid:0x8e txntype:-1 reqpath:n/a Error Path:/config/topics/TestTopic1537754001668 Error:KeeperErrorCode = NoNode for /config/topics/TestTopic1537754001668
2018-09-24 03:53:21.857  INFO 323 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(TestTopic1537754001668-0 -> ArrayBuffer(1))
2018-09-24 03:53:21.901  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(TestTopic1537754001668)], deleted topics: [Set()], new partition replica assignment [Map(TestTopic1537754001668-0 -> Vector(1))]
2018-09-24 03:53:21.901  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for TestTopic1537754001668-0
2018-09-24 03:53:22.407  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions TestTopic1537754001668-0
2018-09-24 03:53:22.409  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=TestTopic1537754001668-0, dir=/tmp/1537753991130-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:22.410  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=TestTopic1537754001668-0, dir=/tmp/1537753991130-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:22.411  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition TestTopic1537754001668-0 in /tmp/1537753991130-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:22.411  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition TestTopic1537754001668-0 broker=1] No checkpointed highwatermark is found for partition TestTopic1537754001668-0
2018-09-24 03:53:22.411  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition TestTopic1537754001668-0 with initial high watermark 0
2018-09-24 03:53:22.412  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition TestTopic1537754001668-0 broker=1] TestTopic1537754001668-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:22.412  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:22.416  INFO 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:40615]
	check.crcs = true
	client.id = TestPrefix-MyConsumerId
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TestPrefix-MyConsumerId
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.sourcelab.kafka.webview.ui.manager.kafka.KafkaConsumerFactoryTest$TestDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.sourcelab.kafka.webview.ui.manager.kafka.KafkaConsumerFactoryTest$TestDeserializer

2018-09-24 03:53:22.418  WARN 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'key.option2' was supplied but isn't a known config.
2018-09-24 03:53:22.418  WARN 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'key.option' was supplied but isn't a known config.
2018-09-24 03:53:22.418  WARN 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'value.option2' was supplied but isn't a known config.
2018-09-24 03:53:22.419  WARN 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'value.option' was supplied but isn't a known config.
2018-09-24 03:53:22.419  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:22.419  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:22.424  INFO 323 --- [           main] org.apache.kafka.clients.Metadata        : Cluster ID: _uqglHXCTSmbdFufzbQUTQ
2018-09-24 03:53:22.427  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Shutting down kafka test server
2018-09-24 03:53:22.427  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shutting down
2018-09-24 03:53:22.427  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Starting controlled shutdown
2018-09-24 03:53:22.430  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Shutting down broker 1
2018-09-24 03:53:22.431  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Controlled shutdown succeeded
2018-09-24 03:53:22.432  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2018-09-24 03:53:22.432  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2018-09-24 03:53:22.432  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2018-09-24 03:53:22.432  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopping socket server request processors
2018-09-24 03:53:22.435  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopped socket server request processors
2018-09-24 03:53:22.435  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shutting down
2018-09-24 03:53:22.435  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shut down completely
2018-09-24 03:53:22.436  INFO 323 --- [           main] kafka.server.KafkaApis                   : [KafkaApi-1] Shutdown complete.
2018-09-24 03:53:22.436  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutting down
2018-09-24 03:53:22.568  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Stopped
2018-09-24 03:53:22.568  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutdown completed
2018-09-24 03:53:22.568  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutting down.
2018-09-24 03:53:22.568  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-24 03:53:22.569  INFO 323 --- [           main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 1]: Shutdown complete
2018-09-24 03:53:22.569  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutting down
2018-09-24 03:53:22.569  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-24 03:53:22.569  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Stopped
2018-09-24 03:53:22.569  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutdown complete.
2018-09-24 03:53:22.569  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutting down.
2018-09-24 03:53:22.569  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-24 03:53:22.768  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-24 03:53:22.768  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-24 03:53:22.768  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-24 03:53:22.968  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-24 03:53:22.968  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutdown complete.
2018-09-24 03:53:22.968  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Stopped
2018-09-24 03:53:22.969  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shutting down
2018-09-24 03:53:22.969  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2018-09-24 03:53:22.969  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2018-09-24 03:53:22.969  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2018-09-24 03:53:22.969  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutting down
2018-09-24 03:53:22.969  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-24 03:53:22.969  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutting down
2018-09-24 03:53:22.969  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2018-09-24 03:53:22.969  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutting down
2018-09-24 03:53:23.047  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-24 03:53:23.047  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Stopped
2018-09-24 03:53:23.047  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutting down
2018-09-24 03:53:23.093  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Stopped
2018-09-24 03:53:23.093  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-24 03:53:23.093  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-24 03:53:23.294  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-24 03:53:23.294  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-24 03:53:23.324  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shut down completely
2018-09-24 03:53:23.324  INFO 323 --- [           main] kafka.log.LogManager                     : Shutting down.
2018-09-24 03:53:23.324  INFO 323 --- [           main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2018-09-24 03:53:23.324  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2018-09-24 03:53:23.324  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2018-09-24 03:53:23.324  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-24 03:53:23.791  INFO 323 --- [ool-33-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=TestTopic-0] Writing producer snapshot at offset 30
2018-09-24 03:53:24.005  INFO 323 --- [ool-33-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 5
2018-09-24 03:53:24.389  INFO 323 --- [ool-33-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=TestTopic-1] Writing producer snapshot at offset 30
2018-09-24 03:53:25.224  INFO 323 --- [           main] kafka.log.LogManager                     : Shutdown complete.
2018-09-24 03:53:25.225  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutting down
2018-09-24 03:53:25.225  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Stopped
2018-09-24 03:53:25.225  INFO 323 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutdown completed
2018-09-24 03:53:25.225  INFO 323 --- [           main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-24 03:53:25.225  INFO 323 --- [           main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-24 03:53:25.225  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutting down
2018-09-24 03:53:25.226  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Stopped
2018-09-24 03:53:25.226  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutdown completed
2018-09-24 03:53:25.227  INFO 323 --- [           main] kafka.controller.KafkaController         : [Controller id=1] Resigned
2018-09-24 03:53:25.227  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2018-09-24 03:53:25.228  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x1660947c3f10000
2018-09-24 03:53:25.266  INFO 323 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x1660947c3f10000
2018-09-24 03:53:25.266  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x1660947c3f10000 closed
2018-09-24 03:53:25.266  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2018-09-24 03:53:25.266  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-24 03:53:25.267  WARN 323 --- [0/0.0.0.0:41166] o.apache.zookeeper.server.NIOServerCnxn  : caught end of stream exception

org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1660947c3f10000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239) ~[zookeeper-3.4.10.jar:3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.10.jar:3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]

2018-09-24 03:53:25.268  INFO 323 --- [0/0.0.0.0:41166] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:49926 which had sessionid 0x1660947c3f10000
2018-09-24 03:53:26.019  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Stopped
2018-09-24 03:53:26.019  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-24 03:53:26.019  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutting down
2018-09-24 03:53:26.019  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Stopped
2018-09-24 03:53:26.019  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-24 03:53:26.019  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutting down
2018-09-24 03:53:26.021  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Stopped
2018-09-24 03:53:26.022  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-24 03:53:26.022  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutting down socket server
2018-09-24 03:53:26.039  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutdown completed
2018-09-24 03:53:26.040  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shut down completed
2018-09-24 03:53:26.040  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Shutting down zookeeper test server
2018-09-24 03:53:26.041  INFO 323 --- [0/0.0.0.0:41166] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:53:26.042  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:53:26.042  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:53:26.042  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:53:26.042  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:53:26.042  INFO 323 --- [0 cport:41166):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:53:26.042  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:53:26.042  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.92 s - in org.sourcelab.kafka.webview.ui.manager.kafka.KafkaConsumerFactoryTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.kafka.SessionIdentifierTest
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in org.sourcelab.kafka.webview.ui.manager.kafka.SessionIdentifierTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.kafka.WebKafkaConsumerFactoryTest
2018-09-24 03:53:26.046  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Starting kafka test server
2018-09-24 03:53:26.046  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:53:26.047  INFO 323 --- [      Thread-22] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:53:26.047  INFO 323 --- [      Thread-22] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:53:26.047  INFO 323 --- [      Thread-22] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:53:26.047  INFO 323 --- [      Thread-22] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:53:26.047  INFO 323 --- [      Thread-22] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:32774
2018-09-24 03:53:27.000  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:53:27.049  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:53:27.049  INFO 323 --- [0/0.0.0.0:32774] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:53:27.050  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:53:27.050  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:53:27.050  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:53:27.050  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:53:27.050  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:53:27.050  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:53:27.050  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2018-09-24 03:53:27.051  INFO 323 --- [      Thread-23] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:53:27.051  INFO 323 --- [      Thread-23] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:53:27.051  INFO 323 --- [      Thread-23] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:53:27.051  INFO 323 --- [      Thread-23] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:53:27.052  INFO 323 --- [      Thread-23] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:32774
2018-09-24 03:53:28.054  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:44019
	advertised.port = 44019
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:44019
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537754008053-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 44019
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:32774
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:28.056  INFO 323 --- [           main] kafka.server.KafkaServer                 : starting
2018-09-24 03:53:28.056  INFO 323 --- [           main] kafka.server.KafkaServer                 : Connecting to zookeeper on 127.0.0.1:32774
2018-09-24 03:53:28.056  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Initializing a new session to 127.0.0.1:32774.
2018-09-24 03:53:28.056  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Initiating client connection, connectString=127.0.0.1:32774 sessionTimeout=30000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7c38d816
2018-09-24 03:53:28.058  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Waiting until connected.
2018-09-24 03:53:28.058  INFO 323 --- [27.0.0.1:32774)] org.apache.zookeeper.ClientCnxn          : Opening socket connection to server 127.0.0.1/127.0.0.1:32774. Will not attempt to authenticate using SASL (unknown error)
2018-09-24 03:53:28.058  INFO 323 --- [27.0.0.1:32774)] org.apache.zookeeper.ClientCnxn          : Socket connection established to 127.0.0.1/127.0.0.1:32774, initiating session
2018-09-24 03:53:28.058  INFO 323 --- [0/0.0.0.0:32774] o.a.z.server.NIOServerCnxnFactory        : Accepted socket connection from /127.0.0.1:35268
2018-09-24 03:53:28.059  INFO 323 --- [0/0.0.0.0:32774] o.a.zookeeper.server.ZooKeeperServer     : Client attempting to establish new session at /127.0.0.1:35268
2018-09-24 03:53:28.059  INFO 323 --- [   SyncThread:0] o.a.z.server.persistence.FileTxnLog      : Creating new log file: log.1
2018-09-24 03:53:28.555  INFO 323 --- [   SyncThread:0] o.a.zookeeper.server.ZooKeeperServer     : Established session 0x1660948060c0000 with negotiated timeout 30000 for client /127.0.0.1:35268
2018-09-24 03:53:28.555  INFO 323 --- [27.0.0.1:32774)] org.apache.zookeeper.ClientCnxn          : Session establishment complete on server 127.0.0.1/127.0.0.1:32774, sessionid = 0x1660948060c0000, negotiated timeout = 30000
2018-09-24 03:53:28.556  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Connected.
2018-09-24 03:53:28.631  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-24 03:53:28.932  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-24 03:53:29.132  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-24 03:53:30.002  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:53:30.035  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-24 03:53:30.297  INFO 323 --- [           main] kafka.server.KafkaServer                 : Cluster ID = ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:30.297  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537754008053-0/meta.properties
2018-09-24 03:53:30.299  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:44019
	advertised.port = 44019
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:44019
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537754008053-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 44019
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:32774
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:30.301  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:44019
	advertised.port = 44019
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:44019
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537754008053-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 44019
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:32774
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:30.305  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Starting
2018-09-24 03:53:30.306  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Starting
2018-09-24 03:53:30.306  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Starting
2018-09-24 03:53:30.312  INFO 323 --- [           main] kafka.log.LogManager                     : Loading logs.
2018-09-24 03:53:30.312  INFO 323 --- [           main] kafka.log.LogManager                     : Logs loading complete in 0 ms.
2018-09-24 03:53:30.313  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log cleanup with a period of 300000 ms.
2018-09-24 03:53:30.313  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-24 03:53:30.314  INFO 323 --- [           main] kafka.log.LogCleaner                     : Starting the log cleaner
2018-09-24 03:53:30.349  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Starting
2018-09-24 03:53:30.362  INFO 323 --- [           main] kafka.network.Acceptor                   : Awaiting socket connections on 127.0.0.1:44019.
2018-09-24 03:53:30.364  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-24 03:53:30.368  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Starting
2018-09-24 03:53:30.368  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Starting
2018-09-24 03:53:30.369  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-24 03:53:30.374  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Creating /brokers/ids/1 (is it secure? false)
2018-09-24 03:53:30.375  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Starting
2018-09-24 03:53:30.449  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Result of znode creation at /brokers/ids/1 is: OK
2018-09-24 03:53:30.449  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(127.0.0.1,44019,ListenerName(PLAINTEXT),PLAINTEXT))
2018-09-24 03:53:30.449  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537754008053-0/meta.properties
2018-09-24 03:53:30.483  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Starting
2018-09-24 03:53:30.483  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Starting
2018-09-24 03:53:30.485  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Creating /controller (is it secure? false)
2018-09-24 03:53:30.486  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Starting
2018-09-24 03:53:30.489  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Starting
2018-09-24 03:53:30.532  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Result of znode creation at /controller is: OK
2018-09-24 03:53:30.532  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] 1 successfully elected as the controller
2018-09-24 03:53:30.532  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Reading controller epoch from ZooKeeper
2018-09-24 03:53:30.533  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Starting up.
2018-09-24 03:53:30.533  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Incrementing controller epoch in ZooKeeper
2018-09-24 03:53:30.533  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Startup complete.
2018-09-24 03:53:30.533  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:setData cxid:0x21 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-24 03:53:30.533  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-24 03:53:30.615  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Epoch incremented to 1
2018-09-24 03:53:30.615  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Registering handlers
2018-09-24 03:53:30.657  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-24 03:53:30.657  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting log dir event notifications
2018-09-24 03:53:30.658  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting isr change notifications
2018-09-24 03:53:30.658  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing controller context
2018-09-24 03:53:30.659  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Starting up.
2018-09-24 03:53:30.659  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Startup complete.
2018-09-24 03:53:30.660  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Starting
2018-09-24 03:53:30.661  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Starting
2018-09-24 03:53:30.671  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions being reassigned: Map()
2018-09-24 03:53:30.671  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Starting
2018-09-24 03:53:30.671  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-24 03:53:30.672  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-24 03:53:30.672  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Current list of topics in the cluster: Set()
2018-09-24 03:53:30.672  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Fetching topic deletions in progress
2018-09-24 03:53:30.672  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics to be deleted: 
2018-09-24 03:53:30.672  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics ineligible for deletion: 
2018-09-24 03:53:30.672  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing topic deletion manager
2018-09-24 03:53:30.673  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Sending update metadata request
2018-09-24 03:53:30.673  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-24 03:53:30.673  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:30.673  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:30.673  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] started
2018-09-24 03:53:30.673  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Initializing replica state
2018-09-24 03:53:30.673  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Triggering online replica state changes
2018-09-24 03:53:30.673  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-24 03:53:30.673  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Initializing partition state
2018-09-24 03:53:30.673  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44019]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:30.673  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Triggering online partition state changes
2018-09-24 03:53:30.673  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-24 03:53:30.673  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-24 03:53:30.673  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Controller 1 connected to 127.0.0.1:44019 (id: 1 rack: null) for sending state change requests
2018-09-24 03:53:30.680  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-24 03:53:30.680  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions that completed preferred replica election: 
2018-09-24 03:53:30.680  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-24 03:53:30.680  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-24 03:53:30.680  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-24 03:53:30.681  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:delete cxid:0x37 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-24 03:53:30.681  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:30.681  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:30.749  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting the controller scheduler
2018-09-24 03:53:30.783  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:30.786  INFO 323 --- [           main] c.s.kafka.test.KafkaTestCluster          : Found 1 brokers on-line, cluster is ready.
2018-09-24 03:53:30.787  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44019]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:30.788  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:30.788  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:30.891  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:30.895  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:setData cxid:0x3c zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/FirstTopic1537754010786 Error:KeeperErrorCode = NoNode for /config/topics/FirstTopic1537754010786
2018-09-24 03:53:31.076  INFO 323 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(FirstTopic1537754010786-1 -> ArrayBuffer(1), FirstTopic1537754010786-0 -> ArrayBuffer(1))
2018-09-24 03:53:31.175  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(FirstTopic1537754010786)], deleted topics: [Set()], new partition replica assignment [Map(FirstTopic1537754010786-1 -> Vector(1), FirstTopic1537754010786-0 -> Vector(1))]
2018-09-24 03:53:31.175  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for FirstTopic1537754010786-1,FirstTopic1537754010786-0
2018-09-24 03:53:31.300  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions FirstTopic1537754010786-0,FirstTopic1537754010786-1
2018-09-24 03:53:31.303  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=FirstTopic1537754010786-0, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:31.303  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=FirstTopic1537754010786-0, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:31.304  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition FirstTopic1537754010786-0 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:31.304  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition FirstTopic1537754010786-0 broker=1] No checkpointed highwatermark is found for partition FirstTopic1537754010786-0
2018-09-24 03:53:31.304  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition FirstTopic1537754010786-0 with initial high watermark 0
2018-09-24 03:53:31.304  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition FirstTopic1537754010786-0 broker=1] FirstTopic1537754010786-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:31.307  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=FirstTopic1537754010786-1, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:31.308  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=FirstTopic1537754010786-1, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:31.308  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition FirstTopic1537754010786-1 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:31.308  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition FirstTopic1537754010786-1 broker=1] No checkpointed highwatermark is found for partition FirstTopic1537754010786-1
2018-09-24 03:53:31.308  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition FirstTopic1537754010786-1 with initial high watermark 0
2018-09-24 03:53:31.309  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition FirstTopic1537754010786-1 broker=1] FirstTopic1537754010786-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:31.309  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:31.313  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44019]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:31.314  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:31.314  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:31.417  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:31.420  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:setData cxid:0x49 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/config/topics/SecondTopic1537754010786 Error:KeeperErrorCode = NoNode for /config/topics/SecondTopic1537754010786
2018-09-24 03:53:31.547  INFO 323 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Topic creation Map(SecondTopic1537754010786-1 -> ArrayBuffer(1), SecondTopic1537754010786-0 -> ArrayBuffer(1))
2018-09-24 03:53:31.590  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(SecondTopic1537754010786)], deleted topics: [Set()], new partition replica assignment [Map(SecondTopic1537754010786-1 -> Vector(1), SecondTopic1537754010786-0 -> Vector(1))]
2018-09-24 03:53:31.590  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for SecondTopic1537754010786-1,SecondTopic1537754010786-0
2018-09-24 03:53:31.717  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions SecondTopic1537754010786-1,SecondTopic1537754010786-0
2018-09-24 03:53:31.719  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=SecondTopic1537754010786-1, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:31.719  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=SecondTopic1537754010786-1, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:31.720  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition SecondTopic1537754010786-1 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:31.720  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition SecondTopic1537754010786-1 broker=1] No checkpointed highwatermark is found for partition SecondTopic1537754010786-1
2018-09-24 03:53:31.720  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition SecondTopic1537754010786-1 with initial high watermark 0
2018-09-24 03:53:31.720  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition SecondTopic1537754010786-1 broker=1] SecondTopic1537754010786-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:31.722  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=SecondTopic1537754010786-0, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:31.723  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=SecondTopic1537754010786-0, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:31.723  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition SecondTopic1537754010786-0 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:31.724  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition SecondTopic1537754010786-0 broker=1] No checkpointed highwatermark is found for partition SecondTopic1537754010786-0
2018-09-24 03:53:31.724  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition SecondTopic1537754010786-0 with initial high watermark 0
2018-09-24 03:53:31.724  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition SecondTopic1537754010786-0 broker=1] SecondTopic1537754010786-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:31.724  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:31.727  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:44019]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:31.729  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:31.729  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:31.732  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:31.736  INFO 323 --- [quest-handler-1] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: FirstTopic1537754010786-0. Cache now contains 0 entries.
2018-09-24 03:53:32.247  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:32.247  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:32.249  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:44019]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:32.250  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:32.250  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:32.253  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:32.256  INFO 323 --- [quest-handler-0] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: FirstTopic1537754010786-1. Cache now contains 0 entries.
2018-09-24 03:53:33.239  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:33.239  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:33.241  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:44019]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:33.243  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:33.243  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:33.248  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:33.252  INFO 323 --- [quest-handler-1] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: SecondTopic1537754010786-0. Cache now contains 0 entries.
2018-09-24 03:53:33.872  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:33.872  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:33.874  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:44019]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:33.877  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:33.877  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:33.888  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:33.891  INFO 323 --- [quest-handler-0] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: SecondTopic1537754010786-1. Cache now contains 0 entries.
2018-09-24 03:53:34.449  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:34.449  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:34.454  INFO 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:44019]
	check.crcs = true
	client.id = MyPrefix-KafkaWebView-Consumer-UserId12-MySession
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MyPrefix-KafkaWebView-Consumer-UserId12-MySession
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 5
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-24 03:53:34.457  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:34.457  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:34.460  INFO 323 --- [           main] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:34.467  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Resetting Partition: 1 To Head Offset: 0
2018-09-24 03:53:34.470  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:setData cxid:0x59 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2018-09-24 03:53:34.574  INFO 323 --- [quest-handler-1] kafka.zk.AdminZkClient                   : Topic creation Map(__consumer_offsets-22 -> ArrayBuffer(1), __consumer_offsets-30 -> ArrayBuffer(1), __consumer_offsets-8 -> ArrayBuffer(1), __consumer_offsets-21 -> ArrayBuffer(1), __consumer_offsets-4 -> ArrayBuffer(1), __consumer_offsets-27 -> ArrayBuffer(1), __consumer_offsets-7 -> ArrayBuffer(1), __consumer_offsets-9 -> ArrayBuffer(1), __consumer_offsets-46 -> ArrayBuffer(1), __consumer_offsets-25 -> ArrayBuffer(1), __consumer_offsets-35 -> ArrayBuffer(1), __consumer_offsets-41 -> ArrayBuffer(1), __consumer_offsets-33 -> ArrayBuffer(1), __consumer_offsets-23 -> ArrayBuffer(1), __consumer_offsets-49 -> ArrayBuffer(1), __consumer_offsets-47 -> ArrayBuffer(1), __consumer_offsets-16 -> ArrayBuffer(1), __consumer_offsets-28 -> ArrayBuffer(1), __consumer_offsets-31 -> ArrayBuffer(1), __consumer_offsets-36 -> ArrayBuffer(1), __consumer_offsets-42 -> ArrayBuffer(1), __consumer_offsets-3 -> ArrayBuffer(1), __consumer_offsets-18 -> ArrayBuffer(1), __consumer_offsets-37 -> ArrayBuffer(1), __consumer_offsets-15 -> ArrayBuffer(1), __consumer_offsets-24 -> ArrayBuffer(1), __consumer_offsets-38 -> ArrayBuffer(1), __consumer_offsets-17 -> ArrayBuffer(1), __consumer_offsets-48 -> ArrayBuffer(1), __consumer_offsets-19 -> ArrayBuffer(1), __consumer_offsets-11 -> ArrayBuffer(1), __consumer_offsets-13 -> ArrayBuffer(1), __consumer_offsets-2 -> ArrayBuffer(1), __consumer_offsets-43 -> ArrayBuffer(1), __consumer_offsets-6 -> ArrayBuffer(1), __consumer_offsets-14 -> ArrayBuffer(1), __consumer_offsets-20 -> ArrayBuffer(1), __consumer_offsets-0 -> ArrayBuffer(1), __consumer_offsets-44 -> ArrayBuffer(1), __consumer_offsets-39 -> ArrayBuffer(1), __consumer_offsets-12 -> ArrayBuffer(1), __consumer_offsets-45 -> ArrayBuffer(1), __consumer_offsets-1 -> ArrayBuffer(1), __consumer_offsets-5 -> ArrayBuffer(1), __consumer_offsets-26 -> ArrayBuffer(1), __consumer_offsets-29 -> ArrayBuffer(1), __consumer_offsets-34 -> ArrayBuffer(1), __consumer_offsets-10 -> ArrayBuffer(1), __consumer_offsets-32 -> ArrayBuffer(1), __consumer_offsets-40 -> ArrayBuffer(1))
2018-09-24 03:53:34.657  INFO 323 --- [quest-handler-1] kafka.server.KafkaApis                   : [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2018-09-24 03:53:34.659  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-22 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-19 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-2 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-40 -> Vector(1))]
2018-09-24 03:53:34.660  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-24 03:53:35.778  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2018-09-24 03:53:35.781  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.782  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.782  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.783  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
2018-09-24 03:53:35.783  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2018-09-24 03:53:35.784  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.789  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-29, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.790  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-29, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.790  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-29 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.791  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29
2018-09-24 03:53:35.791  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-29 with initial high watermark 0
2018-09-24 03:53:35.791  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.794  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-48, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.795  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-48, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.796  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-48 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.796  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48
2018-09-24 03:53:35.796  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-48 with initial high watermark 0
2018-09-24 03:53:35.797  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.800  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-10, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.800  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-10, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.801  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-10 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.801  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10
2018-09-24 03:53:35.802  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-10 with initial high watermark 0
2018-09-24 03:53:35.802  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.805  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-45, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.806  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-45, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.807  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-45 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.807  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45
2018-09-24 03:53:35.807  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-45 with initial high watermark 0
2018-09-24 03:53:35.807  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.811  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-26, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.812  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-26, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.812  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-26 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.813  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26
2018-09-24 03:53:35.813  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-26 with initial high watermark 0
2018-09-24 03:53:35.813  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.817  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-7, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.818  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-7, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.818  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-7 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.819  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7
2018-09-24 03:53:35.819  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-7 with initial high watermark 0
2018-09-24 03:53:35.819  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.822  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-42, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.823  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-42, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.824  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-42 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.824  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42
2018-09-24 03:53:35.825  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-42 with initial high watermark 0
2018-09-24 03:53:35.825  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.828  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.829  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.830  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.830  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4
2018-09-24 03:53:35.830  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2018-09-24 03:53:35.831  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.834  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-23, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.835  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-23, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.835  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-23 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.836  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23
2018-09-24 03:53:35.836  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-23 with initial high watermark 0
2018-09-24 03:53:35.836  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.839  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.840  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.840  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.840  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1
2018-09-24 03:53:35.840  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2018-09-24 03:53:35.840  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.843  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-20, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.843  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-20, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.843  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-20 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.844  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20
2018-09-24 03:53:35.844  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-20 with initial high watermark 0
2018-09-24 03:53:35.844  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.846  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-39, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.847  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-39, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.847  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-39 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.847  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39
2018-09-24 03:53:35.847  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-39 with initial high watermark 0
2018-09-24 03:53:35.847  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.849  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-17, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.850  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-17, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.850  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-17 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.850  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17
2018-09-24 03:53:35.850  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-17 with initial high watermark 0
2018-09-24 03:53:35.850  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.853  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-36, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.853  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-36, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.854  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-36 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.854  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36
2018-09-24 03:53:35.854  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-36 with initial high watermark 0
2018-09-24 03:53:35.854  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.856  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-14, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.856  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-14, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.857  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-14 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.857  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14
2018-09-24 03:53:35.857  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-14 with initial high watermark 0
2018-09-24 03:53:35.857  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.859  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-33, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.860  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-33, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.860  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-33 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.860  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33
2018-09-24 03:53:35.860  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-33 with initial high watermark 0
2018-09-24 03:53:35.860  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.862  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-49, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.863  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-49, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.864  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-49 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.864  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49
2018-09-24 03:53:35.864  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-49 with initial high watermark 0
2018-09-24 03:53:35.864  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.867  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-11, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.868  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-11, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.869  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-11 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.869  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11
2018-09-24 03:53:35.869  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-11 with initial high watermark 0
2018-09-24 03:53:35.869  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.872  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-30, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.872  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-30, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.873  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-30 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.873  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30
2018-09-24 03:53:35.873  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-30 with initial high watermark 0
2018-09-24 03:53:35.873  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.875  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-46, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.876  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-46, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.876  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-46 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.876  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46
2018-09-24 03:53:35.876  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-46 with initial high watermark 0
2018-09-24 03:53:35.876  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.879  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-27, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.879  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-27, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.880  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-27 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.880  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27
2018-09-24 03:53:35.880  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-27 with initial high watermark 0
2018-09-24 03:53:35.880  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.883  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-8, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.884  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-8, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.884  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-8 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.885  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8
2018-09-24 03:53:35.885  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-8 with initial high watermark 0
2018-09-24 03:53:35.885  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.888  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-24, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.888  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-24, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.889  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-24 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.889  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24
2018-09-24 03:53:35.889  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-24 with initial high watermark 0
2018-09-24 03:53:35.889  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.893  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-43, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.894  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-43, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.895  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-43 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.895  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43
2018-09-24 03:53:35.895  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-43 with initial high watermark 0
2018-09-24 03:53:35.895  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.898  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-5, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.899  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-5, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.899  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-5 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.899  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5
2018-09-24 03:53:35.899  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-5 with initial high watermark 0
2018-09-24 03:53:35.900  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.902  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-21, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.903  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-21, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.904  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-21 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.904  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21
2018-09-24 03:53:35.904  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-21 with initial high watermark 0
2018-09-24 03:53:35.904  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.912  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.913  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-24 03:53:35.913  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.914  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2
2018-09-24 03:53:35.914  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2018-09-24 03:53:35.914  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.919  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-40, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.920  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-40, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.920  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-40 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.921  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40
2018-09-24 03:53:35.921  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-40 with initial high watermark 0
2018-09-24 03:53:35.921  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.926  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-37, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.926  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-37, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2018-09-24 03:53:35.927  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-37 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.928  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37
2018-09-24 03:53:35.929  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-37 with initial high watermark 0
2018-09-24 03:53:35.929  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.933  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-18, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.933  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-18, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.934  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-18 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.934  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18
2018-09-24 03:53:35.934  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-18 with initial high watermark 0
2018-09-24 03:53:35.935  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.940  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-34, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.940  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-34, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.941  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-34 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.941  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34
2018-09-24 03:53:35.941  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-34 with initial high watermark 0
2018-09-24 03:53:35.941  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.944  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-15, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.945  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-15, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.945  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-15 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.945  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15
2018-09-24 03:53:35.946  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-15 with initial high watermark 0
2018-09-24 03:53:35.946  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.948  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-12, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.949  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-12, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.950  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-12 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.950  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12
2018-09-24 03:53:35.950  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-12 with initial high watermark 0
2018-09-24 03:53:35.950  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.953  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-31, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.954  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-31, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.954  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-31 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.955  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31
2018-09-24 03:53:35.955  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-31 with initial high watermark 0
2018-09-24 03:53:35.955  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.957  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-9, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.958  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-9, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.958  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-9 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.958  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9
2018-09-24 03:53:35.958  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-9 with initial high watermark 0
2018-09-24 03:53:35.958  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.961  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-47, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.961  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-47, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.962  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-47 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.962  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47
2018-09-24 03:53:35.962  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-47 with initial high watermark 0
2018-09-24 03:53:35.962  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.964  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-19, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.965  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-19, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.965  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-19 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.965  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19
2018-09-24 03:53:35.965  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-19 with initial high watermark 0
2018-09-24 03:53:35.966  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.968  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-28, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.969  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-28, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.969  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-28 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.969  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28
2018-09-24 03:53:35.969  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-28 with initial high watermark 0
2018-09-24 03:53:35.969  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.972  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-38, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.972  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-38, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.973  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-38 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.973  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38
2018-09-24 03:53:35.973  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-38 with initial high watermark 0
2018-09-24 03:53:35.973  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.975  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-35, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.975  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-35, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.976  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-35 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.976  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35
2018-09-24 03:53:35.976  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-35 with initial high watermark 0
2018-09-24 03:53:35.976  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.978  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-44, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.979  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-44, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.979  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-44 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.979  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44
2018-09-24 03:53:35.979  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-44 with initial high watermark 0
2018-09-24 03:53:35.979  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.982  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-6, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.982  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-6, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.983  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-6 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.983  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6
2018-09-24 03:53:35.983  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-6 with initial high watermark 0
2018-09-24 03:53:35.983  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.985  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-25, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.986  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-25, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.986  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-25 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.986  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25
2018-09-24 03:53:35.986  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-25 with initial high watermark 0
2018-09-24 03:53:35.986  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.989  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-16, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.989  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-16, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.990  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-16 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.990  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16
2018-09-24 03:53:35.990  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-16 with initial high watermark 0
2018-09-24 03:53:35.990  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.992  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-22, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.993  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-22, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:35.993  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-22 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.993  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22
2018-09-24 03:53:35.993  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-22 with initial high watermark 0
2018-09-24 03:53:35.993  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:35.997  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-41, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:35.997  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-41, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:35.998  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-41 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:35.998  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41
2018-09-24 03:53:35.998  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-41 with initial high watermark 0
2018-09-24 03:53:35.998  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:36.003  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-32, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:36.004  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-32, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:36.004  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-32 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:36.004  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32
2018-09-24 03:53:36.004  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-32 with initial high watermark 0
2018-09-24 03:53:36.004  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:36.007  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:36.007  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:36.008  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:36.008  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3
2018-09-24 03:53:36.008  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2018-09-24 03:53:36.008  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:36.010  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-13, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:36.011  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=__consumer_offsets-13, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:36.011  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition __consumer_offsets-13 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:36.011  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13
2018-09-24 03:53:36.011  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-13 with initial high watermark 0
2018-09-24 03:53:36.012  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:36.012  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:36.012  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2018-09-24 03:53:36.016  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2018-09-24 03:53:36.016  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2018-09-24 03:53:36.016  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds.
2018-09-24 03:53:36.016  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2018-09-24 03:53:36.017  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds.
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2018-09-24 03:53:36.017  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds.
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2018-09-24 03:53:36.017  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds.
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2018-09-24 03:53:36.017  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds.
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2018-09-24 03:53:36.017  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds.
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2018-09-24 03:53:36.017  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds.
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2018-09-24 03:53:36.017  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds.
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2018-09-24 03:53:36.017  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2018-09-24 03:53:36.017  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds.
2018-09-24 03:53:36.018  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2018-09-24 03:53:36.018  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2018-09-24 03:53:36.018  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds.
2018-09-24 03:53:36.018  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2018-09-24 03:53:36.018  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2018-09-24 03:53:36.018  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2018-09-24 03:53:36.018  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2018-09-24 03:53:36.018  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds.
2018-09-24 03:53:36.018  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds.
2018-09-24 03:53:36.018  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds.
2018-09-24 03:53:36.018  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2018-09-24 03:53:36.018  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2018-09-24 03:53:36.019  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds.
2018-09-24 03:53:36.019  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds.
2018-09-24 03:53:36.019  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds.
2018-09-24 03:53:36.019  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds.
2018-09-24 03:53:36.018  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2018-09-24 03:53:36.019  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2018-09-24 03:53:36.019  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2018-09-24 03:53:36.019  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds.
2018-09-24 03:53:36.019  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2018-09-24 03:53:36.019  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2018-09-24 03:53:36.019  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2018-09-24 03:53:36.020  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2018-09-24 03:53:36.020  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds.
2018-09-24 03:53:36.020  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2018-09-24 03:53:36.020  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds.
2018-09-24 03:53:36.020  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2018-09-24 03:53:36.020  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds.
2018-09-24 03:53:36.020  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2018-09-24 03:53:36.020  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds.
2018-09-24 03:53:36.020  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2018-09-24 03:53:36.020  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds.
2018-09-24 03:53:36.020  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2018-09-24 03:53:36.020  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds.
2018-09-24 03:53:36.020  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2018-09-24 03:53:36.020  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds.
2018-09-24 03:53:36.020  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2018-09-24 03:53:36.020  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2018-09-24 03:53:36.020  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds.
2018-09-24 03:53:36.021  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2018-09-24 03:53:36.021  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds.
2018-09-24 03:53:36.021  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2018-09-24 03:53:36.021  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds.
2018-09-24 03:53:36.021  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2018-09-24 03:53:36.021  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2018-09-24 03:53:36.021  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds.
2018-09-24 03:53:36.021  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2018-09-24 03:53:36.021  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds.
2018-09-24 03:53:36.021  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2018-09-24 03:53:36.021  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2018-09-24 03:53:36.021  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2018-09-24 03:53:36.021  INFO 323 --- [quest-handler-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2018-09-24 03:53:36.021  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2018-09-24 03:53:36.021  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds.
2018-09-24 03:53:36.021  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds.
2018-09-24 03:53:36.022  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds.
2018-09-24 03:53:36.023  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds.
2018-09-24 03:53:36.023  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds.
2018-09-24 03:53:36.089  INFO 323 --- [           main] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=MyPrefix-KafkaWebView-Consumer-UserId12-MySession, groupId=MyPrefix-KafkaWebView-Consumer-UserId12-MySession] Discovered group coordinator 127.0.0.1:44019 (id: 2147483646 rack: null)
2018-09-24 03:53:36.092  INFO 323 --- [quest-handler-1] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: __consumer_offsets-6. Cache now contains 0 entries.
2018-09-24 03:53:36.252  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed 5 records
2018-09-24 03:53:36.481  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed Partition 1 Records: 5
2018-09-24 03:53:36.483  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed 5 records
2018-09-24 03:53:36.580  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed Partition 1 Records: 5
2018-09-24 03:53:37.770  INFO 323 --- [MessageBroker-1] o.s.w.s.c.WebSocketMessageBrokerStats    : WebSocketSession[0 current WS(0)-HttpStream(0)-HttpPoll(0), 0 total, 0 closed abnormally (0 connect failure, 0 send limit, 0 transport error)], stompSubProtocol[processed CONNECT(0)-CONNECTED(0)-DISCONNECT(0)], stompBrokerRelay[null], inboundChannel[pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0], outboundChannelpool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0], sockJsScheduler[pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
2018-09-24 03:53:38.583  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed 0 records
2018-09-24 03:53:38.615  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed Partition 1 Records: 0
2018-09-24 03:53:38.652  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44019]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:38.654  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:38.654  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:38.759  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:38.763  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:setData cxid:0x10e zxid:0x96 txntype:-1 reqpath:n/a Error Path:/config/topics/FirstTopic1537754018652 Error:KeeperErrorCode = NoNode for /config/topics/FirstTopic1537754018652
2018-09-24 03:53:38.840  INFO 323 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(FirstTopic1537754018652-1 -> ArrayBuffer(1), FirstTopic1537754018652-0 -> ArrayBuffer(1))
2018-09-24 03:53:38.875  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(FirstTopic1537754018652)], deleted topics: [Set()], new partition replica assignment [Map(FirstTopic1537754018652-1 -> Vector(1), FirstTopic1537754018652-0 -> Vector(1))]
2018-09-24 03:53:38.875  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for FirstTopic1537754018652-1,FirstTopic1537754018652-0
2018-09-24 03:53:38.990  INFO 323 --- [quest-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions FirstTopic1537754018652-1,FirstTopic1537754018652-0
2018-09-24 03:53:38.993  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=FirstTopic1537754018652-1, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:38.994  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=FirstTopic1537754018652-1, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:38.995  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition FirstTopic1537754018652-1 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:38.996  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition FirstTopic1537754018652-1 broker=1] No checkpointed highwatermark is found for partition FirstTopic1537754018652-1
2018-09-24 03:53:38.996  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition FirstTopic1537754018652-1 with initial high watermark 0
2018-09-24 03:53:38.996  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition FirstTopic1537754018652-1 broker=1] FirstTopic1537754018652-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:38.999  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=FirstTopic1537754018652-0, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:39.000  INFO 323 --- [quest-handler-1] kafka.log.Log                            : [Log partition=FirstTopic1537754018652-0, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2018-09-24 03:53:39.000  INFO 323 --- [quest-handler-1] kafka.log.LogManager                     : Created log for partition FirstTopic1537754018652-0 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:39.001  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition FirstTopic1537754018652-0 broker=1] No checkpointed highwatermark is found for partition FirstTopic1537754018652-0
2018-09-24 03:53:39.002  INFO 323 --- [quest-handler-1] kafka.cluster.Replica                    : Replica loaded for partition FirstTopic1537754018652-0 with initial high watermark 0
2018-09-24 03:53:39.002  INFO 323 --- [quest-handler-1] kafka.cluster.Partition                  : [Partition FirstTopic1537754018652-0 broker=1] FirstTopic1537754018652-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:39.002  INFO 323 --- [quest-handler-1] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:39.006  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:44019]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:39.008  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:39.009  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:39.111  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:39.115  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1660948060c0000 type:setData cxid:0x11b zxid:0x9e txntype:-1 reqpath:n/a Error Path:/config/topics/SecondTopic1537754018652 Error:KeeperErrorCode = NoNode for /config/topics/SecondTopic1537754018652
2018-09-24 03:53:39.198  INFO 323 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(SecondTopic1537754018652-1 -> ArrayBuffer(1), SecondTopic1537754018652-0 -> ArrayBuffer(1))
2018-09-24 03:53:39.241  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New topics: [Set(SecondTopic1537754018652)], deleted topics: [Set()], new partition replica assignment [Map(SecondTopic1537754018652-1 -> Vector(1), SecondTopic1537754018652-0 -> Vector(1))]
2018-09-24 03:53:39.241  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] New partition creation callback for SecondTopic1537754018652-1,SecondTopic1537754018652-0
2018-09-24 03:53:39.450  INFO 323 --- [quest-handler-0] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] Removed fetcher for partitions SecondTopic1537754018652-0,SecondTopic1537754018652-1
2018-09-24 03:53:39.454  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=SecondTopic1537754018652-0, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:39.455  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=SecondTopic1537754018652-0, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:39.455  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition SecondTopic1537754018652-0 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:39.456  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition SecondTopic1537754018652-0 broker=1] No checkpointed highwatermark is found for partition SecondTopic1537754018652-0
2018-09-24 03:53:39.456  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition SecondTopic1537754018652-0 with initial high watermark 0
2018-09-24 03:53:39.456  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition SecondTopic1537754018652-0 broker=1] SecondTopic1537754018652-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:39.459  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=SecondTopic1537754018652-1, dir=/tmp/1537754008053-0] Loading producer state from offset 0 with message format version 2
2018-09-24 03:53:39.459  INFO 323 --- [quest-handler-0] kafka.log.Log                            : [Log partition=SecondTopic1537754018652-1, dir=/tmp/1537754008053-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2018-09-24 03:53:39.460  INFO 323 --- [quest-handler-0] kafka.log.LogManager                     : Created log for partition SecondTopic1537754018652-1 in /tmp/1537754008053-0 with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 1}.
2018-09-24 03:53:39.460  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition SecondTopic1537754018652-1 broker=1] No checkpointed highwatermark is found for partition SecondTopic1537754018652-1
2018-09-24 03:53:39.460  INFO 323 --- [quest-handler-0] kafka.cluster.Replica                    : Replica loaded for partition SecondTopic1537754018652-1 with initial high watermark 0
2018-09-24 03:53:39.460  INFO 323 --- [quest-handler-0] kafka.cluster.Partition                  : [Partition SecondTopic1537754018652-1 broker=1] SecondTopic1537754018652-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2018-09-24 03:53:39.461  INFO 323 --- [quest-handler-0] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] Added fetcher for partitions List()
2018-09-24 03:53:39.465  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:44019]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:39.467  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:39.467  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:39.471  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:39.476  INFO 323 --- [quest-handler-1] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: FirstTopic1537754018652-0. Cache now contains 0 entries.
2018-09-24 03:53:39.899  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:39.899  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:39.900  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:44019]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:39.902  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:39.902  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:39.907  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:39.911  INFO 323 --- [quest-handler-0] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: FirstTopic1537754018652-1. Cache now contains 0 entries.
2018-09-24 03:53:40.332  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:40.332  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:40.333  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:44019]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:40.335  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:40.335  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:40.339  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:40.343  INFO 323 --- [quest-handler-1] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: SecondTopic1537754018652-0. Cache now contains 0 entries.
2018-09-24 03:53:40.722  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:40.722  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:40.723  INFO 323 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 0
	bootstrap.servers = [127.0.0.1:44019]
	buffer.memory = 33554432
	client.id = KafkaTestUtils Producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-09-24 03:53:40.725  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:40.725  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:40.728  INFO 323 --- [tUtils Producer] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:40.731  INFO 323 --- [quest-handler-0] kafka.server.epoch.LeaderEpochFileCache  : Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: SecondTopic1537754018652-1. Cache now contains 0 entries.
2018-09-24 03:53:41.165  INFO 323 --- [           main] c.salesforce.kafka.test.KafkaTestUtils   : Produce completed
2018-09-24 03:53:41.165  INFO 323 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=KafkaTestUtils Producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-24 03:53:41.168  INFO 323 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:44019]
	check.crcs = true
	client.id = MyPrefix-KafkaWebView-Consumer-UserId12-MySession
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MyPrefix-KafkaWebView-Consumer-UserId12-MySession
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 5
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-24 03:53:41.170  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:41.170  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:41.172  INFO 323 --- [           main] org.apache.kafka.clients.Metadata        : Cluster ID: ZUcvqpWvR1-DHWqJvf6DMg
2018-09-24 03:53:41.176  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Resetting Partition: 1 To Head Offset: 0
2018-09-24 03:53:41.176  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Resetting Partition: 0 To Head Offset: 0
2018-09-24 03:53:41.178  INFO 323 --- [           main] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=MyPrefix-KafkaWebView-Consumer-UserId12-MySession, groupId=MyPrefix-KafkaWebView-Consumer-UserId12-MySession] Discovered group coordinator 127.0.0.1:44019 (id: 2147483646 rack: null)
2018-09-24 03:53:41.209  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed 5 records
2018-09-24 03:53:41.240  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed Partition 1 Records: 5
2018-09-24 03:53:41.245  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed 5 records
2018-09-24 03:53:41.273  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed Partition 0 Records: 5
2018-09-24 03:53:41.278  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed 5 records
2018-09-24 03:53:41.307  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed Partition 1 Records: 5
2018-09-24 03:53:41.310  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed 5 records
2018-09-24 03:53:41.372  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed Partition 0 Records: 5
2018-09-24 03:53:43.375  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed 0 records
2018-09-24 03:53:43.423  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed Partition 1 Records: 0
2018-09-24 03:53:45.425  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed 0 records
2018-09-24 03:53:45.465  INFO 323 --- [           main] o.s.k.w.u.m.kafka.WebKafkaConsumer       : Consumed Partition 0 Records: 0
2018-09-24 03:53:45.509  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Shutting down kafka test server
2018-09-24 03:53:45.509  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shutting down
2018-09-24 03:53:45.509  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Starting controlled shutdown
2018-09-24 03:53:45.513  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Shutting down broker 1
2018-09-24 03:53:45.514  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Controlled shutdown succeeded
2018-09-24 03:53:45.515  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2018-09-24 03:53:45.515  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2018-09-24 03:53:45.515  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2018-09-24 03:53:45.515  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopping socket server request processors
2018-09-24 03:53:45.517  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopped socket server request processors
2018-09-24 03:53:45.517  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shutting down
2018-09-24 03:53:45.517  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shut down completely
2018-09-24 03:53:45.519  INFO 323 --- [           main] kafka.server.KafkaApis                   : [KafkaApi-1] Shutdown complete.
2018-09-24 03:53:45.519  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutting down
2018-09-24 03:53:45.694  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutdown completed
2018-09-24 03:53:45.694  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Stopped
2018-09-24 03:53:45.694  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutting down.
2018-09-24 03:53:45.695  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-24 03:53:45.695  INFO 323 --- [           main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 1]: Shutdown complete
2018-09-24 03:53:45.695  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutting down
2018-09-24 03:53:45.695  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Stopped
2018-09-24 03:53:45.695  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-24 03:53:45.695  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutdown complete.
2018-09-24 03:53:45.695  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutting down.
2018-09-24 03:53:45.695  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-24 03:53:45.699  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-24 03:53:45.699  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-24 03:53:45.699  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-24 03:53:45.899  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Stopped
2018-09-24 03:53:45.899  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-24 03:53:45.899  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutdown complete.
2018-09-24 03:53:45.899  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shutting down
2018-09-24 03:53:45.899  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2018-09-24 03:53:45.899  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2018-09-24 03:53:45.899  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2018-09-24 03:53:45.899  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutting down
2018-09-24 03:53:45.900  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-24 03:53:45.900  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutting down
2018-09-24 03:53:45.900  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2018-09-24 03:53:45.900  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutting down
2018-09-24 03:53:46.033  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-24 03:53:46.033  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Stopped
2018-09-24 03:53:46.034  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutting down
2018-09-24 03:53:46.179  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Stopped
2018-09-24 03:53:46.179  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-24 03:53:46.179  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-24 03:53:46.379  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-24 03:53:46.379  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-24 03:53:46.406  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shut down completely
2018-09-24 03:53:46.406  INFO 323 --- [           main] kafka.log.LogManager                     : Shutting down.
2018-09-24 03:53:46.406  INFO 323 --- [           main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2018-09-24 03:53:46.406  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2018-09-24 03:53:46.407  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2018-09-24 03:53:46.407  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-24 03:53:46.663  INFO 323 --- [ool-41-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=FirstTopic1537754010786-0] Writing producer snapshot at offset 10
2018-09-24 03:53:46.864  INFO 323 --- [ool-41-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=SecondTopic1537754010786-1] Writing producer snapshot at offset 10
2018-09-24 03:53:47.006  INFO 323 --- [ool-41-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=FirstTopic1537754010786-1] Writing producer snapshot at offset 10
2018-09-24 03:53:47.129  INFO 323 --- [ool-41-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=SecondTopic1537754010786-0] Writing producer snapshot at offset 10
2018-09-24 03:53:47.163  INFO 323 --- [ool-41-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=FirstTopic1537754018652-0] Writing producer snapshot at offset 10
2018-09-24 03:53:47.196  INFO 323 --- [ool-41-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=SecondTopic1537754018652-0] Writing producer snapshot at offset 10
2018-09-24 03:53:47.431  INFO 323 --- [ool-41-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=FirstTopic1537754018652-1] Writing producer snapshot at offset 10
2018-09-24 03:53:47.539  INFO 323 --- [ool-41-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-6] Writing producer snapshot at offset 15
2018-09-24 03:53:47.597  INFO 323 --- [ool-41-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=SecondTopic1537754018652-1] Writing producer snapshot at offset 10
2018-09-24 03:53:48.114  INFO 323 --- [           main] kafka.log.LogManager                     : Shutdown complete.
2018-09-24 03:53:48.115  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutting down
2018-09-24 03:53:48.115  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Stopped
2018-09-24 03:53:48.115  INFO 323 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutdown completed
2018-09-24 03:53:48.115  INFO 323 --- [           main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-24 03:53:48.115  INFO 323 --- [           main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-24 03:53:48.115  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutting down
2018-09-24 03:53:48.115  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Stopped
2018-09-24 03:53:48.115  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutdown completed
2018-09-24 03:53:48.117  INFO 323 --- [           main] kafka.controller.KafkaController         : [Controller id=1] Resigned
2018-09-24 03:53:48.117  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2018-09-24 03:53:48.118  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x1660948060c0000
2018-09-24 03:53:48.156  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x1660948060c0000 closed
2018-09-24 03:53:48.157  INFO 323 --- [0/0.0.0.0:32774] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:35268 which had sessionid 0x1660948060c0000
2018-09-24 03:53:48.156  INFO 323 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x1660948060c0000
2018-09-24 03:53:48.157  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2018-09-24 03:53:48.157  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-24 03:53:48.308  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Stopped
2018-09-24 03:53:48.308  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-24 03:53:48.308  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutting down
2018-09-24 03:53:48.308  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Stopped
2018-09-24 03:53:48.308  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-24 03:53:48.308  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutting down
2018-09-24 03:53:49.308  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Stopped
2018-09-24 03:53:49.308  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-24 03:53:49.308  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutting down socket server
2018-09-24 03:53:49.329  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutdown completed
2018-09-24 03:53:49.331  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shut down completed
2018-09-24 03:53:49.332  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Shutting down zookeeper test server
2018-09-24 03:53:49.333  INFO 323 --- [0/0.0.0.0:32774] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:53:49.333  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:53:49.333  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:53:49.333  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:53:49.333  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:53:49.333  INFO 323 --- [0 cport:32774):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:53:49.333  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:53:49.334  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.285 s - in org.sourcelab.kafka.webview.ui.manager.kafka.WebKafkaConsumerFactoryTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.kafka.KafkaAdminFactoryTest
2018-09-24 03:53:49.336  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Starting kafka test server
2018-09-24 03:53:49.336  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:53:49.337  INFO 323 --- [      Thread-24] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:53:49.338  INFO 323 --- [      Thread-24] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:53:49.338  INFO 323 --- [      Thread-24] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:53:49.338  INFO 323 --- [      Thread-24] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:53:49.338  INFO 323 --- [      Thread-24] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:38694
2018-09-24 03:53:50.340  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Starting Zookeeper test server
2018-09-24 03:53:50.341  INFO 323 --- [0/0.0.0.0:38694] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:53:50.342  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:53:50.342  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:53:50.342  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:53:50.342  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:53:50.342  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:53:50.342  INFO 323 --- [0 cport:38694):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:53:50.342  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2018-09-24 03:53:50.343  INFO 323 --- [      Thread-25] o.a.z.server.ZooKeeperServerMain         : Starting server
2018-09-24 03:53:50.344  INFO 323 --- [      Thread-25] o.a.zookeeper.server.ZooKeeperServer     : tickTime set to 3000
2018-09-24 03:53:50.344  INFO 323 --- [      Thread-25] o.a.zookeeper.server.ZooKeeperServer     : minSessionTimeout set to -1
2018-09-24 03:53:50.344  INFO 323 --- [      Thread-25] o.a.zookeeper.server.ZooKeeperServer     : maxSessionTimeout set to -1
2018-09-24 03:53:50.344  INFO 323 --- [      Thread-25] o.a.z.server.NIOServerCnxnFactory        : binding to port 0.0.0.0/0.0.0.0:38694
2018-09-24 03:53:51.000  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:53:51.001  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:53:51.347  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:32799
	advertised.port = 32799
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:32799
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537754031346-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 32799
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38694
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:51.349  INFO 323 --- [           main] kafka.server.KafkaServer                 : starting
2018-09-24 03:53:51.349  INFO 323 --- [           main] kafka.server.KafkaServer                 : Connecting to zookeeper on 127.0.0.1:38694
2018-09-24 03:53:51.349  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Initializing a new session to 127.0.0.1:38694.
2018-09-24 03:53:51.349  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Initiating client connection, connectString=127.0.0.1:38694 sessionTimeout=30000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@407bfc49
2018-09-24 03:53:51.350  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Waiting until connected.
2018-09-24 03:53:51.350  INFO 323 --- [27.0.0.1:38694)] org.apache.zookeeper.ClientCnxn          : Opening socket connection to server 127.0.0.1/127.0.0.1:38694. Will not attempt to authenticate using SASL (unknown error)
2018-09-24 03:53:51.350  INFO 323 --- [27.0.0.1:38694)] org.apache.zookeeper.ClientCnxn          : Socket connection established to 127.0.0.1/127.0.0.1:38694, initiating session
2018-09-24 03:53:51.350  INFO 323 --- [0/0.0.0.0:38694] o.a.z.server.NIOServerCnxnFactory        : Accepted socket connection from /127.0.0.1:50120
2018-09-24 03:53:51.351  INFO 323 --- [0/0.0.0.0:38694] o.a.zookeeper.server.ZooKeeperServer     : Client attempting to establish new session at /127.0.0.1:50120
2018-09-24 03:53:51.351  INFO 323 --- [   SyncThread:0] o.a.z.server.persistence.FileTxnLog      : Creating new log file: log.1
2018-09-24 03:53:51.397  INFO 323 --- [   SyncThread:0] o.a.zookeeper.server.ZooKeeperServer     : Established session 0x166094861090000 with negotiated timeout 30000 for client /127.0.0.1:50120
2018-09-24 03:53:51.398  INFO 323 --- [27.0.0.1:38694)] org.apache.zookeeper.ClientCnxn          : Session establishment complete on server 127.0.0.1/127.0.0.1:38694, sessionid = 0x166094861090000, negotiated timeout = 30000
2018-09-24 03:53:51.398  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Connected.
2018-09-24 03:53:51.440  INFO 323 --- [0 cport:38694):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094861090000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2018-09-24 03:53:51.597  INFO 323 --- [0 cport:38694):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094861090000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2018-09-24 03:53:51.721  INFO 323 --- [0 cport:38694):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094861090000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2018-09-24 03:53:52.149  INFO 323 --- [0 cport:38694):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094861090000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2018-09-24 03:53:52.247  INFO 323 --- [           main] kafka.server.KafkaServer                 : Cluster ID = -GsD1wwwR5u3S0dhYn9iXA
2018-09-24 03:53:52.248  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537754031346-0/meta.properties
2018-09-24 03:53:52.250  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:32799
	advertised.port = 32799
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:32799
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537754031346-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 32799
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38694
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:52.253  INFO 323 --- [           main] kafka.server.KafkaConfig                 : KafkaConfig values: 
	advertised.host.name = 127.0.0.1
	advertised.listeners = PLAINTEXT://127.0.0.1:32799
	advertised.port = 32799
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 127.0.0.1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 1.1-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://127.0.0.1:32799
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/1537754031346-0
	log.dirs = null
	log.flush.interval.messages = 1
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 1.1-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 2
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 32799
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 4
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:38694
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 30000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2018-09-24 03:53:52.255  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Starting
2018-09-24 03:53:52.255  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Starting
2018-09-24 03:53:52.256  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Starting
2018-09-24 03:53:52.257  INFO 323 --- [           main] kafka.log.LogManager                     : Loading logs.
2018-09-24 03:53:52.257  INFO 323 --- [           main] kafka.log.LogManager                     : Logs loading complete in 0 ms.
2018-09-24 03:53:52.258  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log cleanup with a period of 300000 ms.
2018-09-24 03:53:52.258  INFO 323 --- [           main] kafka.log.LogManager                     : Starting log flusher with a default period of 9223372036854775807 ms.
2018-09-24 03:53:52.259  INFO 323 --- [           main] kafka.log.LogCleaner                     : Starting the log cleaner
2018-09-24 03:53:52.297  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Starting
2018-09-24 03:53:52.313  INFO 323 --- [           main] kafka.network.Acceptor                   : Awaiting socket connections on 127.0.0.1:32799.
2018-09-24 03:53:52.315  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started 1 acceptor threads
2018-09-24 03:53:52.316  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Starting
2018-09-24 03:53:52.317  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Starting
2018-09-24 03:53:52.317  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Starting
2018-09-24 03:53:52.319  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Starting
2018-09-24 03:53:52.319  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Creating /brokers/ids/1 (is it secure? false)
2018-09-24 03:53:52.356  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Result of znode creation at /brokers/ids/1 is: OK
2018-09-24 03:53:52.356  INFO 323 --- [           main] kafka.zk.KafkaZkClient                   : Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(127.0.0.1,32799,ListenerName(PLAINTEXT),PLAINTEXT))
2018-09-24 03:53:52.356  WARN 323 --- [           main] kafka.server.BrokerMetadataCheckpoint    : No meta.properties file under dir /tmp/1537754031346-0/meta.properties
2018-09-24 03:53:52.382  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Starting
2018-09-24 03:53:52.383  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Starting
2018-09-24 03:53:52.384  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Starting
2018-09-24 03:53:52.384  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Starting
2018-09-24 03:53:52.385  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Starting up.
2018-09-24 03:53:52.385  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Creating /controller (is it secure? false)
2018-09-24 03:53:52.385  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Startup complete.
2018-09-24 03:53:52.385  INFO 323 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2018-09-24 03:53:52.414  INFO 323 --- [er-event-thread] kafka.zk.KafkaZkClient                   : Result of znode creation at /controller is: OK
2018-09-24 03:53:52.415  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] 1 successfully elected as the controller
2018-09-24 03:53:52.415  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Reading controller epoch from ZooKeeper
2018-09-24 03:53:52.447  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Incrementing controller epoch in ZooKeeper
2018-09-24 03:53:52.447  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2018-09-24 03:53:52.448  INFO 323 --- [0 cport:38694):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094861090000 type:setData cxid:0x23 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2018-09-24 03:53:52.489  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Starting up.
2018-09-24 03:53:52.489  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Startup complete.
2018-09-24 03:53:52.489  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Starting
2018-09-24 03:53:52.491  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Starting
2018-09-24 03:53:52.521  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Epoch incremented to 1
2018-09-24 03:53:52.521  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Registering handlers
2018-09-24 03:53:52.523  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting log dir event notifications
2018-09-24 03:53:52.523  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Deleting isr change notifications
2018-09-24 03:53:52.524  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing controller context
2018-09-24 03:53:52.524  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Started processors for 1 acceptors
2018-09-24 03:53:52.524  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:52.524  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:52.524  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] started
2018-09-24 03:53:52.524  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:32799]
	client.id = test-consumer-id
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:52.525  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:52.525  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:52.529  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Starting
2018-09-24 03:53:52.529  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions being reassigned: Map()
2018-09-24 03:53:52.529  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently active brokers in the cluster: Set(1)
2018-09-24 03:53:52.529  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Currently shutting brokers in the cluster: Set()
2018-09-24 03:53:52.529  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Current list of topics in the cluster: Set()
2018-09-24 03:53:52.529  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Fetching topic deletions in progress
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics to be deleted: 
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] List of topics ineligible for deletion: 
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Initializing topic deletion manager
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Sending update metadata request
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Initializing replica state
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Triggering online replica state changes
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Initializing partition state
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Triggering online partition state changes
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2018-09-24 03:53:52.530  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Ready to serve as the new controller with epoch 1
2018-09-24 03:53:52.531  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Controller 1 connected to 127.0.0.1:32799 (id: 1 rack: null) for sending state change requests
2018-09-24 03:53:52.531  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions undergoing preferred replica election: 
2018-09-24 03:53:52.531  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Partitions that completed preferred replica election: 
2018-09-24 03:53:52.531  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2018-09-24 03:53:52.531  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Resuming preferred replica election for partitions: 
2018-09-24 03:53:52.531  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting preferred replica leader election for partitions 
2018-09-24 03:53:52.532  INFO 323 --- [0 cport:38694):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x166094861090000 type:delete cxid:0x37 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2018-09-24 03:53:52.571  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Starting the controller scheduler
2018-09-24 03:53:52.630  INFO 323 --- [est-consumer-id] org.apache.kafka.clients.Metadata        : Cluster ID: -GsD1wwwR5u3S0dhYn9iXA
2018-09-24 03:53:52.634  INFO 323 --- [           main] c.s.kafka.test.KafkaTestCluster          : Found 1 brokers on-line, cluster is ready.
2018-09-24 03:53:52.635  INFO 323 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:32799]
	client.id = MyClientId
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 15000
	retries = 5
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2018-09-24 03:53:52.636  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 1.1.1
2018-09-24 03:53:52.636  INFO 323 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : 98b6346a977495f6
2018-09-24 03:53:52.739  INFO 323 --- [ad | MyClientId] org.apache.kafka.clients.Metadata        : Cluster ID: -GsD1wwwR5u3S0dhYn9iXA
2018-09-24 03:53:52.741  INFO 323 --- [           main] c.s.k.t.junit4.SharedKafkaTestResource   : Shutting down kafka test server
2018-09-24 03:53:52.741  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shutting down
2018-09-24 03:53:52.741  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Starting controlled shutdown
2018-09-24 03:53:52.744  INFO 323 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=1] Shutting down broker 1
2018-09-24 03:53:52.744  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] Controlled shutdown succeeded
2018-09-24 03:53:52.745  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2018-09-24 03:53:52.745  INFO 323 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2018-09-24 03:53:52.745  INFO 323 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2018-09-24 03:53:52.745  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopping socket server request processors
2018-09-24 03:53:52.746  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Stopped socket server request processors
2018-09-24 03:53:52.746  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shutting down
2018-09-24 03:53:52.746  INFO 323 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 1], shut down completely
2018-09-24 03:53:52.747  INFO 323 --- [           main] kafka.server.KafkaApis                   : [KafkaApi-1] Shutdown complete.
2018-09-24 03:53:52.747  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutting down
2018-09-24 03:53:52.783  INFO 323 --- [nReaper-1-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Stopped
2018-09-24 03:53:52.783  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-topic]: Shutdown completed
2018-09-24 03:53:52.784  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutting down.
2018-09-24 03:53:52.784  INFO 323 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
2018-09-24 03:53:52.784  INFO 323 --- [           main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 1]: Shutdown complete
2018-09-24 03:53:52.784  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutting down
2018-09-24 03:53:52.784  INFO 323 --- [rSenderThread-1] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Stopped
2018-09-24 03:53:52.784  INFO 323 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 1]: Shutdown completed
2018-09-24 03:53:52.784  INFO 323 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=1] Shutdown complete.
2018-09-24 03:53:52.784  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutting down.
2018-09-24 03:53:52.784  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutting down
2018-09-24 03:53:52.984  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Shutdown completed
2018-09-24 03:53:52.984  INFO 323 --- [per-1-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Heartbeat]: Stopped
2018-09-24 03:53:52.984  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutting down
2018-09-24 03:53:53.185  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Shutdown completed
2018-09-24 03:53:53.185  INFO 323 --- [per-1-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Rebalance]: Stopped
2018-09-24 03:53:53.185  INFO 323 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 1]: Shutdown complete.
2018-09-24 03:53:53.185  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shutting down
2018-09-24 03:53:53.185  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2018-09-24 03:53:53.185  INFO 323 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2018-09-24 03:53:53.185  INFO 323 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2018-09-24 03:53:53.185  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutting down
2018-09-24 03:53:53.185  INFO 323 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 1] shutdown completed
2018-09-24 03:53:53.185  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutting down
2018-09-24 03:53:53.185  INFO 323 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2018-09-24 03:53:53.185  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutting down
2018-09-24 03:53:53.317  INFO 323 --- [nReaper-1-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Stopped
2018-09-24 03:53:53.317  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Fetch]: Shutdown completed
2018-09-24 03:53:53.318  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutting down
2018-09-24 03:53:53.517  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Shutdown completed
2018-09-24 03:53:53.517  INFO 323 --- [eaper-1-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-Produce]: Stopped
2018-09-24 03:53:53.517  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutting down
2018-09-24 03:53:53.518  INFO 323 --- [1-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Stopped
2018-09-24 03:53:53.518  INFO 323 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2018-09-24 03:53:53.518  INFO 323 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=1] Shut down completely
2018-09-24 03:53:53.518  INFO 323 --- [           main] kafka.log.LogManager                     : Shutting down.
2018-09-24 03:53:53.518  INFO 323 --- [           main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2018-09-24 03:53:53.518  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2018-09-24 03:53:53.518  INFO 323 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2018-09-24 03:53:53.518  INFO 323 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2018-09-24 03:53:53.519  INFO 323 --- [           main] kafka.log.LogManager                     : Shutdown complete.
2018-09-24 03:53:53.519  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutting down
2018-09-24 03:53:53.519  INFO 323 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Stopped
2018-09-24 03:53:53.519  INFO 323 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=1] Shutdown completed
2018-09-24 03:53:53.519  INFO 323 --- [           main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=1] Stopped partition state machine
2018-09-24 03:53:53.519  INFO 323 --- [           main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=1] Stopped replica state machine
2018-09-24 03:53:53.519  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutting down
2018-09-24 03:53:53.519  INFO 323 --- [r-1-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Stopped
2018-09-24 03:53:53.519  INFO 323 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=1] Shutdown completed
2018-09-24 03:53:53.520  INFO 323 --- [           main] kafka.controller.KafkaController         : [Controller id=1] Resigned
2018-09-24 03:53:53.521  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2018-09-24 03:53:53.521  INFO 323 --- [0 cport:38694):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x166094861090000
2018-09-24 03:53:53.556  INFO 323 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x166094861090000 closed
2018-09-24 03:53:53.556  INFO 323 --- [0/0.0.0.0:38694] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:50120 which had sessionid 0x166094861090000
2018-09-24 03:53:53.556  INFO 323 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x166094861090000
2018-09-24 03:53:53.557  INFO 323 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2018-09-24 03:53:53.557  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutting down
2018-09-24 03:53:54.255  INFO 323 --- [estReaper-Fetch] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Stopped
2018-09-24 03:53:54.255  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Fetch]: Shutdown completed
2018-09-24 03:53:54.255  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutting down
2018-09-24 03:53:54.256  INFO 323 --- [tReaper-Produce] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Stopped
2018-09-24 03:53:54.256  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Produce]: Shutdown completed
2018-09-24 03:53:54.256  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutting down
2018-09-24 03:53:54.256  INFO 323 --- [tReaper-Request] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Stopped
2018-09-24 03:53:54.256  INFO 323 --- [           main] lientQuotaManager$ThrottledRequestReaper : [ThrottledRequestReaper-Request]: Shutdown completed
2018-09-24 03:53:54.256  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutting down socket server
2018-09-24 03:53:54.266  INFO 323 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=1] Shutdown completed
2018-09-24 03:53:54.267  INFO 323 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=1] shut down completed
2018-09-24 03:53:54.267  INFO 323 --- [           main] c.s.kafka.test.ZookeeperTestServer       : Shutting down zookeeper test server
2018-09-24 03:53:54.267  INFO 323 --- [0/0.0.0.0:38694] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2018-09-24 03:53:54.268  INFO 323 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2018-09-24 03:53:54.268  INFO 323 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2018-09-24 03:53:54.268  INFO 323 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2018-09-24 03:53:54.268  INFO 323 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2018-09-24 03:53:54.268  INFO 323 --- [0 cport:38694):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2018-09-24 03:53:54.268  INFO 323 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2018-09-24 03:53:54.268  INFO 323 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.929 s - in org.sourcelab.kafka.webview.ui.manager.kafka.KafkaAdminFactoryTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.encryption.Sha1ToolsTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.015 s - in org.sourcelab.kafka.webview.ui.manager.encryption.Sha1ToolsTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.encryption.SecretManagerTest
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.245 s - in org.sourcelab.kafka.webview.ui.manager.encryption.SecretManagerTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.plugin.PluginFactoryTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.006 s - in org.sourcelab.kafka.webview.ui.manager.plugin.PluginFactoryTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.plugin.PluginClassLoaderTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in org.sourcelab.kafka.webview.ui.manager.plugin.PluginClassLoaderTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.plugin.UploadManagerTest
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in org.sourcelab.kafka.webview.ui.manager.plugin.UploadManagerTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.socket.WebSocketConsumersManagerTest
2018-09-24 03:53:55.176  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.177  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.179  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.183  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.184  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.186  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.186  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.188  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.189  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.192  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.192  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
2018-09-24 03:53:55.194  INFO 323 --- [           main] o.s.k.w.u.m.s.WebSocketConsumersManager  : Added new web socket consumer, now has 0/0 running consumers
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.615 s - in org.sourcelab.kafka.webview.ui.manager.socket.WebSocketConsumersManagerTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.socket.ConsumerKeyTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in org.sourcelab.kafka.webview.ui.manager.socket.ConsumerKeyTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.socket.PresenceEventListenerTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.028 s - in org.sourcelab.kafka.webview.ui.manager.socket.PresenceEventListenerTest
[INFO] Running org.sourcelab.kafka.webview.ui.manager.UtilsTest
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in org.sourcelab.kafka.webview.ui.manager.UtilsTest
[INFO] Running org.sourcelab.kafka.webview.ui.model.ClusterTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in org.sourcelab.kafka.webview.ui.model.ClusterTest
[INFO] Running org.sourcelab.kafka.webview.ui.model.ModelsTest
2018-09-24 03:53:55.233  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Neither @ContextConfiguration nor @ContextHierarchy found for test class [org.sourcelab.kafka.webview.ui.model.ModelsTest], using SpringBootContextLoader
2018-09-24 03:53:55.234  INFO 323 --- [           main] o.s.t.c.support.AbstractContextLoader    : Could not detect default resource locations for test class [org.sourcelab.kafka.webview.ui.model.ModelsTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-09-24 03:53:55.234  INFO 323 --- [           main] t.c.s.AnnotationConfigContextLoaderUtils : Could not detect default configuration classes for test class [org.sourcelab.kafka.webview.ui.model.ModelsTest]: ModelsTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2018-09-24 03:53:55.259  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Found @SpringBootConfiguration org.sourcelab.kafka.webview.ui.Application for test class org.sourcelab.kafka.webview.ui.model.ModelsTest
2018-09-24 03:53:55.260  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener]
2018-09-24 03:53:55.260  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@2a9732a7, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5170ebb6, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@773236a7, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@1abe611c, org.springframework.test.context.support.DirtiesContextTestExecutionListener@92f6ae6, org.springframework.test.context.transaction.TransactionalTestExecutionListener@5fd40d2e, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@39b58f7d, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@50eaafd6, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@22608777, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@5d225368, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@48f9f1d6, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@4d687300, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@6b951ee5, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@2463a9ec]

  _  __      __ _          __          __  _      __      ___
 | |/ /     / _| |         \ \        / / | |     \ \    / (_)
 | ' / __ _| |_| | ____ _   \ \  /\  / /__| |__    \ \  / / _  _____      __
 |  < / _` |  _| |/ / _` |   \ \/  \/ / _ \ '_ \    \ \/ / | |/ _ \ \ /\ / /
 | . \ (_| | | |   < (_| |    \  /\  /  __/ |_) |    \  /  | |  __/\ V  V /
 |_|\_\__,_|_| |_|\_\__,_|     \/  \/ \___|_.__/      \/   |_|\___| \_/\_/



2018-09-24 03:53:55.309  INFO 323 --- [           main] o.s.kafka.webview.ui.model.ModelsTest    : Starting ModelsTest on cyclone1 with PID 323 (started by root in /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui)
2018-09-24 03:53:55.310  INFO 323 --- [           main] o.s.kafka.webview.ui.model.ModelsTest    : No active profile set, falling back to default profiles: default
2018-09-24 03:53:55.313  INFO 323 --- [           main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@77f5cffd: startup date [Mon Sep 24 03:53:55 CEST 2018]; root of context hierarchy
2018-09-24 03:53:55.549  INFO 323 --- [           main] beddedDataSourceBeanFactoryPostProcessor : Replacing 'dataSource' DataSource bean with embedded version
2018-09-24 03:53:55.551  INFO 323 --- [           main] o.s.b.f.s.DefaultListableBeanFactory     : Overriding bean definition for bean 'dataSource' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration$Hikari; factoryMethodName=dataSource; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/jdbc/DataSourceConfiguration$Hikari.class]] with [Root bean: class [org.springframework.boot.test.autoconfigure.jdbc.TestDatabaseAutoConfiguration$EmbeddedDataSourceFactoryBean]; scope=; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null]
2018-09-24 03:53:55.634  INFO 323 --- [           main] o.s.j.d.e.EmbeddedDatabaseFactory        : Starting embedded database: url='jdbc:h2:mem:e6387098-6669-42cc-91d9-a37ff6d39275;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=false', username='sa'
2018-09-24 03:53:55.693  INFO 323 --- [           main] o.s.jdbc.datasource.init.ScriptUtils     : Executing SQL script from class path resource [schema/schema.sql]
2018-09-24 03:53:55.726  INFO 323 --- [           main] o.s.jdbc.datasource.init.ScriptUtils     : Executed SQL script from class path resource [schema/schema.sql] in 33 ms.
2018-09-24 03:53:55.780  INFO 323 --- [           main] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-09-24 03:53:55.780  INFO 323 --- [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-09-24 03:53:55.798  INFO 323 --- [           main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-09-24 03:53:55.904  INFO 323 --- [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-09-24 03:53:56.171  INFO 323 --- [           main] o.s.kafka.webview.ui.model.ModelsTest    : Started ModelsTest in 0.908 seconds (JVM running for 107.876)
2018-09-24 03:53:56.187  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Began transaction (1) for test context [DefaultTestContext@25a8128 testClass = ModelsTest, testInstance = org.sourcelab.kafka.webview.ui.model.ModelsTest@3bb75054, testMethod = smokeTest@ModelsTest, testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d980dac testClass = ModelsTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@15329cf9 key = [org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration, org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration, org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration, org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration, org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration, org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration, org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration, org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration, org.springframework.boot.test.autoconfigure.jdbc.TestDatabaseAutoConfiguration, org.springframework.boot.test.autoconfigure.orm.jpa.TestEntityManagerAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@159b4611, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@351584c0, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@f9e28747, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map[[empty]]]; transaction manager [org.springframework.orm.jpa.JpaTransactionManager@3e62fe4d]; rollback [true]
Hibernate: insert into cluster (id, broker_hosts, is_ssl_enabled, is_valid, key_store_file, key_store_password, name, trust_store_file, trust_store_password) values (null, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into message_format (id, classpath, is_default_format, jar, name, option_parameters) values (null, ?, ?, ?, ?, ?)
Hibernate: insert into filter (id, classpath, jar, name, options) values (null, ?, ?, ?, ?)
Hibernate: insert into filter (id, classpath, jar, name, options) values (null, ?, ?, ?, ?)
Hibernate: insert into view (id, cluster_id, created_at, key_message_format_id, name, partitions, results_per_partition, topic, updated_at, value_message_format_id) values (null, ?, ?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: insert into view_to_filter_enforced (id, filter_id, option_parameters, sort_order, view_id) values (null, ?, ?, ?, ?)
Hibernate: insert into view_to_filter_optional (id, filter_id, sort_order, view_id) values (null, ?, ?, ?)
2018-09-24 03:53:56.213  INFO 323 --- [           main] o.s.t.c.transaction.TransactionContext   : Rolled back transaction for test: [DefaultTestContext@25a8128 testClass = ModelsTest, testInstance = org.sourcelab.kafka.webview.ui.model.ModelsTest@3bb75054, testMethod = smokeTest@ModelsTest, testException = [null], mergedContextConfiguration = [MergedContextConfiguration@d980dac testClass = ModelsTest, locations = '{}', classes = '{class org.sourcelab.kafka.webview.ui.Application}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[[ImportsContextCustomizer@15329cf9 key = [org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration, org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration, org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration, org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration, org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration, org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration, org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration, org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration, org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration, org.springframework.boot.test.autoconfigure.jdbc.TestDatabaseAutoConfiguration, org.springframework.boot.test.autoconfigure.orm.jpa.TestEntityManagerAutoConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@51931956, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@18a70f16, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@159b4611, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@351584c0, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@f9e28747, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@534df152], contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map[[empty]]]
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.966 s - in org.sourcelab.kafka.webview.ui.model.ModelsTest
[INFO] Running org.sourcelab.kafka.webview.ui.configuration.AppPropertiesTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in org.sourcelab.kafka.webview.ui.configuration.AppPropertiesTest
[INFO] Running org.sourcelab.kafka.webview.ui.ApplicationTest
2018-09-24 03:53:56.216  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Neither @ContextConfiguration nor @ContextHierarchy found for test class [org.sourcelab.kafka.webview.ui.ApplicationTest], using SpringBootContextLoader
2018-09-24 03:53:56.217  INFO 323 --- [           main] o.s.t.c.support.AbstractContextLoader    : Could not detect default resource locations for test class [org.sourcelab.kafka.webview.ui.ApplicationTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2018-09-24 03:53:56.217  INFO 323 --- [           main] t.c.s.AnnotationConfigContextLoaderUtils : Could not detect default configuration classes for test class [org.sourcelab.kafka.webview.ui.ApplicationTest]: ApplicationTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2018-09-24 03:53:56.222  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Found @SpringBootConfiguration org.sourcelab.kafka.webview.ui.Application for test class org.sourcelab.kafka.webview.ui.ApplicationTest
2018-09-24 03:53:56.223  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener]
2018-09-24 03:53:56.224  INFO 323 --- [           main] .b.t.c.SpringBootTestContextBootstrapper : Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@a90447f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7abe70f7, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@541b377d, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@7a343975, org.springframework.test.context.support.DirtiesContextTestExecutionListener@720f29f0, org.springframework.test.context.transaction.TransactionalTestExecutionListener@7b3fd68e, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@7612a64b, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@2db6d66d, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@26fd2a82, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@23f31375, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@40b0c9be, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@5bae7a7b, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@1448e2b6, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@2f9b33f1]

  _  __      __ _          __          __  _      __      ___
 | |/ /     / _| |         \ \        / / | |     \ \    / (_)
 | ' / __ _| |_| | ____ _   \ \  /\  / /__| |__    \ \  / / _  _____      __
 |  < / _` |  _| |/ / _` |   \ \/  \/ / _ \ '_ \    \ \/ / | |/ _ \ \ /\ / /
 | . \ (_| | | |   < (_| |    \  /\  /  __/ |_) |    \  /  | |  __/\ V  V /
 |_|\_\__,_|_| |_|\_\__,_|     \/  \/ \___|_.__/      \/   |_|\___| \_/\_/



2018-09-24 03:53:56.263  INFO 323 --- [           main] o.s.kafka.webview.ui.ApplicationTest     : Starting ApplicationTest on cyclone1 with PID 323 (started by root in /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui)
2018-09-24 03:53:56.264  INFO 323 --- [           main] o.s.kafka.webview.ui.ApplicationTest     : No active profile set, falling back to default profiles: default
2018-09-24 03:53:56.266  INFO 323 --- [           main] o.s.w.c.s.GenericWebApplicationContext   : Refreshing org.springframework.web.context.support.GenericWebApplicationContext@21d1a0da: startup date [Mon Sep 24 03:53:56 CEST 2018]; root of context hierarchy
2018-09-24 03:53:56.917  INFO 323 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c84796a2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-09-24 03:53:57.000  INFO 323 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2018-09-24 03:53:57.081  INFO 323 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-3 - Starting...
2018-09-24 03:53:57.084  INFO 323 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-3 - Start completed.
2018-09-24 03:53:57.084  INFO 323 --- [           main] o.s.jdbc.datasource.init.ScriptUtils     : Executing SQL script from class path resource [schema/schema.sql]
2018-09-24 03:53:57.088  INFO 323 --- [           main] o.s.jdbc.datasource.init.ScriptUtils     : Executed SQL script from class path resource [schema/schema.sql] in 4 ms.
2018-09-24 03:53:57.170  INFO 323 --- [           main] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-09-24 03:53:57.170  INFO 323 --- [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-09-24 03:53:57.190  INFO 323 --- [           main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-09-24 03:53:57.292  INFO 323 --- [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-09-24 03:53:57.649  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'clientInboundChannelExecutor'
2018-09-24 03:53:57.655  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'clientOutboundChannelExecutor'
2018-09-24 03:53:57.663  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 
2018-09-24 03:53:57.663  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'backgroundConsumerExecutor'
2018-09-24 03:53:57.826  INFO 323 --- [           main] o.s.s.web.DefaultSecurityFilterChain     : Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@7acc95a2, org.springframework.security.web.context.SecurityContextPersistenceFilter@42775280, org.springframework.security.web.header.HeaderWriterFilter@16db679e, org.springframework.security.web.csrf.CsrfFilter@7b31281b, org.springframework.security.web.authentication.logout.LogoutFilter@472d7ab0, org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter@7b6419dd, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@1cce2194, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@51645204, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@3228b5a1, org.springframework.security.web.session.SessionManagementFilter@3074d565, org.springframework.security.web.access.ExceptionTranslationFilter@5381acc6, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@32e14e55]
2018-09-24 03:53:57.840  WARN 323 --- [           main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2018-09-24 03:53:57.874  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topics/list],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicListing> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getTopics(java.lang.Long)
2018-09-24 03:53:57.875  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/create/topic],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.controller.api.responses.ResultResponse org.sourcelab.kafka.webview.ui.controller.api.ApiController.createTopic(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.CreateTopicRequest)
2018-09-24 03:53:57.875  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topic/{topic}/details],methods=[GET],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicDetails org.sourcelab.kafka.webview.ui.controller.api.ApiController.getTopicDetails(java.lang.Long,java.lang.String)
2018-09-24 03:53:57.875  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topic/{topic}/config],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConfigItem> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getTopicConfig(java.lang.Long,java.lang.String)
2018-09-24 03:53:57.875  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/broker/{brokerId}/config],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConfigItem> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getBrokerConfig(java.lang.Long,java.lang.String)
2018-09-24 03:53:57.876  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/nodes],methods=[GET],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.NodeDetails> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getClusterNodes(java.lang.Long)
2018-09-24 03:53:57.876  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/consumer/view/{id}],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.KafkaResults org.sourcelab.kafka.webview.ui.controller.api.ApiController.consume(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.ConsumeRequest)
2018-09-24 03:53:57.876  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/consumer/view/{id}/offsets],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConsumerState org.sourcelab.kafka.webview.ui.controller.api.ApiController.setConsumerOffsets(java.lang.Long,java.util.Map<java.lang.Integer, java.lang.Long>)
2018-09-24 03:53:57.876  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/consumer/view/{id}/timestamp/{timestamp}],methods=[POST],produces=[application/json]}" onto public org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConsumerState org.sourcelab.kafka.webview.ui.controller.api.ApiController.setConsumerOffsetsByTimestamp(java.lang.Long,java.lang.Long)
2018-09-24 03:53:57.876  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/view/{id}/partitions],methods=[GET],produces=[application/json]}" onto public java.util.Collection<java.lang.Integer> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getPartitionsForView(java.lang.Long)
2018-09-24 03:53:57.877  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/topics/details],methods=[GET],produces=[application/json]}" onto public java.util.Collection<org.sourcelab.kafka.webview.ui.manager.kafka.dto.TopicDetails> org.sourcelab.kafka.webview.ui.controller.api.ApiController.getAllTopicsDetails(java.lang.Long)
2018-09-24 03:53:57.877  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/cluster/{id}/modify/topic],methods=[POST],produces=[application/json]}" onto public java.util.List<org.sourcelab.kafka.webview.ui.manager.kafka.dto.ConfigItem> org.sourcelab.kafka.webview.ui.controller.api.ApiController.modifyTopicConfig(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.ModifyTopicConfigRequest)
2018-09-24 03:53:57.877  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/api/filter/{id}/options],methods=[GET],produces=[application/json]}" onto public java.lang.String[] org.sourcelab.kafka.webview.ui.controller.api.ApiController.getFilterOptions(java.lang.Long)
2018-09-24 03:53:57.878  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.clusterIndex(org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.878  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster/{clusterId}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readCluster(java.lang.Long,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.878  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster/{clusterId}/broker/{brokerId}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readBroker(java.lang.Long,java.lang.Integer,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.879  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/cluster/{clusterId}/topic/{topic:.+}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.cluster.ClusterController.readTopic(java.lang.Long,java.lang.String,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.879  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.ConfigurationController.index(org.springframework.ui.Model)
2018-09-24 03:53:57.880  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.createClusterForm(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.ui.Model)
2018-09-24 03:53:57.881  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.editClusterForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:53:57.881  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.clusterUpdate(org.sourcelab.kafka.webview.ui.controller.configuration.cluster.forms.ClusterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.881  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.deleteCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.881  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster/test/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.testCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.881  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/cluster],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.cluster.ClusterConfigController.index(org.springframework.ui.Model)
2018-09-24 03:53:57.883  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.createFilter(org.sourcelab.kafka.webview.ui.controller.configuration.filter.forms.FilterForm,org.springframework.ui.Model)
2018-09-24 03:53:57.883  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.editFilter(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.filter.forms.FilterForm,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.883  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.index(org.springframework.ui.Model)
2018-09-24 03:53:57.883  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.update(org.sourcelab.kafka.webview.ui.controller.configuration.filter.forms.FilterForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.883  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/filter/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.filter.FilterConfigController.delete(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.884  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.createMessageFormat(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.ui.Model)
2018-09-24 03:53:57.885  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.deleteCluster(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.885  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.editMessageFormat(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.885  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.index(org.springframework.ui.Model)
2018-09-24 03:53:57.885  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/messageFormat/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.MessageFormatController.create(org.sourcelab.kafka.webview.ui.controller.configuration.messageformat.forms.MessageFormatForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:53:57.886  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/stream/close/{hash}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController.closeConsumer(java.lang.String,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.886  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/stream],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.stream.StreamConfigController.index(org.springframework.ui.Model)
2018-09-24 03:53:57.887  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.createUser(org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.ui.Model)
2018-09-24 03:53:57.887  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.editUserForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:53:57.887  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.index(org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.ui.Model)
2018-09-24 03:53:57.887  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.update(org.sourcelab.kafka.webview.ui.controller.configuration.user.forms.UserForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:53:57.887  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/user/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.user.UserController.delete(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.888  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/create],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.createViewForm(org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.ui.Model)
2018-09-24 03:53:57.889  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/edit/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.editViewForm(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:53:57.889  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/update],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.updateView(org.sourcelab.kafka.webview.ui.controller.configuration.view.forms.ViewForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:53:57.889  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view/delete/{id}],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.deleteView(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.889  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/configuration/view],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.configuration.view.ViewConfigController.index(org.springframework.ui.Model)
2018-09-24 03:53:57.890  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.home.HomeController.home(org.springframework.ui.Model)
2018-09-24 03:53:57.890  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/help],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.home.HomeController.help(org.springframework.ui.Model)
2018-09-24 03:53:57.891  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/me],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.me(org.springframework.security.core.Authentication)
2018-09-24 03:53:57.891  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.loginForm(org.springframework.ui.Model,java.lang.String)
2018-09-24 03:53:57.891  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/lostPassword],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.lostPasswordForm(org.sourcelab.kafka.webview.ui.controller.login.forms.LostPasswordForm)
2018-09-24 03:53:57.891  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/lostPassword],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.lostPasswordFormSubmit(org.sourcelab.kafka.webview.ui.controller.login.forms.LostPasswordForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:53:57.891  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/resetPassword],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.resetPasswordForm(org.sourcelab.kafka.webview.ui.controller.login.forms.ResetPasswordForm)
2018-09-24 03:53:57.892  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/login/resetPassword],methods=[POST]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.login.LoginController.resetPasswordFormSubmit(org.sourcelab.kafka.webview.ui.controller.login.forms.ResetPasswordForm,org.springframework.validation.BindingResult,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:53:57.892  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/stream],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.index(org.springframework.ui.Model)
2018-09-24 03:53:57.892  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/stream/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.stream(java.lang.Long,org.springframework.ui.Model,org.springframework.web.servlet.mvc.support.RedirectAttributes)
2018-09-24 03:53:57.893  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/view/{id}],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.view.ViewController.index(java.lang.Long,org.springframework.web.servlet.mvc.support.RedirectAttributes,org.springframework.ui.Model)
2018-09-24 03:53:57.893  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/view],methods=[GET]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.view.ViewController.index(org.springframework.ui.Model,java.lang.Long)
2018-09-24 03:53:57.895  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-09-24 03:53:57.896  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-09-24 03:53:57.936  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/css/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:53:57.936  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/js/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:53:57.936  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/vendors/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:53:57.936  INFO 323 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/img/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-09-24 03:53:57.973  INFO 323 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.web.context.support.GenericWebApplicationContext@21d1a0da: startup date [Mon Sep 24 03:53:56 CEST 2018]; root of context hierarchy
2018-09-24 03:53:58.007  INFO 323 --- [           main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService  'messageBrokerTaskScheduler'
2018-09-24 03:53:58.020  INFO 323 --- [           main] o.s.w.s.s.s.WebSocketHandlerMapping      : Mapped URL path [/websocket/**] onto handler of type [class org.springframework.web.socket.sockjs.support.SockJsHttpRequestHandler]
2018-09-24 03:53:58.028  INFO 323 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService  'brokerChannelExecutor'
2018-09-24 03:53:58.046  INFO 323 --- [           main] .WebSocketAnnotationMethodMessageHandler : Mapped "{[/pause/{viewId}],messageType=[MESSAGE]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.pauseConsumer(java.lang.Long,org.springframework.messaging.simp.SimpMessageHeaderAccessor)
2018-09-24 03:53:58.046  INFO 323 --- [           main] .WebSocketAnnotationMethodMessageHandler : Mapped "{[/resume/{viewId}],messageType=[MESSAGE]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.resumeConsumer(java.lang.Long,org.springframework.messaging.simp.SimpMessageHeaderAccessor)
2018-09-24 03:53:58.046  INFO 323 --- [           main] .WebSocketAnnotationMethodMessageHandler : Mapped "{[/consume/{viewId}],messageType=[MESSAGE]}" onto public java.lang.String org.sourcelab.kafka.webview.ui.controller.stream.StreamController.newConsumer(java.lang.Long,org.sourcelab.kafka.webview.ui.controller.api.requests.ConsumeRequest,org.springframework.messaging.simp.SimpMessageHeaderAccessor)
2018-09-24 03:53:58.646  INFO 323 --- [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'
2018-09-24 03:53:58.660  INFO 323 --- [           main] s.b.a.e.w.s.WebMvcEndpointHandlerMapping : Mapped "{[/actuator/health],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:53:58.660  INFO 323 --- [           main] s.b.a.e.w.s.WebMvcEndpointHandlerMapping : Mapped "{[/actuator/info],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.web.servlet.AbstractWebMvcEndpointHandlerMapping$OperationHandler.handle(javax.servlet.http.HttpServletRequest,java.util.Map<java.lang.String, java.lang.String>)
2018-09-24 03:53:58.660  INFO 323 --- [           main] s.b.a.e.w.s.WebMvcEndpointHandlerMapping : Mapped "{[/actuator],methods=[GET],produces=[application/vnd.spring-boot.actuator.v2+json || application/json]}" onto protected java.util.Map<java.lang.String, java.util.Map<java.lang.String, org.springframework.boot.actuate.endpoint.web.Link>> org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping.links(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-09-24 03:53:58.823  INFO 323 --- [           main] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-09-24 03:53:58.824  INFO 323 --- [           main] o.s.m.s.b.SimpleBrokerMessageHandler     : Starting...
2018-09-24 03:53:58.824  INFO 323 --- [           main] o.s.m.s.b.SimpleBrokerMessageHandler     : BrokerAvailabilityEvent[available=true, SimpleBrokerMessageHandler [DefaultSubscriptionRegistry[cache[0 destination(s)], registry[0 sessions]]]]
2018-09-24 03:53:58.824  INFO 323 --- [           main] o.s.m.s.b.SimpleBrokerMessageHandler     : Started.
2018-09-24 03:53:58.833  INFO 323 --- [           main] o.s.kafka.webview.ui.ApplicationTest     : Started ApplicationTest in 2.607 seconds (JVM running for 110.539)
2018-09-24 03:53:58.838  INFO 323 --- [           main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
Hibernate: select count(*) as col_0_0_ from user user0_
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
Hibernate: select messagefor0_.id as id1_2_, messagefor0_.classpath as classpat2_2_, messagefor0_.is_default_format as is_defau3_2_, messagefor0_.jar as jar4_2_, messagefor0_.name as name5_2_, messagefor0_.option_parameters as option_p6_2_ from message_format messagefor0_ where messagefor0_.name=?
Hibernate: select messagefor0_.id as id1_2_0_, messagefor0_.classpath as classpat2_2_0_, messagefor0_.is_default_format as is_defau3_2_0_, messagefor0_.jar as jar4_2_0_, messagefor0_.name as name5_2_0_, messagefor0_.option_parameters as option_p6_2_0_ from message_format messagefor0_ where messagefor0_.id=?
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.656 s - in org.sourcelab.kafka.webview.ui.ApplicationTest
2018-09-24 03:53:58.885  INFO 323 --- [      Thread-27] s.c.a.AnnotationConfigApplicationContext : Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@77f5cffd: startup date [Mon Sep 24 03:53:55 CEST 2018]; root of context hierarchy
2018-09-24 03:53:58.886  INFO 323 --- [      Thread-31] o.s.w.c.s.GenericWebApplicationContext   : Closing org.springframework.web.context.support.GenericWebApplicationContext@21d1a0da: startup date [Mon Sep 24 03:53:56 CEST 2018]; root of context hierarchy
2018-09-24 03:53:58.888  INFO 323 --- [       Thread-7] o.s.w.c.s.GenericWebApplicationContext   : Closing org.springframework.web.context.support.GenericWebApplicationContext@5b7a8434: startup date [Mon Sep 24 03:52:10 CEST 2018]; root of context hierarchy
2018-09-24 03:53:58.888  INFO 323 --- [      Thread-12] o.s.w.c.s.GenericWebApplicationContext   : Closing org.springframework.web.context.support.GenericWebApplicationContext@57d0c779: startup date [Mon Sep 24 03:52:34 CEST 2018]; root of context hierarchy
2018-09-24 03:53:58.891  INFO 323 --- [      Thread-12] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 2147483647
2018-09-24 03:53:58.893  INFO 323 --- [      Thread-27] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2018-09-24 03:53:58.891  INFO 323 --- [       Thread-7] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 2147483647
2018-09-24 03:53:58.892  INFO 323 --- [      Thread-31] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 2147483647
2018-09-24 03:53:58.897  INFO 323 --- [      Thread-31] o.s.m.s.b.SimpleBrokerMessageHandler     : Stopping...
2018-09-24 03:53:58.897  INFO 323 --- [      Thread-31] o.s.m.s.b.SimpleBrokerMessageHandler     : BrokerAvailabilityEvent[available=false, SimpleBrokerMessageHandler [DefaultSubscriptionRegistry[cache[0 destination(s)], registry[0 sessions]]]]
2018-09-24 03:53:58.897  INFO 323 --- [      Thread-31] o.s.m.s.b.SimpleBrokerMessageHandler     : Stopped.
2018-09-24 03:53:58.898  INFO 323 --- [      Thread-12] o.s.m.s.b.SimpleBrokerMessageHandler     : Stopping...
2018-09-24 03:53:58.898  INFO 323 --- [      Thread-12] o.s.m.s.b.SimpleBrokerMessageHandler     : BrokerAvailabilityEvent[available=false, SimpleBrokerMessageHandler [DefaultSubscriptionRegistry[cache[0 destination(s)], registry[0 sessions]]]]
2018-09-24 03:53:58.898  INFO 323 --- [      Thread-12] o.s.m.s.b.SimpleBrokerMessageHandler     : Stopped.
2018-09-24 03:53:58.898  INFO 323 --- [      Thread-31] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'brokerChannelExecutor'
2018-09-24 03:53:58.899  INFO 323 --- [       Thread-7] o.s.m.s.b.SimpleBrokerMessageHandler     : Stopping...
2018-09-24 03:53:58.899  INFO 323 --- [       Thread-7] o.s.m.s.b.SimpleBrokerMessageHandler     : BrokerAvailabilityEvent[available=false, SimpleBrokerMessageHandler [DefaultSubscriptionRegistry[cache[0 destination(s)], registry[0 sessions]]]]
2018-09-24 03:53:58.899  INFO 323 --- [       Thread-7] o.s.m.s.b.SimpleBrokerMessageHandler     : Stopped.
2018-09-24 03:53:58.900  INFO 323 --- [      Thread-31] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'messageBrokerTaskScheduler'
2018-09-24 03:53:58.900  INFO 323 --- [      Thread-12] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'backgroundConsumerExecutor'
2018-09-24 03:53:58.900  INFO 323 --- [       Thread-7] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'brokerChannelExecutor'
2018-09-24 03:53:58.900  INFO 323 --- [      Thread-12] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'brokerChannelExecutor'
2018-09-24 03:53:58.901  INFO 323 --- [       Thread-7] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'messageBrokerTaskScheduler'
2018-09-24 03:53:58.901  INFO 323 --- [      Thread-12] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'messageBrokerTaskScheduler'
2018-09-24 03:53:58.902  INFO 323 --- [      Thread-31] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'backgroundConsumerExecutor'
2018-09-24 03:53:58.905  INFO 323 --- [       Thread-7] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'backgroundConsumerExecutor'
2018-09-24 03:53:58.906  INFO 323 --- [      Thread-12] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'clientOutboundChannelExecutor'
2018-09-24 03:53:58.906  INFO 323 --- [      Thread-12] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'clientInboundChannelExecutor'
2018-09-24 03:53:58.906  INFO 323 --- [       Thread-7] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'clientOutboundChannelExecutor'
2018-09-24 03:53:58.906  INFO 323 --- [       Thread-7] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'clientInboundChannelExecutor'
2018-09-24 03:53:58.909  INFO 323 --- [      Thread-31] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'clientOutboundChannelExecutor'
2018-09-24 03:53:58.910  INFO 323 --- [      Thread-31] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'clientInboundChannelExecutor'
2018-09-24 03:53:58.912  INFO 323 --- [       Thread-7] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2018-09-24 03:53:58.918  INFO 323 --- [      Thread-31] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2018-09-24 03:53:58.922  WARN 323 --- [      Thread-31] o.s.b.f.support.DisposableBeanAdapter    : Invocation of destroy method failed on bean with name 'inMemoryDatabaseShutdownExecutor': org.h2.jdbc.JdbcSQLException: Database is already closed (to disable automatic closing at VM shutdown, add ";DB_CLOSE_ON_EXIT=FALSE" to the db URL) [90121-197]
2018-09-24 03:53:58.923  INFO 323 --- [      Thread-31] com.zaxxer.hikari.HikariDataSource       : HikariPool-3 - Shutdown initiated...
2018-09-24 03:53:58.923  INFO 323 --- [      Thread-12] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2018-09-24 03:53:58.939  INFO 323 --- [      Thread-31] com.zaxxer.hikari.HikariDataSource       : HikariPool-3 - Shutdown completed.
2018-09-24 03:53:58.940  WARN 323 --- [       Thread-7] o.s.b.f.support.DisposableBeanAdapter    : Invocation of destroy method failed on bean with name 'inMemoryDatabaseShutdownExecutor': org.h2.jdbc.JdbcSQLException: Database is already closed (to disable automatic closing at VM shutdown, add ";DB_CLOSE_ON_EXIT=FALSE" to the db URL) [90121-197]
2018-09-24 03:53:58.940  INFO 323 --- [       Thread-7] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2018-09-24 03:53:58.940  WARN 323 --- [      Thread-12] o.s.b.f.support.DisposableBeanAdapter    : Invocation of destroy method failed on bean with name 'inMemoryDatabaseShutdownExecutor': org.h2.jdbc.JdbcSQLException: The database has been closed [90098-197]
2018-09-24 03:53:58.940  INFO 323 --- [      Thread-12] com.zaxxer.hikari.HikariDataSource       : HikariPool-2 - Shutdown initiated...
2018-09-24 03:53:58.941  INFO 323 --- [       Thread-7] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
2018-09-24 03:53:58.944  INFO 323 --- [      Thread-12] com.zaxxer.hikari.HikariDataSource       : HikariPool-2 - Shutdown completed.
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Failures: 
[ERROR]   KafkaOperationsTest.testModifyingATopic:314 Should be set to default
[INFO] 
[ERROR] Tests run: 118, Failures: 1, Errors: 0, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Kafka WebView ...................................... SUCCESS [  3.487 s]
[INFO] Kafka WebView Plugin ............................... SUCCESS [  2.269 s]
[INFO] Kafka WebView UI ................................... FAILURE [01:55 min]
[INFO] Kafka Dev Cluster .................................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 02:02 min
[INFO] Finished at: 2018-09-24T03:53:59+02:00
[INFO] Final Memory: 49M/657M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.21.0:test (default-test) on project kafka-webview-ui: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/SourceLabOrg/kafka-webview/432293183/kafka-webview-ui/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :kafka-webview-ui
